<!DOCTYPE html><html lang="en">
<head>
    <title>Language-Based Audio Retrieval - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2024/task-language-based-audio-retrieval-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description Language-based audio retrieval is the task of retrieving audio signals using their sound content textual descriptions (i.e., audio captions). Human written audio captions are used as text queries. For each text query, the goal of this task is to retrieve 10 audio files from a given dataset â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right navbar-tighter" id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2024</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2024/"><i class="fa fa-home"></i>&nbsp;Intro</a>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-data-efficient-low-complexity-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-t1"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-data-efficient-low-complexity-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-data-efficient-low-complexity-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-t2"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-audio-and-audiovisual-sound-event-localization-and-detection-with-source-distance-estimation" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-t3"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-audio-and-audiovisual-sound-event-localization-and-detection-with-source-distance-estimation"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-audio-and-audiovisual-sound-event-localization-and-detection-with-source-distance-estimation-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-sound-event-detection-with-heterogeneous-training-dataset-and-potentially-missing-labels" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-t4"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-sound-event-detection-with-heterogeneous-training-dataset-and-potentially-missing-labels"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-sound-event-detection-with-heterogeneous-training-dataset-and-potentially-missing-labels-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-t5"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-automated-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-t6"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-automated-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-automated-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-sound-scene-synthesis" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthesis text-t7"></i>&nbsp;Task7&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-sound-scene-synthesis"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-sound-scene-synthesis-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2024/task-language-based-audio-retrieval" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-retrieval text-t8"></i>&nbsp;Task8&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-language-based-audio-retrieval"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2024/task-language-based-audio-retrieval-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-language-queried-audio-source-separation" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-separation text-t9"></i>&nbsp;Task9&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-language-queried-audio-source-separation"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-language-queried-audio-source-separation-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2024/task-acoustic-based-traffic-monitoring" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-traffic text-t10"></i>&nbsp;Task10&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2024/task-acoustic-based-traffic-monitoring"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2024/task-acoustic-based-traffic-monitoring-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2024/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2024/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/wave-02.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-t8"></i><i class="fa dc-retrieval fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Retrieval</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 8</span></span><img src="../images/logos/dcase/dcase2024_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Language-Based Audio Retrieval</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#overview-of-characteristics">Overview of characteristics</a></li>
<li><a href="#detailed-characteristics">Detailed characteristics</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>Language-based audio retrieval is the task of retrieving audio signals using their sound content textual descriptions (i.e., audio captions).
Human written audio captions are used as text queries.
For each text query, the goal of this task is to retrieve 10 audio files from a given dataset and sort them based their match with the query.
Through this subtask, we aim to inspire further research into language-based audio retrieval with unconstrained textual descriptions.</p>
<p>The Clotho v2 is provided as the development dataset, which includes both audio and corresponding captions.
Participants are also allowed using pre-trained models and external data for training their systems.
This includes pre-trained models for feature extraction from audio and/or captions, and pre-optimized methods for natural language processing like <em>part-of-speech (POS) tagging</em>.
Additionally, participants can use <strong>external audio and/or textual data</strong>, e.g., external text corpus for learning a language model or additional audio data like <em>AudioSet</em>, <em>Freesound</em>.</p>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2024/task-language-based-audio-retrieval">task description page</a></p>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Here are listed the best systems all from all teams.
The ranking is based on the achieved mAP@10 metric.
For more elaborated exploration of the performance of different systems, in the same table are listed the values achieved for all the metrics employed in the task.
The metric values are for the development-testing split and the evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="label" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="test_mAP10" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="4">Submission Information</th>
<th class="sep-left-cell text-center" colspan="4">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="4">Development-testing split</th>
</tr>
<tr>
<th data-field="label" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
              Best official <br/>system rank
            </th>
<th data-field="author" data-sortable="false">
              Corresponding author
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="test_mAP10" data-reversed="true" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="text-center" data-chartable="true" data-field="test_R1" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@1
            </th>
<th class="text-center" data-chartable="true" data-field="test_R5" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@5
            </th>
<th class="text-center" data-chartable="true" data-field="test_R10" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@10
            </th>
<th class="text-center sep-left-cell" data-chartable="true" data-field="eval_mAP10" data-reversed="true" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R1" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@1
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R5" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@5
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R10" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@10
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Primus_CP-JKU_8_1</td>
<td>1</td>
<td>Paul Primus</td>
<td>Primus2024_t8</td>
<td>0.416</td>
<td>0.307</td>
<td>0.563</td>
<td>0.686</td>
<td>0.419</td>
<td>0.293</td>
<td>0.593</td>
<td>0.719</td>
</tr>
<tr>
<td></td>
<td>Kulik_SRPOL_task8_4</td>
<td>2</td>
<td>Jan Kulik</td>
<td>Kulik2024_t8</td>
<td>0.403</td>
<td>0.292</td>
<td>0.546</td>
<td>0.663</td>
<td>0.437</td>
<td>0.314</td>
<td>0.601</td>
<td>0.733</td>
</tr>
<tr>
<td></td>
<td>Chen_SRCN_task8_1</td>
<td>3</td>
<td>Minjun Chen</td>
<td>Chen2024_t8</td>
<td>0.396</td>
<td>0.290</td>
<td>0.541</td>
<td>0.661</td>
<td>0.406</td>
<td>0.278</td>
<td>0.576</td>
<td>0.705</td>
</tr>
<tr>
<td></td>
<td>Munakata_LYVA_1</td>
<td>5</td>
<td>Hokuto Munakata</td>
<td>Munakata2024_t8</td>
<td>0.388</td>
<td>0.284</td>
<td>0.532</td>
<td>0.654</td>
<td>0.422</td>
<td>0.290</td>
<td>0.597</td>
<td>0.728</td>
</tr>
<tr>
<td></td>
<td>Kim_MAUM_task8_2</td>
<td>13</td>
<td>Jaeyeon Kim</td>
<td>Kim2024_t8</td>
<td>0.363</td>
<td>0.252</td>
<td>0.514</td>
<td>0.642</td>
<td>0.385</td>
<td>0.265</td>
<td>0.547</td>
<td>0.676</td>
</tr>
<tr>
<td></td>
<td>Cai_NCUT_task8_2</td>
<td>17</td>
<td>Xichang Cai</td>
<td>Cai2024_t8</td>
<td>0.259</td>
<td>0.162</td>
<td>0.391</td>
<td>0.513</td>
<td>0.296</td>
<td>0.186</td>
<td>0.444</td>
<td>0.577</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Xie_tau_task8_1</td>
<td>19</td>
<td>Huang Xie</td>
<td>Xie2024_t8</td>
<td>0.211</td>
<td>0.121</td>
<td>0.332</td>
<td>0.459</td>
<td>0.222</td>
<td>0.130</td>
<td>0.343</td>
<td>0.480</td>
</tr>
</tbody>
</table>
<h1 id="systems-ranking">Systems ranking</h1>
<p>Here are listed all systems and their ranking according to the different metrics.
Detailed information of each system is at the next section.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="test_mAP10" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="3">Submission Information</th>
<th class="sep-left-cell text-center" colspan="4">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="4">Development-testing split</th>
</tr>
<tr>
<th data-field="label" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
              Best official <br/>system rank
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="test_mAP10" data-reversed="true" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="text-center" data-chartable="true" data-field="test_R1" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@1
            </th>
<th class="text-center" data-chartable="true" data-field="test_R5" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@5
            </th>
<th class="text-center" data-chartable="true" data-field="test_R10" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@10
            </th>
<th class="text-center sep-left-cell" data-chartable="true" data-field="eval_mAP10" data-reversed="true" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R1" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@1
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R5" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@5
            </th>
<th class="text-center" data-chartable="true" data-field="eval_R10" data-reversed="true" data-sortable="true" data-value-type="float3">
              R@10
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Primus_CP-JKU_8_1</td>
<td>1</td>
<td>Primus2024_t8</td>
<td>0.416</td>
<td>0.307</td>
<td>0.563</td>
<td>0.686</td>
<td>0.419</td>
<td>0.293</td>
<td>0.593</td>
<td>0.719</td>
</tr>
<tr>
<td></td>
<td>Kulik_SRPOL_task8_4</td>
<td>2</td>
<td>Kulik2024_t8</td>
<td>0.403</td>
<td>0.292</td>
<td>0.546</td>
<td>0.663</td>
<td>0.437</td>
<td>0.314</td>
<td>0.601</td>
<td>0.733</td>
</tr>
<tr>
<td></td>
<td>Chen_SRCN_task8_1</td>
<td>3</td>
<td>Chen2024_t8</td>
<td>0.396</td>
<td>0.290</td>
<td>0.541</td>
<td>0.661</td>
<td>0.406</td>
<td>0.278</td>
<td>0.576</td>
<td>0.705</td>
</tr>
<tr>
<td></td>
<td>Primus_CP-JKU_8_4</td>
<td>4</td>
<td>Primus2024_t8</td>
<td>0.389</td>
<td>0.275</td>
<td>0.545</td>
<td>0.664</td>
<td>0.389</td>
<td>0.268</td>
<td>0.549</td>
<td>0.688</td>
</tr>
<tr>
<td></td>
<td>Munakata_LYVA_1</td>
<td>5</td>
<td>Munakata2024_t8</td>
<td>0.388</td>
<td>0.284</td>
<td>0.532</td>
<td>0.654</td>
<td>0.422</td>
<td>0.290</td>
<td>0.597</td>
<td>0.728</td>
</tr>
<tr>
<td></td>
<td>Munakata_LYVA_2</td>
<td>6</td>
<td>Munakata2024_t8</td>
<td>0.386</td>
<td>0.277</td>
<td>0.531</td>
<td>0.656</td>
<td>0.423</td>
<td>0.292</td>
<td>0.598</td>
<td>0.727</td>
</tr>
<tr>
<td></td>
<td>Kulik_SRPOL_task8_3</td>
<td>7</td>
<td>Kulik2024_t8</td>
<td>0.386</td>
<td>0.269</td>
<td>0.544</td>
<td>0.661</td>
<td>0.426</td>
<td>0.301</td>
<td>0.597</td>
<td>0.731</td>
</tr>
<tr>
<td></td>
<td>Kulik_SRPOL_task8_2</td>
<td>8</td>
<td>Kulik2024_t8</td>
<td>0.384</td>
<td>0.267</td>
<td>0.546</td>
<td>0.659</td>
<td>0.426</td>
<td>0.302</td>
<td>0.592</td>
<td>0.731</td>
</tr>
<tr>
<td></td>
<td>Primus_CP-JKU_8_1</td>
<td>9</td>
<td>Primus2024_t8</td>
<td>0.378</td>
<td>0.266</td>
<td>0.539</td>
<td>0.648</td>
<td>0.398</td>
<td>0.271</td>
<td>0.571</td>
<td>0.699</td>
</tr>
<tr>
<td></td>
<td>Primus_CP-JKU_8_3</td>
<td>10</td>
<td>Primus2024_t8</td>
<td>0.373</td>
<td>0.265</td>
<td>0.524</td>
<td>0.654</td>
<td>0.377</td>
<td>0.252</td>
<td>0.547</td>
<td>0.680</td>
</tr>
<tr>
<td></td>
<td>Kulik_SRPOL_task8_1</td>
<td>11</td>
<td>Kulik2024_t8</td>
<td>0.369</td>
<td>0.250</td>
<td>0.531</td>
<td>0.646</td>
<td>0.408</td>
<td>0.287</td>
<td>0.574</td>
<td>0.709</td>
</tr>
<tr>
<td></td>
<td>Chen_SRCN_task8_2</td>
<td>12</td>
<td>Chen2024_t8</td>
<td>0.364</td>
<td>0.254</td>
<td>0.521</td>
<td>0.627</td>
<td>0.370</td>
<td>0.244</td>
<td>0.534</td>
<td>0.662</td>
</tr>
<tr>
<td></td>
<td>Kim_MAUM_task8_2</td>
<td>13</td>
<td>Kim2024_t8</td>
<td>0.363</td>
<td>0.252</td>
<td>0.514</td>
<td>0.642</td>
<td>0.385</td>
<td>0.265</td>
<td>0.547</td>
<td>0.676</td>
</tr>
<tr>
<td></td>
<td>Kim_MAUM_task8_3</td>
<td>14</td>
<td>Kim2024_t8</td>
<td>0.362</td>
<td>0.246</td>
<td>0.516</td>
<td>0.643</td>
<td>0.386</td>
<td>0.267</td>
<td>0.547</td>
<td>0.680</td>
</tr>
<tr>
<td></td>
<td>Kim_MAUM_task8_4</td>
<td>15</td>
<td>Kim2024_t8</td>
<td>0.359</td>
<td>0.254</td>
<td>0.510</td>
<td>0.633</td>
<td>0.378</td>
<td>0.257</td>
<td>0.543</td>
<td>0.676</td>
</tr>
<tr>
<td></td>
<td>Kim_MAUM_task8_1</td>
<td>16</td>
<td>Kim2024_t8</td>
<td>0.350</td>
<td>0.236</td>
<td>0.499</td>
<td>0.630</td>
<td>0.375</td>
<td>0.256</td>
<td>0.535</td>
<td>0.669</td>
</tr>
<tr>
<td></td>
<td>Cai_NCUT_task8_2</td>
<td>17</td>
<td>Cai2024_t8</td>
<td>0.259</td>
<td>0.162</td>
<td>0.391</td>
<td>0.513</td>
<td>0.296</td>
<td>0.186</td>
<td>0.444</td>
<td>0.577</td>
</tr>
<tr>
<td></td>
<td>Cai_NCUT_task8_1</td>
<td>18</td>
<td>Cai2024_t8</td>
<td>0.255</td>
<td>0.159</td>
<td>0.383</td>
<td>0.520</td>
<td>0.292</td>
<td>0.180</td>
<td>0.440</td>
<td>0.576</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Xie_tau_task8_1</td>
<td>19</td>
<td>Xie2024_t8</td>
<td>0.211</td>
<td>0.121</td>
<td>0.332</td>
<td>0.459</td>
<td>0.222</td>
<td>0.130</td>
<td>0.343</td>
<td>0.480</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<p>In this section you can find the characteristics of the submitted systems.
There are two tables for easy reference, in the corresponding subsections.
The first table has an overview of the systems and the second has a detailed presentation of each system.</p>
<h2 id="overview-of-characteristics">Overview of characteristics</h2>
<table class="datatable table table-hover table-condensed" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="label" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="total_parameters" data-scatter-y="test_mAP10" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_sys_rank" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
            Rank
            </th>
<th class="sm-cell" data-field="label" data-sortable="true">
              Submission<br/>code
            </th>
<th class="text-center" data-chartable="true" data-field="test_mAP10" data-reversed="false" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="total_parameters" data-sortable="true" data-value-type="numeric-unit">
              Amount of parameters
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="audio_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Audio modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="text_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Text modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="loss_function" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Loss<br/>function
            </th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Primus_CP-JKU_8_1</td>
<td>0.416</td>
<td>Primus2024_t8</td>
<td>2596000000</td>
<td>PaSST, ATST, Dynamic MobileNet</td>
<td>BERT, RoBERTa</td>
<td>NT-Xent loss</td>
</tr>
<tr>
<td>2</td>
<td>Kulik_SRPOL_task8_4</td>
<td>0.403</td>
<td>Kulik2024_t8</td>
<td>1485700000</td>
<td>PaSST-S</td>
<td>GTE-large, RoBERTa-large</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>3</td>
<td>Chen_SRCN_task8_1</td>
<td>0.396</td>
<td>Chen2024_t8</td>
<td>10390000000</td>
<td>BEATs</td>
<td>BERT</td>
<td>Contrastive loss</td>
</tr>
<tr>
<td>4</td>
<td>Primus_CP-JKU_8_4</td>
<td>0.389</td>
<td>Primus2024_t8</td>
<td>453000000</td>
<td>ATST</td>
<td>RoBERTa</td>
<td>NT-Xent loss</td>
</tr>
<tr>
<td>5</td>
<td>Munakata_LYVA_1</td>
<td>0.388</td>
<td>Munakata2024_t8</td>
<td>2680000000</td>
<td>PaSST, VAST, BEATs, CAV-MAE</td>
<td>RoBERTa</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>6</td>
<td>Munakata_LYVA_2</td>
<td>0.386</td>
<td>Munakata2024_t8</td>
<td>2240000000</td>
<td>PaSST, VAST</td>
<td>RoBERTa</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>7</td>
<td>Kulik_SRPOL_task8_3</td>
<td>0.386</td>
<td>Kulik2024_t8</td>
<td>3855200000</td>
<td>PaSST-S</td>
<td>GTE-large, RoBERTa-large</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>8</td>
<td>Kulik_SRPOL_task8_2</td>
<td>0.384</td>
<td>Kulik2024_t8</td>
<td>1485700000</td>
<td>PaSST-S</td>
<td>GTE-large, RoBERTa-large</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>9</td>
<td>Primus_CP-JKU_8_1</td>
<td>0.378</td>
<td>Primus2024_t8</td>
<td>442000000</td>
<td>PaSST</td>
<td>RoBERTa</td>
<td>NT-Xent loss</td>
</tr>
<tr>
<td>10</td>
<td>Primus_CP-JKU_8_3</td>
<td>0.373</td>
<td>Primus2024_t8</td>
<td>430000000</td>
<td>Dynamic MobileNet</td>
<td>RoBERTa</td>
<td>NT-Xent loss</td>
</tr>
<tr>
<td>11</td>
<td>Kulik_SRPOL_task8_1</td>
<td>0.369</td>
<td>Kulik2024_t8</td>
<td>521900000</td>
<td>PaSST-S</td>
<td>GTE-large</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>12</td>
<td>Chen_SRCN_task8_2</td>
<td>0.364</td>
<td>Chen2024_t8</td>
<td>230000000</td>
<td>BEATs</td>
<td>BERT</td>
<td>Contrastive loss</td>
</tr>
<tr>
<td>13</td>
<td>Kim_MAUM_task8_2</td>
<td>0.363</td>
<td>Kim2024_t8</td>
<td>1131908653</td>
<td>ConvNeXt-Tiny</td>
<td>BERT, RoBERTa, BGE</td>
<td>m-LTM</td>
</tr>
<tr>
<td>14</td>
<td>Kim_MAUM_task8_3</td>
<td>0.362</td>
<td>Kim2024_t8</td>
<td>1581588058</td>
<td>ConvNeXt-Tiny</td>
<td>BERT, RoBERTa, BGE</td>
<td>m-LTM</td>
</tr>
<tr>
<td>15</td>
<td>Kim_MAUM_task8_4</td>
<td>0.359</td>
<td>Kim2024_t8</td>
<td>3163176116</td>
<td>ConvNeXt-Tiny</td>
<td>BERT, RoBERTa, BGE</td>
<td>m-LTM</td>
</tr>
<tr>
<td>16</td>
<td>Kim_MAUM_task8_1</td>
<td>0.350</td>
<td>Kim2024_t8</td>
<td>390781455</td>
<td>ConvNeXt-Tiny</td>
<td>RoBERTa</td>
<td>m-LTM</td>
</tr>
<tr>
<td>17</td>
<td>Cai_NCUT_task8_2</td>
<td>0.259</td>
<td>Cai2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14, BEATs</td>
<td>RoBERTa</td>
<td>InfoNCE loss</td>
</tr>
<tr>
<td>18</td>
<td>Cai_NCUT_task8_1</td>
<td>0.255</td>
<td>Cai2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14, BEATs</td>
<td>RoBERTa</td>
<td>InfoNCE loss</td>
</tr>
<tr class="info" data-hline="true">
<td>19</td>
<td>Xie_tau_task8_1</td>
<td>0.211</td>
<td>Xie2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14</td>
<td>Sentece-BERT</td>
<td>InfoNCE loss</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="detailed-characteristics">Detailed characteristics</h2>
<table class="datatable table table-hover table-condensed" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="label" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="total_parameters" data-scatter-y="test_mAP10" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_sys_rank" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
            Rank
            </th>
<th class="sm-cell" data-field="label" data-sortable="true">
              Submission<br/>code
            </th>
<th class="text-center" data-chartable="true" data-field="test_mAP10" data-reversed="false" data-sortable="true" data-value-type="float3">
              mAP@10
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="total_parameters" data-sortable="true" data-value-type="numeric-unit">
              Amount of parameters
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="audio_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Audio modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="acoustic_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Acoustic<br/>features
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="text_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Text modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="audio_aug" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Audio<br/>augmentation
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="text_aug" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Text<br/>augmentation
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="input_sr" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="loss_function" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Loss function
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="optimizer" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Optimizer
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="metric_monitored" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Metric monitored for training
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="training_datasets" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Dataset(s) used for training
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="validation_datasets" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Dataset(s) used for validation
            </th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Primus_CP-JKU_8_1</td>
<td>0.416</td>
<td>Primus2024_t8</td>
<td>2596000000</td>
<td>PaSST, ATST, Dynamic MobileNet</td>
<td>log-mel energies</td>
<td>BERT, RoBERTa</td>
<td>patchout, frequency warping</td>
<td>synonym replacement, random deletions</td>
<td>32.0kHz</td>
<td>NT-Xent loss</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WaveCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>2</td>
<td>Kulik_SRPOL_task8_4</td>
<td>0.403</td>
<td>Kulik2024_t8</td>
<td>1485700000</td>
<td>PaSST-S</td>
<td>log-mel energies</td>
<td>GTE-large, RoBERTa-large</td>
<td>mixing, time and frequency masking, patchout</td>
<td>random deletion, synonym replacement, back-translation, LLM mixing, LLM rephrasing</td>
<td>32kHz</td>
<td>InfoNCE loss</td>
<td>AdamW</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, VideoCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>3</td>
<td>Chen_SRCN_task8_1</td>
<td>0.396</td>
<td>Chen2024_t8</td>
<td>10390000000</td>
<td>BEATs</td>
<td>log-mel energies</td>
<td>BERT</td>
<td>mixup</td>
<td>mixup</td>
<td>16kHz</td>
<td>Contrastive loss</td>
<td>adamw</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, FSD50K, Laion630k, LASS validation (synth) set</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>4</td>
<td>Primus_CP-JKU_8_4</td>
<td>0.389</td>
<td>Primus2024_t8</td>
<td>453000000</td>
<td>ATST</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>frequency warping</td>
<td>synonym replacement, random deletions</td>
<td>32.0kHz</td>
<td>NT-Xent loss</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WaveCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>5</td>
<td>Munakata_LYVA_1</td>
<td>0.388</td>
<td>Munakata2024_t8</td>
<td>2680000000</td>
<td>PaSST, VAST, BEATs, CAV-MAE</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>SpecAugment, Patchout, Mix-up Contrast</td>
<td>Text token masking, GPT augmentation</td>
<td>32kHz, 16kHz</td>
<td>InfoNCE loss</td>
<td>Adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, MACS, Auto-ACD-VS</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>6</td>
<td>Munakata_LYVA_2</td>
<td>0.386</td>
<td>Munakata2024_t8</td>
<td>2240000000</td>
<td>PaSST, VAST</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>SpecAugment, Patchout, Mix-up Contrast</td>
<td>Text token masking, GPT augmentation</td>
<td>32kHz, 16kHz</td>
<td>InfoNCE loss</td>
<td>Adam, AdamW</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, MACS, Auto-ACD-VS</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>7</td>
<td>Kulik_SRPOL_task8_3</td>
<td>0.386</td>
<td>Kulik2024_t8</td>
<td>3855200000</td>
<td>PaSST-S</td>
<td>log-mel energies</td>
<td>GTE-large, RoBERTa-large</td>
<td>mixing, time and frequency masking, patchout</td>
<td>random deletion, synonym replacement, back-translation, LLM mixing, LLM rephrasing</td>
<td>32kHz</td>
<td>InfoNCE loss</td>
<td>AdamW</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, VideoCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>8</td>
<td>Kulik_SRPOL_task8_2</td>
<td>0.384</td>
<td>Kulik2024_t8</td>
<td>1485700000</td>
<td>PaSST-S</td>
<td>log-mel energies</td>
<td>GTE-large, RoBERTa-large</td>
<td>mixing, time and frequency masking, patchout</td>
<td>random deletion, synonym replacement, back-translation, LLM mixing, LLM rephrasing</td>
<td>32kHz</td>
<td>InfoNCE loss</td>
<td>AdamW</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, VideoCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>9</td>
<td>Primus_CP-JKU_8_1</td>
<td>0.378</td>
<td>Primus2024_t8</td>
<td>442000000</td>
<td>PaSST</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>patchout</td>
<td>synonym replacement, random deletions</td>
<td>32.0kHz</td>
<td>NT-Xent loss</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WaveCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>10</td>
<td>Primus_CP-JKU_8_3</td>
<td>0.373</td>
<td>Primus2024_t8</td>
<td>430000000</td>
<td>Dynamic MobileNet</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>None</td>
<td>synonym replacement, random deletions</td>
<td>32.0kHz</td>
<td>NT-Xent loss</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WaveCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>11</td>
<td>Kulik_SRPOL_task8_1</td>
<td>0.369</td>
<td>Kulik2024_t8</td>
<td>521900000</td>
<td>PaSST-S</td>
<td>log-mel energies</td>
<td>GTE-large</td>
<td>mixing, time and frequency masking, patchout</td>
<td>random deletion, synonym replacement, back-translation, LLM mixing, LLM rephrasing</td>
<td>32kHz</td>
<td>InfoNCE loss</td>
<td>AdamW</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, VideoCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>12</td>
<td>Chen_SRCN_task8_2</td>
<td>0.364</td>
<td>Chen2024_t8</td>
<td>230000000</td>
<td>BEATs</td>
<td>log-mel energies</td>
<td>BERT</td>
<td>mixup</td>
<td>mixup</td>
<td>16kHz</td>
<td>Contrastive loss</td>
<td>adamw</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps, FSD50K, Laion630k, LASS validation (synth) set</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>13</td>
<td>Kim_MAUM_task8_2</td>
<td>0.363</td>
<td>Kim2024_t8</td>
<td>1131908653</td>
<td>ConvNeXt-Tiny</td>
<td>log-mel energies</td>
<td>BERT, RoBERTa, BGE</td>
<td>SpecAugment</td>
<td></td>
<td>32kHz</td>
<td>m-LTM</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>14</td>
<td>Kim_MAUM_task8_3</td>
<td>0.362</td>
<td>Kim2024_t8</td>
<td>1581588058</td>
<td>ConvNeXt-Tiny</td>
<td>log-mel energies</td>
<td>BERT, RoBERTa, BGE</td>
<td>SpecAugment</td>
<td></td>
<td>32kHz</td>
<td>m-LTM</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>15</td>
<td>Kim_MAUM_task8_4</td>
<td>0.359</td>
<td>Kim2024_t8</td>
<td>3163176116</td>
<td>ConvNeXt-Tiny</td>
<td>log-mel energies</td>
<td>BERT, RoBERTa, BGE</td>
<td>SpecAugment</td>
<td></td>
<td>32kHz</td>
<td>m-LTM</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>16</td>
<td>Kim_MAUM_task8_1</td>
<td>0.350</td>
<td>Kim2024_t8</td>
<td>390781455</td>
<td>ConvNeXt-Tiny</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>SpecAugment</td>
<td></td>
<td>32kHz</td>
<td>m-LTM</td>
<td>adam</td>
<td>mAP</td>
<td>Clotho-development, AudioCaps, WavCaps</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>17</td>
<td>Cai_NCUT_task8_2</td>
<td>0.259</td>
<td>Cai2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14, BEATs</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>Mixup</td>
<td>ChatGPT</td>
<td>44.1kHz</td>
<td>InfoNCE loss</td>
<td>adam</td>
<td>loss</td>
<td>Clotho-development, AudioCaps-train</td>
<td>Clotho-validation</td>
</tr>
<tr>
<td>18</td>
<td>Cai_NCUT_task8_1</td>
<td>0.255</td>
<td>Cai2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14, BEATs</td>
<td>log-mel energies</td>
<td>RoBERTa</td>
<td>Mixup</td>
<td>ChatGPT</td>
<td>44.1kHz</td>
<td>InfoNCE loss</td>
<td>adam</td>
<td>loss</td>
<td>Clotho-development, AudioCaps-train</td>
<td>Clotho-validation</td>
</tr>
<tr class="info" data-hline="true">
<td>19</td>
<td>Xie_tau_task8_1</td>
<td>0.211</td>
<td>Xie2024_t8</td>
<td>160771192</td>
<td>PANNs-CNN14</td>
<td>log-mel energies</td>
<td>Sentece-BERT</td>
<td></td>
<td></td>
<td>44.1kHz</td>
<td>InfoNCE loss</td>
<td>adam</td>
<td>loss</td>
<td>Clotho-development</td>
<td>Clotho-validation</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2024/technical_reports_task8.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Cai2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Cai2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        ENSEMBLE SYSTEMS WITH PRETRAINED DUAL-ENCODERS FOR LANGUAGE-BASED AUDIO RETRIEVAL
       </h4>
<p style="text-align:left">
        Jiafeng Li, Xichang Cai, Shenghao Liu, Liangxiao Zuo, Menglong Wu
       </p>
<p style="text-align:left">
<em>
         North China University of Technology, Beijing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Cai_NCUT_task8_1</span> <span class="label label-primary">Cai_NCUT_task8_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Cai2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Cai2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Cai2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Cai_30_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Cai2024_t8" class="panel-collapse collapse" id="collapse-Cai2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       ENSEMBLE SYSTEMS WITH PRETRAINED DUAL-ENCODERS FOR LANGUAGE-BASED AUDIO RETRIEVAL
      </h4>
<p style="text-align:left">
<small>
        Jiafeng Li, Xichang Cai, Shenghao Liu, Liangxiao Zuo, Menglong Wu
       </small>
<br/>
<small>
<em>
         North China University of Technology, Beijing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This article presents our system developed for Task 8 of the DCASE2024 Challenge, which focuses on audio retrieval using natural language queries. Our submission incorporates a retrieval system that integrates a frozen pre-trained audio encoder and RoBERT as a text encoder. We adopted a methodology similar to the CLAP framework, training our model using paired data from the AudioCaps and Clotho datasets. Our best-performing system achieved a mean Average Precision (mAP) of 29.6% and a Recall at 1 (R@1) of 18.6% on the Clotho evaluation set.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Cai2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Cai_30_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Cai2024_t8label" class="modal fade" id="bibtex-Cai2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexCai2024_t8label">
        ENSEMBLE SYSTEMS WITH PRETRAINED DUAL-ENCODERS FOR LANGUAGE-BASED AUDIO RETRIEVAL
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Cai2024_t8,
    Author = "Li, Jiafeng and Cai, Xichang and Liu, Shenghao and Zuo, Liangxiao and Wu, Menglong",
    title = "ENSEMBLE SYSTEMS WITH PRETRAINED DUAL-ENCODERS FOR LANGUAGE-BASED AUDIO RETRIEVAL",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "This article presents our system developed for Task 8 of the DCASE2024 Challenge, which focuses on audio retrieval using natural language queries. Our submission incorporates a retrieval system that integrates a frozen pre-trained audio encoder and RoBERT as a text encoder. We adopted a methodology similar to the CLAP framework, training our model using paired data from the AudioCaps and Clotho datasets. Our best-performing system achieved a mean Average Precision (mAP) of 29.6\% and a Recall at 1 (R@1) of 18.6\% on the Clotho evaluation set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Chen2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Chen2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2024 CHALLENGE TASK 8 TECHNICAL REPORT
       </h4>
<p style="text-align:left">
        Minjun Chen, Yangyang Liu, Bo Peng, Jie Chen
       </p>
<p style="text-align:left">
<em>
         Samsung Research China-Nanjing, Nanjing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Chen_SRCN_task8_1</span> <span class="label label-primary">Chen_SRCN_task8_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Chen2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Chen2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Chen2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Chen_39_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Chen2024_t8" class="panel-collapse collapse" id="collapse-Chen2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2024 CHALLENGE TASK 8 TECHNICAL REPORT
      </h4>
<p style="text-align:left">
<small>
        Minjun Chen, Yangyang Liu, Bo Peng, Jie Chen
       </small>
<br/>
<small>
<em>
         Samsung Research China-Nanjing, Nanjing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We describe our submitted systems for DCASE2024 Task 8 in this technical report: Language-based Audio Retrieval. Our proposed system focus on training audio encoder and text encoder combined to get expressive audio and text presentation, which helps distinguishing different audios and text more efficiently. We use pre-trained audio and text encoder of VAST, which were trained on a large multi-modality dataset VAST27M. We train these encoders on several audio caption datasets, include AudioCaps, WavCaps, FSD50K, Laion630k, and ClothoV2 furtherly with three learning objectives, except the audio-text contractive objective, we also use audio-text match and masked language model objective to strengthen the training procedure. We use the mix-up as the data augment policy during pre-training. Our proposed systems achieve 0.37 mAP@10, and 0.244 R@1, with model ensemble, our systems achieve 0.406 mAP@10, and 0.278 R@1 on the ClothoV2 evaluation set.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Chen2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Chen_39_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Chen2024_t8label" class="modal fade" id="bibtex-Chen2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChen2024_t8label">
        DCASE 2024 CHALLENGE TASK 8 TECHNICAL REPORT
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Chen2024_t8,
    Author = "Chen, Minjun and Liu, Yangyang and Peng, Bo and Chen, Jie",
    title = "DCASE 2024 CHALLENGE TASK 8 TECHNICAL REPORT",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "We describe our submitted systems for DCASE2024 Task 8 in this technical report: Language-based Audio Retrieval. Our proposed system focus on training audio encoder and text encoder combined to get expressive audio and text presentation, which helps distinguishing different audios and text more efficiently. We use pre-trained audio and text encoder of VAST, which were trained on a large multi-modality dataset VAST27M. We train these encoders on several audio caption datasets, include AudioCaps, WavCaps, FSD50K, Laion630k, and ClothoV2 furtherly with three learning objectives, except the audio-text contractive objective, we also use audio-text match and masked language model objective to strengthen the training procedure. We use the mix-up as the data augment policy during pre-training. Our proposed systems achieve 0.37 mAP@10, and 0.244 R@1, with model ensemble, our systems achieve 0.406 mAP@10, and 0.278 R@1 on the ClothoV2 evaluation set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kim2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Kim2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        EXPANDING ON ENCLAP WITH AUXILIARY RETRIEVAL MODEL FOR AUTOMATED AUDIO CAPTIONING
       </h4>
<p style="text-align:left">
        Jaeyeon Kim, Jaeyoon Jung, Minjeong Jeon, Sang Hoon Woo, Jinjoo Lee
       </p>
<p style="text-align:left">
<em>
         Seoul National Unversity, MAUM AI Inc., Soongsil University, Independent Researcher
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kim_MAUM_task8_1</span> <span class="label label-primary">Kim_MAUM_task8_2</span> <span class="label label-primary">Kim_MAUM_task8_3</span> <span class="label label-primary">Kim_MAUM_task8_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kim2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kim2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kim2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Kim_108_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kim2024_t8" class="panel-collapse collapse" id="collapse-Kim2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       EXPANDING ON ENCLAP WITH AUXILIARY RETRIEVAL MODEL FOR AUTOMATED AUDIO CAPTIONING
      </h4>
<p style="text-align:left">
<small>
        Jaeyeon Kim, Jaeyoon Jung, Minjeong Jeon, Sang Hoon Woo, Jinjoo Lee
       </small>
<br/>
<small>
<em>
         Seoul National Unversity, MAUM AI Inc., Soongsil University, Independent Researcher
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our submission to DCASE2024 Challenge Task6 (Automated Audio Captioning) and Task8 (Language-based Audio Retrieval). We develop our approach building upon the EnCLAP audio captioning framework and optimizing it for Task6 of the challenge. Notably, we outline the changes in the underlying components and the incorporation of the reranking process. Additionally, we submit a supplementary retriever model, a byproduct of our modified framework, to Task8. Our proposed systems achieve FENSE score of 0.542 on Task6 and mAP@10 score of 0.386 on Task8, significantly outperforming the baseline models.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kim2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Kim_108_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kim2024_t8label" class="modal fade" id="bibtex-Kim2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKim2024_t8label">
        EXPANDING ON ENCLAP WITH AUXILIARY RETRIEVAL MODEL FOR AUTOMATED AUDIO CAPTIONING
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kim2024_t8,
    Author = "Kim, Jaeyeon and Jung, Jaeyoon and Jeon, Minjeong and Woo, Sang Hoon and Lee, Jinjoo",
    title = "EXPANDING ON ENCLAP WITH AUXILIARY RETRIEVAL MODEL FOR AUTOMATED AUDIO CAPTIONING",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "In this technical report, we describe our submission to DCASE2024 Challenge Task6 (Automated Audio Captioning) and Task8 (Language-based Audio Retrieval). We develop our approach building upon the EnCLAP audio captioning framework and optimizing it for Task6 of the challenge. Notably, we outline the changes in the underlying components and the incorporation of the reranking process. Additionally, we submit a supplementary retriever model, a byproduct of our modified framework, to Task8. Our proposed systems achieve FENSE score of 0.542 on Task6 and mAP@10 score of 0.386 on Task8, significantly outperforming the baseline models."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kulik2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Kulik2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        TAKE IT FOR GRANTED: IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL WITH LARGE LANGUAGE MODELS
       </h4>
<p style="text-align:left">
        Jan Kulik, Bartlomiej Zgorzynski, Juliusz Kruk, Ivan Ryzhankow, Anna Ples, Theodore Lamort de Gail
       </p>
<p style="text-align:left">
<em>
         Samsung R&amp;D Institute Poland, Warsaw, Poland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">kulik_SRPOL_task8_1</span> <span class="label label-primary">kulik_SRPOL_task8_2</span> <span class="label label-primary">kulik_SRPOL_task8_3</span> <span class="label label-primary">kulik_SRPOL_task8_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kulik2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kulik2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kulik2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Kulik_91_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kulik2024_t8" class="panel-collapse collapse" id="collapse-Kulik2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       TAKE IT FOR GRANTED: IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL WITH LARGE LANGUAGE MODELS
      </h4>
<p style="text-align:left">
<small>
        Jan Kulik, Bartlomiej Zgorzynski, Juliusz Kruk, Ivan Ryzhankow, Anna Ples, Theodore Lamort de Gail
       </small>
<br/>
<small>
<em>
         Samsung R&amp;D Institute Poland, Warsaw, Poland
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we present our solution to DCASE 2024 task 8: Language-Based Audio Retrieval. We employ a bi-encoder architecture trained using InfoNCE loss. The audio encoder is a pretrained PaSST-S model, while the text encoder is either a pre-trained GTE-large or RoBERTa-large model. In order to increase the amount of training data, we obtain 10.8 million video-caption pairs from various open-source datasets. We then extract useful audio-caption pairs and evaluate them using our model to filter out low-quality samples. Finally, we use GPT-4o to rephrase the video captions to make them more audio-oriented. In addition, we use GPT-4o for back-translation and GPT-3.5-turbo for Clotho caption mixing. We achieve 43.69% mAP@10 on the development-testing split of Clotho using an ensemble solution, and 40.78% mAP@10 with a single model.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kulik2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Kulik_91_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kulik2024_t8label" class="modal fade" id="bibtex-Kulik2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKulik2024_t8label">
        TAKE IT FOR GRANTED: IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL WITH LARGE LANGUAGE MODELS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kulik2024_t8,
    Author = "Kulik, Jan and Zgorzynski, Bartlomiej and Kruk, Juliusz and Ryzhankow, Ivan and Ples, Anna and de Gail, Theodore Lamort",
    title = "TAKE IT FOR GRANTED: IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL WITH LARGE LANGUAGE MODELS",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "In this report, we present our solution to DCASE 2024 task 8: Language-Based Audio Retrieval. We employ a bi-encoder architecture trained using InfoNCE loss. The audio encoder is a pretrained PaSST-S model, while the text encoder is either a pre-trained GTE-large or RoBERTa-large model. In order to increase the amount of training data, we obtain 10.8 million video-caption pairs from various open-source datasets. We then extract useful audio-caption pairs and evaluate them using our model to filter out low-quality samples. Finally, we use GPT-4o to rephrase the video captions to make them more audio-oriented. In addition, we use GPT-4o for back-translation and GPT-3.5-turbo for Clotho caption mixing. We achieve 43.69\% mAP@10 on the development-testing split of Clotho using an ensemble solution, and 40.78\% mAP@10 with a single model."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Munakata2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Munakata2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        TRAINING STRATEGY OF MASSIVE TEXT-TO-AUDIO MODELS AND GPT-BASED QUERY-AUGMENTATION
       </h4>
<p style="text-align:left">
        Hokuto Munakata, Taichi Nishimura, Shota Nakada, Tatsuya Komatsu
       </p>
<p style="text-align:left">
<em>
         LY Corporation, Japan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Munakata_LYVA_1</span> <span class="label label-primary">Munakata_LYVA_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Munakata2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Munakata2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Munakata2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Munakata_45_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Munakata2024_t8" class="panel-collapse collapse" id="collapse-Munakata2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       TRAINING STRATEGY OF MASSIVE TEXT-TO-AUDIO MODELS AND GPT-BASED QUERY-AUGMENTATION
      </h4>
<p style="text-align:left">
<small>
        Hokuto Munakata, Taichi Nishimura, Shota Nakada, Tatsuya Komatsu
       </small>
<br/>
<small>
<em>
         LY Corporation, Japan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our system submitted to the DCASE 2024 Task 8: Language-based Audio Retrieval. We adopted a conventional language-based audio retrieval approach, leveraging a joint embedding space for the audio and text encoders trained through contrastive learning. We compared and utilized several state-ofthe-art models for the audio encoder, including PaSST, BEATs, VAST, and CAV-MAE. We also employed various datasets with text-audio pairs for training like AudioCaps, WavCaps, Auto-ACD, and MACS. Additionally, we incorporated advanced training techniques such as Mixco and text token masking. During inference, we devised an ensemble method based on queries augmented by ChatGPT. Our final results achieved 39.65 points with a single model and 42.26 points with the ensemble of multiple models in the mean average precision among the top 10 results on the evaluation split of Clotho-V2. Compared with the champion system of the DCASE 2023 Challenge, our model outperformed by 1.09 points for the single mode and 0.84 points for the ensemble of the multiple models, respectively.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Munakata2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Munakata_45_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Munakata2024_t8label" class="modal fade" id="bibtex-Munakata2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexMunakata2024_t8label">
        TRAINING STRATEGY OF MASSIVE TEXT-TO-AUDIO MODELS AND GPT-BASED QUERY-AUGMENTATION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Munakata2024_t8,
    Author = "Munakata, Hokuto and Nishimura, Taichi and Nakada, Shota and Komatsu, Tatsuya",
    title = "TRAINING STRATEGY OF MASSIVE TEXT-TO-AUDIO MODELS AND GPT-BASED QUERY-AUGMENTATION",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "This report describes our system submitted to the DCASE 2024 Task 8: Language-based Audio Retrieval. We adopted a conventional language-based audio retrieval approach, leveraging a joint embedding space for the audio and text encoders trained through contrastive learning. We compared and utilized several state-ofthe-art models for the audio encoder, including PaSST, BEATs, VAST, and CAV-MAE. We also employed various datasets with text-audio pairs for training like AudioCaps, WavCaps, Auto-ACD, and MACS. Additionally, we incorporated advanced training techniques such as Mixco and text token masking. During inference, we devised an ensemble method based on queries augmented by ChatGPT. Our final results achieved 39.65 points with a single model and 42.26 points with the ensemble of multiple models in the mean average precision among the top 10 results on the evaluation split of Clotho-V2. Compared with the champion system of the DCASE 2023 Challenge, our model outperformed by 1.09 points for the single mode and 0.84 points for the ensemble of the multiple models, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Primus2024_t8" style="box-shadow: none">
<div class="panel-heading" id="heading-Primus2024_t8" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        A KNOWLEDGE DISTILLATION APPROACH TO IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL MODELS
       </h4>
<p style="text-align:left">
        Paul Primus, Gerhard Widmer
       </p>
<p style="text-align:left">
<em>
         Institute of Computational Perception (CP-JKU), LIT Artificial Intelligence Lab, Johannes Kepler University, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Primus_CP-JKU_task8_1</span> <span class="label label-primary">Primus_CP-JKU_task8_2</span> <span class="label label-primary">Primus_CP-JKU_task8_3</span> <span class="label label-primary">Primus_CP-JKU_task8_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Primus2024_t8" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Primus2024_t8" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Primus2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Primus_76_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Primus2024_t8" class="panel-collapse collapse" id="collapse-Primus2024_t8" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       A KNOWLEDGE DISTILLATION APPROACH TO IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL MODELS
      </h4>
<p style="text-align:left">
<small>
        Paul Primus, Gerhard Widmer
       </small>
<br/>
<small>
<em>
         Institute of Computational Perception (CP-JKU), LIT Artificial Intelligence Lab, Johannes Kepler University, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the CP-JKU teamâ€™s submissions to the language-based audio retrieval task of the 2024 DCASE Challenge (Task 8). All our submitted systems are based on the dual encoder architecture that projects recordings and textual descriptions into a shared audio-caption space in which related examples from the two modalities are similar. We utilized pretrained audio and text embedding models and trained them on audio-caption datasets (WavCaps, AudioCaps, and ClothoV2) via contrastive learning. We further fine-tuned the resulting models on ClothoV2 via knowledge distillation from a large ensemble of audio retrieval models. Our best single system submission based on PaSST and RoBERTa achieves a mAP@10 of 39.77 on the ClothoV2 test split, outperforming last yearâ€™s best single system submission by around 1pp. without utilizing metadata and synthetic captions. An ensemble of three distilled models achieves 41.91 mAP@10 on the ClothoV2 test split.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Primus2024_t8" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2024/technical_reports/DCASE2024_Primus_76_t8.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Primus2024_t8label" class="modal fade" id="bibtex-Primus2024_t8" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPrimus2024_t8label">
        A KNOWLEDGE DISTILLATION APPROACH TO IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL MODELS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Primus2024_t8,
    Author = "Primus, Paul and Widmer, Gerhard",
    title = "A KNOWLEDGE DISTILLATION APPROACH TO IMPROVING LANGUAGE-BASED AUDIO RETRIEVAL MODELS",
    institution = "DCASE2024 Challenge",
    year = "2024",
    month = "June",
    abstract = "This technical report describes the CP-JKU teamâ€™s submissions to the language-based audio retrieval task of the 2024 DCASE Challenge (Task 8). All our submitted systems are based on the dual encoder architecture that projects recordings and textual descriptions into a shared audio-caption space in which related examples from the two modalities are similar. We utilized pretrained audio and text embedding models and trained them on audio-caption datasets (WavCaps, AudioCaps, and ClothoV2) via contrastive learning. We further fine-tuned the resulting models on ClothoV2 via knowledge distillation from a large ensemble of audio retrieval models. Our best single system submission based on PaSST and RoBERTa achieves a mAP@10 of 39.77 on the ClothoV2 test split, outperforming last yearâ€™s best single system submission by around 1pp. without utilizing metadata and synthetic captions. An ensemble of three distilled models achieves 41.91 mAP@10 on the ClothoV2 test split."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>