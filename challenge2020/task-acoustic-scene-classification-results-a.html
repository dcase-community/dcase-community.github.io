<!DOCTYPE html><html lang="en">
<head>
    <title>Acoustic Scene Classification with Multiple Devices - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2020/task-acoustic-scene-classification-results-a">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description This subtask is concerned with the classification of data from multiple devices (real and simulated) targeting the generalization properties of systems across a number of different devices. The development dataset consists of recordings from 10 European cities using 9 different devices: 3 real devices (A, B, C) and …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2020</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2020/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group  active">
        <a href="/challenge2020/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class=" active">
        <a href="/challenge2020/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-urban text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2020/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2020/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge awards">
        <a href="/challenge2020/awards"><i class="fa fa-trophy"></i>&nbsp;Awards</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/grid-08.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-primary"></i><strong class="fa-stack-1x icon-text">A</strong><strong class="fa-stack-1x dcase-icon-top-text">Devices</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 1</span></span><img src="../images/logos/dcase/dcase2020_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Acoustic Scene Classification <br>with Multiple Devices</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#generalization-performance">Generalization performance</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a></li>
<li><a href="#device-wise-performance">Device-wise performance</a></li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#general-characteristics">General characteristics</a></li>
<li><a href="#machine-learning-characteristics">Machine learning characteristics</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>This subtask is concerned with the classification of data from multiple devices (real and simulated) targeting 
the generalization properties of systems across a number of different devices. </p>
<p>The development dataset consists of recordings from 10 European cities using 9 different devices: 3 real devices (A, B, C) and 6 simulated devices (S1-S6). Data from devices B, C, and S1-S6 consists of randomly selected segments from the simultaneous recordings, therefore all overlap with the data from device A, but not necessarily with each other. The total amount of audio in the development set is 64 hours. </p>
<p>The evaluation dataset contains data from 12 cities, 10 acoustic scenes, 11 devices. There are five new devices (not available in the development set): real device D and simulated devices S7-S11. Evaluation data contains 33 hours of audio. </p>
<p>The device A consists in a Soundman OKM II Klassik/studio A3, electret binaural microphone and a Zoom F8 audio recorder using 48kHz sampling rate and 24-bit resolution. The other devices are commonly available customer devices: device B is a Samsung Galaxy S7, device C is iPhone SE, and device D is a GoPro Hero5 Session. </p>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2020/task-acoustic-scene-classification#subtask-a" style="">task description page</a></p>
<h1 id="systems-ranking">Systems ranking</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>1a_CNN</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7 (58.8 - 60.6)</td>
<td>1.099</td>
<td>61.6</td>
<td>1.071</td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>1a_CNN</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6 (59.7 - 61.5)</td>
<td>1.063</td>
<td>62.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>CaoJNU1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7 (64.9 - 66.6)</td>
<td>1.265</td>
<td>68.3</td>
<td>1.186</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>CaoJNU2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7 (64.8 - 66.5)</td>
<td>1.259</td>
<td>68.9</td>
<td>1.163</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>CaoJNU3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0 (65.1 - 66.8)</td>
<td>1.268</td>
<td>68.7</td>
<td>1.202</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>CaoJNU4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9 (65.1 - 66.8)</td>
<td>1.267</td>
<td>69.2</td>
<td>1.171</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>CRNN_4kHz</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4 (62.5 - 64.2)</td>
<td>1.106</td>
<td>65.4</td>
<td>2.070</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>CRNN_8kHz</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7 (59.9 - 61.6)</td>
<td>1.142</td>
<td>62.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>CRNN_ens</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8 (63.9 - 65.6)</td>
<td>1.298</td>
<td>67.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>CRNN_ens</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5 (66.6 - 68.3)</td>
<td>1.240</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Baseline</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0 (74.3 - 75.8)</td>
<td>1.225</td>
<td>71.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>focal_ls</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1 (73.3 - 74.9)</td>
<td>1.242</td>
<td>71.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>da</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7 (73.9 - 75.5)</td>
<td>1.231</td>
<td>71.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>ensemble</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2 (74.4 - 76.0)</td>
<td>1.230</td>
<td>72.5</td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td>51.4 (50.5 - 52.3)</td>
<td>1.902</td>
<td>51.6</td>
<td>1.405</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Helin1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4 (72.6 - 74.2)</td>
<td>0.850</td>
<td>84.2</td>
<td>0.569</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Helin2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4 (67.6 - 69.3)</td>
<td>0.991</td>
<td>81.8</td>
<td>0.694</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Helin3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1 (72.3 - 73.9)</td>
<td>0.889</td>
<td>84.5</td>
<td>0.611</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Helin4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3 (71.5 - 73.1)</td>
<td>0.899</td>
<td>84.2</td>
<td>0.601</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu_GT_1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7 (74.9 - 76.4)</td>
<td>0.924</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu_GT_1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9 (75.1 - 76.7)</td>
<td>0.895</td>
<td>81.9</td>
<td>0.936</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu_GT_1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2 (75.4 - 77.0)</td>
<td>0.898</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu_GT_1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8 (75.0 - 76.5)</td>
<td>0.900</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>EF5+SFA</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3 (66.5 - 68.2)</td>
<td>5.219</td>
<td>70.1</td>
<td>0.013</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>EF2+SFA</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2 (65.3 - 67.0)</td>
<td>4.766</td>
<td>68.6</td>
<td>0.019</td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>maxvision</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0 (74.3 - 75.8)</td>
<td>1.209</td>
<td>72.1</td>
<td>1.370</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>5ch_m_2</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6 (70.8 - 72.4)</td>
<td>1.309</td>
<td>72.7</td>
<td>1.307</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>7ch_m_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7 (69.9 - 71.6)</td>
<td>1.304</td>
<td>71.0</td>
<td>1.301</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>7ch_m_4</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7 (69.8 - 71.5)</td>
<td>1.412</td>
<td>72.2</td>
<td>1.408</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>9ch_2</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4 (65.6 - 67.3)</td>
<td>1.428</td>
<td>71.7</td>
<td>1.292</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>fdamp</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9 (71.1 - 72.7)</td>
<td>0.800</td>
<td>71.0</td>
<td>0.820</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>FDswd</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6 (70.8 - 72.4)</td>
<td>0.862</td>
<td>72.5</td>
<td>0.820</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>ensemble</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6 (72.8 - 74.4)</td>
<td>0.796</td>
<td>73.3</td>
<td>0.820</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>DAensem</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4 (72.6 - 74.2)</td>
<td>0.814</td>
<td>73.0</td>
<td>0.820</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2 (68.3 - 70.0)</td>
<td>0.885</td>
<td>67.1</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6 (68.8 - 70.5)</td>
<td>0.859</td>
<td>67.1</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0 (71.2 - 72.8)</td>
<td>0.944</td>
<td>67.1</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9 (72.1 - 73.7)</td>
<td>0.919</td>
<td>67.1</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>PRML</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9 (55.0 - 56.8)</td>
<td>1.969</td>
<td>59.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>PRML</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6 (54.7 - 56.5)</td>
<td>1.818</td>
<td>59.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>PRML</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6 (54.7 - 56.5)</td>
<td>2.987</td>
<td>59.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>PRML</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9 (54.1 - 55.8)</td>
<td>2.847</td>
<td>59.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>ResNet</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3 (68.5 - 70.1)</td>
<td>1.396</td>
<td>70.2</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>CNN-9</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0 (67.2 - 68.9)</td>
<td>4.510</td>
<td>68.8</td>
<td>1.792</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>E-T</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7 (54.8 - 56.6)</td>
<td>9.403</td>
<td>58.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Fusion</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0 (71.2 - 72.8)</td>
<td>3.165</td>
<td>73.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Averag_8</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2 (72.4 - 74.0)</td>
<td>1.305</td>
<td>68.4</td>
<td>1.362</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Averag_18</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4 (71.6 - 73.2)</td>
<td>1.303</td>
<td>69.0</td>
<td>1.367</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Rforest_8</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5 (71.7 - 73.3)</td>
<td>0.755</td>
<td>68.6</td>
<td>0.841</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Rforest_18</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0 (71.2 - 72.8)</td>
<td>0.767</td>
<td>68.4</td>
<td>0.839</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>CNNensem</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3 (63.4 - 65.1)</td>
<td>5.268</td>
<td>68.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>CNNensem</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1 (63.3 - 65.0)</td>
<td>11.870</td>
<td>69.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>city_cv</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2 (70.4 - 72.0)</td>
<td>0.809</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>resnext</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1 (63.3 - 65.0)</td>
<td>1.383</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>2resnext</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4 (65.5 - 67.2)</td>
<td>1.192</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>all</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2 (70.4 - 72.1)</td>
<td>0.806</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>preResnet</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7 (60.8 - 62.6)</td>
<td>5.936</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>TDNN</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9 (55.0 - 56.8)</td>
<td>5.198</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>ModResNet</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8 (49.9 - 51.7)</td>
<td>2.766</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>FuseCNN</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3 (65.5 - 67.2)</td>
<td>2.226</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9 (61.0 - 62.7)</td>
<td>1.246</td>
<td>65.1</td>
<td>1.120</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7 (58.8 - 60.6)</td>
<td>1.314</td>
<td>65.1</td>
<td>1.120</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Pan_UPM</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8 (42.9 - 44.7)</td>
<td>2.053</td>
<td>57.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>UOS_totens</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7 (70.9 - 72.5)</td>
<td>1.190</td>
<td>71.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>UOS_rbfens</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5 (70.7 - 72.4)</td>
<td>0.897</td>
<td>71.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>UOS_lcnn</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5 (67.6 - 69.3)</td>
<td>0.911</td>
<td>70.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>UOS_trgasc</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0 (70.2 - 71.8)</td>
<td>0.945</td>
<td>68.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>TRN_Dev</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5 (71.7 - 73.3)</td>
<td>1.290</td>
<td>73.7</td>
<td>1.285</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>TRN_Eval</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5 (74.7 - 76.2)</td>
<td>1.221</td>
<td>73.7</td>
<td>1.285</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>TRN_Ensem</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5 (75.8 - 77.3)</td>
<td>1.219</td>
<td>74.2</td>
<td>1.289</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>TRN_wEnsem</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5 (75.7 - 77.2)</td>
<td>1.219</td>
<td>74.4</td>
<td>1.288</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>b3_train</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1 (66.2 - 67.9)</td>
<td>0.926</td>
<td>69.3</td>
<td>0.846</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>b3_all</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5 (68.7 - 70.3)</td>
<td>0.851</td>
<td>69.3</td>
<td>0.846</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>b3_all_lr</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3 (69.4 - 71.1)</td>
<td>0.970</td>
<td>68.9</td>
<td>0.973</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>b3_all_mix</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8 (71.0 - 72.7)</td>
<td>0.793</td>
<td>71.9</td>
<td>0.790</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>VilEnsemb1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7 (66.8 - 68.5)</td>
<td>0.929</td>
<td>68.1</td>
<td>0.908</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>VilEnsemb2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8 (67.0 - 68.7)</td>
<td>0.931</td>
<td>69.2</td>
<td>0.890</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>VilEnsemb3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3 (68.5 - 70.1)</td>
<td>0.883</td>
<td>70.3</td>
<td>0.872</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>MFDWC20</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4 (57.5 - 59.2)</td>
<td>1.427</td>
<td>55.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>RoyalFlush</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7 (55.8 - 57.6)</td>
<td>1.576</td>
<td>63.9</td>
<td>1.826</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>RoyalFlush</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2 (64.3 - 66.0)</td>
<td>1.294</td>
<td>62.9</td>
<td>1.586</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>RoyalFlush</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0 (63.1 - 64.8)</td>
<td>1.239</td>
<td>62.1</td>
<td>1.334</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>RoyalFlush</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5 (44.6 - 46.4)</td>
<td>5.880</td>
<td>62.7</td>
<td>1.712</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>CNN_RCE</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7 (63.9 - 65.6)</td>
<td>1.148</td>
<td>65.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>ensemble_4</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3 (68.4 - 70.1)</td>
<td>1.070</td>
<td>67.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>ensemble_5</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9 (67.1 - 68.8)</td>
<td>1.100</td>
<td>67.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>ensemble_9</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4 (68.6 - 70.2)</td>
<td>1.080</td>
<td>68.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>THUEE</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0 (72.2 - 73.8)</td>
<td>1.963</td>
<td>75.0</td>
<td>0.791</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>THUEE</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2 (72.4 - 74.0)</td>
<td>1.967</td>
<td>75.0</td>
<td>0.789</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>THUEE</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3 (71.5 - 73.1)</td>
<td>1.958</td>
<td>74.3</td>
<td>0.824</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>N1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4 (49.5 - 51.3)</td>
<td>1.899</td>
<td>57.4</td>
<td>1.275</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>N2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7 (50.8 - 52.6)</td>
<td>1.805</td>
<td>56.1</td>
<td>1.297</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>N3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4 (46.5 - 48.3)</td>
<td>2.068</td>
<td>53.7</td>
<td>1.344</td>
</tr>
</tbody>
</table>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="4">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_team" data-sortable="true" data-value-type="int">
                Team rank
            </th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>1a_CNN</td>
<td>Abbasi2020</td>
<td>76</td>
<td>24</td>
<td>60.6 (59.7 - 61.5)</td>
<td>1.063</td>
<td>62.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>CaoJNU3</td>
<td>Fei2020</td>
<td>61</td>
<td>20</td>
<td>66.0 (65.1 - 66.8)</td>
<td>1.268</td>
<td>68.7</td>
<td>1.202</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>CRNN_ens</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>17</td>
<td>67.5 (66.6 - 68.3)</td>
<td>1.240</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>ensemble</td>
<td>Gao2020</td>
<td>8</td>
<td>3</td>
<td>75.2 (74.4 - 76.0)</td>
<td>1.230</td>
<td>72.5</td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td></td>
<td>51.4 (50.5 - 52.3)</td>
<td>1.902</td>
<td>51.6</td>
<td>1.405</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Helin1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>6</td>
<td>73.4 (72.6 - 74.2)</td>
<td>0.850</td>
<td>84.2</td>
<td>0.569</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu_GT_1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>2</td>
<td>76.2 (75.4 - 77.0)</td>
<td>0.898</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>EF5+SFA</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>18</td>
<td>67.3 (66.5 - 68.2)</td>
<td>5.219</td>
<td>70.1</td>
<td>0.013</td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>maxvision</td>
<td>Jie2020</td>
<td>10</td>
<td>4</td>
<td>75.0 (74.3 - 75.8)</td>
<td>1.209</td>
<td>72.1</td>
<td>1.370</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>5ch_m_2</td>
<td>Changmin2020</td>
<td>33</td>
<td>13</td>
<td>71.6 (70.8 - 72.4)</td>
<td>1.309</td>
<td>72.7</td>
<td>1.307</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>ensemble</td>
<td>Koutini2020</td>
<td>13</td>
<td>5</td>
<td>73.6 (72.8 - 74.4)</td>
<td>0.796</td>
<td>73.3</td>
<td>0.820</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>20</td>
<td>9</td>
<td>72.9 (72.1 - 73.7)</td>
<td>0.919</td>
<td>67.1</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>PRML</td>
<td>Aryal2020</td>
<td>81</td>
<td>26</td>
<td>55.9 (55.0 - 56.8)</td>
<td>1.969</td>
<td>59.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Fusion</td>
<td>Liu2020</td>
<td>26</td>
<td>10</td>
<td>72.0 (71.2 - 72.8)</td>
<td>3.165</td>
<td>73.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Averag_8</td>
<td>Liu2020a</td>
<td>16</td>
<td>7</td>
<td>73.2 (72.4 - 74.0)</td>
<td>1.305</td>
<td>68.4</td>
<td>1.362</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>CNNensem</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>22</td>
<td>64.3 (63.4 - 65.1)</td>
<td>5.268</td>
<td>68.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>all</td>
<td>Hong2020</td>
<td>35</td>
<td>14</td>
<td>71.2 (70.4 - 72.1)</td>
<td>0.806</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>FuseCNN</td>
<td>Joao2020</td>
<td>59</td>
<td>19</td>
<td>66.3 (65.5 - 67.2)</td>
<td>2.226</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>23</td>
<td>61.9 (61.0 - 62.7)</td>
<td>1.246</td>
<td>65.1</td>
<td>1.120</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Pan_UPM</td>
<td>Paniagua2020</td>
<td>92</td>
<td>28</td>
<td>43.8 (42.9 - 44.7)</td>
<td>2.053</td>
<td>57.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>UOS_totens</td>
<td>Shim2020</td>
<td>31</td>
<td>12</td>
<td>71.7 (70.9 - 72.5)</td>
<td>1.190</td>
<td>71.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>TRN_Ensem</td>
<td>Suh2020</td>
<td>1</td>
<td>1</td>
<td>76.5 (75.8 - 77.3)</td>
<td>1.219</td>
<td>74.2</td>
<td>1.289</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>b3_all_mix</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>11</td>
<td>71.8 (71.0 - 72.7)</td>
<td>0.793</td>
<td>71.9</td>
<td>0.790</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>VilEnsemb3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>16</td>
<td>69.3 (68.5 - 70.1)</td>
<td>0.883</td>
<td>70.3</td>
<td>0.872</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>MFDWC20</td>
<td>Waldekar2020</td>
<td>79</td>
<td>25</td>
<td>58.4 (57.5 - 59.2)</td>
<td>1.427</td>
<td>55.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>RoyalFlush</td>
<td>Wang2020a</td>
<td>65</td>
<td>21</td>
<td>65.2 (64.3 - 66.0)</td>
<td>1.294</td>
<td>62.9</td>
<td>1.586</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>ensemble_9</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>15</td>
<td>69.4 (68.6 - 70.2)</td>
<td>1.080</td>
<td>68.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>THUEE</td>
<td>Shao2020</td>
<td>17</td>
<td>8</td>
<td>73.2 (72.4 - 74.0)</td>
<td>1.967</td>
<td>75.0</td>
<td>0.789</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>N2</td>
<td>Zhang2020</td>
<td>87</td>
<td>27</td>
<td>51.7 (50.8 - 52.6)</td>
<td>1.805</td>
<td>56.1</td>
<td>1.297</td>
</tr>
</tbody>
</table>
<h1 id="generalization-performance">Generalization performance</h1>
<p>All results with evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_source_seen" data-scatter-y="accuracy_eval_source_unseen" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2">Submission information</th>
<th class="sep-left-cell text-center" colspan="2">Overall</th>
<th class="sep-left-cell text-center" colspan="2">Devices</th>
<th class="sep-left-cell text-center" colspan="2">Cities</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Accuracy" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Evaluation dataset)
            </th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy / unseen devices" data-chartable="true" data-field="accuracy_eval_source_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>unseen<small class="hidden"> devices (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / seen devices" data-chartable="true" data-field="accuracy_eval_source_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>seen<small class="hidden"> devices (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy / unseen cities" data-chartable="true" data-field="accuracy_eval_city_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>unseen<small class="hidden"> cities (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / seen cities" data-chartable="true" data-field="accuracy_eval_city_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>seen<small class="hidden"> cities (Evaluation dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7</td>
<td>56.1</td>
<td>62.7</td>
<td>60.2</td>
<td>59.5</td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6</td>
<td>58.9</td>
<td>62.0</td>
<td>58.9</td>
<td>60.8</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7</td>
<td>63.0</td>
<td>68.0</td>
<td>65.4</td>
<td>66.0</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7</td>
<td>62.9</td>
<td>68.0</td>
<td>65.6</td>
<td>65.9</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0</td>
<td>62.9</td>
<td>68.5</td>
<td>64.6</td>
<td>66.4</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9</td>
<td>63.0</td>
<td>68.4</td>
<td>65.2</td>
<td>66.3</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4</td>
<td>57.3</td>
<td>68.5</td>
<td>59.1</td>
<td>64.3</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7</td>
<td>53.4</td>
<td>66.9</td>
<td>60.4</td>
<td>61.4</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8</td>
<td>58.1</td>
<td>70.3</td>
<td>61.9</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5</td>
<td>60.8</td>
<td>73.1</td>
<td>64.6</td>
<td>68.3</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0</td>
<td>73.3</td>
<td>76.5</td>
<td>73.7</td>
<td>75.7</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1</td>
<td>71.9</td>
<td>75.9</td>
<td>73.0</td>
<td>74.9</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7</td>
<td>72.9</td>
<td>76.1</td>
<td>73.3</td>
<td>75.5</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2</td>
<td>73.1</td>
<td>77.0</td>
<td>73.9</td>
<td>75.9</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>51.4</td>
<td>37.2</td>
<td>63.1</td>
<td>51.8</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4</td>
<td>70.1</td>
<td>76.2</td>
<td>71.2</td>
<td>74.1</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4</td>
<td>63.8</td>
<td>72.3</td>
<td>66.5</td>
<td>69.5</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1</td>
<td>70.2</td>
<td>75.5</td>
<td>70.8</td>
<td>74.0</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3</td>
<td>68.8</td>
<td>75.2</td>
<td>70.1</td>
<td>73.2</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7</td>
<td>74.3</td>
<td>76.8</td>
<td>73.0</td>
<td>76.3</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9</td>
<td>74.4</td>
<td>77.2</td>
<td>73.8</td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2</td>
<td>74.7</td>
<td>77.5</td>
<td>74.1</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8</td>
<td>74.3</td>
<td>77.0</td>
<td>74.0</td>
<td>76.3</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3</td>
<td>64.5</td>
<td>69.7</td>
<td>67.7</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2</td>
<td>64.3</td>
<td>67.7</td>
<td>65.4</td>
<td>66.5</td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0</td>
<td>73.2</td>
<td>76.5</td>
<td>73.2</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6</td>
<td>69.2</td>
<td>73.5</td>
<td>69.5</td>
<td>72.5</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7</td>
<td>68.4</td>
<td>72.7</td>
<td>69.4</td>
<td>71.7</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7</td>
<td>68.3</td>
<td>72.6</td>
<td>70.1</td>
<td>71.4</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4</td>
<td>63.5</td>
<td>68.9</td>
<td>62.7</td>
<td>67.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9</td>
<td>68.4</td>
<td>74.9</td>
<td>73.1</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6</td>
<td>66.9</td>
<td>75.5</td>
<td>71.4</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6</td>
<td>69.8</td>
<td>76.8</td>
<td>72.6</td>
<td>74.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4</td>
<td>69.4</td>
<td>76.7</td>
<td>72.4</td>
<td>73.9</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2</td>
<td>66.2</td>
<td>71.6</td>
<td>67.5</td>
<td>69.8</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6</td>
<td>66.5</td>
<td>72.3</td>
<td>68.4</td>
<td>70.2</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0</td>
<td>69.3</td>
<td>74.3</td>
<td>70.7</td>
<td>72.4</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9</td>
<td>69.8</td>
<td>75.5</td>
<td>71.7</td>
<td>73.3</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9</td>
<td>46.4</td>
<td>63.8</td>
<td>55.1</td>
<td>56.2</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6</td>
<td>45.7</td>
<td>63.8</td>
<td>54.9</td>
<td>55.7</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6</td>
<td>45.5</td>
<td>64.0</td>
<td>53.5</td>
<td>56.3</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9</td>
<td>44.7</td>
<td>63.5</td>
<td>53.8</td>
<td>55.4</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3</td>
<td>65.1</td>
<td>72.7</td>
<td>67.6</td>
<td>70.0</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0</td>
<td>64.9</td>
<td>70.6</td>
<td>67.1</td>
<td>68.7</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7</td>
<td>46.8</td>
<td>63.1</td>
<td>49.4</td>
<td>57.0</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0</td>
<td>67.5</td>
<td>75.8</td>
<td>69.6</td>
<td>72.7</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2</td>
<td>71.9</td>
<td>74.3</td>
<td>73.3</td>
<td>73.4</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4</td>
<td>71.1</td>
<td>73.5</td>
<td>73.1</td>
<td>72.5</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5</td>
<td>71.3</td>
<td>73.5</td>
<td>71.7</td>
<td>72.9</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0</td>
<td>70.3</td>
<td>73.4</td>
<td>71.7</td>
<td>72.3</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3</td>
<td>60.9</td>
<td>67.1</td>
<td>62.9</td>
<td>64.4</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1</td>
<td>61.1</td>
<td>66.7</td>
<td>62.2</td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2</td>
<td>68.8</td>
<td>73.2</td>
<td>69.1</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1</td>
<td>60.8</td>
<td>66.9</td>
<td>62.4</td>
<td>64.5</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4</td>
<td>63.3</td>
<td>68.9</td>
<td>64.5</td>
<td>66.5</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2</td>
<td>68.8</td>
<td>73.3</td>
<td>68.6</td>
<td>71.9</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7</td>
<td>59.4</td>
<td>63.6</td>
<td>59.4</td>
<td>62.0</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9</td>
<td>51.8</td>
<td>59.3</td>
<td>52.5</td>
<td>56.4</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8</td>
<td>44.5</td>
<td>56.1</td>
<td>47.4</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3</td>
<td>63.2</td>
<td>69.0</td>
<td>63.7</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9</td>
<td>55.9</td>
<td>66.9</td>
<td>59.6</td>
<td>62.8</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7</td>
<td>54.0</td>
<td>64.5</td>
<td>54.7</td>
<td>60.8</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8</td>
<td>36.0</td>
<td>50.3</td>
<td>45.7</td>
<td>43.5</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7</td>
<td>69.0</td>
<td>74.0</td>
<td>71.4</td>
<td>71.9</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5</td>
<td>68.4</td>
<td>74.2</td>
<td>70.5</td>
<td>71.7</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5</td>
<td>64.9</td>
<td>71.4</td>
<td>67.4</td>
<td>68.7</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0</td>
<td>68.2</td>
<td>73.3</td>
<td>68.9</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5</td>
<td>69.9</td>
<td>74.6</td>
<td>70.4</td>
<td>73.1</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5</td>
<td>73.6</td>
<td>77.0</td>
<td>75.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5</td>
<td>74.6</td>
<td>78.1</td>
<td>75.8</td>
<td>77.3</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5</td>
<td>74.7</td>
<td>77.9</td>
<td>75.8</td>
<td>77.2</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1</td>
<td>64.0</td>
<td>69.6</td>
<td>65.7</td>
<td>66.9</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5</td>
<td>66.5</td>
<td>72.0</td>
<td>68.9</td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3</td>
<td>68.2</td>
<td>72.0</td>
<td>66.5</td>
<td>71.1</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8</td>
<td>69.0</td>
<td>74.2</td>
<td>69.4</td>
<td>72.4</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7</td>
<td>63.5</td>
<td>71.2</td>
<td>65.8</td>
<td>68.1</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8</td>
<td>63.0</td>
<td>71.8</td>
<td>65.6</td>
<td>68.4</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3</td>
<td>65.3</td>
<td>72.6</td>
<td>66.9</td>
<td>70.1</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4</td>
<td>52.9</td>
<td>62.9</td>
<td>52.8</td>
<td>59.6</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7</td>
<td>54.8</td>
<td>58.2</td>
<td>54.9</td>
<td>57.4</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2</td>
<td>63.0</td>
<td>67.0</td>
<td>64.1</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0</td>
<td>60.0</td>
<td>67.3</td>
<td>63.7</td>
<td>64.4</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5</td>
<td>42.9</td>
<td>47.7</td>
<td>45.2</td>
<td>45.7</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7</td>
<td>60.0</td>
<td>68.7</td>
<td>63.7</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3</td>
<td>63.0</td>
<td>74.5</td>
<td>65.1</td>
<td>70.4</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9</td>
<td>62.7</td>
<td>72.3</td>
<td>66.3</td>
<td>68.3</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4</td>
<td>63.6</td>
<td>74.3</td>
<td>66.1</td>
<td>70.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0</td>
<td>69.9</td>
<td>75.6</td>
<td>71.8</td>
<td>73.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2</td>
<td>70.0</td>
<td>75.8</td>
<td>71.6</td>
<td>74.1</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3</td>
<td>68.8</td>
<td>75.2</td>
<td>70.2</td>
<td>73.2</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4</td>
<td>35.8</td>
<td>62.5</td>
<td>50.3</td>
<td>50.7</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7</td>
<td>37.5</td>
<td>63.5</td>
<td>50.8</td>
<td>52.5</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4</td>
<td>32.2</td>
<td>60.1</td>
<td>46.7</td>
<td>47.8</td>
</tr>
</tbody>
</table>
<h1 id="class-wise-performance">Class-wise performance</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2020 baseline" data-comparison-active-set="Class-wise performance (all)" data-comparison-b-row="Suh_ETRI_task1a_3" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (all)",
        "data_axis_title": "Accuracy",
        "fields": ["class_accuracy_eval_airport", "class_accuracy_eval_bus", "class_accuracy_eval_metro", "class_accuracy_eval_metro_station", "class_accuracy_eval_park", "class_accuracy_eval_public_square", "class_accuracy_eval_shopping_mall", "class_accuracy_eval_street_pedestrian", "class_accuracy_eval_street_traffic", "class_accuracy_eval_tram"]
        },
        {"title": "Class-wise performance (indoor)","data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_airport", "class_accuracy_eval_metro_station", "class_accuracy_eval_shopping_mall"]
        },
        {"title": "Class-wise performance (outdoor)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_park", "class_accuracy_eval_public_square", "class_accuracy_eval_street_pedestrian", "class_accuracy_eval_street_traffic"]
        },
        {"title": "Class-wise performance (transport)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_bus","class_accuracy_eval_metro","class_accuracy_eval_tram"]
        }]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="accuracy_eval" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="class_accuracy_eval_airport" data-sortable="true" data-value-type="float1-percentage">
                Airport
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_bus" data-sortable="true" data-value-type="float1-percentage">
                Bus
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_metro" data-sortable="true" data-value-type="float1-percentage">
                Metro
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_metro_station" data-sortable="true" data-value-type="float1-percentage">
                Metro <br/>station
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_park" data-sortable="true" data-value-type="float1-percentage">
                Park
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_public_square" data-sortable="true" data-value-type="float1-percentage">
                Public <br/>square
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_shopping_mall" data-sortable="true" data-value-type="float1-percentage">
                Shopping <br/>mall
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_street_pedestrian" data-sortable="true" data-value-type="float1-percentage">
                Street <br/>pedestrian
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_street_traffic" data-sortable="true" data-value-type="float1-percentage">
                Street <br/>traffic
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_tram" data-sortable="true" data-value-type="float1-percentage">
                Tram
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7</td>
<td>38.0</td>
<td>68.9</td>
<td>56.1</td>
<td>57.3</td>
<td>73.7</td>
<td>44.2</td>
<td>69.4</td>
<td>36.7</td>
<td>80.1</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6</td>
<td>39.1</td>
<td>63.4</td>
<td>53.5</td>
<td>59.2</td>
<td>70.9</td>
<td>40.7</td>
<td>70.6</td>
<td>43.4</td>
<td>84.1</td>
<td>81.0</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7</td>
<td>56.1</td>
<td>74.6</td>
<td>72.3</td>
<td>70.4</td>
<td>85.9</td>
<td>47.4</td>
<td>70.3</td>
<td>30.1</td>
<td>79.8</td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7</td>
<td>52.0</td>
<td>72.1</td>
<td>71.8</td>
<td>70.6</td>
<td>84.1</td>
<td>47.5</td>
<td>70.7</td>
<td>32.9</td>
<td>82.2</td>
<td>72.7</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0</td>
<td>54.2</td>
<td>74.4</td>
<td>73.2</td>
<td>69.8</td>
<td>85.0</td>
<td>46.2</td>
<td>70.8</td>
<td>32.0</td>
<td>82.2</td>
<td>71.8</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9</td>
<td>51.8</td>
<td>71.9</td>
<td>72.1</td>
<td>69.9</td>
<td>84.1</td>
<td>47.0</td>
<td>71.3</td>
<td>33.8</td>
<td>83.7</td>
<td>74.0</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4</td>
<td>52.0</td>
<td>89.8</td>
<td>68.7</td>
<td>50.1</td>
<td>78.1</td>
<td>36.6</td>
<td>62.7</td>
<td>37.0</td>
<td>78.8</td>
<td>80.0</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7</td>
<td>50.4</td>
<td>77.6</td>
<td>68.1</td>
<td>49.0</td>
<td>76.7</td>
<td>39.0</td>
<td>55.8</td>
<td>37.7</td>
<td>72.6</td>
<td>80.4</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8</td>
<td>53.7</td>
<td>89.1</td>
<td>71.9</td>
<td>52.4</td>
<td>78.7</td>
<td>39.4</td>
<td>62.2</td>
<td>38.9</td>
<td>78.0</td>
<td>83.2</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5</td>
<td>55.8</td>
<td>90.7</td>
<td>79.0</td>
<td>57.2</td>
<td>79.5</td>
<td>44.1</td>
<td>63.0</td>
<td>43.8</td>
<td>75.9</td>
<td>85.9</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0</td>
<td>58.2</td>
<td>87.8</td>
<td>76.2</td>
<td>75.6</td>
<td>92.7</td>
<td>57.5</td>
<td>75.3</td>
<td>52.3</td>
<td>90.7</td>
<td>84.3</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1</td>
<td>59.3</td>
<td>88.2</td>
<td>79.9</td>
<td>72.7</td>
<td>92.3</td>
<td>51.4</td>
<td>72.4</td>
<td>52.7</td>
<td>90.3</td>
<td>81.9</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7</td>
<td>57.3</td>
<td>86.7</td>
<td>78.4</td>
<td>74.5</td>
<td>93.0</td>
<td>57.1</td>
<td>73.3</td>
<td>52.3</td>
<td>90.3</td>
<td>83.8</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2</td>
<td>58.5</td>
<td>88.0</td>
<td>79.4</td>
<td>74.7</td>
<td>92.8</td>
<td>56.4</td>
<td>74.2</td>
<td>53.4</td>
<td>90.5</td>
<td>84.3</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>51.4</td>
<td>26.3</td>
<td>82.3</td>
<td>45.4</td>
<td>53.8</td>
<td>67.3</td>
<td>34.7</td>
<td>40.3</td>
<td>30.4</td>
<td>69.4</td>
<td>63.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4</td>
<td>60.2</td>
<td>82.7</td>
<td>81.4</td>
<td>72.8</td>
<td>93.4</td>
<td>52.9</td>
<td>74.6</td>
<td>44.4</td>
<td>85.0</td>
<td>86.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4</td>
<td>51.8</td>
<td>75.2</td>
<td>76.8</td>
<td>68.6</td>
<td>89.0</td>
<td>48.5</td>
<td>61.4</td>
<td>44.1</td>
<td>83.0</td>
<td>86.2</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1</td>
<td>56.9</td>
<td>82.4</td>
<td>81.7</td>
<td>73.7</td>
<td>92.8</td>
<td>53.8</td>
<td>72.6</td>
<td>44.9</td>
<td>85.7</td>
<td>86.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3</td>
<td>57.2</td>
<td>82.0</td>
<td>80.6</td>
<td>72.1</td>
<td>92.5</td>
<td>52.2</td>
<td>71.0</td>
<td>44.3</td>
<td>84.6</td>
<td>86.6</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7</td>
<td>62.3</td>
<td>89.8</td>
<td>82.1</td>
<td>72.4</td>
<td>92.8</td>
<td>56.2</td>
<td>83.4</td>
<td>40.4</td>
<td>91.5</td>
<td>85.7</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9</td>
<td>60.7</td>
<td>91.8</td>
<td>83.2</td>
<td>75.5</td>
<td>93.8</td>
<td>52.4</td>
<td>81.1</td>
<td>39.4</td>
<td>92.3</td>
<td>88.6</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2</td>
<td>61.7</td>
<td>92.1</td>
<td>84.0</td>
<td>74.5</td>
<td>93.9</td>
<td>53.8</td>
<td>81.5</td>
<td>39.4</td>
<td>92.6</td>
<td>88.6</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8</td>
<td>59.5</td>
<td>91.6</td>
<td>83.4</td>
<td>75.0</td>
<td>93.9</td>
<td>52.4</td>
<td>81.4</td>
<td>39.1</td>
<td>92.6</td>
<td>88.7</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3</td>
<td>68.9</td>
<td>83.1</td>
<td>79.2</td>
<td>65.2</td>
<td>84.6</td>
<td>32.7</td>
<td>56.6</td>
<td>40.1</td>
<td>85.4</td>
<td>77.7</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2</td>
<td>57.6</td>
<td>80.9</td>
<td>67.8</td>
<td>63.6</td>
<td>86.1</td>
<td>41.9</td>
<td>63.9</td>
<td>46.2</td>
<td>82.3</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0</td>
<td>62.4</td>
<td>88.6</td>
<td>75.2</td>
<td>70.4</td>
<td>93.8</td>
<td>58.4</td>
<td>76.8</td>
<td>48.3</td>
<td>90.4</td>
<td>86.1</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6</td>
<td>51.2</td>
<td>78.5</td>
<td>82.0</td>
<td>71.9</td>
<td>93.0</td>
<td>46.4</td>
<td>76.3</td>
<td>48.7</td>
<td>90.4</td>
<td>77.4</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7</td>
<td>47.7</td>
<td>79.6</td>
<td>79.2</td>
<td>72.2</td>
<td>92.2</td>
<td>50.2</td>
<td>72.9</td>
<td>47.1</td>
<td>89.7</td>
<td>76.5</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7</td>
<td>47.6</td>
<td>76.0</td>
<td>77.2</td>
<td>74.4</td>
<td>92.8</td>
<td>48.6</td>
<td>74.3</td>
<td>42.8</td>
<td>90.9</td>
<td>81.9</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4</td>
<td>31.8</td>
<td>75.8</td>
<td>80.0</td>
<td>66.9</td>
<td>95.9</td>
<td>36.4</td>
<td>77.4</td>
<td>42.5</td>
<td>88.5</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9</td>
<td>60.2</td>
<td>90.6</td>
<td>75.8</td>
<td>72.5</td>
<td>89.5</td>
<td>51.9</td>
<td>64.9</td>
<td>44.9</td>
<td>84.0</td>
<td>85.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6</td>
<td>60.4</td>
<td>90.2</td>
<td>74.9</td>
<td>70.9</td>
<td>86.1</td>
<td>52.4</td>
<td>66.7</td>
<td>43.9</td>
<td>84.3</td>
<td>86.0</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6</td>
<td>59.3</td>
<td>92.5</td>
<td>77.0</td>
<td>75.9</td>
<td>89.8</td>
<td>53.9</td>
<td>66.9</td>
<td>47.5</td>
<td>84.7</td>
<td>88.6</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4</td>
<td>59.9</td>
<td>92.3</td>
<td>75.8</td>
<td>75.5</td>
<td>89.8</td>
<td>53.0</td>
<td>67.5</td>
<td>46.1</td>
<td>84.8</td>
<td>89.1</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2</td>
<td>53.5</td>
<td>82.2</td>
<td>69.5</td>
<td>69.4</td>
<td>83.9</td>
<td>50.1</td>
<td>66.8</td>
<td>47.9</td>
<td>84.4</td>
<td>84.1</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6</td>
<td>54.0</td>
<td>82.7</td>
<td>68.5</td>
<td>70.4</td>
<td>85.7</td>
<td>48.9</td>
<td>66.5</td>
<td>50.1</td>
<td>84.6</td>
<td>85.2</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0</td>
<td>62.8</td>
<td>87.5</td>
<td>69.4</td>
<td>71.2</td>
<td>87.5</td>
<td>53.0</td>
<td>65.7</td>
<td>50.2</td>
<td>86.4</td>
<td>86.2</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9</td>
<td>65.4</td>
<td>87.3</td>
<td>72.8</td>
<td>72.1</td>
<td>87.2</td>
<td>56.1</td>
<td>65.5</td>
<td>49.7</td>
<td>85.9</td>
<td>87.1</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9</td>
<td>37.7</td>
<td>83.2</td>
<td>50.4</td>
<td>49.3</td>
<td>82.9</td>
<td>36.4</td>
<td>56.8</td>
<td>37.0</td>
<td>62.5</td>
<td>62.7</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6</td>
<td>29.7</td>
<td>80.1</td>
<td>43.9</td>
<td>50.1</td>
<td>81.1</td>
<td>34.5</td>
<td>54.7</td>
<td>49.8</td>
<td>62.8</td>
<td>68.9</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6</td>
<td>40.5</td>
<td>81.4</td>
<td>51.6</td>
<td>48.0</td>
<td>77.1</td>
<td>38.3</td>
<td>58.6</td>
<td>32.9</td>
<td>68.0</td>
<td>59.6</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9</td>
<td>30.0</td>
<td>77.9</td>
<td>52.9</td>
<td>51.1</td>
<td>76.3</td>
<td>34.3</td>
<td>59.4</td>
<td>36.4</td>
<td>68.8</td>
<td>62.4</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3</td>
<td>55.6</td>
<td>85.4</td>
<td>74.4</td>
<td>64.3</td>
<td>88.5</td>
<td>47.3</td>
<td>67.0</td>
<td>45.2</td>
<td>83.7</td>
<td>81.4</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0</td>
<td>55.6</td>
<td>84.3</td>
<td>74.5</td>
<td>64.5</td>
<td>90.1</td>
<td>46.9</td>
<td>63.5</td>
<td>36.9</td>
<td>82.0</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7</td>
<td>35.5</td>
<td>65.4</td>
<td>54.2</td>
<td>50.8</td>
<td>80.6</td>
<td>35.6</td>
<td>52.4</td>
<td>38.9</td>
<td>71.5</td>
<td>71.9</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0</td>
<td>57.6</td>
<td>90.3</td>
<td>77.2</td>
<td>69.7</td>
<td>91.8</td>
<td>51.4</td>
<td>68.7</td>
<td>42.3</td>
<td>85.1</td>
<td>86.1</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2</td>
<td>55.1</td>
<td>79.1</td>
<td>80.2</td>
<td>71.5</td>
<td>86.3</td>
<td>58.3</td>
<td>85.9</td>
<td>46.0</td>
<td>90.6</td>
<td>79.1</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4</td>
<td>55.3</td>
<td>78.1</td>
<td>79.7</td>
<td>69.8</td>
<td>85.6</td>
<td>57.5</td>
<td>84.8</td>
<td>45.9</td>
<td>90.4</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5</td>
<td>55.1</td>
<td>80.4</td>
<td>78.4</td>
<td>74.2</td>
<td>86.2</td>
<td>60.8</td>
<td>77.4</td>
<td>50.3</td>
<td>83.3</td>
<td>78.8</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0</td>
<td>55.1</td>
<td>78.6</td>
<td>77.9</td>
<td>73.0</td>
<td>87.3</td>
<td>58.8</td>
<td>78.3</td>
<td>49.7</td>
<td>82.6</td>
<td>78.6</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3</td>
<td>46.5</td>
<td>74.2</td>
<td>74.5</td>
<td>63.4</td>
<td>84.7</td>
<td>41.9</td>
<td>67.3</td>
<td>39.4</td>
<td>81.0</td>
<td>69.9</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1</td>
<td>48.8</td>
<td>75.3</td>
<td>75.5</td>
<td>61.1</td>
<td>85.4</td>
<td>42.9</td>
<td>65.6</td>
<td>38.9</td>
<td>79.8</td>
<td>68.0</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2</td>
<td>51.1</td>
<td>79.6</td>
<td>77.9</td>
<td>73.1</td>
<td>89.7</td>
<td>43.6</td>
<td>75.4</td>
<td>49.6</td>
<td>87.3</td>
<td>84.7</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1</td>
<td>50.6</td>
<td>77.2</td>
<td>69.6</td>
<td>65.4</td>
<td>85.1</td>
<td>31.6</td>
<td>65.9</td>
<td>41.0</td>
<td>82.8</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4</td>
<td>49.6</td>
<td>79.1</td>
<td>71.1</td>
<td>69.4</td>
<td>84.8</td>
<td>33.7</td>
<td>72.0</td>
<td>44.9</td>
<td>85.2</td>
<td>73.8</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2</td>
<td>51.5</td>
<td>80.1</td>
<td>77.9</td>
<td>73.8</td>
<td>90.0</td>
<td>42.1</td>
<td>75.5</td>
<td>50.5</td>
<td>87.3</td>
<td>83.7</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7</td>
<td>46.1</td>
<td>71.5</td>
<td>55.7</td>
<td>56.2</td>
<td>83.2</td>
<td>32.1</td>
<td>72.3</td>
<td>47.3</td>
<td>85.6</td>
<td>67.0</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9</td>
<td>42.1</td>
<td>60.4</td>
<td>53.4</td>
<td>47.9</td>
<td>77.2</td>
<td>36.6</td>
<td>54.5</td>
<td>37.3</td>
<td>83.4</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8</td>
<td>43.1</td>
<td>49.5</td>
<td>46.0</td>
<td>48.1</td>
<td>72.9</td>
<td>33.0</td>
<td>52.5</td>
<td>24.5</td>
<td>80.4</td>
<td>58.3</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3</td>
<td>49.2</td>
<td>73.1</td>
<td>64.8</td>
<td>61.5</td>
<td>84.8</td>
<td>41.5</td>
<td>77.3</td>
<td>47.6</td>
<td>88.1</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9</td>
<td>47.8</td>
<td>75.5</td>
<td>60.1</td>
<td>60.3</td>
<td>83.9</td>
<td>35.4</td>
<td>60.9</td>
<td>46.2</td>
<td>70.6</td>
<td>77.9</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7</td>
<td>51.1</td>
<td>49.6</td>
<td>68.8</td>
<td>59.3</td>
<td>82.5</td>
<td>39.1</td>
<td>64.8</td>
<td>29.5</td>
<td>75.4</td>
<td>77.2</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8</td>
<td>32.5</td>
<td>80.0</td>
<td>65.8</td>
<td>46.5</td>
<td>62.4</td>
<td>28.6</td>
<td>45.9</td>
<td>31.6</td>
<td>44.4</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7</td>
<td>53.7</td>
<td>82.2</td>
<td>72.1</td>
<td>67.4</td>
<td>89.5</td>
<td>49.9</td>
<td>74.7</td>
<td>49.4</td>
<td>89.6</td>
<td>88.3</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5</td>
<td>53.9</td>
<td>82.4</td>
<td>71.9</td>
<td>71.0</td>
<td>89.3</td>
<td>51.9</td>
<td>73.1</td>
<td>49.3</td>
<td>87.1</td>
<td>85.5</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5</td>
<td>49.1</td>
<td>77.9</td>
<td>69.2</td>
<td>69.2</td>
<td>85.8</td>
<td>53.0</td>
<td>66.9</td>
<td>49.2</td>
<td>86.3</td>
<td>78.2</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0</td>
<td>56.2</td>
<td>82.8</td>
<td>74.2</td>
<td>65.0</td>
<td>89.9</td>
<td>46.6</td>
<td>73.2</td>
<td>49.2</td>
<td>87.8</td>
<td>85.4</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5</td>
<td>52.9</td>
<td>82.2</td>
<td>82.7</td>
<td>73.5</td>
<td>93.5</td>
<td>41.8</td>
<td>79.3</td>
<td>47.1</td>
<td>92.8</td>
<td>79.0</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5</td>
<td>59.2</td>
<td>88.0</td>
<td>83.4</td>
<td>76.0</td>
<td>93.4</td>
<td>49.8</td>
<td>78.5</td>
<td>51.3</td>
<td>92.1</td>
<td>82.7</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5</td>
<td>60.8</td>
<td>88.8</td>
<td>82.9</td>
<td>76.6</td>
<td>93.7</td>
<td>52.9</td>
<td>81.4</td>
<td>50.9</td>
<td>92.3</td>
<td>84.8</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5</td>
<td>60.7</td>
<td>88.6</td>
<td>83.2</td>
<td>76.5</td>
<td>93.7</td>
<td>52.4</td>
<td>81.2</td>
<td>51.2</td>
<td>92.3</td>
<td>84.9</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1</td>
<td>52.8</td>
<td>71.1</td>
<td>67.6</td>
<td>65.8</td>
<td>87.1</td>
<td>49.2</td>
<td>72.0</td>
<td>41.6</td>
<td>84.6</td>
<td>78.8</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5</td>
<td>54.7</td>
<td>77.9</td>
<td>72.1</td>
<td>67.6</td>
<td>85.5</td>
<td>52.9</td>
<td>73.7</td>
<td>45.3</td>
<td>85.7</td>
<td>79.9</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3</td>
<td>60.4</td>
<td>79.7</td>
<td>78.5</td>
<td>67.2</td>
<td>86.4</td>
<td>53.8</td>
<td>69.7</td>
<td>43.4</td>
<td>85.8</td>
<td>77.9</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8</td>
<td>59.4</td>
<td>81.6</td>
<td>78.2</td>
<td>69.9</td>
<td>88.6</td>
<td>55.6</td>
<td>72.7</td>
<td>44.2</td>
<td>86.8</td>
<td>81.5</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7</td>
<td>45.8</td>
<td>88.6</td>
<td>60.1</td>
<td>58.2</td>
<td>90.3</td>
<td>57.4</td>
<td>77.4</td>
<td>47.6</td>
<td>81.2</td>
<td>70.4</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8</td>
<td>50.5</td>
<td>87.0</td>
<td>59.8</td>
<td>67.3</td>
<td>85.9</td>
<td>39.6</td>
<td>79.0</td>
<td>49.8</td>
<td>84.3</td>
<td>75.1</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3</td>
<td>50.5</td>
<td>89.1</td>
<td>61.1</td>
<td>65.1</td>
<td>89.3</td>
<td>49.5</td>
<td>79.9</td>
<td>49.7</td>
<td>84.2</td>
<td>74.6</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4</td>
<td>50.4</td>
<td>70.4</td>
<td>53.5</td>
<td>51.9</td>
<td>84.0</td>
<td>38.9</td>
<td>59.6</td>
<td>33.4</td>
<td>72.9</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7</td>
<td>39.7</td>
<td>82.4</td>
<td>69.9</td>
<td>41.1</td>
<td>82.9</td>
<td>37.2</td>
<td>53.5</td>
<td>27.9</td>
<td>75.3</td>
<td>56.6</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2</td>
<td>56.4</td>
<td>74.9</td>
<td>67.7</td>
<td>49.5</td>
<td>84.5</td>
<td>50.8</td>
<td>68.0</td>
<td>43.9</td>
<td>79.7</td>
<td>76.2</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0</td>
<td>60.4</td>
<td>63.1</td>
<td>65.7</td>
<td>49.5</td>
<td>83.9</td>
<td>46.1</td>
<td>59.8</td>
<td>49.2</td>
<td>77.1</td>
<td>84.7</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5</td>
<td>5.6</td>
<td>89.6</td>
<td>69.1</td>
<td>62.1</td>
<td>84.8</td>
<td>34.2</td>
<td>6.3</td>
<td>0.0</td>
<td>78.6</td>
<td>24.7</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7</td>
<td>51.4</td>
<td>84.1</td>
<td>56.0</td>
<td>55.7</td>
<td>86.0</td>
<td>43.9</td>
<td>59.7</td>
<td>48.0</td>
<td>83.9</td>
<td>78.5</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3</td>
<td>46.3</td>
<td>87.1</td>
<td>76.8</td>
<td>68.2</td>
<td>86.9</td>
<td>43.3</td>
<td>65.7</td>
<td>49.8</td>
<td>84.7</td>
<td>83.8</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9</td>
<td>46.8</td>
<td>85.1</td>
<td>66.5</td>
<td>63.9</td>
<td>87.4</td>
<td>45.0</td>
<td>65.7</td>
<td>50.1</td>
<td>86.0</td>
<td>82.9</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4</td>
<td>46.9</td>
<td>86.7</td>
<td>72.6</td>
<td>66.6</td>
<td>88.0</td>
<td>45.6</td>
<td>65.5</td>
<td>51.6</td>
<td>86.1</td>
<td>84.5</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0</td>
<td>57.0</td>
<td>85.5</td>
<td>78.4</td>
<td>73.2</td>
<td>92.5</td>
<td>55.1</td>
<td>69.4</td>
<td>52.8</td>
<td>84.3</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2</td>
<td>57.4</td>
<td>85.7</td>
<td>79.1</td>
<td>73.2</td>
<td>92.3</td>
<td>55.1</td>
<td>68.9</td>
<td>53.8</td>
<td>84.3</td>
<td>81.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3</td>
<td>55.6</td>
<td>85.6</td>
<td>77.4</td>
<td>72.6</td>
<td>90.7</td>
<td>54.5</td>
<td>67.3</td>
<td>53.5</td>
<td>84.3</td>
<td>81.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4</td>
<td>30.1</td>
<td>66.6</td>
<td>48.5</td>
<td>51.9</td>
<td>72.3</td>
<td>28.7</td>
<td>43.4</td>
<td>28.5</td>
<td>62.0</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7</td>
<td>32.1</td>
<td>82.8</td>
<td>53.8</td>
<td>47.8</td>
<td>65.1</td>
<td>31.1</td>
<td>47.3</td>
<td>37.0</td>
<td>64.4</td>
<td>55.6</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4</td>
<td>33.2</td>
<td>84.0</td>
<td>39.8</td>
<td>37.0</td>
<td>66.8</td>
<td>29.8</td>
<td>44.2</td>
<td>28.6</td>
<td>52.9</td>
<td>57.8</td>
</tr>
</tbody>
</table>
<h1 id="device-wise-performance">Device-wise performance</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2020 baseline" data-comparison-active-set="Device-wise performance (all)" data-comparison-b-row="Suh_ETRI_task1a_3" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title":"Device-wise performance (all)","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_d","device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Real","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_d"]},
        {"title":"Device-wise performance / Simulated","data_axis_title":"Accuracy","fields":["device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Unseen devices","data_axis_title":"Accuracy","fields":["device_accuracy_eval_d","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Seen devices","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3"]}]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_source_seen" data-scatter-y="accuracy_eval_source_unseen" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell"></th>
<th class="sep-right-cell" colspan="2"></th>
<th class="sep-right-cell" colspan="4"></th>
<th class="sep-right-cell text-center" colspan="5">Unseen devices</th>
<th class="sep-right-cell text-center" colspan="6">Seen devices</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval_source_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>Unseen
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval_source_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>Seen
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_accuracy_eval_d" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">D</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s7" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S7</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s8" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S8</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s9" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S9</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s10" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S10</span>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_accuracy_eval_a" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">A</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_b" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">B</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_c" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">C</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s1" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S1</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s2" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S2</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s3" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S3</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7</td>
<td>56.1</td>
<td>62.7</td>
<td>42.4</td>
<td>61.1</td>
<td>61.9</td>
<td>62.8</td>
<td>52.3</td>
<td>69.3</td>
<td>59.8</td>
<td>64.0</td>
<td>60.5</td>
<td>61.3</td>
<td>61.3</td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6</td>
<td>58.9</td>
<td>62.0</td>
<td>52.4</td>
<td>63.2</td>
<td>59.2</td>
<td>63.9</td>
<td>55.6</td>
<td>65.5</td>
<td>61.0</td>
<td>60.8</td>
<td>59.0</td>
<td>64.6</td>
<td>61.2</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7</td>
<td>63.0</td>
<td>68.0</td>
<td>56.8</td>
<td>70.0</td>
<td>66.0</td>
<td>64.3</td>
<td>58.0</td>
<td>74.4</td>
<td>65.7</td>
<td>70.5</td>
<td>65.5</td>
<td>65.6</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7</td>
<td>62.9</td>
<td>68.0</td>
<td>56.8</td>
<td>69.9</td>
<td>66.0</td>
<td>63.7</td>
<td>57.9</td>
<td>73.9</td>
<td>66.6</td>
<td>70.3</td>
<td>66.1</td>
<td>65.8</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0</td>
<td>62.9</td>
<td>68.5</td>
<td>56.7</td>
<td>69.8</td>
<td>66.3</td>
<td>63.3</td>
<td>58.5</td>
<td>74.4</td>
<td>66.5</td>
<td>71.1</td>
<td>66.3</td>
<td>65.2</td>
<td>67.4</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9</td>
<td>63.0</td>
<td>68.4</td>
<td>57.3</td>
<td>70.0</td>
<td>65.0</td>
<td>63.3</td>
<td>59.2</td>
<td>73.9</td>
<td>66.1</td>
<td>70.7</td>
<td>66.9</td>
<td>65.4</td>
<td>67.5</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4</td>
<td>57.3</td>
<td>68.5</td>
<td>40.9</td>
<td>66.6</td>
<td>62.6</td>
<td>60.6</td>
<td>55.7</td>
<td>75.1</td>
<td>64.7</td>
<td>70.2</td>
<td>67.7</td>
<td>64.9</td>
<td>68.1</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7</td>
<td>53.4</td>
<td>66.9</td>
<td>40.7</td>
<td>61.9</td>
<td>59.8</td>
<td>54.6</td>
<td>49.7</td>
<td>74.7</td>
<td>63.2</td>
<td>68.3</td>
<td>66.4</td>
<td>64.1</td>
<td>64.5</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8</td>
<td>58.1</td>
<td>70.3</td>
<td>41.1</td>
<td>67.5</td>
<td>64.0</td>
<td>61.9</td>
<td>56.2</td>
<td>75.4</td>
<td>65.4</td>
<td>72.6</td>
<td>70.8</td>
<td>67.4</td>
<td>70.2</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5</td>
<td>60.8</td>
<td>73.1</td>
<td>40.5</td>
<td>69.7</td>
<td>69.4</td>
<td>63.3</td>
<td>61.0</td>
<td>78.1</td>
<td>69.5</td>
<td>73.9</td>
<td>71.7</td>
<td>72.7</td>
<td>72.7</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0</td>
<td>73.3</td>
<td>76.5</td>
<td>64.6</td>
<td>76.8</td>
<td>73.9</td>
<td>76.0</td>
<td>75.0</td>
<td>79.7</td>
<td>74.4</td>
<td>78.0</td>
<td>74.2</td>
<td>76.6</td>
<td>76.3</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1</td>
<td>71.9</td>
<td>75.9</td>
<td>61.0</td>
<td>76.6</td>
<td>72.9</td>
<td>74.6</td>
<td>74.5</td>
<td>80.1</td>
<td>73.5</td>
<td>78.1</td>
<td>73.3</td>
<td>75.8</td>
<td>74.8</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7</td>
<td>72.9</td>
<td>76.1</td>
<td>63.1</td>
<td>77.5</td>
<td>74.1</td>
<td>75.2</td>
<td>74.7</td>
<td>79.7</td>
<td>73.5</td>
<td>78.4</td>
<td>74.1</td>
<td>75.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2</td>
<td>73.1</td>
<td>77.0</td>
<td>62.5</td>
<td>77.6</td>
<td>74.4</td>
<td>75.6</td>
<td>75.4</td>
<td>80.3</td>
<td>74.9</td>
<td>78.9</td>
<td>74.7</td>
<td>76.5</td>
<td>76.7</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>51.4</td>
<td>37.2</td>
<td>63.1</td>
<td>22.8</td>
<td>49.8</td>
<td>41.1</td>
<td>31.0</td>
<td>41.3</td>
<td>72.8</td>
<td>61.7</td>
<td>68.9</td>
<td>62.7</td>
<td>54.6</td>
<td>58.2</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4</td>
<td>70.1</td>
<td>76.2</td>
<td>65.0</td>
<td>76.3</td>
<td>74.5</td>
<td>66.9</td>
<td>67.6</td>
<td>81.7</td>
<td>74.6</td>
<td>79.8</td>
<td>72.9</td>
<td>73.8</td>
<td>74.4</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4</td>
<td>63.8</td>
<td>72.3</td>
<td>62.0</td>
<td>72.2</td>
<td>69.1</td>
<td>57.8</td>
<td>58.0</td>
<td>80.7</td>
<td>72.9</td>
<td>76.9</td>
<td>67.6</td>
<td>66.9</td>
<td>68.9</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1</td>
<td>70.2</td>
<td>75.5</td>
<td>66.6</td>
<td>77.3</td>
<td>73.9</td>
<td>66.6</td>
<td>66.8</td>
<td>82.4</td>
<td>74.2</td>
<td>78.8</td>
<td>73.1</td>
<td>71.7</td>
<td>73.1</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3</td>
<td>68.8</td>
<td>75.2</td>
<td>65.6</td>
<td>75.9</td>
<td>73.1</td>
<td>64.4</td>
<td>65.1</td>
<td>81.8</td>
<td>73.9</td>
<td>79.3</td>
<td>71.8</td>
<td>70.9</td>
<td>73.7</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7</td>
<td>74.3</td>
<td>76.8</td>
<td>68.0</td>
<td>76.0</td>
<td>76.4</td>
<td>76.6</td>
<td>74.4</td>
<td>80.0</td>
<td>74.7</td>
<td>77.7</td>
<td>75.0</td>
<td>76.6</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9</td>
<td>74.4</td>
<td>77.2</td>
<td>67.6</td>
<td>76.7</td>
<td>77.7</td>
<td>77.2</td>
<td>72.7</td>
<td>81.6</td>
<td>75.6</td>
<td>79.7</td>
<td>74.6</td>
<td>75.6</td>
<td>75.8</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2</td>
<td>74.7</td>
<td>77.5</td>
<td>68.2</td>
<td>76.6</td>
<td>77.1</td>
<td>77.9</td>
<td>73.6</td>
<td>81.5</td>
<td>75.4</td>
<td>79.8</td>
<td>75.0</td>
<td>76.2</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8</td>
<td>74.3</td>
<td>77.0</td>
<td>67.4</td>
<td>76.2</td>
<td>77.2</td>
<td>77.4</td>
<td>73.2</td>
<td>81.3</td>
<td>75.4</td>
<td>79.5</td>
<td>74.7</td>
<td>75.4</td>
<td>75.6</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3</td>
<td>64.5</td>
<td>69.7</td>
<td>55.2</td>
<td>70.7</td>
<td>68.4</td>
<td>64.8</td>
<td>63.4</td>
<td>74.4</td>
<td>67.4</td>
<td>72.4</td>
<td>68.1</td>
<td>67.9</td>
<td>67.8</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2</td>
<td>64.3</td>
<td>67.7</td>
<td>58.7</td>
<td>68.1</td>
<td>66.2</td>
<td>66.5</td>
<td>61.9</td>
<td>73.6</td>
<td>64.3</td>
<td>69.6</td>
<td>64.9</td>
<td>66.8</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0</td>
<td>73.2</td>
<td>76.5</td>
<td>65.8</td>
<td>76.8</td>
<td>75.0</td>
<td>74.6</td>
<td>74.0</td>
<td>78.5</td>
<td>74.7</td>
<td>79.1</td>
<td>73.8</td>
<td>76.1</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6</td>
<td>69.2</td>
<td>73.5</td>
<td>60.1</td>
<td>73.7</td>
<td>70.7</td>
<td>73.9</td>
<td>67.8</td>
<td>77.6</td>
<td>70.7</td>
<td>78.5</td>
<td>71.6</td>
<td>70.6</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7</td>
<td>68.4</td>
<td>72.7</td>
<td>56.9</td>
<td>75.1</td>
<td>70.0</td>
<td>72.8</td>
<td>67.4</td>
<td>77.7</td>
<td>69.3</td>
<td>75.6</td>
<td>69.2</td>
<td>71.9</td>
<td>72.3</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7</td>
<td>68.3</td>
<td>72.6</td>
<td>60.1</td>
<td>72.5</td>
<td>70.2</td>
<td>71.9</td>
<td>66.9</td>
<td>77.0</td>
<td>70.1</td>
<td>75.9</td>
<td>70.4</td>
<td>70.6</td>
<td>71.7</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4</td>
<td>63.5</td>
<td>68.9</td>
<td>54.7</td>
<td>70.5</td>
<td>67.4</td>
<td>67.5</td>
<td>57.5</td>
<td>74.7</td>
<td>66.0</td>
<td>72.4</td>
<td>64.4</td>
<td>67.6</td>
<td>68.0</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9</td>
<td>68.4</td>
<td>74.9</td>
<td>54.4</td>
<td>74.4</td>
<td>72.0</td>
<td>70.6</td>
<td>70.5</td>
<td>79.7</td>
<td>72.7</td>
<td>73.9</td>
<td>74.1</td>
<td>73.4</td>
<td>75.6</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6</td>
<td>66.9</td>
<td>75.5</td>
<td>49.4</td>
<td>74.3</td>
<td>71.1</td>
<td>71.5</td>
<td>68.1</td>
<td>78.1</td>
<td>72.9</td>
<td>77.4</td>
<td>74.8</td>
<td>74.9</td>
<td>74.8</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6</td>
<td>69.8</td>
<td>76.8</td>
<td>52.9</td>
<td>77.6</td>
<td>74.0</td>
<td>74.3</td>
<td>70.1</td>
<td>80.6</td>
<td>74.8</td>
<td>77.6</td>
<td>76.2</td>
<td>75.4</td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4</td>
<td>69.4</td>
<td>76.7</td>
<td>52.9</td>
<td>76.8</td>
<td>73.9</td>
<td>73.4</td>
<td>70.1</td>
<td>80.5</td>
<td>74.9</td>
<td>78.1</td>
<td>75.4</td>
<td>75.1</td>
<td>76.5</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2</td>
<td>66.2</td>
<td>71.6</td>
<td>53.7</td>
<td>71.6</td>
<td>69.4</td>
<td>68.8</td>
<td>67.7</td>
<td>76.1</td>
<td>69.4</td>
<td>74.2</td>
<td>70.4</td>
<td>70.6</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6</td>
<td>66.5</td>
<td>72.3</td>
<td>54.5</td>
<td>71.0</td>
<td>70.4</td>
<td>67.8</td>
<td>68.8</td>
<td>77.5</td>
<td>69.4</td>
<td>74.4</td>
<td>71.4</td>
<td>70.6</td>
<td>70.4</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0</td>
<td>69.3</td>
<td>74.3</td>
<td>61.1</td>
<td>75.4</td>
<td>71.2</td>
<td>68.1</td>
<td>70.6</td>
<td>78.1</td>
<td>71.6</td>
<td>76.0</td>
<td>74.4</td>
<td>71.8</td>
<td>73.8</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9</td>
<td>69.8</td>
<td>75.5</td>
<td>60.2</td>
<td>76.1</td>
<td>72.5</td>
<td>69.7</td>
<td>70.4</td>
<td>79.8</td>
<td>73.2</td>
<td>77.2</td>
<td>74.5</td>
<td>74.2</td>
<td>74.2</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9</td>
<td>46.4</td>
<td>63.8</td>
<td>30.4</td>
<td>52.0</td>
<td>52.6</td>
<td>44.0</td>
<td>53.0</td>
<td>73.9</td>
<td>64.1</td>
<td>68.8</td>
<td>62.7</td>
<td>55.6</td>
<td>58.1</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6</td>
<td>45.7</td>
<td>63.8</td>
<td>29.8</td>
<td>50.4</td>
<td>52.8</td>
<td>43.7</td>
<td>52.0</td>
<td>75.4</td>
<td>62.5</td>
<td>69.6</td>
<td>61.4</td>
<td>56.1</td>
<td>57.6</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6</td>
<td>45.5</td>
<td>64.0</td>
<td>28.1</td>
<td>54.1</td>
<td>55.5</td>
<td>40.7</td>
<td>48.9</td>
<td>74.4</td>
<td>64.0</td>
<td>67.5</td>
<td>61.1</td>
<td>57.9</td>
<td>59.4</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9</td>
<td>44.7</td>
<td>63.5</td>
<td>26.6</td>
<td>52.4</td>
<td>55.0</td>
<td>41.7</td>
<td>47.9</td>
<td>74.3</td>
<td>63.1</td>
<td>68.8</td>
<td>60.4</td>
<td>56.9</td>
<td>57.5</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3</td>
<td>65.1</td>
<td>72.7</td>
<td>50.7</td>
<td>74.4</td>
<td>69.4</td>
<td>67.3</td>
<td>63.8</td>
<td>76.5</td>
<td>70.1</td>
<td>72.1</td>
<td>73.0</td>
<td>71.8</td>
<td>73.0</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0</td>
<td>64.9</td>
<td>70.6</td>
<td>55.9</td>
<td>70.0</td>
<td>66.1</td>
<td>66.3</td>
<td>66.0</td>
<td>74.7</td>
<td>69.8</td>
<td>71.3</td>
<td>68.6</td>
<td>70.1</td>
<td>69.3</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7</td>
<td>46.8</td>
<td>63.1</td>
<td>40.3</td>
<td>55.7</td>
<td>56.3</td>
<td>35.0</td>
<td>46.8</td>
<td>74.4</td>
<td>65.6</td>
<td>70.6</td>
<td>55.3</td>
<td>56.8</td>
<td>55.6</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0</td>
<td>67.5</td>
<td>75.8</td>
<td>52.6</td>
<td>76.4</td>
<td>71.8</td>
<td>70.0</td>
<td>66.8</td>
<td>79.0</td>
<td>73.7</td>
<td>76.4</td>
<td>76.3</td>
<td>74.1</td>
<td>75.3</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2</td>
<td>71.9</td>
<td>74.3</td>
<td>66.1</td>
<td>75.1</td>
<td>71.5</td>
<td>75.6</td>
<td>71.4</td>
<td>78.3</td>
<td>71.7</td>
<td>76.6</td>
<td>73.3</td>
<td>74.0</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4</td>
<td>71.1</td>
<td>73.5</td>
<td>64.4</td>
<td>74.2</td>
<td>71.1</td>
<td>74.8</td>
<td>71.0</td>
<td>77.4</td>
<td>70.6</td>
<td>75.3</td>
<td>73.3</td>
<td>72.6</td>
<td>71.7</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5</td>
<td>71.3</td>
<td>73.5</td>
<td>65.2</td>
<td>75.0</td>
<td>71.0</td>
<td>75.0</td>
<td>70.3</td>
<td>77.8</td>
<td>70.3</td>
<td>77.1</td>
<td>71.7</td>
<td>72.3</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0</td>
<td>70.3</td>
<td>73.4</td>
<td>63.8</td>
<td>73.2</td>
<td>70.9</td>
<td>73.3</td>
<td>70.4</td>
<td>78.0</td>
<td>70.2</td>
<td>76.8</td>
<td>71.0</td>
<td>72.8</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3</td>
<td>60.9</td>
<td>67.1</td>
<td>54.2</td>
<td>68.2</td>
<td>65.1</td>
<td>60.0</td>
<td>57.0</td>
<td>76.4</td>
<td>64.4</td>
<td>68.5</td>
<td>63.8</td>
<td>62.7</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1</td>
<td>61.1</td>
<td>66.7</td>
<td>54.1</td>
<td>67.8</td>
<td>64.5</td>
<td>60.6</td>
<td>58.6</td>
<td>75.5</td>
<td>64.4</td>
<td>68.9</td>
<td>62.9</td>
<td>62.1</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2</td>
<td>68.8</td>
<td>73.2</td>
<td>66.0</td>
<td>74.4</td>
<td>71.0</td>
<td>62.6</td>
<td>69.7</td>
<td>79.2</td>
<td>72.5</td>
<td>73.2</td>
<td>70.5</td>
<td>70.7</td>
<td>73.2</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1</td>
<td>60.8</td>
<td>66.9</td>
<td>61.2</td>
<td>65.6</td>
<td>64.4</td>
<td>53.2</td>
<td>59.6</td>
<td>73.1</td>
<td>68.1</td>
<td>68.8</td>
<td>63.3</td>
<td>62.4</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4</td>
<td>63.3</td>
<td>68.9</td>
<td>63.1</td>
<td>68.1</td>
<td>67.1</td>
<td>56.5</td>
<td>61.8</td>
<td>74.7</td>
<td>68.0</td>
<td>70.8</td>
<td>66.7</td>
<td>64.4</td>
<td>68.9</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2</td>
<td>68.8</td>
<td>73.3</td>
<td>66.0</td>
<td>74.4</td>
<td>70.7</td>
<td>63.6</td>
<td>69.4</td>
<td>79.6</td>
<td>73.1</td>
<td>73.8</td>
<td>70.6</td>
<td>70.3</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7</td>
<td>59.4</td>
<td>63.6</td>
<td>46.8</td>
<td>63.0</td>
<td>60.6</td>
<td>65.6</td>
<td>60.9</td>
<td>68.0</td>
<td>61.5</td>
<td>63.2</td>
<td>62.3</td>
<td>64.2</td>
<td>62.7</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9</td>
<td>51.8</td>
<td>59.3</td>
<td>32.1</td>
<td>59.0</td>
<td>56.9</td>
<td>58.7</td>
<td>52.2</td>
<td>65.6</td>
<td>56.1</td>
<td>57.3</td>
<td>57.9</td>
<td>59.9</td>
<td>59.0</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8</td>
<td>44.5</td>
<td>56.1</td>
<td>37.5</td>
<td>47.4</td>
<td>45.6</td>
<td>46.8</td>
<td>45.2</td>
<td>64.8</td>
<td>57.7</td>
<td>60.4</td>
<td>51.8</td>
<td>51.0</td>
<td>51.1</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3</td>
<td>63.2</td>
<td>69.0</td>
<td>50.2</td>
<td>66.5</td>
<td>65.5</td>
<td>68.3</td>
<td>65.6</td>
<td>74.7</td>
<td>66.7</td>
<td>68.5</td>
<td>68.0</td>
<td>68.9</td>
<td>67.0</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9</td>
<td>55.9</td>
<td>66.9</td>
<td>45.6</td>
<td>62.5</td>
<td>60.3</td>
<td>53.3</td>
<td>57.6</td>
<td>74.9</td>
<td>65.9</td>
<td>70.8</td>
<td>63.3</td>
<td>63.2</td>
<td>63.1</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7</td>
<td>54.0</td>
<td>64.5</td>
<td>52.4</td>
<td>60.0</td>
<td>61.2</td>
<td>54.1</td>
<td>42.3</td>
<td>73.6</td>
<td>66.0</td>
<td>68.2</td>
<td>59.5</td>
<td>59.7</td>
<td>59.8</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8</td>
<td>36.0</td>
<td>50.3</td>
<td>28.1</td>
<td>42.2</td>
<td>40.1</td>
<td>33.9</td>
<td>35.5</td>
<td>60.6</td>
<td>46.9</td>
<td>52.0</td>
<td>47.2</td>
<td>47.0</td>
<td>47.8</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7</td>
<td>69.0</td>
<td>74.0</td>
<td>57.4</td>
<td>72.8</td>
<td>71.4</td>
<td>72.8</td>
<td>70.6</td>
<td>78.7</td>
<td>72.2</td>
<td>75.4</td>
<td>73.1</td>
<td>72.9</td>
<td>71.5</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5</td>
<td>68.4</td>
<td>74.2</td>
<td>56.2</td>
<td>72.4</td>
<td>70.8</td>
<td>72.5</td>
<td>69.8</td>
<td>79.4</td>
<td>71.7</td>
<td>76.1</td>
<td>73.4</td>
<td>73.1</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5</td>
<td>64.9</td>
<td>71.4</td>
<td>49.6</td>
<td>69.1</td>
<td>68.1</td>
<td>69.8</td>
<td>68.0</td>
<td>75.7</td>
<td>69.7</td>
<td>72.9</td>
<td>71.0</td>
<td>70.3</td>
<td>69.0</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0</td>
<td>68.2</td>
<td>73.3</td>
<td>56.2</td>
<td>71.9</td>
<td>71.9</td>
<td>72.4</td>
<td>68.8</td>
<td>79.3</td>
<td>71.1</td>
<td>76.2</td>
<td>71.7</td>
<td>72.0</td>
<td>69.8</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5</td>
<td>69.9</td>
<td>74.6</td>
<td>62.1</td>
<td>73.9</td>
<td>71.3</td>
<td>72.3</td>
<td>69.8</td>
<td>78.5</td>
<td>73.5</td>
<td>78.2</td>
<td>71.2</td>
<td>72.2</td>
<td>74.1</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5</td>
<td>73.6</td>
<td>77.0</td>
<td>66.0</td>
<td>76.1</td>
<td>75.5</td>
<td>76.1</td>
<td>74.5</td>
<td>79.7</td>
<td>74.6</td>
<td>79.0</td>
<td>75.3</td>
<td>76.5</td>
<td>76.7</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5</td>
<td>74.6</td>
<td>78.1</td>
<td>65.6</td>
<td>78.0</td>
<td>75.6</td>
<td>77.6</td>
<td>76.3</td>
<td>81.1</td>
<td>75.6</td>
<td>80.0</td>
<td>76.3</td>
<td>77.6</td>
<td>77.9</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5</td>
<td>74.7</td>
<td>77.9</td>
<td>65.8</td>
<td>78.2</td>
<td>75.6</td>
<td>77.6</td>
<td>76.4</td>
<td>81.1</td>
<td>75.6</td>
<td>79.6</td>
<td>76.4</td>
<td>77.4</td>
<td>77.5</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1</td>
<td>64.0</td>
<td>69.6</td>
<td>49.6</td>
<td>68.0</td>
<td>67.6</td>
<td>70.4</td>
<td>64.6</td>
<td>72.7</td>
<td>69.0</td>
<td>70.5</td>
<td>67.5</td>
<td>70.8</td>
<td>67.0</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5</td>
<td>66.5</td>
<td>72.0</td>
<td>55.0</td>
<td>70.4</td>
<td>71.5</td>
<td>71.1</td>
<td>64.5</td>
<td>77.3</td>
<td>71.1</td>
<td>71.9</td>
<td>70.7</td>
<td>71.3</td>
<td>69.9</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3</td>
<td>68.2</td>
<td>72.0</td>
<td>56.4</td>
<td>72.6</td>
<td>73.0</td>
<td>73.7</td>
<td>65.5</td>
<td>75.6</td>
<td>68.9</td>
<td>72.3</td>
<td>71.2</td>
<td>72.8</td>
<td>71.0</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8</td>
<td>69.0</td>
<td>74.2</td>
<td>55.9</td>
<td>74.4</td>
<td>74.4</td>
<td>73.6</td>
<td>66.9</td>
<td>78.1</td>
<td>72.2</td>
<td>74.0</td>
<td>73.1</td>
<td>75.0</td>
<td>72.7</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7</td>
<td>63.5</td>
<td>71.2</td>
<td>60.6</td>
<td>68.1</td>
<td>62.9</td>
<td>59.9</td>
<td>65.8</td>
<td>78.1</td>
<td>69.2</td>
<td>75.6</td>
<td>67.4</td>
<td>68.6</td>
<td>68.3</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8</td>
<td>63.0</td>
<td>71.8</td>
<td>54.4</td>
<td>68.4</td>
<td>63.4</td>
<td>63.0</td>
<td>65.9</td>
<td>77.4</td>
<td>69.8</td>
<td>74.4</td>
<td>69.7</td>
<td>70.6</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3</td>
<td>65.3</td>
<td>72.6</td>
<td>59.9</td>
<td>70.3</td>
<td>64.9</td>
<td>63.2</td>
<td>68.2</td>
<td>79.1</td>
<td>69.4</td>
<td>75.5</td>
<td>70.0</td>
<td>70.7</td>
<td>71.0</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4</td>
<td>52.9</td>
<td>62.9</td>
<td>50.8</td>
<td>57.8</td>
<td>59.2</td>
<td>47.5</td>
<td>49.3</td>
<td>68.2</td>
<td>59.8</td>
<td>66.9</td>
<td>59.3</td>
<td>62.0</td>
<td>61.0</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7</td>
<td>54.8</td>
<td>58.2</td>
<td>47.3</td>
<td>58.6</td>
<td>57.5</td>
<td>56.4</td>
<td>54.4</td>
<td>65.0</td>
<td>55.4</td>
<td>61.9</td>
<td>57.4</td>
<td>53.7</td>
<td>55.7</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2</td>
<td>63.0</td>
<td>67.0</td>
<td>56.8</td>
<td>67.2</td>
<td>63.0</td>
<td>65.4</td>
<td>62.6</td>
<td>74.1</td>
<td>63.3</td>
<td>70.8</td>
<td>64.5</td>
<td>62.6</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0</td>
<td>60.0</td>
<td>67.3</td>
<td>56.8</td>
<td>65.5</td>
<td>63.3</td>
<td>57.2</td>
<td>57.1</td>
<td>75.7</td>
<td>65.7</td>
<td>70.3</td>
<td>65.2</td>
<td>63.2</td>
<td>63.5</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5</td>
<td>42.9</td>
<td>47.7</td>
<td>40.4</td>
<td>46.7</td>
<td>47.3</td>
<td>40.3</td>
<td>39.8</td>
<td>52.2</td>
<td>47.0</td>
<td>50.5</td>
<td>42.6</td>
<td>46.6</td>
<td>47.2</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7</td>
<td>60.0</td>
<td>68.7</td>
<td>47.7</td>
<td>63.8</td>
<td>64.2</td>
<td>65.4</td>
<td>58.8</td>
<td>76.7</td>
<td>64.4</td>
<td>71.1</td>
<td>66.2</td>
<td>66.3</td>
<td>67.4</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3</td>
<td>63.0</td>
<td>74.5</td>
<td>48.1</td>
<td>70.7</td>
<td>70.1</td>
<td>68.6</td>
<td>57.3</td>
<td>80.4</td>
<td>73.0</td>
<td>77.7</td>
<td>71.3</td>
<td>71.9</td>
<td>72.8</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9</td>
<td>62.7</td>
<td>72.3</td>
<td>50.2</td>
<td>68.0</td>
<td>68.9</td>
<td>68.6</td>
<td>58.1</td>
<td>78.9</td>
<td>68.6</td>
<td>73.8</td>
<td>70.7</td>
<td>71.2</td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4</td>
<td>63.6</td>
<td>74.3</td>
<td>49.4</td>
<td>70.4</td>
<td>69.8</td>
<td>69.2</td>
<td>59.2</td>
<td>80.6</td>
<td>71.0</td>
<td>75.9</td>
<td>72.4</td>
<td>73.8</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0</td>
<td>69.9</td>
<td>75.6</td>
<td>59.2</td>
<td>75.8</td>
<td>71.7</td>
<td>72.4</td>
<td>70.4</td>
<td>80.4</td>
<td>73.7</td>
<td>79.3</td>
<td>74.4</td>
<td>71.9</td>
<td>74.1</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2</td>
<td>70.0</td>
<td>75.8</td>
<td>59.0</td>
<td>75.9</td>
<td>71.3</td>
<td>72.7</td>
<td>71.0</td>
<td>80.6</td>
<td>73.9</td>
<td>79.4</td>
<td>74.1</td>
<td>72.3</td>
<td>74.6</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3</td>
<td>68.8</td>
<td>75.2</td>
<td>55.6</td>
<td>75.4</td>
<td>71.3</td>
<td>71.9</td>
<td>69.9</td>
<td>80.0</td>
<td>72.7</td>
<td>78.7</td>
<td>72.9</td>
<td>73.4</td>
<td>73.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4</td>
<td>35.8</td>
<td>62.5</td>
<td>20.9</td>
<td>46.8</td>
<td>45.1</td>
<td>28.3</td>
<td>38.0</td>
<td>73.5</td>
<td>62.7</td>
<td>68.5</td>
<td>58.1</td>
<td>52.4</td>
<td>59.7</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7</td>
<td>37.5</td>
<td>63.5</td>
<td>21.6</td>
<td>52.0</td>
<td>45.1</td>
<td>28.3</td>
<td>40.6</td>
<td>72.6</td>
<td>63.6</td>
<td>68.3</td>
<td>61.5</td>
<td>55.4</td>
<td>59.6</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4</td>
<td>32.2</td>
<td>60.1</td>
<td>19.1</td>
<td>44.0</td>
<td>37.2</td>
<td>22.4</td>
<td>38.2</td>
<td>71.0</td>
<td>61.5</td>
<td>64.8</td>
<td>55.0</td>
<td>53.9</td>
<td>54.4</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<h2 id="general-characteristics">General characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label 
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data <br/>augmentation
            </th>
<th class="text-center narrow-col" data-field="system_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Features
            </th>
<th class="text-center narrow-col" data-field="system_embeddings" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Embeddings
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>log-mel spectrogram, gamma-tone spectrogram, CQT</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>log-mel spectrogram, gamma-tone spectrogram, CQT</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>log-mel spectrogram, gamma-tone spectrogram, CQT</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>log-mel spectrogram, gamma-tone spectrogram, CQT</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4</td>
<td>4kHz</td>
<td>mixup, time shifting</td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7</td>
<td>8kHz</td>
<td>mixup, time shifting</td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8</td>
<td>4kHz, 8kHz</td>
<td>mixup, time shifting</td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5</td>
<td>4kHz, 8kHz</td>
<td>mixup, time shifting</td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>51.4</td>
<td>44.1kHz</td>
<td></td>
<td></td>
<td>OpenL3</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>MFCC, log-mel energies, CQT, Gammatone</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>MFCC, log-mel energies, CQT, Gammatone</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>MFCC, log-mel energies, CQT, Gammatone</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>MFCC, log-mel energies, CQT, Gammatone</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shift, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shift, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shift, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shift, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3</td>
<td>44.1kHz</td>
<td>subtract filter</td>
<td>HPSS, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2</td>
<td>44.1kHz</td>
<td>subtract filter</td>
<td>HPSS, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, class-wise random masking</td>
<td>log-mel energies, deltas, delta-deltas, multiple channel feature</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, class-wise random masking</td>
<td>log-mel energies, deltas, delta-deltas, multiple channel feature</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, class-wise random masking</td>
<td>log-mel energies, deltas, delta-deltas, multiple channel feature</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, class-wise random masking</td>
<td>log-mel energies, deltas, delta-deltas, multiple channel feature</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9</td>
<td>44.1kHz</td>
<td>mixup, time masking, frequency masking</td>
<td></td>
<td>OpenL3 (env)</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6</td>
<td>44.1kHz</td>
<td>mixup, time masking, frequency masking</td>
<td></td>
<td>OpenL3 (env)</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6</td>
<td>44.1kHz</td>
<td>mixup, time masking, frequency masking</td>
<td></td>
<td>OpenL3 (music)</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9</td>
<td>44.1kHz</td>
<td>mixup, time masking, frequency masking</td>
<td></td>
<td>OpenL3 (music)</td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3</td>
<td>22.05kHz</td>
<td>mixup, deviceaugment</td>
<td>perceptual weighted power spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>perceptual weighted power spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7</td>
<td>44.1kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0</td>
<td>22.05kHz,44.1kHz</td>
<td>mixup, deviceaugment</td>
<td>perceptual weighted power spectrogram</td>
<td>OpenL3</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2</td>
<td>44.1kHz</td>
<td>HPSS,NNF,vocal separation,HRTF</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4</td>
<td>44.1kHz</td>
<td>HPSS,NNF,vocal separation,HRTF</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5</td>
<td>44.1kHz</td>
<td>HPSS,NNF,vocal separation,HRTF</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0</td>
<td>44.1kHz</td>
<td>HPSS,NNF,vocal separation,HRTF</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3</td>
<td>16kHz</td>
<td>random noise, random gain, random cropping, mixup, SpecAugment</td>
<td>raw waveform, mel filterbank</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1</td>
<td>16kHz</td>
<td>random noise, random gain, random cropping, mixup, SpecAugment</td>
<td>raw waveform, mel filterbank</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2</td>
<td>32kHz</td>
<td>mixup, weight decay, dropout, SpecAugment</td>
<td>mel spectrogram, CQT</td>
<td>None</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1</td>
<td>32kHz</td>
<td>mixup, weight decay, dropout, SpecAugment</td>
<td>mel spectrogram, CQT</td>
<td>None</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4</td>
<td>32kHz</td>
<td>mixup, weight decay, dropout, SpecAugment</td>
<td>mel spectrogram, CQT</td>
<td>None</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2</td>
<td>32kHz</td>
<td>mixup, weight decay, dropout, SpecAugment</td>
<td>mel spectrogram, CQT</td>
<td>None</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7</td>
<td>44.1kHz</td>
<td>Sox distortions, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9</td>
<td>44.1kHz</td>
<td>Sox distortions, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8</td>
<td>44.1kHz</td>
<td>Sox distortions, SpecAugment</td>
<td>modulation spectra</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3</td>
<td>44.1kHz</td>
<td>Sox distortions, SpecAugment</td>
<td>log-mel energies, modulation spectra</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>Gammatone</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>HPSS, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8</td>
<td>44.1kHz</td>
<td></td>
<td>LTAS, envelope modulation spectrum</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>mel spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5</td>
<td>44.1kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5</td>
<td>44.1kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5</td>
<td>44.1kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5</td>
<td>44.1kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, random resize, random cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, random resize, random cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, random resize, random cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, random resize, random cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies, PCEN</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8</td>
<td>44.1kHz</td>
<td>mixup, time stretching, frequency masking, shifting, clipping distortion</td>
<td>log-mel energies, PCEN</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3</td>
<td>44.1kHz</td>
<td>mixup, time stretching, frequency masking, shifting, clipping distortion</td>
<td>log-mel energies, PCEN</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4</td>
<td>44.1kHz</td>
<td></td>
<td>MFDWC</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7</td>
<td>44.1kHz</td>
<td>mixup, spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2</td>
<td>44.1kHz</td>
<td>mixup, spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0</td>
<td>44.1kHz</td>
<td>mixup, spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5</td>
<td>44.1kHz</td>
<td>mixup, spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0</td>
<td>44.1kHz</td>
<td>mixup, ImageDataGenerator, temporal cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2</td>
<td>44.1kHz</td>
<td>mixup, ImageDataGenerator, temporal cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3</td>
<td>44.1kHz</td>
<td>mixup, ImageDataGenerator, temporal cropping</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td>OpenL3</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td>OpenL3</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td>OpenL3</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="machine-learning-characteristics">Machine learning characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="system_complexity_total" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_external_data_usage" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data usage
            </th>
<th class="text-center narrow-col" data-field="external_data_sources" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data sources
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total" data-sortable="true" data-value-type="numeric-unit">
                Model <br/>complexity
            </th>
<th class="text-center narrow-col" data-field="system_classifier" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Classifier
            </th>
<th class="text-center narrow-col" data-chartable="true" data-field="system_ensemble_method_subsystem_count" data-sortable="true" data-value-type="int">
                Ensemble <br/>subsystems
            </th>
<th class="text-center narrow-col" data-field="system_decision_making" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Decision <br/>making
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_1</td>
<td>Abbasi2020</td>
<td>78</td>
<td>59.7</td>
<td></td>
<td></td>
<td>180310</td>
<td>CNN,ensemble</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Abbasi_ARI_task1a_2</td>
<td>Abbasi2020</td>
<td>76</td>
<td>60.6</td>
<td></td>
<td></td>
<td>180310</td>
<td>CNN, ensemble, XGBoost</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_1</td>
<td>Fei2020</td>
<td>63</td>
<td>65.7</td>
<td></td>
<td></td>
<td>2631282</td>
<td>CNN, 2-DenseNet</td>
<td>5</td>
<td>majority vote</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_2</td>
<td>Fei2020</td>
<td>64</td>
<td>65.7</td>
<td></td>
<td></td>
<td>2631282</td>
<td>CNN,2-DenseNet</td>
<td>5</td>
<td>majority vote</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_3</td>
<td>Fei2020</td>
<td>61</td>
<td>66.0</td>
<td></td>
<td></td>
<td>5094806</td>
<td>CNN,2-DenseNet</td>
<td>7</td>
<td>majority vote</td>
</tr>
<tr>
<td></td>
<td>Cao_JNU_task1a_4</td>
<td>Fei2020</td>
<td>62</td>
<td>65.9</td>
<td></td>
<td></td>
<td>5094806</td>
<td>CNN,2-DenseNet</td>
<td>7</td>
<td>majority vote</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_1</td>
<td>Fanioudakis2020</td>
<td>72</td>
<td>63.4</td>
<td></td>
<td></td>
<td>20477140</td>
<td>CRNN</td>
<td></td>
<td>sample-based average</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_2</td>
<td>Fanioudakis2020</td>
<td>75</td>
<td>60.7</td>
<td></td>
<td></td>
<td>20477140</td>
<td>CRNN</td>
<td></td>
<td>sample-based average</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_3</td>
<td>Fanioudakis2020</td>
<td>66</td>
<td>64.8</td>
<td></td>
<td></td>
<td>20477140</td>
<td>CRNN</td>
<td>2</td>
<td>sample average with weights</td>
</tr>
<tr>
<td></td>
<td>FanVaf__task1a_4</td>
<td>Fanioudakis2020</td>
<td>54</td>
<td>67.5</td>
<td></td>
<td></td>
<td>20477140</td>
<td>CRNN</td>
<td>2</td>
<td>sample average with weights</td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_1</td>
<td>Gao2020</td>
<td>9</td>
<td>75.0</td>
<td></td>
<td></td>
<td>4311732</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_2</td>
<td>Gao2020</td>
<td>12</td>
<td>74.1</td>
<td></td>
<td></td>
<td>4311732</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_3</td>
<td>Gao2020</td>
<td>11</td>
<td>74.7</td>
<td></td>
<td></td>
<td>4312628# embeddings (OpenL2)=4684224, classifier=328707</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Gao_UNISA_task1a_4</td>
<td>Gao2020</td>
<td>8</td>
<td>75.2</td>
<td></td>
<td></td>
<td>12936092</td>
<td>ResNet, ensemble</td>
<td>3</td>
<td>average</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>51.4</td>
<td>embeddings</td>
<td></td>
<td>5012931</td>
<td>MLP</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_1</td>
<td>Wang2020_t1</td>
<td>14</td>
<td>73.4</td>
<td>directly</td>
<td>AudioSet</td>
<td>341229835</td>
<td>CNN, ensemble</td>
<td>9</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_2</td>
<td>Wang2020_t1</td>
<td>49</td>
<td>68.4</td>
<td></td>
<td></td>
<td>839596544</td>
<td>CNN, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_3</td>
<td>Wang2020_t1</td>
<td>18</td>
<td>73.1</td>
<td>directly</td>
<td>AudioSet</td>
<td>361028107</td>
<td>CNN, ensemble</td>
<td>13</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1a_4</td>
<td>Wang2020_t1</td>
<td>24</td>
<td>72.3</td>
<td>directly</td>
<td>AudioSet</td>
<td>380826379</td>
<td>CNN, ensemble</td>
<td>17</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_1</td>
<td>Hu2020</td>
<td>6</td>
<td>75.7</td>
<td></td>
<td></td>
<td>62525968</td>
<td>CNN, ResNet, ensemble</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_2</td>
<td>Hu2020</td>
<td>4</td>
<td>75.9</td>
<td></td>
<td></td>
<td>67763768</td>
<td>CNN, ResNet, ensemble</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_3</td>
<td>Hu2020</td>
<td>3</td>
<td>76.2</td>
<td></td>
<td></td>
<td>130289736</td>
<td>CNN, ResNet, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1a_4</td>
<td>Hu2020</td>
<td>5</td>
<td>75.8</td>
<td></td>
<td></td>
<td>91251960</td>
<td>CNN, ResNet, ensemble</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_1</td>
<td>Kim2020_t1</td>
<td>55</td>
<td>67.3</td>
<td>pre-trained model</td>
<td></td>
<td>115300</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>JHKim_IVS_task1a_2</td>
<td>Kim2020_t1</td>
<td>60</td>
<td>66.2</td>
<td>pre-trained model</td>
<td></td>
<td>31600</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jie_Maxvision_task1a_1</td>
<td>Jie2020</td>
<td>10</td>
<td>75.0</td>
<td></td>
<td></td>
<td>3584924</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_1</td>
<td>Changmin2020</td>
<td>33</td>
<td>71.6</td>
<td></td>
<td></td>
<td>3254028</td>
<td>Residual CNN</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_2</td>
<td>Changmin2020</td>
<td>38</td>
<td>70.7</td>
<td></td>
<td></td>
<td>3254908</td>
<td>Residual CNN</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_3</td>
<td>Changmin2020</td>
<td>39</td>
<td>70.7</td>
<td></td>
<td></td>
<td>6352740</td>
<td>Residual CNN</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Kim_SGU_task1a_4</td>
<td>Changmin2020</td>
<td>57</td>
<td>66.4</td>
<td></td>
<td></td>
<td>3255788</td>
<td>Residual CNN</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2020</td>
<td>29</td>
<td>71.9</td>
<td></td>
<td></td>
<td>19702400</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2020</td>
<td>32</td>
<td>71.6</td>
<td></td>
<td></td>
<td>36783360</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2020</td>
<td>13</td>
<td>73.6</td>
<td></td>
<td></td>
<td>225943040</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2020</td>
<td>15</td>
<td>73.4</td>
<td></td>
<td></td>
<td>225943040</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_1</td>
<td>Lee2020</td>
<td>47</td>
<td>69.2</td>
<td></td>
<td></td>
<td>10088328‬</td>
<td>CNN, ResNet, LCNN, InceptionLike, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_2</td>
<td>Lee2020</td>
<td>41</td>
<td>69.6</td>
<td></td>
<td></td>
<td>10088328‬</td>
<td>CNN</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_3</td>
<td>Lee2020</td>
<td>27</td>
<td>72.0</td>
<td></td>
<td></td>
<td>10088328‬</td>
<td>CNN, ResNet, LCNN, InceptionLike, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1a_4</td>
<td>Lee2020</td>
<td>20</td>
<td>72.9</td>
<td></td>
<td></td>
<td>10088328‬</td>
<td>CNN, ResNet, LCNN, InceptionLike, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_1</td>
<td>Aryal2020</td>
<td>81</td>
<td>55.9</td>
<td>embeddings</td>
<td></td>
<td>15940046</td>
<td>ResNet, Attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_2</td>
<td>Aryal2020</td>
<td>85</td>
<td>55.6</td>
<td>embeddings</td>
<td></td>
<td>15940046</td>
<td>ResNet, Attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_3</td>
<td>Aryal2020</td>
<td>84</td>
<td>55.6</td>
<td>embeddings</td>
<td></td>
<td>15940046</td>
<td>ResNet, Attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_GU_task1a_4</td>
<td>Aryal2020</td>
<td>86</td>
<td>54.9</td>
<td>embeddings</td>
<td></td>
<td>15940046</td>
<td>ResNet, Attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_1</td>
<td>Liu2020</td>
<td>45</td>
<td>69.3</td>
<td></td>
<td></td>
<td>3563412</td>
<td>ResNet , Receptive Field Regularization</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_2</td>
<td>Liu2020</td>
<td>50</td>
<td>68.0</td>
<td></td>
<td></td>
<td>4691274</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_3</td>
<td>Liu2020</td>
<td>83</td>
<td>55.7</td>
<td></td>
<td></td>
<td>8756749</td>
<td>Self-attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_SHNU_task1a_4</td>
<td>Liu2020</td>
<td>26</td>
<td>72.0</td>
<td>embeddings</td>
<td></td>
<td>13267617</td>
<td>ResNet , Receptive Field Regularization, CNN , MLP</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2020a</td>
<td>16</td>
<td>73.2</td>
<td></td>
<td></td>
<td>26023864</td>
<td>ResNet</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2020a</td>
<td>23</td>
<td>72.4</td>
<td></td>
<td></td>
<td>58559744</td>
<td>ResNet</td>
<td>18</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2020a</td>
<td>21</td>
<td>72.5</td>
<td></td>
<td></td>
<td>26023864</td>
<td>ResNet</td>
<td>8</td>
<td>stacking</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2020a</td>
<td>28</td>
<td>72.0</td>
<td></td>
<td></td>
<td>58559744</td>
<td>ResNet</td>
<td>18</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_1</td>
<td>Lopez-Meyer2020_t1a</td>
<td>68</td>
<td>64.3</td>
<td>directly</td>
<td>AudioSet</td>
<td>39998697</td>
<td>CNN, ResNet, VGG, ensemble</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1a_2</td>
<td>Lopez-Meyer2020_t1a</td>
<td>70</td>
<td>64.1</td>
<td>directly</td>
<td>AudioSet</td>
<td>39998697</td>
<td>CNN, ResNet, VGG, ensemble</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_1</td>
<td>Hong2020</td>
<td>36</td>
<td>71.2</td>
<td>pre-trained model</td>
<td>AudioSet</td>
<td>27184858</td>
<td>ResNext</td>
<td>10</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_2</td>
<td>Hong2020</td>
<td>69</td>
<td>64.1</td>
<td>pre-trained model</td>
<td>AudioSet</td>
<td>27184858</td>
<td>ResNext</td>
<td>None</td>
<td>softmax</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_3</td>
<td>Hong2020</td>
<td>58</td>
<td>66.4</td>
<td>pre-trained model</td>
<td>AudioSet</td>
<td>27184858</td>
<td>ResNext</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Lu_INTC_task1a_4</td>
<td>Hong2020</td>
<td>35</td>
<td>71.2</td>
<td>pre-trained model</td>
<td>AudioSet</td>
<td>27184858</td>
<td>ResNext</td>
<td>12</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_1</td>
<td>Joao2020</td>
<td>74</td>
<td>61.7</td>
<td></td>
<td></td>
<td>4978634</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_2</td>
<td>Joao2020</td>
<td>82</td>
<td>55.9</td>
<td></td>
<td></td>
<td>4522398</td>
<td>TDNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_3</td>
<td>Joao2020</td>
<td>88</td>
<td>50.8</td>
<td></td>
<td></td>
<td>20731100</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1a_4</td>
<td>Joao2020</td>
<td>59</td>
<td>66.3</td>
<td></td>
<td></td>
<td>20731100</td>
<td>CNN, ResNet12, ResNet18, TDNN</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>73</td>
<td>61.9</td>
<td></td>
<td></td>
<td>425294</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1a_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>77</td>
<td>59.7</td>
<td></td>
<td></td>
<td>528014</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1a_1</td>
<td>Paniagua2020</td>
<td>92</td>
<td>43.8</td>
<td></td>
<td></td>
<td>11264</td>
<td>MLP</td>
<td></td>
<td>average log-likelihood</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_1</td>
<td>Shim2020</td>
<td>31</td>
<td>71.7</td>
<td>embeddings</td>
<td></td>
<td>1115461</td>
<td>ensemble</td>
<td>16</td>
<td>score-sum</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_2</td>
<td>Shim2020</td>
<td>34</td>
<td>71.5</td>
<td>embeddings</td>
<td></td>
<td>1115461</td>
<td>ensemble</td>
<td>8</td>
<td>score-sum</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_3</td>
<td>Shim2020</td>
<td>48</td>
<td>68.5</td>
<td></td>
<td></td>
<td>856693</td>
<td>LCNN</td>
<td>4</td>
<td>score-sum</td>
</tr>
<tr>
<td></td>
<td>Shim_UOS_task1a_4</td>
<td>Shim2020</td>
<td>37</td>
<td>71.0</td>
<td>embeddings</td>
<td></td>
<td>594923</td>
<td>ResNet</td>
<td>8</td>
<td>score-sum</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_1</td>
<td>Suh2020</td>
<td>22</td>
<td>72.5</td>
<td></td>
<td></td>
<td>13164184</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_2</td>
<td>Suh2020</td>
<td>7</td>
<td>75.5</td>
<td></td>
<td></td>
<td>13164184</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_3</td>
<td>Suh2020</td>
<td>1</td>
<td>76.5</td>
<td></td>
<td></td>
<td>39492555</td>
<td>Snapshot</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1a_4</td>
<td>Suh2020</td>
<td>2</td>
<td>76.5</td>
<td></td>
<td></td>
<td>39492555</td>
<td>Snapshot</td>
<td>3</td>
<td>weighted score average</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_1</td>
<td>Swiecicki2020</td>
<td>56</td>
<td>67.1</td>
<td></td>
<td></td>
<td>10711602</td>
<td>EfficientNet</td>
<td></td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_2</td>
<td>Swiecicki2020</td>
<td>42</td>
<td>69.5</td>
<td></td>
<td></td>
<td>10711602</td>
<td>EfficientNet</td>
<td></td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_3</td>
<td>Swiecicki2020</td>
<td>40</td>
<td>70.3</td>
<td></td>
<td></td>
<td>10711602</td>
<td>EfficientNet</td>
<td></td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Swiecicki_NON_task1a_4</td>
<td>Swiecicki2020</td>
<td>30</td>
<td>71.8</td>
<td></td>
<td></td>
<td>21423204</td>
<td>EfficientNet</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_1</td>
<td>Vilouras2020</td>
<td>53</td>
<td>67.7</td>
<td></td>
<td></td>
<td>3343774</td>
<td>ResNet, ensemble</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_2</td>
<td>Vilouras2020</td>
<td>52</td>
<td>67.8</td>
<td></td>
<td></td>
<td>3343774</td>
<td>ResNet, ensemble</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1a_3</td>
<td>Vilouras2020</td>
<td>44</td>
<td>69.3</td>
<td></td>
<td></td>
<td>6687548</td>
<td>ResNet, ensemble</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1a_1</td>
<td>Waldekar2020</td>
<td>79</td>
<td>58.4</td>
<td></td>
<td></td>
<td>32400</td>
<td>SVM</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_1</td>
<td>Wang2020a</td>
<td>80</td>
<td>56.7</td>
<td></td>
<td></td>
<td>542190</td>
<td>CNN, ensemble</td>
<td>6</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_2</td>
<td>Wang2020a</td>
<td>65</td>
<td>65.2</td>
<td></td>
<td></td>
<td>542190</td>
<td>CNN, ensemble</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_3</td>
<td>Wang2020a</td>
<td>71</td>
<td>64.0</td>
<td></td>
<td></td>
<td>542190</td>
<td>CNN, ensemble</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wang_RoyalFlush_task1a_4</td>
<td>Wang2020a</td>
<td>91</td>
<td>45.5</td>
<td></td>
<td></td>
<td>650628</td>
<td>CNN, ensemble</td>
<td>6</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_1</td>
<td>Wu2020_t1a</td>
<td>67</td>
<td>64.7</td>
<td></td>
<td></td>
<td>13143642</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_2</td>
<td>Wu2020_t1a</td>
<td>46</td>
<td>69.3</td>
<td></td>
<td></td>
<td>53300328</td>
<td>CNN</td>
<td>4</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_3</td>
<td>Wu2020_t1a</td>
<td>51</td>
<td>67.9</td>
<td></td>
<td></td>
<td>65718210</td>
<td>CNN</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1a_4</td>
<td>Wu2020_t1a</td>
<td>43</td>
<td>69.4</td>
<td></td>
<td></td>
<td>119018538</td>
<td>CNN</td>
<td>9</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_1</td>
<td>Shao2020</td>
<td>19</td>
<td>73.0</td>
<td></td>
<td></td>
<td>3524258</td>
<td>ResNet, Mini-SegNet</td>
<td>11</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_2</td>
<td>Shao2020</td>
<td>17</td>
<td>73.2</td>
<td></td>
<td></td>
<td>2516564</td>
<td>ResNet, Mini-SegNet</td>
<td>13</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_THUEE_task1a_3</td>
<td>Shao2020</td>
<td>25</td>
<td>72.3</td>
<td></td>
<td></td>
<td>2196170</td>
<td>ResNet, Mini-SegNet</td>
<td>8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_1</td>
<td>Zhang2020</td>
<td>89</td>
<td>50.4</td>
<td>embeddings</td>
<td></td>
<td>329610</td>
<td>MLP , CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_2</td>
<td>Zhang2020</td>
<td>87</td>
<td>51.7</td>
<td>embeddings</td>
<td></td>
<td>329610</td>
<td>MLP , CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Zhang_UESTC_task1a_3</td>
<td>Zhang2020</td>
<td>90</td>
<td>47.4</td>
<td>embeddings</td>
<td></td>
<td>518090</td>
<td>MLP , CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
</tbody>
</table>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2020/technical_reports_task1a.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Abbasi2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Abbasi2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification by the Snapshot Ensemble of CNNs with XGBoost
       </h4>
<p style="text-align:left">
        Reyhaneh Abbasi and Peter Balazs
       </p>
<p style="text-align:left">
<em>
         Mathematics and Signal Processing in Acoustics, acoustic research institute of OEAW, Vienna, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Abbasi_ARI_task1a_1</span> <span class="label label-primary">Abbasi_ARI_task1a_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Abbasi2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Abbasi2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Abbasi2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Abbasi_144.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Abbasi2020" class="panel-collapse collapse" id="collapse-Abbasi2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification by the Snapshot Ensemble of CNNs with XGBoost
      </h4>
<p style="text-align:left">
<small>
        Reyhaneh Abbasi and Peter Balazs
       </small>
<br/>
<small>
<em>
         Mathematics and Signal Processing in Acoustics, acoustic research institute of OEAW, Vienna, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This is the report for the DCASE challenge task 1A. The aim is to implement acoustic scene classification of audio recordings into 10 predefined classes including Airport, shopping mall, metro station, street pedestrian, public square, street traffic, tram, bus, metro, and park. Two main drawbacks of this task are that recordings are provided by five devices with different quality and that some of these classes are very close in terms of acoustic information. To bias correct all instruments against the reference (here the instrument A), we have used XGboost algorithm fed by standaridiezd Mel spectrogram. Our classifier consists of a CNN, mix-up augmentation, and snapshot ensemble (to decrease the total number of parameters and, consequently, the variance of model prediction). Our model has yielded an accuracy of 62.1% and cross-entropy loss of 1.06. Whereas the baseline model has yielded the accuracy and cross-entropy loss of 54.1% and 1.36, respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN,ensemble; CNN, ensemble, XGBoost
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Abbasi2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Abbasi_144.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Abbasi2020label" class="modal fade" id="bibtex-Abbasi2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexAbbasi2020label">
        Acoustic Scene Classification by the Snapshot Ensemble of CNNs with XGBoost
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Abbasi2020,
    Author = "Abbasi, Reyhaneh and Balazs, Peter",
    title = "Acoustic Scene Classification by the Snapshot Ensemble of {CNNs} with {XGBoost}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This is the report for the DCASE challenge task 1A. The aim is to implement acoustic scene classification of audio recordings into 10 predefined classes including Airport, shopping mall, metro station, street pedestrian, public square, street traffic, tram, bus, metro, and park. Two main drawbacks of this task are that recordings are provided by five devices with different quality and that some of these classes are very close in terms of acoustic information. To bias correct all instruments against the reference (here the instrument A), we have used XGboost algorithm fed by standaridiezd Mel spectrogram. Our classifier consists of a CNN, mix-up augmentation, and snapshot ensemble (to decrease the total number of parameters and, consequently, the variance of model prediction). Our model has yielded an accuracy of 62.1\% and cross-entropy loss of 1.06. Whereas the baseline model has yielded the accuracy and cross-entropy loss of 54.1\% and 1.36, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Aryal2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Aryal2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Attention-Based Resnet-18 Model for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Nisan Aryal and Sang Woong Lee
       </p>
<p style="text-align:left">
<em>
         Gachon University, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lee_GU_task1a_1</span> <span class="label label-primary">Lee_GU_task1a_2</span> <span class="label label-primary">Lee_GU_task1a_3</span> <span class="label label-primary">Lee_GU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Aryal2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Aryal2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Aryal2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_23.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Aryal2020" class="panel-collapse collapse" id="collapse-Aryal2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Attention-Based Resnet-18 Model for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Nisan Aryal and Sang Woong Lee
       </small>
<br/>
<small>
<em>
         Gachon University, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approach to solve Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 challenge task1a. Resnet-18 with attention model and Openl3 embedding are used to solve the acoustic scene classification problem. The model shows 59.6% accuracy in the training and validation split of the development set, which is 5.5% higher than that of the baseline network.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time masking, frequency masking
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         OpenL3 (env); OpenL3 (music)
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet, Attention
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Aryal2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_23.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Aryal2020label" class="modal fade" id="bibtex-Aryal2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexAryal2020label">
        Attention-Based Resnet-18 Model for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Aryal2020,
    Author = "Aryal, Nisan and Lee, Sang Woong",
    title = "Attention-Based Resnet-18 Model for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our approach to solve Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 challenge task1a. Resnet-18 with attention model and Openl3 embedding are used to solve the acoustic scene classification problem. The model shows 59.6\% accuracy in the training and validation split of the development set, which is 5.5\% higher than that of the baseline network."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Changmin2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Changmin2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Multi-Channel Feature Using Inter-Class and Inter-Device Standard Deviations for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Kim Changmin, Seo Soonshin and Kim Ji-Hwan
       </p>
<p style="text-align:left">
<em>
         Dept. of Computer Scinece and Engineering, Sogang University, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kim_SGU_task1a_1</span> <span class="label label-primary">Kim_SGU_task1a_2</span> <span class="label label-primary">Kim_SGU_task1a_3</span> <span class="label label-primary">Kim_SGU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Changmin2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Changmin2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Changmin2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Kim_87.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Changmin2020').collapse('show');window.location.hash='#Changmin2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Changmin2020" class="panel-collapse collapse" id="collapse-Changmin2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Multi-Channel Feature Using Inter-Class and Inter-Device Standard Deviations for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Kim Changmin, Seo Soonshin and Kim Ji-Hwan
       </small>
<br/>
<small>
<em>
         Dept. of Computer Scinece and Engineering, Sogang University, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our acoustic scene classification methods submitted to detection and classification of acoustic scenes and events challenge 2020 task 1a. Our proposed methods aim to maximize the differences between acoustic scene classes and minimize the differences between various devices. We obtained the inter-class and inter-device standard deviations of the training data and applied them to the log-mel spectrogram features. These features are added to the channel of the original log-mel spectrogram. In addition, we applied class-wise random masking for the frequency domain with small standard deviations. Then, masked features are divided into quarters on the frequency axis. They are trained using four-pathway residual convolutional neural networks. Our proposed methods achieved an overall accuracy of 72.7% for the official development dataset, which was an improvement by 18.6% over the official baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping, class-wise random masking
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas, multiple channel feature
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Residual CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Changmin2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Kim_87.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/sunshines14/DCASE2020" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Changmin2020label" class="modal fade" id="bibtex-Changmin2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChangmin2020label">
        Multi-Channel Feature Using Inter-Class and Inter-Device Standard Deviations for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Changmin2020,
    Author = "Changmin, Kim and Soonshin, Seo and Ji-Hwan, Kim",
    title = "Multi-Channel Feature Using Inter-Class and Inter-Device Standard Deviations for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this technical report, we describe our acoustic scene classification methods submitted to detection and classification of acoustic scenes and events challenge 2020 task 1a. Our proposed methods aim to maximize the differences between acoustic scene classes and minimize the differences between various devices. We obtained the inter-class and inter-device standard deviations of the training data and applied them to the log-mel spectrogram features. These features are added to the channel of the original log-mel spectrogram. In addition, we applied class-wise random masking for the frequency domain with small standard deviations. Then, masked features are divided into quarters on the frequency axis. They are trained using four-pathway residual convolutional neural networks. Our proposed methods achieved an overall accuracy of 72.7\% for the official development dataset, which was an improvement by 18.6\% over the official baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Fanioudakis2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Fanioudakis2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Investigating Temporal and Spectral Sequences Combining GRU-RNNS for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Eleftherios Fanioudakis and Anastasios Vafeiadis
       </p>
<p style="text-align:left">
<em>
         Greece
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">FanVaf__task1a_1</span> <span class="label label-primary">FanVaf__task1a_2</span> <span class="label label-primary">FanVaf__task1a_3</span> <span class="label label-primary">FanVaf__task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Fanioudakis2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Fanioudakis2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Fanioudakis2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_FanVaf_96.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Fanioudakis2020" class="panel-collapse collapse" id="collapse-Fanioudakis2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Investigating Temporal and Spectral Sequences Combining GRU-RNNS for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Eleftherios Fanioudakis and Anastasios Vafeiadis
       </small>
<br/>
<small>
<em>
         Greece
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our contribution to Task 1A of the 2020 Detection and Classification of Acoustic Scenes and Events (DCASE) challenge. We investigated the use of bi-directional Gated Recurrent Unit (GRU) - Recurrent Neural Networks (RNNs) in order to capture the spectral and temporal information of the input signal. The GRU-RNNs are used as an ensemble during training, having equal weights for the time and the frequency sequences. Our architecture is based on a Convolutional Recurrent Neural Network (CRNN), where the short-time Fourier magnitude spectrogram is used as an input to the network. By exploiting the mixup augmentation technique, randomly selecting the mixup coefficient α for every sample, and down-sampling the original signal from 44.1 kHz to 4 kHz, we achieved an average class accuracy of 65.4%. Since most of the information of the environmental sound signals was found in the lower frequencies, a CRNN model ensemble was performed, combining 4 and 8 kHz as the sampling frequencies. The latter system’s accuracy was boosted to 67.3%, a 24.4% increase over the development set baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         4kHz; 8kHz; 4kHz, 8kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time shifting
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CRNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         sample-based average; sample average with weights
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Fanioudakis2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_FanVaf_96.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Fanioudakis2020label" class="modal fade" id="bibtex-Fanioudakis2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexFanioudakis2020label">
        Investigating Temporal and Spectral Sequences Combining GRU-RNNS for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Fanioudakis2020,
    Author = "Fanioudakis, Eleftherios and Vafeiadis, Anastasios",
    title = "Investigating Temporal and Spectral Sequences Combining {GRU}-RNNS for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes our contribution to Task 1A of the 2020 Detection and Classification of Acoustic Scenes and Events (DCASE) challenge. We investigated the use of bi-directional Gated Recurrent Unit (GRU) - Recurrent Neural Networks (RNNs) in order to capture the spectral and temporal information of the input signal. The GRU-RNNs are used as an ensemble during training, having equal weights for the time and the frequency sequences. Our architecture is based on a Convolutional Recurrent Neural Network (CRNN), where the short-time Fourier magnitude spectrogram is used as an input to the network. By exploiting the mixup augmentation technique, randomly selecting the mixup coefficient α for every sample, and down-sampling the original signal from 44.1 kHz to 4 kHz, we achieved an average class accuracy of 65.4\%. Since most of the information of the environmental sound signals was found in the lower frequencies, a CRNN model ensemble was performed, combining 4 and 8 kHz as the sampling frequencies. The latter system’s accuracy was boosted to 67.3\%, a 24.4\% increase over the development set baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Fei2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Fei2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Based on 2-Order Dense Convolutional Network
       </h4>
<p style="text-align:left">
        Hongbo Fei, Zilong Huang, Yi Cao and Chen Liu
       </p>
<p style="text-align:left">
<em>
         Mechanical engineering, Jiangnan University, Wuxi, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Cao_JNU_task1a_1</span> <span class="label label-primary">Cao_JNU_task1a_2</span> <span class="label label-primary">Cao_JNU_task1a_3</span> <span class="label label-primary">Cao_JNU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Fei2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Fei2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Fei2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Cao_7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Fei2020" class="panel-collapse collapse" id="collapse-Fei2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Based on 2-Order Dense Convolutional Network
      </h4>
<p style="text-align:left">
<small>
        Hongbo Fei, Zilong Huang, Yi Cao and Chen Liu
       </small>
<br/>
<small>
<em>
         Mechanical engineering, Jiangnan University, Wuxi, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our acoustic scene classification algorithm submitted in DCASE 2020 Task 1a. We focus on network innovation, a novel acoustic scene classification model based on 2-order dense convolutional network is proposed, which aims at the problems of insufficient classification accuracy and adaptability of current models. Based on the dense convolutional neural network, combined with the N-order Markov model, the traditional dense connection is improved to the N-order correlation connection, and then the N-order dense convolutional network model is proposed. In terms of audio feature extraction, we use Log-Mel spectrograms and Gamma-Tone spectrograms to stitch together. In order to further improve system performance, virtual data generation technology is adopted. Finally, use the trained model for transfer learning. By using proposed systems, we achieved a classification accuracy of 69.16% on the officially provided evaluation dataset, which is 15.06% over than the baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel spectrogram, gamma-tone spectrogram, CQT
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, 2-DenseNet; CNN,2-DenseNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         majority vote
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Fei2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Cao_7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Fei2020label" class="modal fade" id="bibtex-Fei2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexFei2020label">
        Acoustic Scene Classification Based on 2-Order Dense Convolutional Network
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Fei2020,
    Author = "Fei, Hongbo and Huang, Zilong and Cao, Yi and Liu, Chen",
    title = "Acoustic Scene Classification Based on 2-Order Dense Convolutional Network",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this technical report, we describe our acoustic scene classification algorithm submitted in DCASE 2020 Task 1a. We focus on network innovation, a novel acoustic scene classification model based on 2-order dense convolutional network is proposed, which aims at the problems of insufficient classification accuracy and adaptability of current models. Based on the dense convolutional neural network, combined with the N-order Markov model, the traditional dense connection is improved to the N-order correlation connection, and then the N-order dense convolutional network model is proposed. In terms of audio feature extraction, we use Log-Mel spectrograms and Gamma-Tone spectrograms to stitch together. In order to further improve system performance, virtual data generation technology is adopted. Finally, use the trained model for transfer learning. By using proposed systems, we achieved a classification accuracy of 69.16\% on the officially provided evaluation dataset, which is 15.06\% over than the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Gao2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Gao2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Deep Residual Networks with Focal Loss and Mild Domain Adaptation
       </h4>
<p style="text-align:left">
        Wei Gao and Mark McDonnell
       </p>
<p style="text-align:left">
<em>
         UniSA STEM, University of South Australia, Adelaide, Australia
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Gao_UNISA_task1a_1</span> <span class="label label-primary">Gao_UNISA_task1a_2</span> <span class="label label-primary">Gao_UNISA_task1a_3</span> <span class="label label-primary">Gao_UNISA_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Gao2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Gao2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Gao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Gao_132.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Gao2020').collapse('show');window.location.hash='#Gao2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Gao2020" class="panel-collapse collapse" id="collapse-Gao2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Deep Residual Networks with Focal Loss and Mild Domain Adaptation
      </h4>
<p style="text-align:left">
<small>
        Wei Gao and Mark McDonnell
       </small>
<br/>
<small>
<em>
         UniSA STEM, University of South Australia, Adelaide, Australia
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approach to Tasks 1a in the 2020 DCASE acoustic scene classification challenge. We have incorporated few more training techniques based on our previous contest entries. One was replacing cross-entropy loss with focal loss which aims to focus on poor-classified samples while reducing the loss on well-classified samples with high probability; another methods used was to add an auxiliary binary classifier to serve the purpose of domain adaptation.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; ResNet, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Gao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Gao_132.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/emilywg/DCASE2020-Task1" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Gao2020label" class="modal fade" id="bibtex-Gao2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGao2020label">
        Acoustic Scene Classification Using Deep Residual Networks with Focal Loss and Mild Domain Adaptation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Gao2020,
    Author = "Gao, Wei and McDonnell, Mark",
    title = "Acoustic Scene Classification Using Deep Residual Networks with Focal Loss and Mild Domain Adaptation",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our approach to Tasks 1a in the 2020 DCASE acoustic scene classification challenge. We have incorporated few more training techniques based on our previous contest entries. One was replacing cross-entropy loss with focal loss which aims to focus on poor-classified samples while reducing the loss on well-classified samples with high probability; another methods used was to add an auxiliary binary classifier to serve the purpose of domain adaptation."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Hong2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Hong2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Mel-Spectrum and CQT Based Neural Network Ensemble
       </h4>
<p style="text-align:left">
        Lu Hong
       </p>
<p style="text-align:left">
<em>
         Intel Labs, Intel Corporation, Santa Clara, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lu_INTC_task1a_1</span> <span class="label label-primary">Lu_INTC_task1a_2</span> <span class="label label-primary">Lu_INTC_task1a_3</span> <span class="label label-primary">Lu_INTC_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Hong2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Hong2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Hong2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lu_92.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Hong2020" class="panel-collapse collapse" id="collapse-Hong2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Mel-Spectrum and CQT Based Neural Network Ensemble
      </h4>
<p style="text-align:left">
<small>
        Lu Hong
       </small>
<br/>
<small>
<em>
         Intel Labs, Intel Corporation, Santa Clara, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In our submission to the DCASE 2020 Task1a, we have explored the use of ResNeXt-50 architecture with Log-Mel-spectrum and Constant-Q transform(CQT) based frontend. In order to improve performance, we use transfer learning technique. The neural networks were pre-trained with AudioSet data, and then fine-tuned over the DCASE task1a dataset. With DCASE 2020 task1a default train/validation split, we got about 70% average accuracy across all the 10 classes. To further improve the performance, we applied a leave-one-city out cross validation(CV) method to train 10 more models, with one city’s data as holdout set for each of the CV fold. These models were combined together with different ensemble strategies to produce 4 final submission entries.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         32kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, weight decay, dropout, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel spectrogram, CQT
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         None
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNext
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average; softmax
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Hong2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lu_92.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Hong2020label" class="modal fade" id="bibtex-Hong2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHong2020label">
        Acoustic Scene Classification Using Mel-Spectrum and CQT Based Neural Network Ensemble
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Hong2020,
    Author = "Hong, Lu",
    title = "Acoustic Scene Classification Using Mel-Spectrum and {CQT} Based Neural Network Ensemble",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In our submission to the DCASE 2020 Task1a, we have explored the use of ResNeXt-50 architecture with Log-Mel-spectrum and Constant-Q transform(CQT) based frontend. In order to improve performance, we use transfer learning technique. The neural networks were pre-trained with AudioSet data, and then fine-tuned over the DCASE task1a dataset. With DCASE 2020 task1a default train/validation split, we got about 70\% average accuracy across all the 10 classes. To further improve the performance, we applied a leave-one-city out cross validation(CV) method to train 10 more models, with one city’s data as holdout set for each of the CV fold. These models were combined together with different ensemble strategies to produce 4 final submission entries."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Hu2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Hu2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
       </h4>
<p style="text-align:left">
        Hu Hu<sup>1</sup>, Chao-Han Huck Yang<sup>1</sup>, Xianjun Xia<sup>2</sup>, Xue Bai<sup>3</sup>, Xin Tang<sup>3</sup>, Yajian Wang<sup>3</sup>, Shutong Niu<sup>3</sup>, Li Chai<sup>3</sup>, Juanjuan Li<sup>2</sup>, Hongning Zhu<sup>2</sup>, Feng Bao<sup>4</sup>, Yuanjun Zhao<sup>2</sup>, Sabato Marco Siniscalchi<sup>5</sup>, Yannan Wang<sup>2</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA, <sup>2</sup>Tencent Media Lab, Shenzhen, China, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Beijing, China, <sup>5</sup>Computer Engineering School, University of Enna Kore, Italy
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Hu_GT_task1a_1</span> <span class="label label-primary">Hu_GT_task1a_2</span> <span class="label label-primary">Hu_GT_task1a_3</span> <span class="label label-primary">Hu_GT_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Hu2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Hu2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Hu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Hu_114.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Hu2020').collapse('show');window.location.hash='#Hu2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Hu2020" class="panel-collapse collapse" id="collapse-Hu2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
      </h4>
<p style="text-align:left">
<small>
        Hu Hu<sup>1</sup>, Chao-Han Huck Yang<sup>1</sup>, Xianjun Xia<sup>2</sup>, Xue Bai<sup>3</sup>, Xin Tang<sup>3</sup>, Yajian Wang<sup>3</sup>, Shutong Niu<sup>3</sup>, Li Chai<sup>3</sup>, Juanjuan Li<sup>2</sup>, Hongning Zhu<sup>2</sup>, Feng Bao<sup>4</sup>, Yuanjun Zhao<sup>2</sup>, Sabato Marco Siniscalchi<sup>5</sup>, Yannan Wang<sup>2</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA, <sup>2</sup>Tencent Media Lab, Shenzhen, China, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Beijing, China, <sup>5</sup>Computer Engineering School, University of Enna Kore, Italy
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we present a joint effort of four groups, namely GT, USTC, Tencent, and UKE, to tackle Task 1 - Acoustic Scene Classification (ASC) in the DCASE 2020 Challenge. Task 1 comprises two different sub-tasks: (i) Task 1a focuses on ASC of audio signals recorded with multiple (real and simulated) devices into ten different fine-grained classes, and (ii) Task 1b concerns with classification of data into three higher-level classes using lowcomplexity solutions. For Task 1a, we propose a novel two-stage ASC system leveraging upon ad-hoc score combination of two convolutional neural networks (CNNs), classifying the acoustic input according to three classes, and then ten classes, respectively. Four different CNN-based architectures are explored to implement the two-stage classifiers, and several data augmentation techniques are also investigated. For Task 1b, we leverage upon a quantization method to reduce the complexity of two of our top-accuracy three-classes CNN-based architectures. On Task 1a development data set, an ASC accuracy of 76.9% is attained using our best single classifier and data augmentation. An accuracy of 81.9% is then attained by a final model fusion of our two-stage ASC classifiers. On Task 1b development data set, we achieve an accuracy of 96.7% with a model size smaller than 500KB
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shift, speed change, random noise, mix audios
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, ResNet, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Hu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Hu_114.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/MihawkHu/DCASE2020_task1" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Hu2020label" class="modal fade" id="bibtex-Hu2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHu2020label">
        Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Hu2020,
    Author = "Hu, Hu and Yang, Chao-Han Huck and Xia, Xianjun and Bai, Xue and Tang, Xin and Wang, Yajian and Niu, Shutong and Chai, Li and Li, Juanjuan and Zhu, Hongning and Bao, Feng and Zhao, Yuanjun and Siniscalchi, Sabato Marco and Wang, Yannan and Du, Jun and Lee, Chin-Hui",
    title = "Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this technical report, we present a joint effort of four groups, namely GT, USTC, Tencent, and UKE, to tackle Task 1 - Acoustic Scene Classification (ASC) in the DCASE 2020 Challenge. Task 1 comprises two different sub-tasks: (i) Task 1a focuses on ASC of audio signals recorded with multiple (real and simulated) devices into ten different fine-grained classes, and (ii) Task 1b concerns with classification of data into three higher-level classes using lowcomplexity solutions. For Task 1a, we propose a novel two-stage ASC system leveraging upon ad-hoc score combination of two convolutional neural networks (CNNs), classifying the acoustic input according to three classes, and then ten classes, respectively. Four different CNN-based architectures are explored to implement the two-stage classifiers, and several data augmentation techniques are also investigated. For Task 1b, we leverage upon a quantization method to reduce the complexity of two of our top-accuracy three-classes CNN-based architectures. On Task 1a development data set, an ASC accuracy of 76.9\% is attained using our best single classifier and data augmentation. An accuracy of 81.9\% is then attained by a final model fusion of our two-stage ASC classifiers. On Task 1b development data set, we achieve an accuracy of 96.7\% with a model size smaller than 500KB"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Jie2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Jie2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Residual Networks and Attention Mechanism
       </h4>
<p style="text-align:left">
        Liu Jie
       </p>
<p style="text-align:left">
<em>
         Maxvision, Wuhan, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Jie_Maxvision_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Jie2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Jie2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Jie2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Jie_19.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Jie2020" class="panel-collapse collapse" id="collapse-Jie2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Residual Networks and Attention Mechanism
      </h4>
<p style="text-align:left">
<small>
        Liu Jie
       </small>
<br/>
<small>
<em>
         Maxvision, Wuhan, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for TASK1A of DCASE2020 challenge. We use log-mel spectrograms and a residual network. We follow the idea of McDonnell [1] in DCASE2019 and do not downsample in the frequency axis. Besides, we use attention mechanism to improve the performance of the system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Jie2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Jie_19.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Jie2020label" class="modal fade" id="bibtex-Jie2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJie2020label">
        Acoustic Scene Classification with Residual Networks and Attention Mechanism
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Jie2020,
    Author = "Jie, Liu",
    title = "Acoustic Scene Classification with Residual Networks and Attention Mechanism",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our submission for TASK1A of DCASE2020 challenge. We use log-mel spectrograms and a residual network. We follow the idea of McDonnell [1] in DCASE2019 and do not downsample in the frequency axis. Besides, we use attention mechanism to improve the performance of the system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Joao2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Joao2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
       </h4>
<p style="text-align:left">
        Monteiro Joao, Shruti Kshirsagar, Anderson Avila, Amr Aaballah, Parth Tiwari and Tiago Falk
       </p>
<p style="text-align:left">
<em>
         EMT, Institut National de la Recherche Scientifique, Montreal, Canada
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Monteiro_INRS_task1a_1</span> <span class="label label-primary">Monteiro_INRS_task1a_2</span> <span class="label label-primary">Monteiro_INRS_task1a_3</span> <span class="label label-primary">Monteiro_INRS_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Joao2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Joao2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Joao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Montreiro_73.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Joao2020').collapse('show');window.location.hash='#Joao2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Joao2020" class="panel-collapse collapse" id="collapse-Joao2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
      </h4>
<p style="text-align:left">
<small>
        Monteiro Joao, Shruti Kshirsagar, Anderson Avila, Amr Aaballah, Parth Tiwari and Tiago Falk
       </small>
<br/>
<small>
<em>
         EMT, Institut National de la Recherche Scientifique, Montreal, Canada
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report we provide a brief overview of a set of submissions for the scene classification sub-tasks of the 2020 edition of the DCASE challenge. Our submissions comprise efforts at the feature representation level, where we explored the use of modulation spectra and i-vectors (extracted from mel cepstral coefficients, as well as modulation spectra) and modeling strategies, where recent convolutional deep neural network models were used. Results on the Challenge validation set show several of the submitted methods outperforming the baseline model.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Sox distortions, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies; modulation spectra; log-mel energies, modulation spectra
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; TDNN; CNN, ResNet12, ResNet18, TDNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Joao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Montreiro_73.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/joaomonteirof/dcase" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Joao2020label" class="modal fade" id="bibtex-Joao2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJoao2020label">
        Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Joao2020,
    Author = "Joao, Monteiro and Kshirsagar, Shruti and Avila, Anderson and Aaballah, Amr and Tiwari, Parth and Falk, Tiago",
    title = "Development of the {INRS-EMT} Scene Classification Systems for the 2020 Edition of the {DCASE} Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this report we provide a brief overview of a set of submissions for the scene classification sub-tasks of the 2020 edition of the DCASE challenge. Our submissions comprise efforts at the feature representation level, where we explored the use of modulation spectra and i-vectors (extracted from mel cepstral coefficients, as well as modulation spectra) and modeling strategies, where recent convolutional deep neural network models were used. Results on the Challenge validation set show several of the submitted methods outperforming the baseline model."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kim2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Kim2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Multi-Channel Audio Feature with Convolutional Neural Networks and Subtract Filter Augmentation
       </h4>
<p style="text-align:left">
        Jaehun Kim
       </p>
<p style="text-align:left">
<em>
         AI Research Lab, IVS Inc, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">JHKim_IVS_task1a_1</span> <span class="label label-primary">JHKim_IVS_task1a_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kim2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kim2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kim2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_JHKim_21_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kim2020_t1" class="panel-collapse collapse" id="collapse-Kim2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Multi-Channel Audio Feature with Convolutional Neural Networks and Subtract Filter Augmentation
      </h4>
<p style="text-align:left">
<small>
        Jaehun Kim
       </small>
<br/>
<small>
<em>
         AI Research Lab, IVS Inc, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This paper presents a multi-channel audio feature using imagenet model based on convolutional neural networks for DCASE 2020 Task1-A Acoustic scene classification with multiple devices. We use the TAU Urban Acoustic Scenes 2020 Mobile Dataset. It consists of 10 seconds of audio clips about 10 scenes. We proposed a multi-channel audio feature to use imagenet pre-trained model weight. also, we proposed filtered augmentation for other devices' recorded audio. the multichannel feature consists of raw and harmonic, percussive (HPSS) data’s Log-Mel-Spectrogram. Also, we use EfficientNet pre-trained model weight.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         subtract filter
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         HPSS, log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kim2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_JHKim_21_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kim2020_t1label" class="modal fade" id="bibtex-Kim2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKim2020_t1label">
        Acoustic Scene Classification Using Multi-Channel Audio Feature with Convolutional Neural Networks and Subtract Filter Augmentation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kim2020_t1,
    Author = "Kim, Jaehun",
    title = "Acoustic Scene Classification Using Multi-Channel Audio Feature with Convolutional Neural Networks and Subtract Filter Augmentation",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This paper presents a multi-channel audio feature using imagenet model based on convolutional neural networks for DCASE 2020 Task1-A Acoustic scene classification with multiple devices. We use the TAU Urban Acoustic Scenes 2020 Mobile Dataset. It consists of 10 seconds of audio clips about 10 scenes. We proposed a multi-channel audio feature to use imagenet pre-trained model weight. also, we proposed filtered augmentation for other devices' recorded audio. the multichannel feature consists of raw and harmonic, percussive (HPSS) data’s Log-Mel-Spectrogram. Also, we use EfficientNet pre-trained model weight."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Koutini2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Koutini2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CP-JKU Submissions to DCASE’20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
       </h4>
<p style="text-align:left">
        Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh and Gerhard Widmer
       </p>
<p style="text-align:left">
<em>
         Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Koutini_CPJKU_task1a_1</span> <span class="label label-primary">Koutini_CPJKU_task1a_2</span> <span class="label label-primary">Koutini_CPJKU_task1a_3</span> <span class="label label-primary">Koutini_CPJKU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Koutini2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Koutini2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Koutini2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Koutini_142.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Koutini2020').collapse('show');window.location.hash='#Koutini2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Koutini2020" class="panel-collapse collapse" id="collapse-Koutini2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CP-JKU Submissions to DCASE’20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
      </h4>
<p style="text-align:left">
<small>
        Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh and Gerhard Widmer
       </small>
<br/>
<small>
<em>
         Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the CP-JKU team’s submission for Task 1 - Subtask A (Acoustic Scene Classification with Multiple Devices) and Subtask B (Low-Complexity Acoustic Scene Classification) of the DCASE-2020 challenge. For Subtask 1A, we provide our Receptive Field (RF) regularized CNN model as a baseline, and additionally explore the use of two different domain adaption objectives in the form of the Maximum Mean Discrepancy (MMD) and the Sliced Wasserstein Distance (SWD). For Subtask 1B, we investigate different parameter reduction methods such as Pruning and Knowledge Distillation (KD). Additionally, we incorporate a decomposed convolutional layer that reduces the number of nonezero parameters in our models while only slightly decreasing the accuracy compared to full-parameter baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Perceptually-weighted log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RF-regularized CNNs
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Koutini2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Koutini_142.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/kkoutini/cpjku_dcase19" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Koutini2020label" class="modal fade" id="bibtex-Koutini2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKoutini2020label">
        CP-JKU Submissions to DCASE’20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Koutini2020,
    Author = "Koutini, Khaled and Henkel, Florian and Eghbal-zadeh, Hamid and Widmer, Gerhard",
    title = "{CP-JKU} Submissions to {DCASE’20}: Low-Complexity Cross-Device Acoustic Scene Classification with {RF}-Regularized {CNNs}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the CP-JKU team’s submission for Task 1 - Subtask A (Acoustic Scene Classification with Multiple Devices) and Subtask B (Low-Complexity Acoustic Scene Classification) of the DCASE-2020 challenge. For Subtask 1A, we provide our Receptive Field (RF) regularized CNN model as a baseline, and additionally explore the use of two different domain adaption objectives in the form of the Maximum Mean Discrepancy (MMD) and the Sliced Wasserstein Distance (SWD). For Subtask 1B, we investigate different parameter reduction methods such as Pruning and Knowledge Distillation (KD). Additionally, we incorporate a decomposed convolutional layer that reduces the number of nonezero parameters in our models while only slightly decreasing the accuracy compared to full-parameter baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lee2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Lee2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
       </h4>
<p style="text-align:left">
        Yerin Lee<sup>1</sup>, Soyoung Lim<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Statistics Dept., Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lee_CAU_task1a_1</span> <span class="label label-primary">Lee_CAU_task1a_2</span> <span class="label label-primary">Lee_CAU_task1a_3</span> <span class="label label-primary">Lee_CAU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lee2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lee2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lee2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_143.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lee2020" class="panel-collapse collapse" id="collapse-Lee2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
      </h4>
<p style="text-align:left">
<small>
        Yerin Lee<sup>1</sup>, Soyoung Lim<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Statistics Dept., Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The acoustic scenry classification problem is an interesting topic that has been studied for a long time through the DCASE competition. This technical report presents the CAU-ET’s submitted scenery detection system to the DCASE 2020 challenge, Task 1. In our method we generate mel-spectrogram from audio. From log-mel spectrogram, we got Deltas, Delta-deltas and Harmonic-percussive source seperation(HPSS) feature as inputs of our deep neural network models. The classification result of the proposed system was 66.26% for development dataset in subtask A and 95.27% in subtask B
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas, HPSS
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, ResNet, LCNN, InceptionLike, ensemble; CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lee2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_143.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lee2020label" class="modal fade" id="bibtex-Lee2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLee2020label">
        The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lee2020,
    Author = "Lee, Yerin and Lim, Soyoung and Kwak, Il-Youp",
    title = "The {CAU-ET} Acoustic Scenery Classification System for {DCASE} 2020 Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "The acoustic scenry classification problem is an interesting topic that has been studied for a long time through the DCASE competition. This technical report presents the CAU-ET’s submitted scenery detection system to the DCASE 2020 challenge, Task 1. In our method we generate mel-spectrogram from audio. From log-mel spectrogram, we got Deltas, Delta-deltas and Harmonic-percussive source seperation(HPSS) feature as inputs of our deep neural network models. The classification result of the proposed system was 66.26\% for development dataset in subtask A and 95.27\% in subtask B"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Liu2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Liu2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Various Deep Classifiers
       </h4>
<p style="text-align:left">
        Yue Liu, XinYuan Zhou and YanHua Long
       </p>
<p style="text-align:left">
<em>
         The College of Information,Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Liu_SHNU_task1a_1</span> <span class="label label-primary">Liu_SHNU_task1a_2</span> <span class="label label-primary">Liu_SHNU_task1a_3</span> <span class="label label-primary">Liu_SHNU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Liu2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Liu2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Liu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Liu_47.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Liu2020" class="panel-collapse collapse" id="collapse-Liu2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Various Deep Classifiers
      </h4>
<p style="text-align:left">
<small>
        Yue Liu, XinYuan Zhou and YanHua Long
       </small>
<br/>
<small>
<em>
         The College of Information,Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we describes the SHNU team’s submission to the DCASE-2020 challenge Task1-A (Acoustic Scene Classification with Multiple Devices). In our submissions, three different deep models are investigated. The first one is a ResNet-based model with receptive-field regularization. The second one is a common two-dimensional CNN model with perceptual weighted power spectrogram as input. The third one is a self-attention based model with only Transformer encoder architecture which is specially designed for acoustic scene classification. In addition, we proposed a deviceenhancement data augmentation method, together with the conventional mix-up and specAugment to improve the model robustness to multiple devices. Experimental results on the fold1 validation set show that these models are complementary in some extent. We prepared all of our submissions without the use of any external data except for the official baseline embeddings. The logistic regression score fusion is used to fuse the softmax outputs of single-systems.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz; 44.1kHz; 22.05kHz,44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, deviceaugment; mixup; SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         perceptual weighted power spectrogram; log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         OpenL3
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet , Receptive Field Regularization; CNN; Self-attention; ResNet , Receptive Field Regularization, CNN , MLP
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Liu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Liu_47.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Liu2020label" class="modal fade" id="bibtex-Liu2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLiu2020label">
        Acoustic Scene Classification with Various Deep Classifiers
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Liu2020,
    Author = "Liu, Yue and Zhou, XinYuan and Long, YanHua",
    title = "Acoustic Scene Classification with Various Deep Classifiers",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this report, we describes the SHNU team’s submission to the DCASE-2020 challenge Task1-A (Acoustic Scene Classification with Multiple Devices). In our submissions, three different deep models are investigated. The first one is a ResNet-based model with receptive-field regularization. The second one is a common two-dimensional CNN model with perceptual weighted power spectrogram as input. The third one is a self-attention based model with only Transformer encoder architecture which is specially designed for acoustic scene classification. In addition, we proposed a deviceenhancement data augmentation method, together with the conventional mix-up and specAugment to improve the model robustness to multiple devices. Experimental results on the fold1 validation set show that these models are complementary in some extent. We prepared all of our submissions without the use of any external data except for the official baseline embeddings. The logistic regression score fusion is used to fuse the softmax outputs of single-systems."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Liu2020a" style="box-shadow: none">
<div class="panel-heading" id="heading-Liu2020a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Ensembles of Deep Residual Networks and Spectrogram Decompositions
       </h4>
<p style="text-align:left">
        Yingzi Liu, Shengwang Jiang, Chuang Shi and Huiyong Li
       </p>
<p style="text-align:left">
<em>
         School of imformation and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Liu_UESTC_task1a_1</span> <span class="label label-primary">Liu_UESTC_task1a_2</span> <span class="label label-primary">Liu_UESTC_task1a_3</span> <span class="label label-primary">Liu_UESTC_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Liu2020a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Liu2020a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Liu2020a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Liu_64.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Liu2020a" class="panel-collapse collapse" id="collapse-Liu2020a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Ensembles of Deep Residual Networks and Spectrogram Decompositions
      </h4>
<p style="text-align:left">
<small>
        Yingzi Liu, Shengwang Jiang, Chuang Shi and Huiyong Li
       </small>
<br/>
<small>
<em>
         School of imformation and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes ensembles of convolutional neural networks (CNNs) for the task 1 / subtask B of the DACSE 2020 challenge, with emphasis on the use of a deep residual network applied to different spectrogram decompositions. The harmonic percussive source separation (HPSS), nearest neighbor filter (NNF), vocal separation and Head-related transfer function (HRTF) are used to augment the acoustic features. Our system achieves higher classification accuracies and lower log loss in the development dataset than baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         HPSS,NNF,vocal separation,HRTF
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average; stacking
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Liu2020a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Liu_64.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Liu2020alabel" class="modal fade" id="bibtex-Liu2020a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLiu2020alabel">
        Acoustic Scene Classification Using Ensembles of Deep Residual Networks and Spectrogram Decompositions
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Liu2020a,
    Author = "Liu, Yingzi and Jiang, Shengwang and Shi, Chuang and Li, Huiyong",
    title = "Acoustic Scene Classification Using Ensembles of Deep Residual Networks and Spectrogram Decompositions",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes ensembles of convolutional neural networks (CNNs) for the task 1 / subtask B of the DACSE 2020 challenge, with emphasis on the use of a deep residual network applied to different spectrogram decompositions. The harmonic percussive source separation (HPSS), nearest neighbor filter (NNF), vocal separation and Head-related transfer function (HRTF) are used to augment the acoustic features. Our system achieves higher classification accuracies and lower log loss in the development dataset than baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lopez-Meyer2020_t1a" style="box-shadow: none">
<div class="panel-heading" id="heading-Lopez-Meyer2020_t1a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Ensemble of Convolutional Neural Networks for the DCASE 2020 Acoustic Scene Classification Challenge
       </h4>
<p style="text-align:left">
        Paulo Lopez-Meyer<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>1</sup>, Georg Stemmer<sup>2</sup>, Lama Nachman<sup>3</sup> and Jonathan Huang<sup>4</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, Neubiberg, Germany, <sup>3</sup>Intel Labs, Intel Corporation, California, USA, <sup>4</sup>California, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lopez-Meyer_IL_task1a_1</span> <span class="label label-primary">Lopez-Meyer_IL_task1a_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lopez-Meyer2020_t1a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lopez-Meyer2020_t1a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lopez-Meyer2020_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lopez-Meyer_128_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lopez-Meyer2020_t1a" class="panel-collapse collapse" id="collapse-Lopez-Meyer2020_t1a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Ensemble of Convolutional Neural Networks for the DCASE 2020 Acoustic Scene Classification Challenge
      </h4>
<p style="text-align:left">
<small>
        Paulo Lopez-Meyer<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>1</sup>, Georg Stemmer<sup>2</sup>, Lama Nachman<sup>3</sup> and Jonathan Huang<sup>4</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, Neubiberg, Germany, <sup>3</sup>Intel Labs, Intel Corporation, California, USA, <sup>4</sup>California, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       For the DCASE 2020 Task 1a, we propose the use of three different deep learning based convolutional neural networks architectures: AclNet, AclResNet50, and Vgg12. These three neural network architectures were pre-trained with Audioset data for embedding generation, and then fine-tuned with an added classification layer, though the development dataset provided by the task. The outputs produced by these trained models proved to be complementary when ensemble, as expected, due to the different nature of the feature front-end, and of architecture diversity. The ensemble average of these models’ outputs improved significantly from best single model classification accuracy of 67.55% to 69.74% on the evaluation dataset, when trained with the challenge suggested development partitioning.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         random noise, random gain, random cropping, mixup, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         raw waveform, mel filterbank
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, ResNet, VGG, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lopez-Meyer2020_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lopez-Meyer_128_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lopez-Meyer2020_t1alabel" class="modal fade" id="bibtex-Lopez-Meyer2020_t1a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLopez-Meyer2020_t1alabel">
        Ensemble of Convolutional Neural Networks for the DCASE 2020 Acoustic Scene Classification Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lopez-Meyer2020_t1a,
    Author = "Lopez-Meyer, Paulo and Del Hoyo Ontiveros, Juan Antonio and Stemmer, Georg and Nachman, Lama and Huang, Jonathan",
    title = "Ensemble of Convolutional Neural Networks for the {DCASE} 2020 Acoustic Scene Classification Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "For the DCASE 2020 Task 1a, we propose the use of three different deep learning based convolutional neural networks architectures: AclNet, AclResNet50, and Vgg12. These three neural network architectures were pre-trained with Audioset data for embedding generation, and then fine-tuned with an added classification layer, though the development dataset provided by the task. The outputs produced by these trained models proved to be complementary when ensemble, as expected, due to the different nature of the feature front-end, and of architecture diversity. The ensemble average of these models’ outputs improved significantly from best single model classification accuracy of 67.55\% to 69.74\% on the evaluation dataset, when trained with the challenge suggested development partitioning."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Naranjo-Alcazar2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Naranjo-Alcazar2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
       </h4>
<p style="text-align:left">
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>3</sup>, Pedro Zuccarello<sup>3</sup> and Maximo Cobos<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>AI department, Visualfy, Benisano, Spain, <sup>2</sup>Computer Science Department, Universitat de Valencia, Burjassot, Spain, <sup>3</sup>AI department, Visualfy, Benisano, Valencia
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Naranjo-Alcazar_Vfy_task1a_1</span> <span class="label label-primary">Naranjo-Alcazar_Vfy_task1a_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Naranjo-Alcazar2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Naranjo-Alcazar2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Naranjo-Alcazar2020_t1" class="panel-collapse collapse" id="collapse-Naranjo-Alcazar2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
      </h4>
<p style="text-align:left">
<small>
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>3</sup>, Pedro Zuccarello<sup>3</sup> and Maximo Cobos<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>AI department, Visualfy, Benisano, Spain, <sup>2</sup>Computer Science Department, Universitat de Valencia, Burjassot, Spain, <sup>3</sup>AI department, Visualfy, Benisano, Valencia
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Acoustic Scene Classification (ASC) is a problem related to the field of machine listening whose objective is to classify/tag an audio clip in a predefined label describing a scene location such as park, airport among others. Due to the emergence of more extensive audio datasets, solutions based on Deep Learning techniques have become the state-of-the-art. The most common choice are those that implement a convolutional neural network (CNN) having previously transformed the audio signal into a 2D representation. This twodimensional audio representation is currently a subject of research. In addition, there are solutions that propose several concatenated 2D representations, thus creating a representation with several input channels. This article proposes two novel stereo audio representations to maximize the accuracy of an ASC framework. These representations correspond to the 3-channel representations such as the left channel, the right channel and the difference between channels (L − R) using the Gammatone filter bank and the harmonic, percussive and difference between channels sources using the Mel filter bank. Both representations are also concatenated creating a 6-channel with different audio filter banks. Furthermore, the proposed CNN is a residual network that employs squeeze-excitation techniques in its residual blocks in a novel way to force the network to extract meaningful features from the audio representation. The proposed network is used in both subtasks with different modifications to meet the requirements of each one. However, since stereo audio is not available in Subtask A, the representations are slightly modified in that task. This technical report first presents the overlaps of the two tasks and then makes the relevant changes to each task in one section per task. The baselines are surpassed in both tasks by approximately 10 percentage points.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Gammatone; HPSS, log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Naranjo-Alcazar2020_t1label" class="modal fade" id="bibtex-Naranjo-Alcazar2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNaranjo-Alcazar2020_t1label">
        Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Naranjo-Alcazar2020_t1,
    Author = "Naranjo-Alcazar, Javier and Perez-Castanos, Sergi and Zuccarello, Pedro and Cobos, Maximo",
    title = "Task 1 {DCASE} 2020: {ASC} with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation {CNNs}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "Acoustic Scene Classification (ASC) is a problem related to the field of machine listening whose objective is to classify/tag an audio clip in a predefined label describing a scene location such as park, airport among others. Due to the emergence of more extensive audio datasets, solutions based on Deep Learning techniques have become the state-of-the-art. The most common choice are those that implement a convolutional neural network (CNN) having previously transformed the audio signal into a 2D representation. This twodimensional audio representation is currently a subject of research. In addition, there are solutions that propose several concatenated 2D representations, thus creating a representation with several input channels. This article proposes two novel stereo audio representations to maximize the accuracy of an ASC framework. These representations correspond to the 3-channel representations such as the left channel, the right channel and the difference between channels (L − R) using the Gammatone filter bank and the harmonic, percussive and difference between channels sources using the Mel filter bank. Both representations are also concatenated creating a 6-channel with different audio filter banks. Furthermore, the proposed CNN is a residual network that employs squeeze-excitation techniques in its residual blocks in a novel way to force the network to extract meaningful features from the audio representation. The proposed network is used in both subtasks with different modifications to meet the requirements of each one. However, since stereo audio is not available in Subtask A, the representations are slightly modified in that task. This technical report first presents the overlaps of the two tasks and then makes the relevant changes to each task in one section per task. The baselines are surpassed in both tasks by approximately 10 percentage points."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Paniagua2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Paniagua2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
       </h4>
<p style="text-align:left">
        Arturo Paniagua, Rubén Fraile, Juana M. Gutiérrez-Arriola, Nicolás Sáenz-lechón and Víctor J- Osma-Ruiz
       </p>
<p style="text-align:left">
<em>
         CITSEM, Universidad Politéctica de Madrid, Madrid, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Paniagua_UPM_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Paniagua2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Paniagua2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Paniagua2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Paniagua_97.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Paniagua2020" class="panel-collapse collapse" id="collapse-Paniagua2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
      </h4>
<p style="text-align:left">
<small>
        Arturo Paniagua, Rubén Fraile, Juana M. Gutiérrez-Arriola, Nicolás Sáenz-lechón and Víctor J- Osma-Ruiz
       </small>
<br/>
<small>
<em>
         CITSEM, Universidad Politéctica de Madrid, Madrid, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       A system for the automatic classification of acoustic scenes is proposed that uses one audio channel for calculating the spectral distribution of energy across auditory-relevant frequency bands, and some descriptors of the envelope modulation spectrum (EMS) obtained by means of the discrete cosine transform. When the stereophonic signal captured by a binaural microphone is available, this parameter set is augmented by including the first coefficients of the cepstrum of the cross-correlation between both audio channels. This cross-correlation contains information on the angular distribution of acoustic sources. These three types of features (energy spectrum, EMS and cepstrum of cross-correlation) are used as inputs for a multilayer perceptron with two hidden layers and a number of adjustable parameters below 15,000.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         LTAS, envelope modulation spectrum
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MLP
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average log-likelihood
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Paniagua2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Paniagua_97.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Paniagua2020label" class="modal fade" id="bibtex-Paniagua2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPaniagua2020label">
        Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Paniagua2020,
    Author = "Paniagua, Arturo and Fraile, Rubén and Gutiérrez-Arriola, Juana M. and Sáenz-lechón, Nicolás and Osma-Ruiz, Víctor J-",
    title = "Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "A system for the automatic classification of acoustic scenes is proposed that uses one audio channel for calculating the spectral distribution of energy across auditory-relevant frequency bands, and some descriptors of the envelope modulation spectrum (EMS) obtained by means of the discrete cosine transform. When the stereophonic signal captured by a binaural microphone is available, this parameter set is augmented by including the first coefficients of the cepstrum of the cross-correlation between both audio channels. This cross-correlation contains information on the angular distribution of acoustic sources. These three types of features (energy spectrum, EMS and cepstrum of cross-correlation) are used as inputs for a multilayer perceptron with two hidden layers and a number of adjustable parameters below 15,000."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Shao2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Shao2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Thuee Submission for DCASE 2020 Challenge Task1a
       </h4>
<p style="text-align:left">
        Yunfei Shao<sup>1</sup>, Xinxin Ma<sup>2</sup>, Yong Ma<sup>2</sup> and Wei-Qiang Zhang<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Department of Electronic Engineering, Tsinghua University, Beijing, China, <sup>2</sup>School of Physics and Electronic Engineering, Jiangsu Normal University, Xuzhou, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Zhang_THUEE_task1a_1</span> <span class="label label-primary">Zhang_THUEE_task1a_2</span> <span class="label label-primary">Zhang_THUEE_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Shao2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Shao2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Shao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_48.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Shao2020" class="panel-collapse collapse" id="collapse-Shao2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Thuee Submission for DCASE 2020 Challenge Task1a
      </h4>
<p style="text-align:left">
<small>
        Yunfei Shao<sup>1</sup>, Xinxin Ma<sup>2</sup>, Yong Ma<sup>2</sup> and Wei-Qiang Zhang<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Department of Electronic Engineering, Tsinghua University, Beijing, China, <sup>2</sup>School of Physics and Electronic Engineering, Jiangsu Normal University, Xuzhou, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we described our submission for the task1a of Detection and Classification of Acoustic Scenes and Events (DACSE) 2020 Challenge: Acoustic Scene Classification with Multiple Devices. Our methods are mainly based on two types of deep learning models: ResNet and Mini-SegNet. In our submissions, we designed two classification systems. Firstly, we applied spectrum correction to combat mismatched frequency responses, and further proposed in log-mel domain. Then these features are fed to ResNet or Mini-SegNet models for feature learning. In order to prevent overfitting, we adopted mixup augmentation, ImageDataGenrator and temporal crop augmentation for data augmentation. Besides, we tried an ensemble of multiple subsystems to enhance the generalization capability of our system. In our work, our final system achieved an average of 75.02% on different devices in the Development dataset.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, ImageDataGenerator, temporal cropping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet, Mini-SegNet
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Shao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_48.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Shao2020label" class="modal fade" id="bibtex-Shao2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexShao2020label">
        Thuee Submission for DCASE 2020 Challenge Task1a
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Shao2020,
    Author = "Shao, Yunfei and Ma, Xinxin and Ma, Yong and Zhang, Wei-Qiang",
    title = "Thuee Submission for {DCASE} 2020 Challenge Task1a",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this report, we described our submission for the task1a of Detection and Classification of Acoustic Scenes and Events (DACSE) 2020 Challenge: Acoustic Scene Classification with Multiple Devices. Our methods are mainly based on two types of deep learning models: ResNet and Mini-SegNet. In our submissions, we designed two classification systems. Firstly, we applied spectrum correction to combat mismatched frequency responses, and further proposed in log-mel domain. Then these features are fed to ResNet or Mini-SegNet models for feature learning. In order to prevent overfitting, we adopted mixup augmentation, ImageDataGenrator and temporal crop augmentation for data augmentation. Besides, we tried an ensemble of multiple subsystems to enhance the generalization capability of our system. In our work, our final system achieved an average of 75.02\% on different devices in the Development dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Shim2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Shim2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Audio Tagging and Deep Architectures for Acoustic Scene Classification: Uos Submission for the DCASE 2020 Challenge
       </h4>
<p style="text-align:left">
        Hye-jin Shim, Ju-ho Kim, Jee-weon Jung and Ha-jin Yu
       </p>
<p style="text-align:left">
<em>
         School of Computer Science, University of Seoul, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Shim_UOS_task1a_1</span> <span class="label label-primary">Shim_UOS_task1a_2</span> <span class="label label-primary">Shim_UOS_task1a_3</span> <span class="label label-primary">Shim_UOS_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Shim2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Shim2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Shim2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Shim_120.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Shim2020" class="panel-collapse collapse" id="collapse-Shim2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Audio Tagging and Deep Architectures for Acoustic Scene Classification: Uos Submission for the DCASE 2020 Challenge
      </h4>
<p style="text-align:left">
<small>
        Hye-jin Shim, Ju-ho Kim, Jee-weon Jung and Ha-jin Yu
       </small>
<br/>
<small>
<em>
         School of Computer Science, University of Seoul, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we address the UOS submission for the Detection and Classification of Acoustic Scenes and Events 2020 Challenge Task 1-a. We propose to utilize the representation vectors, extracted from a pre-trained audio tagging system, for the acoustic scene classification task. Audio tagging denotes the existence of various sound events and is known to help the classification of acoustic scene. To select suitable feature for the acoustic scene classification task, we also explore deep architectures such as light convolutional neural networks and convolutional block attention module. Experiments are conducted using the official fold-1 configuration test set. Results using audio tagging representation and deep architectures demonstrate accuracies of 68.8% and 70.5%, compared to that of 65.3% of the baseline. Additionally, score-sum ensemble of the two proposed systems has an accuracy of 71.9% which shows 10.1% relative improvement.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, SpecAugment; mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ensemble; LCNN; ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         score-sum
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Shim2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Shim_120.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Shim2020label" class="modal fade" id="bibtex-Shim2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexShim2020label">
        Audio Tagging and Deep Architectures for Acoustic Scene Classification: Uos Submission for the DCASE 2020 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Shim2020,
    Author = "Shim, Hye-jin and Kim, Ju-ho and Jung, Jee-weon and Yu, Ha-jin",
    title = "Audio Tagging and Deep Architectures for Acoustic Scene Classification: Uos Submission for the {DCASE} 2020 Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this technical report, we address the UOS submission for the Detection and Classification of Acoustic Scenes and Events 2020 Challenge Task 1-a. We propose to utilize the representation vectors, extracted from a pre-trained audio tagging system, for the acoustic scene classification task. Audio tagging denotes the existence of various sound events and is known to help the classification of acoustic scene. To select suitable feature for the acoustic scene classification task, we also explore deep architectures such as light convolutional neural networks and convolutional block attention module. Experiments are conducted using the official fold-1 configuration test set. Results using audio tagging representation and deep architectures demonstrate accuracies of 68.8\% and 70.5\%, compared to that of 65.3\% of the baseline. Additionally, score-sum ensemble of the two proposed systems has an accuracy of 71.9\% which shows 10.1\% relative improvement."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Suh2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Suh2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Designing Acoustic Scene Classification Models with CNN Variants
       </h4>
<p style="text-align:left">
        Sangwon Suh, Sooyoung Park, Youngho Jeong and Taejin Lee
       </p>
<p style="text-align:left">
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Suh_ETRI_task1a_1</span> <span class="label label-primary">Suh_ETRI_task1a_2</span> <span class="label label-primary">Suh_ETRI_task1a_3</span> <span class="label label-primary">Suh_ETRI_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Suh2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Suh2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Suh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Suh_101.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Suh2020" class="panel-collapse collapse" id="collapse-Suh2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Designing Acoustic Scene Classification Models with CNN Variants
      </h4>
<p style="text-align:left">
<small>
        Sangwon Suh, Sooyoung Park, Youngho Jeong and Taejin Lee
       </small>
<br/>
<small>
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our Acoustic Scene Classification systems for DCASE2020 challenge Task1. For subtask A, we designed a single model implemented with three parallel ResNets, which is named Trident ResNet. We have confirmed that this structure is beneficial when analyzing samples collected from minority or unseen devices, and confirmed 73.7% classification accuracy for the test split. For subtask B, we used the Inception module to build a Shallow Inception model that has fewer parameters than the CNN of the DCASE baseline system. Due to the sparse structure of the Inception module, we have enhanced the accuracy of the model up to 97.6%, while reducing the number of parameters.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         temporal cropping, mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; Snapshot
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average; weighted score average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Suh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Suh_101.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Suh2020label" class="modal fade" id="bibtex-Suh2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSuh2020label">
        Designing Acoustic Scene Classification Models with CNN Variants
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Suh2020,
    Author = "Suh, Sangwon and Park, Sooyoung and Jeong, Youngho and Lee, Taejin",
    title = "Designing Acoustic Scene Classification Models with {CNN} Variants",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our Acoustic Scene Classification systems for DCASE2020 challenge Task1. For subtask A, we designed a single model implemented with three parallel ResNets, which is named Trident ResNet. We have confirmed that this structure is beneficial when analyzing samples collected from minority or unseen devices, and confirmed 73.7\% classification accuracy for the test split. For subtask B, we used the Inception module to build a Shallow Inception model that has fewer parameters than the CNN of the DCASE baseline system. Due to the sparse structure of the Inception module, we have enhanced the accuracy of the model up to 97.6\%, while reducing the number of parameters."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Swiecicki2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Swiecicki2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Efficientnet
       </h4>
<p style="text-align:left">
        Jakub Swiecicki
       </p>
<p style="text-align:left">
<em>
         None, Warsaw, Poland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Swiecicki_NON_task1a_1</span> <span class="label label-primary">Swiecicki_NON_task1a_2</span> <span class="label label-primary">Swiecicki_NON_task1a_3</span> <span class="label label-primary">Swiecicki_NON_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Swiecicki2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Swiecicki2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Swiecicki2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Swiecicki_98.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Swiecicki2020" class="panel-collapse collapse" id="collapse-Swiecicki2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Efficientnet
      </h4>
<p style="text-align:left">
<small>
        Jakub Swiecicki
       </small>
<br/>
<small>
<em>
         None, Warsaw, Poland
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our solution to task 1b of the DCASE 2020 acoustic scene classification challenge. Our primary focus was to develop a single efficient model. We decided to concentrate on a single model in order to reflect the typical business situation. In our solution we chose to use log-mel spectrograms with deltas and delta-deltas features as a sound sample representation. We augmented the data with multiple techniques - mixup, specaugment, and spectrogram resizing. Our final model used EfficientNet [1] architecture.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, SpecAugment, random resize, random cropping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         EfficientNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Swiecicki2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Swiecicki_98.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Swiecicki2020label" class="modal fade" id="bibtex-Swiecicki2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSwiecicki2020label">
        Acoustic Scene Classification Using Efficientnet
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Swiecicki2020,
    Author = "Swiecicki, Jakub",
    title = "Acoustic Scene Classification Using Efficientnet",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our solution to task 1b of the DCASE 2020 acoustic scene classification challenge. Our primary focus was to develop a single efficient model. We decided to concentrate on a single model in order to reflect the typical business situation. In our solution we chose to use log-mel spectrograms with deltas and delta-deltas features as a sound sample representation. We augmented the data with multiple techniques - mixup, specaugment, and spectrogram resizing. Our final model used EfficientNet [1] architecture."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Vilouras2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Vilouras2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
       </h4>
<p style="text-align:left">
        Konstantinos Vilouras
       </p>
<p style="text-align:left">
<em>
         Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Vilouras_AUTh_task1a_1</span> <span class="label label-primary">Vilouras_AUTh_task1a_2</span> <span class="label label-primary">Vilouras_AUTh_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Vilouras2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Vilouras2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Vilouras2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Vilouras_3.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Vilouras2020" class="panel-collapse collapse" id="collapse-Vilouras2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
      </h4>
<p style="text-align:left">
<small>
        Konstantinos Vilouras
       </small>
<br/>
<small>
<em>
         Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approach to Task 1 ''Acoustic Scene Classification'' of the DCASE 2020 challenge. For subtask A, we introduce per-channel energy normalization (PCEN) as an additional preprocessing step along with log-Mel spectrograms. We also propose two residual network architectures utilizing “Shake-Shake” regularization and the “Squeeze-and-Excitation” block, respectively. Our best submission (ensemble of 8 classifiers) outperforms the corresponding baseline system by 16.2% in terms of macro-average accuracy. For subtask B, we mainly focus on a low complexity, fully convolutional neural network architecture, which leads to 5% relative improvement over baseline accuracy.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time stretching, frequency masking, shifting, clipping distortion
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, PCEN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Vilouras2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Vilouras_3.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Vilouras2020label" class="modal fade" id="bibtex-Vilouras2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexVilouras2020label">
        Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Vilouras2020,
    Author = "Vilouras, Konstantinos",
    title = "Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our approach to Task 1 ''Acoustic Scene Classification'' of the DCASE 2020 challenge. For subtask A, we introduce per-channel energy normalization (PCEN) as an additional preprocessing step along with log-Mel spectrograms. We also propose two residual network architectures utilizing “Shake-Shake” regularization and the “Squeeze-and-Excitation” block, respectively. Our best submission (ensemble of 8 classifiers) outperforms the corresponding baseline system by 16.2\% in terms of macro-average accuracy. For subtask B, we mainly focus on a low complexity, fully convolutional neural network architecture, which leads to 5\% relative improvement over baseline accuracy."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Waldekar2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Waldekar2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
       </h4>
<p style="text-align:left">
        Shefali Waldekar, Kishore Kumar A and Goutam Saha
       </p>
<p style="text-align:left">
<em>
         Electronics and Electrical Communication Engineering Dept., Indian Institute of Technology Kharagpur, Kharagpur, India
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Waldekar_IITKGP_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Waldekar2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Waldekar2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Waldekar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Waldekar_148.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Waldekar2020" class="panel-collapse collapse" id="collapse-Waldekar2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
      </h4>
<p style="text-align:left">
<small>
        Shefali Waldekar, Kishore Kumar A and Goutam Saha
       </small>
<br/>
<small>
<em>
         Electronics and Electrical Communication Engineering Dept., Indian Institute of Technology Kharagpur, Kharagpur, India
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes a submission for IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 for Task 1 (acoustic scene classification (ASC)), sub-task A (ASC with Multiple Devices) and sub-task B (LowComplexity ASC). The systems exploit time-frequency representation of audio to obtain the scene labels. The system for Task1A follows a simple pattern classification framework employing wavelet transform based mel-scaled features along with support vector machine (SVM) as classifier. Texture features, namely Local Binary Pattern (LBP) extracted from log of mel-band energies is used in a similar classification framework for Task 1B. The proposed systems outperform the deep-learning based baseline system with the development dataset provided for the respective sub-tasks.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFDWC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Waldekar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Waldekar_148.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Waldekar2020label" class="modal fade" id="bibtex-Waldekar2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWaldekar2020label">
        Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Waldekar2020,
    Author = "Waldekar, Shefali and Kumar A, Kishore and Saha, Goutam",
    title = "Mel-Scaled Wavelet-Based Features for Sub-Task {A} and Texture Features for Sub-Task {B} of {DCASE} 2020 Task 1",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes a submission for IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 for Task 1 (acoustic scene classification (ASC)), sub-task A (ASC with Multiple Devices) and sub-task B (LowComplexity ASC). The systems exploit time-frequency representation of audio to obtain the scene labels. The system for Task1A follows a simple pattern classification framework employing wavelet transform based mel-scaled features along with support vector machine (SVM) as classifier. Texture features, namely Local Binary Pattern (LBP) extracted from log of mel-band energies is used in a similar classification framework for Task 1B. The proposed systems outperform the deep-learning based baseline system with the development dataset provided for the respective sub-tasks."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wang2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Wang2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Multiple Decision Schemes
       </h4>
<p style="text-align:left">
        Helin Wang, Dading Chong and Yuexian Zou
       </p>
<p style="text-align:left">
<em>
         School of ECE, Peking University, Shenzhen, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Helin_ADSPLAB_task1a_1</span> <span class="label label-primary">Helin_ADSPLAB_task1a_2</span> <span class="label label-primary">Helin_ADSPLAB_task1a_3</span> <span class="label label-primary">Helin_ADSPLAB_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wang2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wang2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wang2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Helin_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wang2020_t1" class="panel-collapse collapse" id="collapse-Wang2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Multiple Decision Schemes
      </h4>
<p style="text-align:left">
<small>
        Helin Wang, Dading Chong and Yuexian Zou
       </small>
<br/>
<small>
<em>
         School of ECE, Peking University, Shenzhen, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the ADSPLAB team’s submission for Task1 of DCASE2020 challenge. Our acoustic scene classifi- cation (ASC) system is based on the convolutional neural networks (CNN). Multiple decision schemes are proposed in our system, in- cluding the decision schemes in multiple representations, multiple frequency bands, and multiple temporal frames. The final system is the fusion of models with multiple decision schemes and mod- els pre-trained on AudioSet. The experimental results show that our system could achieve the accuracy of 84.5 %(official baseline: 54.1%) and 92.1% (official baseline: 87.3%) on the officially provided fold 1 evaluation dataset of Task1A and Task1B, respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC, log-mel energies, CQT, Gammatone
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wang2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Helin_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wang2020_t1label" class="modal fade" id="bibtex-Wang2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWang2020_t1label">
        Acoustic Scene Classification with Multiple Decision Schemes
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wang2020_t1,
    Author = "Wang, Helin and Chong, Dading and Zou, Yuexian",
    title = "Acoustic Scene Classification with Multiple Decision Schemes",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the ADSPLAB team’s submission for Task1 of DCASE2020 challenge. Our acoustic scene classifi- cation (ASC) system is based on the convolutional neural networks (CNN). Multiple decision schemes are proposed in our system, in- cluding the decision schemes in multiple representations, multiple frequency bands, and multiple temporal frames. The final system is the fusion of models with multiple decision schemes and mod- els pre-trained on AudioSet. The experimental results show that our system could achieve the accuracy of 84.5 \%(official baseline: 54.1\%) and 92.1\% (official baseline: 87.3\%) on the officially provided fold 1 evaluation dataset of Task1A and Task1B, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wang2020a" style="box-shadow: none">
<div class="panel-heading" id="heading-Wang2020a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Device Mismatch Using Data Augmentation by Spectrum Correction
       </h4>
<p style="text-align:left">
        Peiyao Wang, Zhiyuan Cheng and Xinkang Xu
       </p>
<p style="text-align:left">
<em>
         Speech Group, Hithink RoyalFlush Information Network Co.,Ltd, Hangzhou, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Wang_RoyalFlush_task1a_1</span> <span class="label label-primary">Wang_RoyalFlush_task1a_2</span> <span class="label label-primary">Wang_RoyalFlush_task1a_3</span> <span class="label label-primary">Wang_RoyalFlush_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wang2020a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wang2020a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wang2020a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wang_126.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wang2020a" class="panel-collapse collapse" id="collapse-Wang2020a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Device Mismatch Using Data Augmentation by Spectrum Correction
      </h4>
<p style="text-align:left">
<small>
        Peiyao Wang, Zhiyuan Cheng and Xinkang Xu
       </small>
<br/>
<small>
<em>
         Speech Group, Hithink RoyalFlush Information Network Co.,Ltd, Hangzhou, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes the submissions by RoyalFlush of DCASE2020 task1a. Our aim is to find an audio scene classification system that is robust against multiple devices. We use logMel and its first and second derivatives as input features. We use the fully convolutional deep neural networks as classification model, and some strategies such as pre-Act, L2 regularization, dropout and feature normalization were applied. For improving the data imbalance caused by the different device, we tried to generate more training data by using device-related spectrum correction method
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, spectrum correction
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wang2020a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wang_126.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wang2020alabel" class="modal fade" id="bibtex-Wang2020a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWang2020alabel">
        Acoustic Scene Classification with Device Mismatch Using Data Augmentation by Spectrum Correction
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wang2020a,
    Author = "Wang, Peiyao and Cheng, Zhiyuan and Xu, Xinkang",
    title = "Acoustic Scene Classification with Device Mismatch Using Data Augmentation by Spectrum Correction",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes the submissions by RoyalFlush of DCASE2020 task1a. Our aim is to find an audio scene classification system that is robust against multiple devices. We use logMel and its first and second derivatives as input features. We use the fully convolutional deep neural networks as classification model, and some strategies such as pre-Act, L2 regularization, dropout and feature normalization were applied. For improving the data imbalance caused by the different device, we tried to generate more training data by using device-related spectrum correction method"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wu2020_t1a" style="box-shadow: none">
<div class="panel-heading" id="heading-Wu2020_t1a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Robust Feature Learning for Acoustic Scene Classification with Multiple Devices
       </h4>
<p style="text-align:left">
        Yuzhong Wu and Tan Lee
       </p>
<p style="text-align:left">
<em>
         Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Wu_CUHK_task1a_1</span> <span class="label label-primary">Wu_CUHK_task1a_2</span> <span class="label label-primary">Wu_CUHK_task1a_3</span> <span class="label label-primary">Wu_CUHK_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wu2020_t1a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wu2020_t1a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wu2020_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wu_11_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Wu2020_t1a').collapse('show');window.location.hash='#Wu2020_t1a';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wu2020_t1a" class="panel-collapse collapse" id="collapse-Wu2020_t1a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Robust Feature Learning for Acoustic Scene Classification with Multiple Devices
      </h4>
<p style="text-align:left">
<small>
        Yuzhong Wu and Tan Lee
       </small>
<br/>
<small>
<em>
         Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for Task 1A of DCASE2020 challenge. The objective of the task is to identify acoustic scenes from audios recorded by various recording devices. In our ASC systems, we use sound-duration based decomposition method to decompose the time-frequency (TF) features into 3 components. Our observation shows that low frequency bins of the longduration component image are most easily affected by the change of recording devices. We use an AlexNet-like CNN model with the decomposed TF features to build ASC systems. To prevent the CNN classifier from over-fitting to the seen recording devices in the training dataset, we apply an auxiliary classifier on the embedding feature extracted from long-duration component image. We propose the regularized cross-entropy (RCE) loss to train the auxiliary classifier. Experiment results on development dataset shows that the use of regularized cross-entropy loss significantly improves the CNN accuracy on audios from unseen devices.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         wavelet filter-bank features
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wu2020_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wu_11_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/yzwu2017/DCASE2020_task1a" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wu2020_t1alabel" class="modal fade" id="bibtex-Wu2020_t1a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWu2020_t1alabel">
        Robust Feature Learning for Acoustic Scene Classification with Multiple Devices
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wu2020_t1a,
    Author = "Wu, Yuzhong and Lee, Tan",
    title = "Robust Feature Learning for Acoustic Scene Classification with Multiple Devices",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our submission for Task 1A of DCASE2020 challenge. The objective of the task is to identify acoustic scenes from audios recorded by various recording devices. In our ASC systems, we use sound-duration based decomposition method to decompose the time-frequency (TF) features into 3 components. Our observation shows that low frequency bins of the longduration component image are most easily affected by the change of recording devices. We use an AlexNet-like CNN model with the decomposed TF features to build ASC systems. To prevent the CNN classifier from over-fitting to the seen recording devices in the training dataset, we apply an auxiliary classifier on the embedding feature extracted from long-duration component image. We propose the regularized cross-entropy (RCE) loss to train the auxiliary classifier. Experiment results on development dataset shows that the use of regularized cross-entropy loss significantly improves the CNN accuracy on audios from unseen devices."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zhang2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Zhang2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Simple Convolutional Networks Attempting Acoustic Scene Classification Cross Devices
       </h4>
<p style="text-align:left">
        Chi Zhang<sup>1</sup>, Hanxin Zhu<sup>2</sup> and Cheng Ting<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Electronic Information Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>2</sup>Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>3</sup>University of Electronic Science and Technology of China, Chengdu, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Zhang_UESTC_task1a_1</span> <span class="label label-primary">Zhang_UESTC_task1a_2</span> <span class="label label-primary">Zhang_UESTC_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zhang2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zhang2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zhang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_20.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zhang2020" class="panel-collapse collapse" id="collapse-Zhang2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Simple Convolutional Networks Attempting Acoustic Scene Classification Cross Devices
      </h4>
<p style="text-align:left">
<small>
        Chi Zhang<sup>1</sup>, Hanxin Zhu<sup>2</sup> and Cheng Ting<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Electronic Information Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>2</sup>Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>3</sup>University of Electronic Science and Technology of China, Chengdu, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for task1a (Acoustic Scene Classification with Multiple Devices) of the DCASE 2020 Challenge. The results of the DCASE 2019 show that the convolution neural networks (CNNs) can acquire excellent classification accuracies. Our work will still be based on the convolution neural networks. We consider two feature extraction methods that are provided by OpenL3 library. Finally, our method improves the accuracy of classification by 2% as compared to the baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         OpenL3
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MLP , CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         maximum likelihood
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zhang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_20.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zhang2020label" class="modal fade" id="bibtex-Zhang2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZhang2020label">
        Simple Convolutional Networks Attempting Acoustic Scene Classification Cross Devices
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zhang2020,
    Author = "Zhang, Chi and Zhu, Hanxin and Ting, Cheng",
    title = "Simple Convolutional Networks Attempting Acoustic Scene Classification Cross Devices",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our submission for task1a (Acoustic Scene Classification with Multiple Devices) of the DCASE 2020 Challenge. The results of the DCASE 2019 show that the convolution neural networks (CNNs) can acquire excellent classification accuracies. Our work will still be based on the convolution neural networks. We consider two feature extraction methods that are provided by OpenL3 library. Finally, our method improves the accuracy of classification by 2\% as compared to the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>