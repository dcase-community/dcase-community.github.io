<!DOCTYPE html><html lang="en">
<head>
    <title>Acoustic scene classification - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2013/task-acoustic-scene-classification">
        <meta name="author" content="Toni Heittola" />
        <meta name="description" content="Challenge has ended. Full results for this task can be found here This page collects information from original DCASE2013 Challenge website to document DCASE challenge tasks in an uniform way. Description The scene classification (SC) challenge will address the problem of identifying and classifying acoustic scenes and soundscapes. The dataset …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2013</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2013/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group  active">
        <a href="/challenge2013/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2013/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2013/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2013/task-sound-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2013/task-sound-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-ol"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OL</a>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-os"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OS</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2013/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2013/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2013/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/water-01.jpg);box-shadow: 0px 1000px rgba(0, 0, 0, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-primary"></i><i class="fa dc-scene fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Scenes</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 1</span></span><img src="../images/logos/dcase/dcase2013_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Acoustic<br> scene classification</h1><hr class="small right bold"><span class="subheading">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Dimitrios Giannoulis" class="img img-circle" src="/images/person/dimitrios_giannoulis.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Dimitrios Giannoulis</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Dan Stowell" class="img img-circle" src="/images/person/dan_stowell.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Dan Stowell</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Emmanouil Benetos" class="img img-circle" src="/images/person/emmanouil_benetos.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Emmanouil Benetos</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mathieu Lagrange" class="img img-circle" src="/images/person/mathieu_lagrange_.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mathieu Lagrange</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.irccyn.ec-nantes.fr/en/research-teams/adtsi">
                                IRCCYN
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mathias Rossignol" class="img img-circle" src="/images/person/default.png" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mathias Rossignol</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://anasynth.ircam.fr/home/english">
                                IRCAM
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mark D. Plumbley" class="img img-circle" src="/images/person/mark_plumbley.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mark D. Plumbley</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a></li>
<li><a href="#audio-dataset">Audio dataset</a>
<ul>
<li><a href="#download">Download</a></li>
</ul>
</li>
<li><a href="#submission">Submission</a>
<ul>
<li><a href="#submission-calling-formats">Submission calling formats</a></li>
<li><a href="#input-and-output-file-formats">Input and output file formats</a></li>
<li><a href="#packaging-submissions">Packaging submissions</a></li>
<li><a href="#time-and-hardware-limits">Time and Hardware limits</a></li>
</ul>
</li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#baseline-system">Baseline system</a></li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="alert alert-info">
<strong>Challenge has ended.</strong> Full results for this task can be found <a class="btn btn-default btn-xs" href="/challenge2013/task-acoustic-scene-classification-results">here <i class="fa fa-caret-right"></i></a>
<br/>This page collects information from original <a href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/" target="_blank">DCASE2013 Challenge website</a> to document DCASE challenge tasks in an uniform way.
</p>
<h1 id="description">Description</h1>
<p>The scene classification (SC) challenge will address the problem of identifying and classifying acoustic scenes and soundscapes.</p>
<p>The dataset for the scene classification task will consist of 30sec recordings of various acoustic scenes. The dataset will consist of 2 parts each made up of 6 audio recordings for each scene (class). The one will be sent out to the participants as a development set and the second will be kept secret and used for the train/test scene classification task. The list of scenes is: busy street, quiet street, Park, open-air market, bus, subway-train, restaurant, shop/supermarket, office, subway station.</p>
<p>The recording device used for the task is a set of Soundman binaural microphones specifically made so that they imitate a pair of in-ear headphones that the user can wear. The proposed specifications for the recordings are: PCM, 44100 Hz, 16 bit (CD quality).</p>
<figure>
<div class="row row-centered">
<div class="col-xs-10 col-md-5 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2016/task1_overview.png"/>
<figcaption>Figure 1: Overview of acoustic scene classification system.</figcaption>
</div>
</div>
</figure>
<h1 id="audio-dataset">Audio dataset</h1>
<p>The data consists of 30-second audio files (WAV, stereo, 44.1 kHz, 16-bit), recorded using binaural headphones in locations around London at various times in 2012, by three different people. Locations were selected to represent instances of the following 10 classes:</p>
<ul>
<li><code>bus</code></li>
<li><code>busystreet</code></li>
<li><code>office</code></li>
<li><code>openairmarket</code></li>
<li><code>park</code></li>
<li><code>quietstreet</code></li>
<li><code>restaurant</code></li>
<li><code>supermarket</code></li>
<li><code>tube</code></li>
<li><code>tubestation</code></li>
</ul>
<p>The train/test (private) dataset consists of 10 recordings of each class, making 100 recordings total. This is similar to the publicly-released development dataset.</p>
<h2 id="download">Download</h2>
<p>** Development dataset (public)**</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_scene_classification" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_scene_classification" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Public</strong> Dataset for Scene Classification Task <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(345MB)</span>
<br/>
</div>
</div>
<p><br/></p>
<p>** Train/Test dataset (private)**</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_scene_classification_testset" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_scene_classification_testset" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Private</strong> Dataset for Scene Classification Task <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(354MB)</span>
<br/>
</div>
</div>
<p><br/></p>
<p><strong>In publications using the datasets, cite as:</strong></p>
<div class="btex-item" data-item="Stowell2015" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Stowell2015"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D. <span class="bibtex-protected">Stowell</span>, D. <span class="bibtex-protected">Giannoulis</span>, E. <span class="bibtex-protected">Benetos</span>, M. <span class="bibtex-protected">Lagrange</span>, and M. D. <span class="bibtex-protected">Plumbley</span>.
<em>Detection and classification of acoustic scenes and events.</em>
<em>IEEE Transactions on Multimedia</em>, 17(10):1733–1746, Oct 2015.
<a href="https://doi.org/10.1109/TMM.2015.2428998">doi:10.1109/TMM.2015.2428998</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexStowell2015d8cbed83eec345a48c51944f25e3b720" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseStowell2015d8cbed83eec345a48c51944f25e3b720" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseStowell2015d8cbed83eec345a48c51944f25e3b720" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingStowell2015d8cbed83eec345a48c51944f25e3b720" class="panel-collapse collapse" id="collapseStowell2015d8cbed83eec345a48c51944f25e3b720" role="tabpanel">
<h4>Detection and Classification of Acoustic Scenes and Events</h4>
<h5>Abstract</h5>
<p class="text-justify">For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexStowell2015d8cbed83eec345a48c51944f25e3b720" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexStowell2015d8cbed83eec345a48c51944f25e3b720label" class="modal fade" id="bibtexStowell2015d8cbed83eec345a48c51944f25e3b720" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexStowell2015d8cbed83eec345a48c51944f25e3b720label">Detection and Classification of Acoustic Scenes and Events</h4>
</div>
<div class="modal-body">
<pre>@article{Stowell2015,
    author = "{Stowell}, D. and {Giannoulis}, D. and {Benetos}, E. and {Lagrange}, M. and {Plumbley}, M. D.",
    journal = "IEEE Transactions on Multimedia",
    title = "Detection and Classification of Acoustic Scenes and Events",
    year = "2015",
    volume = "17",
    number = "10",
    pages = "1733-1746",
    abstract = "For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.",
    keywords = "acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition",
    doi = "10.1109/TMM.2015.2428998",
    issn = "1520-9210",
    month = "Oct"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<h1 id="submission">Submission</h1>
<p>The challenge participants submit an executable which accepts training list file and testing list file as a command-line parameter and outputs classification results to specified file.  </p>
<h2 id="submission-calling-formats">Submission calling formats</h2>
<p>Executables must accept command-line parameters which specify:</p>
<ul>
<li>A path to a training list file</li>
<li>A path to a test list file</li>
<li>A path to specify where the classification output file will be written</li>
<li>A path to a scratch folder which the executable can optionally use to write temporary data</li>
</ul>
<p>Executables must <strong>NOT write</strong> data anywhere except the classification output file and the scratch folder.</p>
<p>A typical entry-point for your submission could be for us to run a command such as one of these:</p>
<div class="highlight"><pre><span></span><code>TrainAndClassify.sh /path/to/scratch/folder /path/to/trainListFile.txt /path/to/testListFile.txt  /path/to/outputListFile.txt

python smacpy.py -q --trainlist /path/to/trainListFile.txt --testlist /path/to/testListFile.txt --outlist /path/to/outputListFile.txt
</code></pre></div>
<h2 id="input-and-output-file-formats">Input and output file formats</h2>
<p>The audio files to be used in these tasks will be specified in simple ASCII list files. The formats for the list files are specified below:</p>
<h3>Training list file</h3>
<p>The list file passed for model training will be a simple ASCII list file. This file will contain one path per line, followed by a tab character and the class label, again with no header line. I.e.</p>
<div class="highlight"><pre><span></span><code>&lt;example path and filename&gt;\t&lt;class label&gt;
</code></pre></div>
<p>E.g.</p>
<div class="highlight"><pre><span></span><code>/path/to/track1.wav tubestation
/path/to/track2.wav park
...
</code></pre></div>
<h3>Test (classification) list file</h3>
<p>The list file passed for testing classification will be a simple ASCII list file with one path per line with no header line, and no class label. I.e.</p>
<div class="highlight"><pre><span></span><code>&lt;example path and filename&gt;
</code></pre></div>
<p>E.g.</p>
<div class="highlight"><pre><span></span><code>/path/to/track1.wav
/path/to/track2.wav
...
</code></pre></div>
<h3>Classification output file</h3>
<p>Participating algorithms should produce a simple ASCII list file identical in format to the Training list file. This file will contain one path per line, followed by a tab character and the scene label,
again with no header line. I.e. </p>
<div class="highlight"><pre><span></span><code>&lt;example path and filename&gt;\t&lt;class label&gt;
</code></pre></div>
<p>E.g.</p>
<div class="highlight"><pre><span></span><code>/path/to/track1.wav tubestation
/path/to/track2.wav park
...
</code></pre></div>
<p>There should be no additional tab characters anywhere, and there should be no whitespace added after the label, just the newline.</p>
<h2 id="packaging-submissions">Packaging submissions</h2>
<p>For Python/R/C/C++/etc submissions, please ensure that the submission can run on the Linux disk image we provide, WITHOUT any additional configuration. You may have modified the virtual machine after downloading it, but we will not be using your modified disk image - we will be running your submission on the standard disk image. This means:</p>
<ul>
<li>if you have used additional Python/R script libraries, they must be included in your submission bundle, and your script should be able to use them without installing them systemwide.</li>
<li>if you have used any additional C/C++ libraries, they must be statically-linked to your executable. </li>
</ul>
<p>For Matlab submissions, ensure that the submission can run with the toolboxes and system that the organisers have specified. If you need any particular toolboxes or configuration please contact the organisers as soon as you can. Please aim to make MATLAB submissions compatible across multiple OS (usual problems exist in the file/path separators). All Matlab submissions should be written in the form of a function, e.g. eventdetection(input,output); which can allow calling the script from the command line very easily.</p>
<p>Please provide some console output, which can provide a sanity check to the challenge team when running the code. This can be of the form of simply writing out a line corresponding to different stages of your algorithm. All submissions should include a README file including the following the information:</p>
<ul>
<li>Command line calling format for all executables including examples</li>
<li>Number of threads/cores used or whether this should be specified on the command line</li>
<li>Expected memory footprint</li>
<li>Expected runtime</li>
<li>Approximately how much scratch disk space will the submission need to store any feature/cache
files?</li>
<li>Any special notice regarding to running your algorithm</li>
</ul>
<p>Note that the information that you place in the README file is extremely important in ensuring  that your submission is evaluated properly. </p>
<h2 id="time-and-hardware-limits">Time and Hardware limits</h2>
<p>Due to the potentially high resource requirements across all participants, hard limits on the runtime of submissions will be imposed. A hard limit of 48 hours will be imposed for each submission</p>
<h1 id="evaluation">Evaluation</h1>
<p>Participating algorithms will be evaluated with 5-fold stratified cross validation.</p>
<p>The raw classification (identification) accuracy, standard deviation and a confusion matrix for each algorithm will be computed.</p>
<p>In addition computation times of each participating algorithm will be measured.</p>
<p>Matlab implementation of metrics:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://code.soundsoftware.ac.uk/projects/aasp-d-case-metrics" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-info"></i>
<i class="fa fa-gears fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://code.soundsoftware.ac.uk/projects/aasp-d-case-metrics" target="_blank">
<span style="font-size:20px;">IEEE AASP D-CASE Challenge Metrics <i class="fa fa-download"></i></span>
</a>
<br/>
<span class="text-muted">
                
                
                (.git)
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="results">Results</h1>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="code" data-page-list="[10, 25, 50, All]" data-page-size="10" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="4">Submission Information</th>
<th class="sep-left-cell" colspan="1"></th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell" data-field="corresponding_author" data-sortable="false">
                Author
            </th>
<th class="sm-cell" data-field="corresponding_affiliation" data-sortable="false">
                Affiliation
            </th>
<th class="sep-left-cell text-center" data-field="external_anchor" data-sortable="false" data-value-type="url">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Classification Accuracy" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% <br/>confidence interval</small>
</th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Dan Stowell</td>
<td>Centre for Digital Music, Queen Mary University of London, London, UK</td>
<td>task-acoustic-scene-classification-results#Stowell2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>CHR_1</td>
<td>May Chum</td>
<td>Electrical Engineering Department, The Cooper Union, New York, USA</td>
<td>task-acoustic-scene-classification-results#Chum2013</td>
<td>63.0 (53.5 - 72.5)</td>
</tr>
<tr>
<td></td>
<td>CHR_2</td>
<td>May Chum</td>
<td>Electrical Engineering Department, The Cooper Union, New York, USA</td>
<td>task-acoustic-scene-classification-results#Chum2013</td>
<td>65.0 (55.7 - 74.3)</td>
</tr>
<tr>
<td></td>
<td>ELF</td>
<td>Benjamin Elizalde</td>
<td>International Computer Science Institute, Berkeley, USA</td>
<td>task-acoustic-scene-classification-results#Elizalde2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>GSR</td>
<td>Jürgen T. Geiger</td>
<td>Institute for Human-Machine Communication, Technische Universität München, München, Germany</td>
<td>task-acoustic-scene-classification-results#Geiger2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>KH</td>
<td>Johannes D. Krijnders</td>
<td>INCAS3, Assen, Netherlands</td>
<td>task-acoustic-scene-classification-results#Krijnders2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>LTT_1</td>
<td>David Li</td>
<td>Cooper Union, New York, USA</td>
<td>task-acoustic-scene-classification-results#Li2013</td>
<td>72.0 (63.2 - 80.8)</td>
</tr>
<tr>
<td></td>
<td>LTT_2</td>
<td>David Li</td>
<td>Cooper Union, New York, USA</td>
<td>task-acoustic-scene-classification-results#Li2013</td>
<td>70.0 (61.0 - 79.0)</td>
</tr>
<tr>
<td></td>
<td>LTT_3</td>
<td>David Li</td>
<td>Cooper Union, New York, USA</td>
<td>task-acoustic-scene-classification-results#Li2013</td>
<td>67.0 (57.8 - 76.2)</td>
</tr>
<tr>
<td></td>
<td>NHL</td>
<td>Juhan Nam</td>
<td>Stanford University, Stanford, USA</td>
<td>task-acoustic-scene-classification-results#Nam2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_1</td>
<td>Waldo Nogueira</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-acoustic-scene-classification-results#Nogueira2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_2</td>
<td>Waldo Nogueira</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-acoustic-scene-classification-results#Nogueira2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_3</td>
<td>Waldo Nogueira</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-acoustic-scene-classification-results#Nogueira2013</td>
<td>59.0 (49.4 - 68.6)</td>
</tr>
<tr>
<td></td>
<td>OE</td>
<td>Emanuele Olivetti</td>
<td>NeuroInformatics Laboratory, Bruno Kessler Foundation, Trento, Italy; Center for Mind and Brain Sciences, Trento, Italy</td>
<td>task-acoustic-scene-classification-results#Olivetti2013</td>
<td>14.0 (7.2 - 20.8)</td>
</tr>
<tr>
<td></td>
<td>PE</td>
<td>Kailash Patil</td>
<td>Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, USA</td>
<td>task-acoustic-scene-classification-results#Patil2013</td>
<td>58.0 (48.3 - 67.7)</td>
</tr>
<tr>
<td></td>
<td>RG</td>
<td>Alain Rakotomamonjy</td>
<td>Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Normandie Universite, Rouen, France</td>
<td>task-acoustic-scene-classification-results#Rakotomamonjy2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>RNH_1</td>
<td>Gerard Roma</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-acoustic-scene-classification-results#Roma2013</td>
<td>71.0 (62.1 - 79.9)</td>
</tr>
<tr>
<td></td>
<td>RNH_2</td>
<td>Gerard Roma</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-acoustic-scene-classification-results#Roma2013</td>
<td>76.0 (67.6 - 84.4)</td>
</tr>
</tbody>
</table>
<p><br/></p>
<p>Complete results and technical reports can be found at <a class="btn btn-primary" href="/challenge2013/task-acoustic-scene-classification-results">Task 1 result page</a></p>
<h1 id="baseline-system">Baseline system</h1>
<p>The baseline system for the task is provided. System is based on MFCC+GMM approach and and bag-of-frames model.  The system is described in detail in Stowell et al. :</p>
<div class="btex-item" data-item="Giannoulis2013" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Giannoulis2013"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D. <span class="bibtex-protected">Giannoulis</span>, D. <span class="bibtex-protected">Stowell</span>, E. <span class="bibtex-protected">Benetos</span>, M. <span class="bibtex-protected">Rossignol</span>, M. <span class="bibtex-protected">Lagrange</span>, and M. D. <span class="bibtex-protected">Plumbley</span>.
<em>A database and challenge for acoustic scene classification and event detection.</em>
In 21st European Signal Processing Conference (EUSIPCO 2013), volume, 1–5. Sep. 2013.
<a href="https://doi.org/">doi:</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexGiannoulis201377b0a156993a4df8803435597863a0c1" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseGiannoulis201377b0a156993a4df8803435597863a0c1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseGiannoulis201377b0a156993a4df8803435597863a0c1" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingGiannoulis201377b0a156993a4df8803435597863a0c1" class="panel-collapse collapse" id="collapseGiannoulis201377b0a156993a4df8803435597863a0c1" role="tabpanel">
<h4>A database and challenge for acoustic scene classification and event detection</h4>
<h5>Abstract</h5>
<p class="text-justify">An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexGiannoulis201377b0a156993a4df8803435597863a0c1" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexGiannoulis201377b0a156993a4df8803435597863a0c1label" class="modal fade" id="bibtexGiannoulis201377b0a156993a4df8803435597863a0c1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexGiannoulis201377b0a156993a4df8803435597863a0c1label">A database and challenge for acoustic scene classification and event detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Giannoulis2013,
    author = "{Giannoulis}, D. and {Stowell}, D. and {Benetos}, E. and {Rossignol}, M. and {Lagrange}, M. and {Plumbley}, M. D.",
    booktitle = "21st European Signal Processing Conference (EUSIPCO 2013)",
    title = "A database and challenge for acoustic scene classification and event detection",
    year = "2013",
    volume = "",
    number = "",
    pages = "1-5",
    abstract = "An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.",
    keywords = "acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection",
    doi = "",
    issn = "2076-1465",
    month = "Sep."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<h4>Python implementation</h4>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://code.soundsoftware.ac.uk/projects/smacpy" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-warning"></i>
<i class="fa fa-gears fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://code.soundsoftware.ac.uk/projects/smacpy" target="_blank">
<span style="font-size:20px;">DCASE2013 Task1 Baseline, repository <i class="fa fa-download"></i></span>
</a>
<br/>
<span class="text-muted">
                
                
                (.git)
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="citation">Citation</h1>
<p>If you are using the <strong>dataset</strong> or <strong>baseline</strong> code please cite the following paper:</p>
<div class="btex-item" data-item="Giannoulis2013" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Giannoulis2013"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D. <span class="bibtex-protected">Giannoulis</span>, D. <span class="bibtex-protected">Stowell</span>, E. <span class="bibtex-protected">Benetos</span>, M. <span class="bibtex-protected">Rossignol</span>, M. <span class="bibtex-protected">Lagrange</span>, and M. D. <span class="bibtex-protected">Plumbley</span>.
<em>A database and challenge for acoustic scene classification and event detection.</em>
In 21st European Signal Processing Conference (EUSIPCO 2013), volume, 1–5. Sep. 2013.
<a href="https://doi.org/">doi:</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexGiannoulis2013683781db52e94421913b0f9c4180fc87" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseGiannoulis2013683781db52e94421913b0f9c4180fc87" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseGiannoulis2013683781db52e94421913b0f9c4180fc87" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingGiannoulis2013683781db52e94421913b0f9c4180fc87" class="panel-collapse collapse" id="collapseGiannoulis2013683781db52e94421913b0f9c4180fc87" role="tabpanel">
<h4>A database and challenge for acoustic scene classification and event detection</h4>
<h5>Abstract</h5>
<p class="text-justify">An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexGiannoulis2013683781db52e94421913b0f9c4180fc87" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexGiannoulis2013683781db52e94421913b0f9c4180fc87label" class="modal fade" id="bibtexGiannoulis2013683781db52e94421913b0f9c4180fc87" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexGiannoulis2013683781db52e94421913b0f9c4180fc87label">A database and challenge for acoustic scene classification and event detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Giannoulis2013,
    author = "{Giannoulis}, D. and {Stowell}, D. and {Benetos}, E. and {Rossignol}, M. and {Lagrange}, M. and {Plumbley}, M. D.",
    booktitle = "21st European Signal Processing Conference (EUSIPCO 2013)",
    title = "A database and challenge for acoustic scene classification and event detection",
    year = "2013",
    volume = "",
    number = "",
    pages = "1-5",
    abstract = "An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.",
    keywords = "acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection",
    doi = "",
    issn = "2076-1465",
    month = "Sep."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<p>When citing <strong>challenge task</strong> and <strong>results</strong> please cite the following paper:</p>
<div class="btex-item" data-item="Stowell2015" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Stowell2015"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D. <span class="bibtex-protected">Stowell</span>, D. <span class="bibtex-protected">Giannoulis</span>, E. <span class="bibtex-protected">Benetos</span>, M. <span class="bibtex-protected">Lagrange</span>, and M. D. <span class="bibtex-protected">Plumbley</span>.
<em>Detection and classification of acoustic scenes and events.</em>
<em>IEEE Transactions on Multimedia</em>, 17(10):1733–1746, Oct 2015.
<a href="https://doi.org/10.1109/TMM.2015.2428998">doi:10.1109/TMM.2015.2428998</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexStowell2015eb01013085444b16ba3263253db1d99e" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseStowell2015eb01013085444b16ba3263253db1d99e" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseStowell2015eb01013085444b16ba3263253db1d99e" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingStowell2015eb01013085444b16ba3263253db1d99e" class="panel-collapse collapse" id="collapseStowell2015eb01013085444b16ba3263253db1d99e" role="tabpanel">
<h4>Detection and Classification of Acoustic Scenes and Events</h4>
<h5>Abstract</h5>
<p class="text-justify">For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexStowell2015eb01013085444b16ba3263253db1d99e" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexStowell2015eb01013085444b16ba3263253db1d99elabel" class="modal fade" id="bibtexStowell2015eb01013085444b16ba3263253db1d99e" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexStowell2015eb01013085444b16ba3263253db1d99elabel">Detection and Classification of Acoustic Scenes and Events</h4>
</div>
<div class="modal-body">
<pre>@article{Stowell2015,
    author = "{Stowell}, D. and {Giannoulis}, D. and {Benetos}, E. and {Lagrange}, M. and {Plumbley}, M. D.",
    journal = "IEEE Transactions on Multimedia",
    title = "Detection and Classification of Acoustic Scenes and Events",
    year = "2015",
    volume = "17",
    number = "10",
    pages = "1733-1746",
    abstract = "For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.",
    keywords = "acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition",
    doi = "10.1109/TMM.2015.2428998",
    issn = "1520-9210",
    month = "Oct"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>