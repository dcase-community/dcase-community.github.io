<!DOCTYPE html><html lang="en">
<head>
    <title>Automated Audio Captioning - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2022/task-automatic-audio-captioning-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description Automated audio captioning is the task of general audio content description using free text. It is an intermodal translation task (not speech-to-text), where a system accepts as an input an audio signal and outputs the textual description (i.e. the caption) of that signal. Given the novelty of …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2022</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2022/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2022/task-low-complexity-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-low-complexity-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-low-complexity-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2022/task-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2022/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2022/task-sound-event-detection-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-sound-event-detection-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-sound-event-detection-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2022/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Introduction</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Automatic audio-captioning</strong>
    </li>
            <li class="">
        <a href="/challenge2022/task-automatic-audio-captioning"><i class="fa dc-captioning fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2022/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Language-Based Audio Retrieval</strong>
    </li>
            <li class="">
        <a href="/challenge2022/task-language-based-audio-retrieval"><i class="fa fa-file-text fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2022/task-language-based-audio-retrieval-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2022/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2022/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/stones-03.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-task1"></i><strong class="fa-stack-1x icon-text">A</strong><strong class="fa-stack-1x dcase-icon-top-text">Captioning</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 6</span></span><img src="../images/logos/dcase/dcase2022_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Automated Audio Captioning</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#systems-ranking">Systems ranking</a>
<ul>
<li><a href="#systems-ranking-all-metrics">Systems ranking, all metrics</a></li>
<li><a href="#systems-ranking-machine-translation-metrics">Systems ranking, machine translation metrics</a></li>
<li><a href="#systems-ranking-captioning-metrics">Systems ranking, captioning metrics</a></li>
</ul>
</li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#overview-of-characteristics">Overview of characteristics</a></li>
<li><a href="#detailed-characteristics">Detailed characteristics</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>Automated audio captioning is the task of general audio content
description using free text. It is an intermodal translation task
(not speech-to-text), where a system accepts as an input an audio
signal and outputs the textual description (i.e. the caption) of
that signal. Given the novelty of the task of audio captioning,
current focus is on exploring and developing different methods
that can provide some kind of captions for a general audio recording.
To this aim, the Clotho dataset is used, which provides
good quality captions, without speech transcription, named entities,
and hapax legomena (i.e. words that appear once in a split).</p>
<p>Participants used the freely available splits of Clotho development
and evaluation, as well as any external data they deemed fit.
The developed systems are evaluated on their generated captions,
using the testing split of Clotho, which does not provide the corresponding
captions for the audio. More information about Task 6a: Automated
Audio Captioning can be found at the
<a class="btn btn-primary" href="/challenge2022/task-automatic-audio-captioning" style="">task description page.</a></p>
<p>The ranking of the submitted systems is based on the achieved SPIDEr
metric. Though, in this page is provided a more thorough presentation,
grouping the metrics into those that are originated from machine translation
and to those that originated from captioning.</p>
<p><em>This year, we also introduce contrastive metrics as well as an analysis subset of Clotho. The corresponding results will be published in the coming days.</em></p>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Here are listed the best systems all from all teams. The ranking is based on the
SPIDEr metric. For more elaborated exploration of the performance of the
different systems, at the same table are listed the values achieved for
all the metrics employed in the task. The values for the metrics are for
the Clotho testing split and the Clotho evaluation split. The values for the
Clotho evaluation split are provided in order to allow further comparison
with systems and methods developed outside of this task, since captions for the Clotho
evaluation split are freely available.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="abbreviation" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="tes_spider" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="4">Submission Information</th>
<th class="sep-left-cell text-center" colspan="9">Clotho testing split</th>
<th class="sep-left-cell text-center" colspan="9">Clotho evaluation split</th>
</tr>
<tr>
<th data-field="abbreviation" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
              Best official <br/>system rank
            </th>
<th data-field="corresponding_author" data-sortable="false">
              Corresponding author
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="tes_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
              METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="tes_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
              ROUGE<sub>L</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eva_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
              METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="eva_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
              ROUGE<sub>L</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Xu_t6a_4</td>
<td>1</td>
<td>Xuenan Xu</td>
<td>xu2022_t6a</td>
<td>0.666</td>
<td>0.433</td>
<td>0.282</td>
<td>0.178</td>
<td>0.187</td>
<td>0.412</td>
<td>0.508</td>
<td>0.130</td>
<td>0.319</td>
<td>0.667</td>
<td>0.435</td>
<td>0.285</td>
<td>0.183</td>
<td>0.186</td>
<td>0.415</td>
<td>0.513</td>
<td>0.126</td>
<td>0.320</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_3</td>
<td>2</td>
<td>Yuexian Zou</td>
<td>zou2022_t6a</td>
<td>0.670</td>
<td>0.437</td>
<td>0.289</td>
<td>0.183</td>
<td>0.185</td>
<td>0.415</td>
<td>0.502</td>
<td>0.133</td>
<td>0.318</td>
<td>0.646</td>
<td>0.430</td>
<td>0.289</td>
<td>0.186</td>
<td>0.186</td>
<td>0.409</td>
<td>0.497</td>
<td>0.119</td>
<td>0.308</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_3</td>
<td>3</td>
<td>Xinhao Mei</td>
<td>mei2022_t6a</td>
<td>0.661</td>
<td>0.433</td>
<td>0.287</td>
<td>0.179</td>
<td>0.188</td>
<td>0.415</td>
<td>0.482</td>
<td>0.135</td>
<td>0.309</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_4</td>
<td>4</td>
<td>Paul Primus</td>
<td>primus2022_t6a</td>
<td>0.641</td>
<td>0.421</td>
<td>0.276</td>
<td>0.168</td>
<td>0.184</td>
<td>0.402</td>
<td>0.458</td>
<td>0.134</td>
<td>0.296</td>
<td>0.636</td>
<td>0.417</td>
<td>0.275</td>
<td>0.168</td>
<td>0.183</td>
<td>0.401</td>
<td>0.461</td>
<td>0.130</td>
<td>0.295</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_4</td>
<td>5</td>
<td>Thodoris Kouzelis</td>
<td>kouzelis2022_t6a</td>
<td>0.581</td>
<td>0.387</td>
<td>0.262</td>
<td>0.170</td>
<td>0.180</td>
<td>0.388</td>
<td>0.453</td>
<td>0.134</td>
<td>0.293</td>
<td>0.579</td>
<td>0.386</td>
<td>0.262</td>
<td>0.173</td>
<td>0.178</td>
<td>0.387</td>
<td>0.457</td>
<td>0.134</td>
<td>0.296</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_4</td>
<td>6</td>
<td>Jian Guan</td>
<td>guan2022_t6a</td>
<td>0.623</td>
<td>0.417</td>
<td>0.284</td>
<td>0.180</td>
<td>0.177</td>
<td>0.405</td>
<td>0.451</td>
<td>0.130</td>
<td>0.291</td>
<td>0.649</td>
<td>0.439</td>
<td>0.303</td>
<td>0.199</td>
<td>0.181</td>
<td>0.415</td>
<td>0.471</td>
<td>0.133</td>
<td>0.302</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_1</td>
<td>7</td>
<td>Dawid Kiciński</td>
<td>kiciński2022_t6a</td>
<td>0.567</td>
<td>0.368</td>
<td>0.244</td>
<td>0.155</td>
<td>0.175</td>
<td>0.378</td>
<td>0.414</td>
<td>0.126</td>
<td>0.270</td>
<td>0.583</td>
<td>0.382</td>
<td>0.255</td>
<td>0.164</td>
<td>0.179</td>
<td>0.387</td>
<td>0.433</td>
<td>0.125</td>
<td>0.279</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_4</td>
<td>8</td>
<td>Chaofan Pan</td>
<td>pan2022_t6a</td>
<td>0.555</td>
<td>0.361</td>
<td>0.240</td>
<td>0.155</td>
<td>0.173</td>
<td>0.374</td>
<td>0.387</td>
<td>0.123</td>
<td>0.255</td>
<td>0.568</td>
<td>0.367</td>
<td>0.245</td>
<td>0.161</td>
<td>0.175</td>
<td>0.383</td>
<td>0.395</td>
<td>0.119</td>
<td>0.257</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_1</td>
<td>9</td>
<td>Etienne Labbe</td>
<td>labbe2022_t6a</td>
<td>0.548</td>
<td>0.351</td>
<td>0.233</td>
<td>0.149</td>
<td>0.170</td>
<td>0.370</td>
<td>0.359</td>
<td>0.123</td>
<td>0.241</td>
<td>0.555</td>
<td>0.357</td>
<td>0.240</td>
<td>0.157</td>
<td>0.170</td>
<td>0.374</td>
<td>0.367</td>
<td>0.118</td>
<td>0.242</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline</td>
<td>10</td>
<td>Felix Gontier</td>
<td>gontier2022_t6a</td>
<td>0.549</td>
<td>0.353</td>
<td>0.234</td>
<td>0.147</td>
<td>0.164</td>
<td>0.361</td>
<td>0.338</td>
<td>0.110</td>
<td>0.224</td>
<td>0.555</td>
<td>0.358</td>
<td>0.239</td>
<td>0.156</td>
<td>0.164</td>
<td>0.364</td>
<td>0.358</td>
<td>0.109</td>
<td>0.233</td>
</tr>
</tbody>
</table>
<h1 id="systems-ranking">Systems ranking</h1>
<p>Here are listed all submitted systems and their ranking according to the different
metrics and grouping of metrics. The first table shows all metrics and
all systems, the second table shows all systems but with only machine
translation metrics, and the third table shows all systems but with only
captioning metrics.</p>
<p>Detailed information for each system is provided in the next section.</p>
<h2 id="systems-ranking-all-metrics">Systems ranking, all metrics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="abbreviation" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="tes_spider" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="3">Submission Information</th>
<th class="sep-left-cell text-center" colspan="9">Clotho testing split</th>
<th class="sep-left-cell text-center" colspan="9">Clotho evaluation split</th>
</tr>
<tr>
<th data-field="abbreviation" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
              Best official <br/>system rank
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="tes_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
              METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="tes_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
              ROUGE<sub>L</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eva_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
              METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="eva_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
              ROUGE<sub>L</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Xu_t6a_4</td>
<td>1</td>
<td>xu2022_t6a</td>
<td>0.666</td>
<td>0.433</td>
<td>0.282</td>
<td>0.178</td>
<td>0.187</td>
<td>0.412</td>
<td>0.508</td>
<td>0.130</td>
<td>0.319</td>
<td>0.667</td>
<td>0.435</td>
<td>0.285</td>
<td>0.183</td>
<td>0.186</td>
<td>0.415</td>
<td>0.513</td>
<td>0.126</td>
<td>0.320</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_3</td>
<td>2</td>
<td>zou2022_t6a</td>
<td>0.670</td>
<td>0.437</td>
<td>0.289</td>
<td>0.183</td>
<td>0.185</td>
<td>0.415</td>
<td>0.502</td>
<td>0.133</td>
<td>0.318</td>
<td>0.646</td>
<td>0.430</td>
<td>0.289</td>
<td>0.186</td>
<td>0.186</td>
<td>0.409</td>
<td>0.497</td>
<td>0.119</td>
<td>0.308</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_3</td>
<td>3</td>
<td>xu2022_t6a</td>
<td>0.658</td>
<td>0.430</td>
<td>0.281</td>
<td>0.178</td>
<td>0.186</td>
<td>0.410</td>
<td>0.501</td>
<td>0.131</td>
<td>0.316</td>
<td>0.663</td>
<td>0.433</td>
<td>0.285</td>
<td>0.185</td>
<td>0.185</td>
<td>0.413</td>
<td>0.517</td>
<td>0.127</td>
<td>0.322</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_1</td>
<td>4</td>
<td>xu2022_t6a</td>
<td>0.645</td>
<td>0.421</td>
<td>0.276</td>
<td>0.173</td>
<td>0.186</td>
<td>0.402</td>
<td>0.498</td>
<td>0.130</td>
<td>0.314</td>
<td>0.647</td>
<td>0.424</td>
<td>0.280</td>
<td>0.180</td>
<td>0.186</td>
<td>0.409</td>
<td>0.507</td>
<td>0.130</td>
<td>0.318</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_4</td>
<td>5</td>
<td>zou2022_t6a</td>
<td>0.652</td>
<td>0.433</td>
<td>0.287</td>
<td>0.182</td>
<td>0.185</td>
<td>0.408</td>
<td>0.497</td>
<td>0.130</td>
<td>0.314</td>
<td>0.663</td>
<td>0.443</td>
<td>0.299</td>
<td>0.195</td>
<td>0.189</td>
<td>0.416</td>
<td>0.520</td>
<td>0.126</td>
<td>0.323</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_2</td>
<td>6</td>
<td>xu2022_t6a</td>
<td>0.650</td>
<td>0.425</td>
<td>0.278</td>
<td>0.176</td>
<td>0.187</td>
<td>0.407</td>
<td>0.495</td>
<td>0.127</td>
<td>0.311</td>
<td>0.654</td>
<td>0.431</td>
<td>0.286</td>
<td>0.187</td>
<td>0.188</td>
<td>0.413</td>
<td>0.524</td>
<td>0.126</td>
<td>0.325</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_1</td>
<td>7</td>
<td>zou2022_t6a</td>
<td>0.648</td>
<td>0.424</td>
<td>0.279</td>
<td>0.176</td>
<td>0.185</td>
<td>0.410</td>
<td>0.489</td>
<td>0.133</td>
<td>0.311</td>
<td>0.647</td>
<td>0.438</td>
<td>0.296</td>
<td>0.194</td>
<td>0.185</td>
<td>0.414</td>
<td>0.503</td>
<td>0.132</td>
<td>0.317</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_2</td>
<td>8</td>
<td>zou2022_t6a</td>
<td>0.655</td>
<td>0.429</td>
<td>0.283</td>
<td>0.178</td>
<td>0.184</td>
<td>0.405</td>
<td>0.491</td>
<td>0.128</td>
<td>0.309</td>
<td>0.645</td>
<td>0.422</td>
<td>0.281</td>
<td>0.183</td>
<td>0.186</td>
<td>0.408</td>
<td>0.495</td>
<td>0.131</td>
<td>0.313</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_3</td>
<td>9</td>
<td>mei2022_t6a</td>
<td>0.661</td>
<td>0.433</td>
<td>0.287</td>
<td>0.179</td>
<td>0.188</td>
<td>0.415</td>
<td>0.482</td>
<td>0.135</td>
<td>0.309</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_1</td>
<td>10</td>
<td>mei2022_t6a</td>
<td>0.647</td>
<td>0.423</td>
<td>0.278</td>
<td>0.174</td>
<td>0.186</td>
<td>0.407</td>
<td>0.476</td>
<td>0.134</td>
<td>0.305</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_4</td>
<td>11</td>
<td>mei2022_t6a</td>
<td>0.669</td>
<td>0.428</td>
<td>0.281</td>
<td>0.173</td>
<td>0.184</td>
<td>0.410</td>
<td>0.468</td>
<td>0.138</td>
<td>0.303</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_2</td>
<td>12</td>
<td>mei2022_t6a</td>
<td>0.672</td>
<td>0.427</td>
<td>0.276</td>
<td>0.167</td>
<td>0.182</td>
<td>0.410</td>
<td>0.456</td>
<td>0.138</td>
<td>0.297</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_4</td>
<td>13</td>
<td>primus2022_t6a</td>
<td>0.641</td>
<td>0.421</td>
<td>0.276</td>
<td>0.168</td>
<td>0.184</td>
<td>0.402</td>
<td>0.458</td>
<td>0.134</td>
<td>0.296</td>
<td>0.636</td>
<td>0.417</td>
<td>0.275</td>
<td>0.168</td>
<td>0.183</td>
<td>0.401</td>
<td>0.461</td>
<td>0.130</td>
<td>0.295</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_4</td>
<td>14</td>
<td>kouzelis2022_t6a</td>
<td>0.581</td>
<td>0.387</td>
<td>0.262</td>
<td>0.170</td>
<td>0.180</td>
<td>0.388</td>
<td>0.453</td>
<td>0.134</td>
<td>0.293</td>
<td>0.579</td>
<td>0.386</td>
<td>0.262</td>
<td>0.173</td>
<td>0.178</td>
<td>0.387</td>
<td>0.457</td>
<td>0.134</td>
<td>0.296</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_4</td>
<td>15</td>
<td>guan2022_t6a</td>
<td>0.623</td>
<td>0.417</td>
<td>0.284</td>
<td>0.180</td>
<td>0.177</td>
<td>0.405</td>
<td>0.451</td>
<td>0.130</td>
<td>0.291</td>
<td>0.649</td>
<td>0.439</td>
<td>0.303</td>
<td>0.199</td>
<td>0.181</td>
<td>0.415</td>
<td>0.471</td>
<td>0.133</td>
<td>0.302</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_2</td>
<td>16</td>
<td>guan2022_t6a</td>
<td>0.575</td>
<td>0.388</td>
<td>0.268</td>
<td>0.178</td>
<td>0.178</td>
<td>0.387</td>
<td>0.451</td>
<td>0.129</td>
<td>0.290</td>
<td>0.595</td>
<td>0.402</td>
<td>0.277</td>
<td>0.189</td>
<td>0.179</td>
<td>0.395</td>
<td>0.465</td>
<td>0.127</td>
<td>0.296</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_3</td>
<td>17</td>
<td>guan2022_t6a</td>
<td>0.657</td>
<td>0.425</td>
<td>0.279</td>
<td>0.169</td>
<td>0.179</td>
<td>0.405</td>
<td>0.447</td>
<td>0.132</td>
<td>0.290</td>
<td>0.660</td>
<td>0.424</td>
<td>0.279</td>
<td>0.170</td>
<td>0.178</td>
<td>0.410</td>
<td>0.442</td>
<td>0.129</td>
<td>0.285</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_3</td>
<td>18</td>
<td>kouzelis2022_t6a</td>
<td>0.567</td>
<td>0.378</td>
<td>0.257</td>
<td>0.169</td>
<td>0.176</td>
<td>0.385</td>
<td>0.447</td>
<td>0.131</td>
<td>0.289</td>
<td>0.575</td>
<td>0.384</td>
<td>0.262</td>
<td>0.174</td>
<td>0.178</td>
<td>0.386</td>
<td>0.557</td>
<td>0.133</td>
<td>0.295</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_1</td>
<td>19</td>
<td>kouzelis2022_t6a</td>
<td>0.570</td>
<td>0.382</td>
<td>0.259</td>
<td>0.170</td>
<td>0.177</td>
<td>0.384</td>
<td>0.439</td>
<td>0.132</td>
<td>0.286</td>
<td>0.576</td>
<td>0.384</td>
<td>0.261</td>
<td>0.176</td>
<td>0.166</td>
<td>0.385</td>
<td>0.453</td>
<td>0.130</td>
<td>0.292</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_2</td>
<td>20</td>
<td>kouzelis2022_t6a</td>
<td>0.569</td>
<td>0.378</td>
<td>0.256</td>
<td>0.168</td>
<td>0.177</td>
<td>0.386</td>
<td>0.441</td>
<td>0.130</td>
<td>0.285</td>
<td>0.578</td>
<td>0.384</td>
<td>0.262</td>
<td>0.176</td>
<td>0.177</td>
<td>0.387</td>
<td>0.454</td>
<td>0.133</td>
<td>0.293</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_3</td>
<td>21</td>
<td>primus2022_t6a</td>
<td>0.654</td>
<td>0.420</td>
<td>0.271</td>
<td>0.163</td>
<td>0.177</td>
<td>0.395</td>
<td>0.434</td>
<td>0.127</td>
<td>0.280</td>
<td>0.653</td>
<td>0.424</td>
<td>0.278</td>
<td>0.169</td>
<td>0.181</td>
<td>0.404</td>
<td>0.455</td>
<td>0.125</td>
<td>0.290</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_2</td>
<td>22</td>
<td>primus2022_t6a</td>
<td>0.562</td>
<td>0.364</td>
<td>0.243</td>
<td>0.153</td>
<td>0.181</td>
<td>0.374</td>
<td>0.418</td>
<td>0.132</td>
<td>0.275</td>
<td>0.573</td>
<td>0.370</td>
<td>0.244</td>
<td>0.158</td>
<td>0.181</td>
<td>0.376</td>
<td>0.440</td>
<td>0.128</td>
<td>0.284</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_1</td>
<td>23</td>
<td>guan2022_t6a</td>
<td>0.556</td>
<td>0.367</td>
<td>0.249</td>
<td>0.165</td>
<td>0.173</td>
<td>0.375</td>
<td>0.417</td>
<td>0.124</td>
<td>0.270</td>
<td>0.581</td>
<td>0.386</td>
<td>0.265</td>
<td>0.181</td>
<td>0.175</td>
<td>0.385</td>
<td>0.437</td>
<td>0.126</td>
<td>0.281</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_1</td>
<td>24</td>
<td>kiciński2022_t6a</td>
<td>0.567</td>
<td>0.368</td>
<td>0.244</td>
<td>0.155</td>
<td>0.175</td>
<td>0.378</td>
<td>0.414</td>
<td>0.126</td>
<td>0.270</td>
<td>0.583</td>
<td>0.382</td>
<td>0.255</td>
<td>0.164</td>
<td>0.179</td>
<td>0.387</td>
<td>0.433</td>
<td>0.125</td>
<td>0.279</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_1</td>
<td>25</td>
<td>primus2022_t6a</td>
<td>0.556</td>
<td>0.364</td>
<td>0.241</td>
<td>0.150</td>
<td>0.176</td>
<td>0.367</td>
<td>0.400</td>
<td>0.127</td>
<td>0.264</td>
<td>0.566</td>
<td>0.373</td>
<td>0.252</td>
<td>0.164</td>
<td>0.178</td>
<td>0.376</td>
<td>0.408</td>
<td>0.120</td>
<td>0.264</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_4</td>
<td>26</td>
<td>pan2022_t6a</td>
<td>0.555</td>
<td>0.361</td>
<td>0.240</td>
<td>0.155</td>
<td>0.173</td>
<td>0.374</td>
<td>0.387</td>
<td>0.123</td>
<td>0.255</td>
<td>0.568</td>
<td>0.367</td>
<td>0.245</td>
<td>0.161</td>
<td>0.175</td>
<td>0.383</td>
<td>0.395</td>
<td>0.119</td>
<td>0.257</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_3</td>
<td>27</td>
<td>kiciński2022_t6a</td>
<td>0.546</td>
<td>0.346</td>
<td>0.224</td>
<td>0.138</td>
<td>0.170</td>
<td>0.364</td>
<td>0.379</td>
<td>0.123</td>
<td>0.251</td>
<td>0.566</td>
<td>0.363</td>
<td>0.236</td>
<td>0.147</td>
<td>0.173</td>
<td>0.372</td>
<td>0.400</td>
<td>0.121</td>
<td>0.260</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_4</td>
<td>28</td>
<td>kiciński2022_t6a</td>
<td>0.556</td>
<td>0.360</td>
<td>0.238</td>
<td>0.152</td>
<td>0.171</td>
<td>0.367</td>
<td>0.380</td>
<td>0.121</td>
<td>0.250</td>
<td>0.562</td>
<td>0.364</td>
<td>0.242</td>
<td>0.157</td>
<td>0.172</td>
<td>0.377</td>
<td>0.378</td>
<td>0.119</td>
<td>0.249</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_3</td>
<td>29</td>
<td>pan2022_t6a</td>
<td>0.559</td>
<td>0.360</td>
<td>0.237</td>
<td>0.152</td>
<td>0.173</td>
<td>0.376</td>
<td>0.376</td>
<td>0.123</td>
<td>0.250</td>
<td>0.567</td>
<td>0.363</td>
<td>0.240</td>
<td>0.154</td>
<td>0.174</td>
<td>0.380</td>
<td>0.386</td>
<td>0.121</td>
<td>0.253</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_1</td>
<td>30</td>
<td>pan2022_t6a</td>
<td>0.556</td>
<td>0.365</td>
<td>0.244</td>
<td>0.154</td>
<td>0.170</td>
<td>0.375</td>
<td>0.377</td>
<td>0.121</td>
<td>0.249</td>
<td>0.560</td>
<td>0.362</td>
<td>0.240</td>
<td>0.155</td>
<td>0.169</td>
<td>0.375</td>
<td>0.381</td>
<td>0.116</td>
<td>0.248</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_2</td>
<td>31</td>
<td>kiciński2022_t6a</td>
<td>0.556</td>
<td>0.358</td>
<td>0.235</td>
<td>0.148</td>
<td>0.171</td>
<td>0.369</td>
<td>0.378</td>
<td>0.119</td>
<td>0.249</td>
<td>0.567</td>
<td>0.365</td>
<td>0.242</td>
<td>0.155</td>
<td>0.172</td>
<td>0.378</td>
<td>0.393</td>
<td>0.117</td>
<td>0.255</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_2</td>
<td>32</td>
<td>pan2022_t6a</td>
<td>0.556</td>
<td>0.358</td>
<td>0.236</td>
<td>0.146</td>
<td>0.169</td>
<td>0.371</td>
<td>0.363</td>
<td>0.120</td>
<td>0.241</td>
<td>0.562</td>
<td>0.361</td>
<td>0.240</td>
<td>0.156</td>
<td>0.172</td>
<td>0.377</td>
<td>0.384</td>
<td>0.118</td>
<td>0.251</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_1</td>
<td>33</td>
<td>labbe2022_t6a</td>
<td>0.548</td>
<td>0.351</td>
<td>0.233</td>
<td>0.149</td>
<td>0.170</td>
<td>0.370</td>
<td>0.359</td>
<td>0.123</td>
<td>0.241</td>
<td>0.555</td>
<td>0.357</td>
<td>0.240</td>
<td>0.157</td>
<td>0.170</td>
<td>0.374</td>
<td>0.367</td>
<td>0.118</td>
<td>0.242</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline</td>
<td>34</td>
<td>gontier2022_t6a</td>
<td>0.549</td>
<td>0.353</td>
<td>0.234</td>
<td>0.147</td>
<td>0.164</td>
<td>0.361</td>
<td>0.338</td>
<td>0.110</td>
<td>0.224</td>
<td>0.555</td>
<td>0.358</td>
<td>0.239</td>
<td>0.156</td>
<td>0.164</td>
<td>0.364</td>
<td>0.358</td>
<td>0.109</td>
<td>0.233</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_3</td>
<td>35</td>
<td>labbe2022_t6a</td>
<td>0.535</td>
<td>0.326</td>
<td>0.203</td>
<td>0.121</td>
<td>0.164</td>
<td>0.356</td>
<td>0.307</td>
<td>0.117</td>
<td>0.212</td>
<td>0.532</td>
<td>0.322</td>
<td>0.200</td>
<td>0.121</td>
<td>0.161</td>
<td>0.354</td>
<td>0.303</td>
<td>0.111</td>
<td>0.207</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_2</td>
<td>36</td>
<td>labbe2022_t6a</td>
<td>0.490</td>
<td>0.282</td>
<td>0.163</td>
<td>0.090</td>
<td>0.156</td>
<td>0.328</td>
<td>0.247</td>
<td>0.113</td>
<td>0.180</td>
<td>0.488</td>
<td>0.279</td>
<td>0.160</td>
<td>0.085</td>
<td>0.154</td>
<td>0.329</td>
<td>0.241</td>
<td>0.106</td>
<td>0.174</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_4</td>
<td>37</td>
<td>labbe2022_t6a</td>
<td>0.460</td>
<td>0.251</td>
<td>0.139</td>
<td>0.072</td>
<td>0.142</td>
<td>0.311</td>
<td>0.203</td>
<td>0.099</td>
<td>0.151</td>
<td>0.457</td>
<td>0.245</td>
<td>0.135</td>
<td>0.067</td>
<td>0.140</td>
<td>0.310</td>
<td>0.198</td>
<td>0.090</td>
<td>0.144</td>
</tr>
</tbody>
</table>
<h2 id="systems-ranking-machine-translation-metrics">Systems ranking, machine translation metrics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="abbreviation" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="tes_meteor" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="3">Submission Information</th>
<th class="sep-left-cell text-center" colspan="6">Clotho testing split</th>
<th class="sep-left-cell text-center" colspan="6">Clotho evaluation split</th>
</tr>
<tr>
<th data-field="abbreviation" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
              Best official <br/>system rank
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="tes_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
              BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="tes_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
                METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="tes_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
                ROUGE<sub>L</sub>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eva_bleu_1" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>1</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_2" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>2</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_3" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>3</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_bleu_4" data-reversed="true" data-sortable="true" data-value-type="float3">
                BLEU<sub>4</sub>
</th>
<th class="text-center" data-chartable="true" data-field="eva_meteor" data-reversed="true" data-sortable="true" data-value-type="float3">
                METEOR
            </th>
<th class="text-center" data-chartable="true" data-field="eva_rouge_l" data-reversed="true" data-sortable="true" data-value-type="float3">
                ROUGE<sub>L</sub>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Xu_t6a_4</td>
<td>1</td>
<td>xu2022_t6a</td>
<td>0.666</td>
<td>0.433</td>
<td>0.282</td>
<td>0.178</td>
<td>0.187</td>
<td>0.412</td>
<td>0.667</td>
<td>0.435</td>
<td>0.285</td>
<td>0.183</td>
<td>0.186</td>
<td>0.415</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_3</td>
<td>2</td>
<td>zou2022_t6a</td>
<td>0.670</td>
<td>0.437</td>
<td>0.289</td>
<td>0.183</td>
<td>0.185</td>
<td>0.415</td>
<td>0.646</td>
<td>0.430</td>
<td>0.289</td>
<td>0.186</td>
<td>0.186</td>
<td>0.409</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_3</td>
<td>3</td>
<td>xu2022_t6a</td>
<td>0.658</td>
<td>0.430</td>
<td>0.281</td>
<td>0.178</td>
<td>0.186</td>
<td>0.410</td>
<td>0.663</td>
<td>0.433</td>
<td>0.285</td>
<td>0.185</td>
<td>0.185</td>
<td>0.413</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_1</td>
<td>4</td>
<td>xu2022_t6a</td>
<td>0.645</td>
<td>0.421</td>
<td>0.276</td>
<td>0.173</td>
<td>0.186</td>
<td>0.402</td>
<td>0.647</td>
<td>0.424</td>
<td>0.280</td>
<td>0.180</td>
<td>0.186</td>
<td>0.409</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_4</td>
<td>5</td>
<td>zou2022_t6a</td>
<td>0.652</td>
<td>0.433</td>
<td>0.287</td>
<td>0.182</td>
<td>0.185</td>
<td>0.408</td>
<td>0.663</td>
<td>0.443</td>
<td>0.299</td>
<td>0.195</td>
<td>0.189</td>
<td>0.416</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_2</td>
<td>6</td>
<td>xu2022_t6a</td>
<td>0.650</td>
<td>0.425</td>
<td>0.278</td>
<td>0.176</td>
<td>0.187</td>
<td>0.407</td>
<td>0.654</td>
<td>0.431</td>
<td>0.286</td>
<td>0.187</td>
<td>0.188</td>
<td>0.413</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_1</td>
<td>7</td>
<td>zou2022_t6a</td>
<td>0.648</td>
<td>0.424</td>
<td>0.279</td>
<td>0.176</td>
<td>0.185</td>
<td>0.410</td>
<td>0.647</td>
<td>0.438</td>
<td>0.296</td>
<td>0.194</td>
<td>0.185</td>
<td>0.414</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_2</td>
<td>8</td>
<td>zou2022_t6a</td>
<td>0.655</td>
<td>0.429</td>
<td>0.283</td>
<td>0.178</td>
<td>0.184</td>
<td>0.405</td>
<td>0.645</td>
<td>0.422</td>
<td>0.281</td>
<td>0.183</td>
<td>0.186</td>
<td>0.408</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_3</td>
<td>9</td>
<td>mei2022_t6a</td>
<td>0.661</td>
<td>0.433</td>
<td>0.287</td>
<td>0.179</td>
<td>0.188</td>
<td>0.415</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_1</td>
<td>10</td>
<td>mei2022_t6a</td>
<td>0.647</td>
<td>0.423</td>
<td>0.278</td>
<td>0.174</td>
<td>0.186</td>
<td>0.407</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_4</td>
<td>11</td>
<td>mei2022_t6a</td>
<td>0.669</td>
<td>0.428</td>
<td>0.281</td>
<td>0.173</td>
<td>0.184</td>
<td>0.410</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_2</td>
<td>12</td>
<td>mei2022_t6a</td>
<td>0.672</td>
<td>0.427</td>
<td>0.276</td>
<td>0.167</td>
<td>0.182</td>
<td>0.410</td>
<td>0.646</td>
<td>0.414</td>
<td>0.270</td>
<td>0.169</td>
<td>0.183</td>
<td>0.407</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_4</td>
<td>13</td>
<td>primus2022_t6a</td>
<td>0.641</td>
<td>0.421</td>
<td>0.276</td>
<td>0.168</td>
<td>0.184</td>
<td>0.402</td>
<td>0.636</td>
<td>0.417</td>
<td>0.275</td>
<td>0.168</td>
<td>0.183</td>
<td>0.401</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_4</td>
<td>14</td>
<td>kouzelis2022_t6a</td>
<td>0.581</td>
<td>0.387</td>
<td>0.262</td>
<td>0.170</td>
<td>0.180</td>
<td>0.388</td>
<td>0.579</td>
<td>0.386</td>
<td>0.262</td>
<td>0.173</td>
<td>0.178</td>
<td>0.387</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_4</td>
<td>15</td>
<td>guan2022_t6a</td>
<td>0.623</td>
<td>0.417</td>
<td>0.284</td>
<td>0.180</td>
<td>0.177</td>
<td>0.405</td>
<td>0.649</td>
<td>0.439</td>
<td>0.303</td>
<td>0.199</td>
<td>0.181</td>
<td>0.415</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_2</td>
<td>16</td>
<td>guan2022_t6a</td>
<td>0.575</td>
<td>0.388</td>
<td>0.268</td>
<td>0.178</td>
<td>0.178</td>
<td>0.387</td>
<td>0.595</td>
<td>0.402</td>
<td>0.277</td>
<td>0.189</td>
<td>0.179</td>
<td>0.395</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_3</td>
<td>17</td>
<td>guan2022_t6a</td>
<td>0.657</td>
<td>0.425</td>
<td>0.279</td>
<td>0.169</td>
<td>0.179</td>
<td>0.405</td>
<td>0.660</td>
<td>0.424</td>
<td>0.279</td>
<td>0.170</td>
<td>0.178</td>
<td>0.410</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_3</td>
<td>18</td>
<td>kouzelis2022_t6a</td>
<td>0.567</td>
<td>0.378</td>
<td>0.257</td>
<td>0.169</td>
<td>0.176</td>
<td>0.385</td>
<td>0.575</td>
<td>0.384</td>
<td>0.262</td>
<td>0.174</td>
<td>0.178</td>
<td>0.386</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_1</td>
<td>19</td>
<td>kouzelis2022_t6a</td>
<td>0.570</td>
<td>0.382</td>
<td>0.259</td>
<td>0.170</td>
<td>0.177</td>
<td>0.384</td>
<td>0.576</td>
<td>0.384</td>
<td>0.261</td>
<td>0.176</td>
<td>0.166</td>
<td>0.385</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_2</td>
<td>20</td>
<td>kouzelis2022_t6a</td>
<td>0.569</td>
<td>0.378</td>
<td>0.256</td>
<td>0.168</td>
<td>0.177</td>
<td>0.386</td>
<td>0.578</td>
<td>0.384</td>
<td>0.262</td>
<td>0.176</td>
<td>0.177</td>
<td>0.387</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_3</td>
<td>21</td>
<td>primus2022_t6a</td>
<td>0.654</td>
<td>0.420</td>
<td>0.271</td>
<td>0.163</td>
<td>0.177</td>
<td>0.395</td>
<td>0.653</td>
<td>0.424</td>
<td>0.278</td>
<td>0.169</td>
<td>0.181</td>
<td>0.404</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_2</td>
<td>22</td>
<td>primus2022_t6a</td>
<td>0.562</td>
<td>0.364</td>
<td>0.243</td>
<td>0.153</td>
<td>0.181</td>
<td>0.374</td>
<td>0.573</td>
<td>0.370</td>
<td>0.244</td>
<td>0.158</td>
<td>0.181</td>
<td>0.376</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_1</td>
<td>23</td>
<td>guan2022_t6a</td>
<td>0.556</td>
<td>0.367</td>
<td>0.249</td>
<td>0.165</td>
<td>0.173</td>
<td>0.375</td>
<td>0.581</td>
<td>0.386</td>
<td>0.265</td>
<td>0.181</td>
<td>0.175</td>
<td>0.385</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_1</td>
<td>24</td>
<td>kiciński2022_t6a</td>
<td>0.567</td>
<td>0.368</td>
<td>0.244</td>
<td>0.155</td>
<td>0.175</td>
<td>0.378</td>
<td>0.583</td>
<td>0.382</td>
<td>0.255</td>
<td>0.164</td>
<td>0.179</td>
<td>0.387</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_1</td>
<td>25</td>
<td>primus2022_t6a</td>
<td>0.556</td>
<td>0.364</td>
<td>0.241</td>
<td>0.150</td>
<td>0.176</td>
<td>0.367</td>
<td>0.566</td>
<td>0.373</td>
<td>0.252</td>
<td>0.164</td>
<td>0.178</td>
<td>0.376</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_4</td>
<td>26</td>
<td>pan2022_t6a</td>
<td>0.555</td>
<td>0.361</td>
<td>0.240</td>
<td>0.155</td>
<td>0.173</td>
<td>0.374</td>
<td>0.568</td>
<td>0.367</td>
<td>0.245</td>
<td>0.161</td>
<td>0.175</td>
<td>0.383</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_3</td>
<td>27</td>
<td>kiciński2022_t6a</td>
<td>0.546</td>
<td>0.346</td>
<td>0.224</td>
<td>0.138</td>
<td>0.170</td>
<td>0.364</td>
<td>0.566</td>
<td>0.363</td>
<td>0.236</td>
<td>0.147</td>
<td>0.173</td>
<td>0.372</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_4</td>
<td>28</td>
<td>kiciński2022_t6a</td>
<td>0.556</td>
<td>0.360</td>
<td>0.238</td>
<td>0.152</td>
<td>0.171</td>
<td>0.367</td>
<td>0.562</td>
<td>0.364</td>
<td>0.242</td>
<td>0.157</td>
<td>0.172</td>
<td>0.377</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_3</td>
<td>29</td>
<td>pan2022_t6a</td>
<td>0.559</td>
<td>0.360</td>
<td>0.237</td>
<td>0.152</td>
<td>0.173</td>
<td>0.376</td>
<td>0.567</td>
<td>0.363</td>
<td>0.240</td>
<td>0.154</td>
<td>0.174</td>
<td>0.380</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_1</td>
<td>30</td>
<td>pan2022_t6a</td>
<td>0.556</td>
<td>0.365</td>
<td>0.244</td>
<td>0.154</td>
<td>0.170</td>
<td>0.375</td>
<td>0.560</td>
<td>0.362</td>
<td>0.240</td>
<td>0.155</td>
<td>0.169</td>
<td>0.375</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_2</td>
<td>31</td>
<td>kiciński2022_t6a</td>
<td>0.556</td>
<td>0.358</td>
<td>0.235</td>
<td>0.148</td>
<td>0.171</td>
<td>0.369</td>
<td>0.567</td>
<td>0.365</td>
<td>0.242</td>
<td>0.155</td>
<td>0.172</td>
<td>0.378</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_2</td>
<td>32</td>
<td>pan2022_t6a</td>
<td>0.556</td>
<td>0.358</td>
<td>0.236</td>
<td>0.146</td>
<td>0.169</td>
<td>0.371</td>
<td>0.562</td>
<td>0.361</td>
<td>0.240</td>
<td>0.156</td>
<td>0.172</td>
<td>0.377</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_1</td>
<td>33</td>
<td>labbe2022_t6a</td>
<td>0.548</td>
<td>0.351</td>
<td>0.233</td>
<td>0.149</td>
<td>0.170</td>
<td>0.370</td>
<td>0.555</td>
<td>0.357</td>
<td>0.240</td>
<td>0.157</td>
<td>0.170</td>
<td>0.374</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline</td>
<td>34</td>
<td>gontier2022_t6a</td>
<td>0.549</td>
<td>0.353</td>
<td>0.234</td>
<td>0.147</td>
<td>0.164</td>
<td>0.361</td>
<td>0.555</td>
<td>0.358</td>
<td>0.239</td>
<td>0.156</td>
<td>0.164</td>
<td>0.364</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_3</td>
<td>35</td>
<td>labbe2022_t6a</td>
<td>0.535</td>
<td>0.326</td>
<td>0.203</td>
<td>0.121</td>
<td>0.164</td>
<td>0.356</td>
<td>0.532</td>
<td>0.322</td>
<td>0.200</td>
<td>0.121</td>
<td>0.161</td>
<td>0.354</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_2</td>
<td>36</td>
<td>labbe2022_t6a</td>
<td>0.490</td>
<td>0.282</td>
<td>0.163</td>
<td>0.090</td>
<td>0.156</td>
<td>0.328</td>
<td>0.488</td>
<td>0.279</td>
<td>0.160</td>
<td>0.085</td>
<td>0.154</td>
<td>0.329</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_4</td>
<td>37</td>
<td>labbe2022_t6a</td>
<td>0.460</td>
<td>0.251</td>
<td>0.139</td>
<td>0.072</td>
<td>0.142</td>
<td>0.311</td>
<td>0.457</td>
<td>0.245</td>
<td>0.135</td>
<td>0.067</td>
<td>0.140</td>
<td>0.310</td>
</tr>
</tbody>
</table>
<h2 id="systems-ranking-captioning-metrics">Systems ranking, captioning metrics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="abbreviation" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="tes_spider" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Selected<br/> metric<br/>rank</th>
<th class="sep-left-cell text-center" colspan="3">Submission Information</th>
<th class="sep-left-cell text-center" colspan="3">Clotho testing split</th>
<th class="sep-left-cell text-center" colspan="3">Clotho evaluation split</th>
</tr>
<tr>
<th data-field="abbreviation" data-sortable="true">
              Submission code
            </th>
<th class="text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
        Best official <br/>system rank
        </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="tes_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eva_cider" data-reversed="true" data-sortable="true" data-value-type="float3">
              CIDEr
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spice" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPICE
            </th>
<th class="text-center" data-chartable="true" data-field="eva_spider" data-reversed="true" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Xu_t6a_4</td>
<td>1</td>
<td>xu2022_t6a</td>
<td>0.508</td>
<td>0.130</td>
<td>0.319</td>
<td>0.513</td>
<td>0.126</td>
<td>0.320</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_3</td>
<td>2</td>
<td>zou2022_t6a</td>
<td>0.502</td>
<td>0.133</td>
<td>0.318</td>
<td>0.497</td>
<td>0.119</td>
<td>0.308</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_3</td>
<td>3</td>
<td>xu2022_t6a</td>
<td>0.501</td>
<td>0.131</td>
<td>0.316</td>
<td>0.517</td>
<td>0.127</td>
<td>0.322</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_1</td>
<td>4</td>
<td>xu2022_t6a</td>
<td>0.498</td>
<td>0.130</td>
<td>0.314</td>
<td>0.507</td>
<td>0.130</td>
<td>0.318</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_4</td>
<td>5</td>
<td>zou2022_t6a</td>
<td>0.497</td>
<td>0.130</td>
<td>0.314</td>
<td>0.520</td>
<td>0.126</td>
<td>0.323</td>
</tr>
<tr>
<td></td>
<td>Xu_t6a_2</td>
<td>6</td>
<td>xu2022_t6a</td>
<td>0.495</td>
<td>0.127</td>
<td>0.311</td>
<td>0.524</td>
<td>0.126</td>
<td>0.325</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_1</td>
<td>7</td>
<td>zou2022_t6a</td>
<td>0.489</td>
<td>0.133</td>
<td>0.311</td>
<td>0.503</td>
<td>0.132</td>
<td>0.317</td>
</tr>
<tr>
<td></td>
<td>Zou_t6a_2</td>
<td>8</td>
<td>zou2022_t6a</td>
<td>0.491</td>
<td>0.128</td>
<td>0.309</td>
<td>0.495</td>
<td>0.131</td>
<td>0.313</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_3</td>
<td>9</td>
<td>mei2022_t6a</td>
<td>0.482</td>
<td>0.135</td>
<td>0.309</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_1</td>
<td>10</td>
<td>mei2022_t6a</td>
<td>0.476</td>
<td>0.134</td>
<td>0.305</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_4</td>
<td>11</td>
<td>mei2022_t6a</td>
<td>0.468</td>
<td>0.138</td>
<td>0.303</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Mei_t6a_2</td>
<td>12</td>
<td>mei2022_t6a</td>
<td>0.456</td>
<td>0.138</td>
<td>0.297</td>
<td>0.453</td>
<td>0.128</td>
<td>0.291</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_4</td>
<td>13</td>
<td>primus2022_t6a</td>
<td>0.458</td>
<td>0.134</td>
<td>0.296</td>
<td>0.461</td>
<td>0.130</td>
<td>0.295</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_4</td>
<td>14</td>
<td>kouzelis2022_t6a</td>
<td>0.453</td>
<td>0.134</td>
<td>0.293</td>
<td>0.457</td>
<td>0.134</td>
<td>0.296</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_4</td>
<td>15</td>
<td>guan2022_t6a</td>
<td>0.451</td>
<td>0.130</td>
<td>0.291</td>
<td>0.471</td>
<td>0.133</td>
<td>0.302</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_2</td>
<td>16</td>
<td>guan2022_t6a</td>
<td>0.451</td>
<td>0.129</td>
<td>0.290</td>
<td>0.465</td>
<td>0.127</td>
<td>0.296</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_3</td>
<td>17</td>
<td>guan2022_t6a</td>
<td>0.447</td>
<td>0.132</td>
<td>0.290</td>
<td>0.442</td>
<td>0.129</td>
<td>0.285</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_3</td>
<td>18</td>
<td>kouzelis2022_t6a</td>
<td>0.447</td>
<td>0.131</td>
<td>0.289</td>
<td>0.557</td>
<td>0.133</td>
<td>0.295</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_1</td>
<td>19</td>
<td>kouzelis2022_t6a</td>
<td>0.439</td>
<td>0.132</td>
<td>0.286</td>
<td>0.453</td>
<td>0.130</td>
<td>0.292</td>
</tr>
<tr>
<td></td>
<td>Kouzelis_t6a_2</td>
<td>20</td>
<td>kouzelis2022_t6a</td>
<td>0.441</td>
<td>0.130</td>
<td>0.285</td>
<td>0.454</td>
<td>0.133</td>
<td>0.293</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_3</td>
<td>21</td>
<td>primus2022_t6a</td>
<td>0.434</td>
<td>0.127</td>
<td>0.280</td>
<td>0.455</td>
<td>0.125</td>
<td>0.290</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_2</td>
<td>22</td>
<td>primus2022_t6a</td>
<td>0.418</td>
<td>0.132</td>
<td>0.275</td>
<td>0.440</td>
<td>0.128</td>
<td>0.284</td>
</tr>
<tr>
<td></td>
<td>Guan_t6a_1</td>
<td>23</td>
<td>guan2022_t6a</td>
<td>0.417</td>
<td>0.124</td>
<td>0.270</td>
<td>0.437</td>
<td>0.126</td>
<td>0.281</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_1</td>
<td>24</td>
<td>kiciński2022_t6a</td>
<td>0.414</td>
<td>0.126</td>
<td>0.270</td>
<td>0.433</td>
<td>0.125</td>
<td>0.279</td>
</tr>
<tr>
<td></td>
<td>Primus_t6a_1</td>
<td>25</td>
<td>primus2022_t6a</td>
<td>0.400</td>
<td>0.127</td>
<td>0.264</td>
<td>0.408</td>
<td>0.120</td>
<td>0.264</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_4</td>
<td>26</td>
<td>pan2022_t6a</td>
<td>0.387</td>
<td>0.123</td>
<td>0.255</td>
<td>0.395</td>
<td>0.119</td>
<td>0.257</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_3</td>
<td>27</td>
<td>kiciński2022_t6a</td>
<td>0.379</td>
<td>0.123</td>
<td>0.251</td>
<td>0.400</td>
<td>0.121</td>
<td>0.260</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_4</td>
<td>28</td>
<td>kiciński2022_t6a</td>
<td>0.380</td>
<td>0.121</td>
<td>0.250</td>
<td>0.378</td>
<td>0.119</td>
<td>0.249</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_3</td>
<td>29</td>
<td>pan2022_t6a</td>
<td>0.376</td>
<td>0.123</td>
<td>0.250</td>
<td>0.386</td>
<td>0.121</td>
<td>0.253</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_1</td>
<td>30</td>
<td>pan2022_t6a</td>
<td>0.377</td>
<td>0.121</td>
<td>0.249</td>
<td>0.381</td>
<td>0.116</td>
<td>0.248</td>
</tr>
<tr>
<td></td>
<td>Kiciński_t6a_2</td>
<td>31</td>
<td>kiciński2022_t6a</td>
<td>0.378</td>
<td>0.119</td>
<td>0.249</td>
<td>0.393</td>
<td>0.117</td>
<td>0.255</td>
</tr>
<tr>
<td></td>
<td>Pan_t6a_2</td>
<td>32</td>
<td>pan2022_t6a</td>
<td>0.363</td>
<td>0.120</td>
<td>0.241</td>
<td>0.384</td>
<td>0.118</td>
<td>0.251</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_1</td>
<td>33</td>
<td>labbe2022_t6a</td>
<td>0.359</td>
<td>0.123</td>
<td>0.241</td>
<td>0.367</td>
<td>0.118</td>
<td>0.242</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline</td>
<td>34</td>
<td>gontier2022_t6a</td>
<td>0.338</td>
<td>0.110</td>
<td>0.224</td>
<td>0.358</td>
<td>0.109</td>
<td>0.233</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_3</td>
<td>35</td>
<td>labbe2022_t6a</td>
<td>0.307</td>
<td>0.117</td>
<td>0.212</td>
<td>0.303</td>
<td>0.111</td>
<td>0.207</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_2</td>
<td>36</td>
<td>labbe2022_t6a</td>
<td>0.247</td>
<td>0.113</td>
<td>0.180</td>
<td>0.241</td>
<td>0.106</td>
<td>0.174</td>
</tr>
<tr>
<td></td>
<td>Labbe_t6a_4</td>
<td>37</td>
<td>labbe2022_t6a</td>
<td>0.203</td>
<td>0.099</td>
<td>0.151</td>
<td>0.198</td>
<td>0.090</td>
<td>0.144</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<p>In this section you can find the characteristics of the submitted systems. There are two tables
for easy reference, in the corresponding subsections. The first table has an overview of the systems
and the second has a detailed presentation of each system.</p>
<h2 id="overview-of-characteristics">Overview of characteristics</h2>
<table class="datatable table table-hover table-condensed" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="abbreviation" data-filter-control="true" data-filter-show-clear="true" data-id-field="abbreviation" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="total_parameters" data-scatter-y="tes_spider" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_sys_rank" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
            Rank
            </th>
<th class="sm-cell" data-field="abbreviation" data-sortable="true">
              Submission<br/>code
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spider" data-reversed="false" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="machine_learning_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Method scheme/architecture
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="total_parameters" data-sortable="true" data-value-type="numeric-unit">
              Amount of parameters
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="audio_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Audio modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="word_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Word modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Data<br/>augmentation
            </th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Xu_t6a_4</td>
<td>0.319</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>528099252</td>
<td>RNN</td>
<td>Transformer, RNN</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Zou_t6a_3</td>
<td>0.318</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>84541437</td>
<td>CNN</td>
<td>LSTM</td>
<td>SpecAugment, SpecAugment++</td>
</tr>
<tr>
<td>3</td>
<td>Xu_t6a_3</td>
<td>0.316</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>347873912</td>
<td>RNN</td>
<td>Transformer</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Xu_t6a_1</td>
<td>0.314</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>85915038</td>
<td>RNN</td>
<td>Transformer</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Zou_t6a_4</td>
<td>0.314</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>84541437</td>
<td>CNN</td>
<td>LSTM</td>
<td>SpecAugment, SpecAugment++</td>
</tr>
<tr>
<td>6</td>
<td>Xu_t6a_2</td>
<td>0.311</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>171830076</td>
<td>RNN</td>
<td>Transformer</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Zou_t6a_1</td>
<td>0.311</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>86643711</td>
<td>CNN</td>
<td>LSTM</td>
<td>SpecAugment, SpecAugment++</td>
</tr>
<tr>
<td>8</td>
<td>Zou_t6a_2</td>
<td>0.309</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>140000000</td>
<td>CNN</td>
<td>LSTM</td>
<td>SpecAugment, SpecAugment++</td>
</tr>
<tr>
<td>9</td>
<td>Mei_t6a_3</td>
<td>0.309</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>10</td>
<td>Mei_t6a_1</td>
<td>0.305</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>11</td>
<td>Mei_t6a_4</td>
<td>0.303</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>12</td>
<td>Mei_t6a_2</td>
<td>0.297</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>13</td>
<td>Primus_t6a_4</td>
<td>0.296</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>780000000</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>14</td>
<td>Kouzelis_t6a_4</td>
<td>0.293</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>Transformer</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
</tr>
<tr>
<td>15</td>
<td>Guan_t6a_4</td>
<td>0.291</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>36147701</td>
<td>PANNs, GAT</td>
<td>Transformer, LocalAFT</td>
<td>Mixup, SpecAugment</td>
</tr>
<tr>
<td>16</td>
<td>Guan_t6a_2</td>
<td>0.290</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>28920672</td>
<td>PANNs, GAT</td>
<td>Transformer, LocalAFT</td>
<td>Mixup, SpecAugment</td>
</tr>
<tr>
<td>17</td>
<td>Guan_t6a_3</td>
<td>0.290</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>7227029</td>
<td>PANNs, GAT</td>
<td>Transformer</td>
<td>Mixup, SpecAugment</td>
</tr>
<tr>
<td>18</td>
<td>Kouzelis_t6a_3</td>
<td>0.289</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>Transformer</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
</tr>
<tr>
<td>19</td>
<td>Kouzelis_t6a_1</td>
<td>0.286</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>Transformer</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
</tr>
<tr>
<td>20</td>
<td>Kouzelis_t6a_2</td>
<td>0.285</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>Transformer</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
</tr>
<tr>
<td>21</td>
<td>Primus_t6a_3</td>
<td>0.280</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>22</td>
<td>Primus_t6a_2</td>
<td>0.275</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>23</td>
<td>Guan_t6a_1</td>
<td>0.270</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>7227029</td>
<td>PANNs, GAT</td>
<td>Transformer</td>
<td>Mixup, SpecAugment</td>
</tr>
<tr>
<td>24</td>
<td>Kiciński_t6a_1</td>
<td>0.270</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>104000000</td>
<td>PANNs</td>
<td>Transformer</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
</tr>
<tr>
<td>25</td>
<td>Primus_t6a_1</td>
<td>0.264</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>26</td>
<td>Pan_t6a_4</td>
<td>0.255</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>Transformer</td>
<td>Mixture</td>
</tr>
<tr>
<td>27</td>
<td>Kiciński_t6a_3</td>
<td>0.251</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>104000000</td>
<td>PANNs</td>
<td>Transformer, KeyBert</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
</tr>
<tr>
<td>28</td>
<td>Kiciński_t6a_4</td>
<td>0.250</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>207000000</td>
<td>PANNs</td>
<td>GPT2, KeyBert</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
</tr>
<tr>
<td>29</td>
<td>Pan_t6a_3</td>
<td>0.250</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>Transformer</td>
<td>Zero_value, Mixup</td>
</tr>
<tr>
<td>30</td>
<td>Pan_t6a_1</td>
<td>0.249</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>Transformer</td>
<td>Zero_value, Mixup</td>
</tr>
<tr>
<td>31</td>
<td>Kiciński_t6a_2</td>
<td>0.249</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>207000000</td>
<td>PANNs</td>
<td>GPT2</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
</tr>
<tr>
<td>32</td>
<td>Pan_t6a_2</td>
<td>0.241</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>Transformer</td>
<td>Zero_value, Mixup</td>
</tr>
<tr>
<td>33</td>
<td>Labbe_t6a_1</td>
<td>0.241</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr class="info" data-hline="true">
<td>34</td>
<td>Baseline</td>
<td>0.224</td>
<td>gontier2022_t6a</td>
<td>encoder-decoder</td>
<td>140000000</td>
<td>Transformer</td>
<td>Transformer</td>
<td></td>
</tr>
<tr>
<td>35</td>
<td>Labbe_t6a_3</td>
<td>0.212</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>36</td>
<td>Labbe_t6a_2</td>
<td>0.180</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>37</td>
<td>Labbe_t6a_4</td>
<td>0.151</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>Transformer</td>
<td>SpecAugment</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="detailed-characteristics">Detailed characteristics</h2>
<table class="datatable table table-hover table-condensed" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="abbreviation" data-filter-control="true" data-filter-show-clear="true" data-id-field="abbreviation" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="total_parameters" data-scatter-y="tes_spider" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_sys_rank" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
            Rank
            </th>
<th class="sm-cell" data-field="abbreviation" data-sortable="true">
              Submission<br/>code
            </th>
<th class="text-center" data-chartable="true" data-field="tes_spider" data-reversed="false" data-sortable="true" data-value-type="float3">
              SPIDEr
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
              Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="machine_learning_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Method scheme/architecture
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="total_parameters" data-sortable="true" data-value-type="numeric-unit">
              Amount of parameters
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="audio_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Audio modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="acoustic_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Acoustic<br/>features
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="word_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Word modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="word_embeddings" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Word<br/>embeddings
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Data<br/>augmentation
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="input_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="learning_scheme" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Learning set-up
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="ensemble" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Ensemble method
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="loss_function" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Loss function
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="optimizer" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Learning set-up
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="learning_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Learning rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="gradient_clipping" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Gradient clipping
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="gradient_norm" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Gradient norm for clipping
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="metric_monitored" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Metric monitored for training
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="dataset_audio_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Dataset(s) used for audio modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="dataset_word_modelling" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Dataset(s) used for word modelling
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="dataset_audio_similarity" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
              Dataset(s) used for audio similarity
            </th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Xu_t6a_4</td>
<td>0.319</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>528099252</td>
<td>RNN</td>
<td>Clap feature</td>
<td>Transformer, RNN</td>
<td>learned</td>
<td></td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>CIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Zou_t6a_3</td>
<td>0.318</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>84541437</td>
<td>CNN</td>
<td>ResNet38</td>
<td>LSTM</td>
<td>Random</td>
<td>SpecAugment, SpecAugment++</td>
<td>44.1KHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, Clotho</td>
<td>Clotho, Clotho</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Xu_t6a_3</td>
<td>0.316</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>347873912</td>
<td>RNN</td>
<td>Clap feature</td>
<td>Transformer</td>
<td>learned</td>
<td></td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>CIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Xu_t6a_1</td>
<td>0.314</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>85915038</td>
<td>RNN</td>
<td>Clap feature</td>
<td>Transformer</td>
<td>learned</td>
<td></td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>CIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Zou_t6a_4</td>
<td>0.314</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>84541437</td>
<td>CNN</td>
<td>ResNet38</td>
<td>LSTM</td>
<td>Random</td>
<td>SpecAugment, SpecAugment++</td>
<td>44.1KHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, Clotho</td>
<td>Clotho, Clotho</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Xu_t6a_2</td>
<td>0.311</td>
<td>xu2022_t6a</td>
<td>Rnn_Transformer</td>
<td>171830076</td>
<td>RNN</td>
<td>Clap feature</td>
<td>Transformer</td>
<td>learned</td>
<td></td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>CIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Zou_t6a_1</td>
<td>0.311</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>86643711</td>
<td>CNN</td>
<td>ResNet38</td>
<td>LSTM</td>
<td>Random</td>
<td>SpecAugment, SpecAugment++</td>
<td>44.1KHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, Clotho</td>
<td>Clotho, Clotho</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Zou_t6a_2</td>
<td>0.309</td>
<td>zou2022_t6a</td>
<td>encoder-decoder</td>
<td>140000000</td>
<td>CNN</td>
<td>ResNet38</td>
<td>LSTM</td>
<td>Random</td>
<td>SpecAugment, SpecAugment++</td>
<td>44.1KHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, Clotho</td>
<td>Clotho, Clotho</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Mei_t6a_3</td>
<td>0.309</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>PANNs</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Mei_t6a_1</td>
<td>0.305</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>PANNs</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Mei_t6a_4</td>
<td>0.303</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>PANNs</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Mei_t6a_2</td>
<td>0.297</td>
<td>mei2022_t6a</td>
<td>encoder-decoder</td>
<td>8867215</td>
<td>CNN</td>
<td>PANNs</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>Primus_t6a_4</td>
<td>0.296</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>780000000</td>
<td>CNN</td>
<td>CNN10</td>
<td>Transformer</td>
<td>BART</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>score function estimator</td>
<td>adamw</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, AudioSet</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>14</td>
<td>Kouzelis_t6a_4</td>
<td>0.293</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>Guan_t6a_4</td>
<td>0.291</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>36147701</td>
<td>PANNs, GAT</td>
<td>log-mel energies</td>
<td>Transformer, LocalAFT</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment</td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss, SPIDEr</td>
<td>Clotho, AudioCaps</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>Guan_t6a_2</td>
<td>0.290</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>28920672</td>
<td>PANNs, GAT</td>
<td>log-mel energies</td>
<td>Transformer, LocalAFT</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss, SPIDEr</td>
<td>Clotho, AudioCaps</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>17</td>
<td>Guan_t6a_3</td>
<td>0.290</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>7227029</td>
<td>PANNs, GAT</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment</td>
<td>44.1kHz</td>
<td>supervised, reinforcement learning</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss, SPIDEr</td>
<td>Clotho, AudioCaps</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>18</td>
<td>Kouzelis_t6a_3</td>
<td>0.289</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>19</td>
<td>Kouzelis_t6a_1</td>
<td>0.286</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>linear warmup 1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>20</td>
<td>Kouzelis_t6a_2</td>
<td>0.285</td>
<td>kouzelis2022_t6a</td>
<td>encoder-decoder</td>
<td>119757102</td>
<td>PaSST</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment, Label Smoothing</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, MACS</td>
<td>Clotho, AudioCaps, MACS</td>
<td></td>
</tr>
<tr>
<td>21</td>
<td>Primus_t6a_3</td>
<td>0.280</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>CNN10</td>
<td>Transformer</td>
<td>BART</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>score function estimator</td>
<td>adamw</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, AudioSet</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>22</td>
<td>Primus_t6a_2</td>
<td>0.275</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>CNN10</td>
<td>Transformer</td>
<td>BART</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioCaps, AudioSet</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>23</td>
<td>Guan_t6a_1</td>
<td>0.270</td>
<td>guan2022_t6a</td>
<td>encoder-decoder</td>
<td>7227029</td>
<td>PANNs, GAT</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixup, SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss, SPIDEr</td>
<td>Clotho, AudioCaps</td>
<td>Clotho, AudioCaps</td>
<td></td>
</tr>
<tr>
<td>24</td>
<td>Kiciński_t6a_1</td>
<td>0.270</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>104000000</td>
<td>PANNs</td>
<td>mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
<td>16kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, AudioCaps, Freesound</td>
<td>Clotho, AudioCaps, Freesound</td>
<td></td>
</tr>
<tr>
<td>25</td>
<td>Primus_t6a_1</td>
<td>0.264</td>
<td>primus2022_t6a</td>
<td>encoder-decoder</td>
<td>130000000</td>
<td>CNN</td>
<td>CNN10</td>
<td>Transformer</td>
<td>BART</td>
<td>SpecAugment</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>SPIDEr</td>
<td>Clotho, AudioSet</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>26</td>
<td>Pan_t6a_4</td>
<td>0.255</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Mixture</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>27</td>
<td>Kiciński_t6a_3</td>
<td>0.251</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>104000000</td>
<td>PANNs</td>
<td>mel energies</td>
<td>Transformer, KeyBert</td>
<td>learned</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
<td>16kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, AudioCaps, Freesound</td>
<td>Clotho, AudioCaps, Freesound</td>
<td></td>
</tr>
<tr>
<td>28</td>
<td>Kiciński_t6a_4</td>
<td>0.250</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>207000000</td>
<td>PANNs</td>
<td>mel energies</td>
<td>GPT2, KeyBert</td>
<td>GPT2</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
<td>16kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, AudioCaps, Freesound</td>
<td>Clotho, AudioCaps, Freesound</td>
<td></td>
</tr>
<tr>
<td>29</td>
<td>Pan_t6a_3</td>
<td>0.250</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Zero_value, Mixup</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>30</td>
<td>Pan_t6a_1</td>
<td>0.249</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>Zero_value, Mixup</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>31</td>
<td>Kiciński_t6a_2</td>
<td>0.249</td>
<td>kiciński2022_t6a</td>
<td>encoder-decoder</td>
<td>207000000</td>
<td>PANNs</td>
<td>mel energies</td>
<td>GPT2</td>
<td>GPT2</td>
<td>random crop, random pad, adding white noise, SpecAugment</td>
<td>16kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>5e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho, AudioCaps, Freesound</td>
<td>Clotho, AudioCaps, Freesound</td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>Pan_t6a_2</td>
<td>0.241</td>
<td>pan2022_t6a</td>
<td>encoder-decoder</td>
<td>9857679</td>
<td>CNN</td>
<td>mel energies</td>
<td>Transformer</td>
<td>Word2Vec</td>
<td>Zero_value, Mixup</td>
<td>44.1kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>1e-3</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>33</td>
<td>Labbe_t6a_1</td>
<td>0.241</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>SpecAugment</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td>34</td>
<td>Baseline</td>
<td>0.224</td>
<td>gontier2022_t6a</td>
<td>encoder-decoder</td>
<td>140000000</td>
<td>Transformer</td>
<td>VGGish</td>
<td>Transformer</td>
<td>BART</td>
<td></td>
<td>16kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adamw</td>
<td>1e-5</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>35</td>
<td>Labbe_t6a_3</td>
<td>0.212</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>SpecAugment</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>36</td>
<td>Labbe_t6a_2</td>
<td>0.180</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>SpecAugment</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
<tr>
<td>37</td>
<td>Labbe_t6a_4</td>
<td>0.151</td>
<td>labbe2022_t6a</td>
<td>encoder-decoder</td>
<td>16531922</td>
<td>CNN10</td>
<td>log-mel energies</td>
<td>Transformer</td>
<td>learned</td>
<td>SpecAugment</td>
<td>32kHz</td>
<td>supervised</td>
<td></td>
<td>cross-entropy</td>
<td>adam</td>
<td>5e-4</td>
<td></td>
<td></td>
<td>loss</td>
<td>Clotho</td>
<td>Clotho</td>
<td></td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2022/technical_reports_task6a.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="guan2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-guan2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Ensemble learning for audio captioning with graph audio feature representation
       </h4>
<p style="text-align:left">
        Feiyang Xiao<sup>1</sup>, Jian Guan<sup>1</sup>, Haiyan Lan<sup>1</sup>, Qiaoxi Zhu<sup>2</sup>, Wenwu Wang<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Group of Intelligent Signal Processing, College of Computer Science and Technology, Harbin Engineering University, Harbin, China, <sup>2</sup>Centre for Audio, Acoustic and Vibration, University of Technology Sydney, Ultimo, Australia, <sup>3</sup>Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">guan_t6a_1</span> <span class="label label-primary">guan_t6a_2</span> <span class="label label-primary">guan_t6a_3</span> <span class="label label-primary">guan_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-guan2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-guan2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-guan2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Guan_31_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-guan2022_t6a" class="panel-collapse collapse" id="collapse-guan2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Ensemble learning for audio captioning with graph audio feature representation
      </h4>
<p style="text-align:left">
<small>
        Feiyang Xiao<sup>1</sup>, Jian Guan<sup>1</sup>, Haiyan Lan<sup>1</sup>, Qiaoxi Zhu<sup>2</sup>, Wenwu Wang<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Group of Intelligent Signal Processing, College of Computer Science and Technology, Harbin Engineering University, Harbin, China, <sup>2</sup>Centre for Audio, Acoustic and Vibration, University of Technology Sydney, Ultimo, Australia, <sup>3</sup>Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for Task 6A of the DCASE2022 Challenge (automated audio captioning). Our system is built based on the ensemble learning strategy. It integrates the advantages of different audio captioning methods, including the graph attention-based audio feature representation method. Experiments show that our ensemble system can achieve the SPIDEr score (used for ranking) of 30.2 on the evaluation split of the Clotho v2 dataset.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Mixup, SpecAugment
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-guan2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Guan_31_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-guan2022_t6alabel" class="modal fade" id="bibtex-guan2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexguan2022_t6alabel">
        Ensemble learning for audio captioning with graph audio feature representation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{guan2022_t6a,
    Author = "Xiao, Feiyang and Guan, Jian and Lan, Haiyan and Zhu, Qiaoxi and Wang, Wenwu",
    title = "Ensemble learning for audio captioning with graph audio feature representation",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes our submission for Task 6A of the DCASE2022 Challenge (automated audio captioning). Our system is built based on the ensemble learning strategy. It integrates the advantages of different audio captioning methods, including the graph attention-based audio feature representation method. Experiments show that our ensemble system can achieve the SPIDEr score (used for ranking) of 30.2 on the evaluation split of the Clotho v2 dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="kicinski2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-kicinski2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Exploring audio captioning with keyword-guided text generation
       </h4>
<p style="text-align:left">
        Dawid Kicinski, Teodor Lamort de Gail, Pawel Bujnowski
       </p>
<p style="text-align:left">
<em>
         Samsung R&amp;D Institute Poland, Artificial Intelligence, Warsaw, Poland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">kicinski_t6a_1</span> <span class="label label-primary">kicinski_t6a_2</span> <span class="label label-primary">kicinski_t6a_3</span> <span class="label label-primary">kicinski_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-kicinski2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-kicinski2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-kicinski2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Kicinski_115_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-kicinski2022_t6a" class="panel-collapse collapse" id="collapse-kicinski2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Exploring audio captioning with keyword-guided text generation
      </h4>
<p style="text-align:left">
<small>
        Dawid Kicinski, Teodor Lamort de Gail, Pawel Bujnowski
       </small>
<br/>
<small>
<em>
         Samsung R&amp;D Institute Poland, Artificial Intelligence, Warsaw, Poland
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission to the DCASE 2022 challenge, Task 6 A: automated audio captioning. In our system, we explore the use of pre-trained language models for the audio captioning task. The proposed system is an encoder-decoder architecture consisting of a pre-trained PANN encoder and a GPT2 decoder. Audio embeddings are encoded to language model prompts using a simple mapping network. We further develop our system by employing strategies of guiding the decoder with textual information. We prompt the decoder with keywords extracted from semantically similar audios and use them to choose the best matching caption by their occurrence.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         random crop, random pad, adding white noise, SpecAugment
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-kicinski2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Kicinski_115_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-kicinski2022_t6alabel" class="modal fade" id="bibtex-kicinski2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexkicinski2022_t6alabel">
        Exploring audio captioning with keyword-guided text generation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{kicinski2022_t6a,
    Author = "Kicinski, Dawid and de Gail, Teodor Lamort and Bujnowski, Pawel",
    title = "Exploring audio captioning with keyword-guided text generation",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes our submission to the DCASE 2022 challenge, Task 6 A: automated audio captioning. In our system, we explore the use of pre-trained language models for the audio captioning task. The proposed system is an encoder-decoder architecture consisting of a pre-trained PANN encoder and a GPT2 decoder. Audio embeddings are encoded to language model prompts using a simple mapping network. We further develop our system by employing strategies of guiding the decoder with textual information. We prompt the decoder with keywords extracted from semantically similar audios and use them to choose the best matching caption by their occurrence."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="kouzelis2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-kouzelis2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Efficient audio captioning transformer with patchout and text guidance
       </h4>
<p style="text-align:left">
        Thodoris Kouzelis<sup>1,2</sup>, Grigoris Bastas<sup>1,2</sup>, Athanasios Katsamanis<sup>2</sup>, Alexandros Potamianos<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute for Language and Speech Processing, Athena Research Center, Athens, Greece, <sup>2</sup>School of ECE, National Technical University of Athens, Athens, Greece
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">kouzelis_t6a_1</span> <span class="label label-primary">kouzelis_t6a_2</span> <span class="label label-primary">kouzelis_t6a_3</span> <span class="label label-primary">kouzelis_t6a_4</span>
</p>
<p style="text-align:left">
<span class="label label-success">
         Judges’ award
        </span>
</p>
<button aria-controls="collapse-kouzelis2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-kouzelis2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-kouzelis2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Kouzelis_60_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-kouzelis2022_t6a" class="panel-collapse collapse" id="collapse-kouzelis2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Efficient audio captioning transformer with patchout and text guidance
      </h4>
<p style="text-align:left">
<small>
        Thodoris Kouzelis<sup>1,2</sup>, Grigoris Bastas<sup>1,2</sup>, Athanasios Katsamanis<sup>2</sup>, Alexandros Potamianos<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Institute for Language and Speech Processing, Athena Research Center, Athens, Greece, <sup>2</sup>School of ECE, National Technical University of Athens, Athens, Greece
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes an Automated Audio Captioning model for the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Challenge, Task 6. We propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning (AAC) we pre-train our model on an enlarged dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Our best model achieves the SPIDEr score of 0.296.
      </p>
<p>
<strong>
        Awards:
       </strong>
       Judges’ award
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Mixup, SpecAugment, Label Smoothing
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-kouzelis2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Kouzelis_60_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-kouzelis2022_t6alabel" class="modal fade" id="bibtex-kouzelis2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexkouzelis2022_t6alabel">
        Efficient audio captioning transformer with patchout and text guidance
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{kouzelis2022_t6a,
    Author = "Kouzelis, Thodoris and Bastas, Grigoris and Katsamanis, Athanasios and Potamianos, Alexandros",
    title = "Efficient audio captioning transformer with patchout and text guidance",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes an Automated Audio Captioning model for the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Challenge, Task 6. We propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning (AAC) we pre-train our model on an enlarged dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Our best model achieves the SPIDEr score of 0.296."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="labbe2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-labbe2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        IRIT-UPS DCASE 2022 task6a system: stochastic decoding methods for audio captioning
       </h4>
<p style="text-align:left">
        Etienne Labbé, Thomas Pellegrini, Julien Pinquier
       </p>
<p style="text-align:left">
<em>
         IRIT (UMR 5505), Université Paul Sabatier, CNRS, Toulouse, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">labbe_t6a_1</span> <span class="label label-primary">labbe_t6a_2</span> <span class="label label-primary">labbe_t6a_3</span> <span class="label label-primary">labbe_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-labbe2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-labbe2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-labbe2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Labbe_87_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-labbe2022_t6a" class="panel-collapse collapse" id="collapse-labbe2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       IRIT-UPS DCASE 2022 task6a system: stochastic decoding methods for audio captioning
      </h4>
<p style="text-align:left">
<small>
        Etienne Labbé, Thomas Pellegrini, Julien Pinquier
       </small>
<br/>
<small>
<em>
         IRIT (UMR 5505), Université Paul Sabatier, CNRS, Toulouse, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This document presents a summary of our models used in the Automated Audio Captioning task (6a) for the DCASE2022 challenge. Four submissions were made using different decoding methods : beam search, top k sampling, nucleus sampling and typical decoding.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-labbe2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Labbe_87_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-labbe2022_t6alabel" class="modal fade" id="bibtex-labbe2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexlabbe2022_t6alabel">
        IRIT-UPS DCASE 2022 task6a system: stochastic decoding methods for audio captioning
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{labbe2022_t6a,
    Author = "Labbé, Etienne and Pellegrini, Thomas and Pinquier, Julien",
    title = "IRIT-UPS DCASE 2022 task6a system: stochastic decoding methods for audio captioning",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This document presents a summary of our models used in the Automated Audio Captioning task (6a) for the DCASE2022 challenge. Four submissions were made using different decoding methods : beam search, top k sampling, nucleus sampling and typical decoding."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="mei2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-mei2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Automated audio captioning with keywords guidance
       </h4>
<p style="text-align:left">
        Xinhao Mei, Xubo Liu, Haohe Liu, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang
       </p>
<p style="text-align:left">
<em>
         Centre for Vision, Speech, and Signal Processing (CVSSP), University of Surrey, UK
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">mei_t6a_1</span> <span class="label label-primary">mei_t6a_2</span> <span class="label label-primary">mei_t6a_3</span> <span class="label label-primary">mei_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-mei2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-mei2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-mei2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-mei2022_t6a" class="panel-collapse collapse" id="collapse-mei2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Automated audio captioning with keywords guidance
      </h4>
<p style="text-align:left">
<small>
        Xinhao Mei, Xubo Liu, Haohe Liu, Jianyuan Sun, Mark D. Plumbley, Wenwu Wang
       </small>
<br/>
<small>
<em>
         Centre for Vision, Speech, and Signal Processing (CVSSP), University of Surrey, UK
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes an automated audio captioning system we submitted to Detection and Classification of Acoustic Scenes and Events (DCASE) Challenge 2022 Task 6a. The proposed system is built on an encoder-decoder architecture we submitted to DCASE 2021 Challenge Task 6 last year, where the encoder is a pre-trained 10-layer convolutional neural network and the decoder is a Transformer network. In this new submission, we investigate the use of keywords estimated from input audio clips to guide the caption generation process. The results show that keywords guidance can improve the system performance especially when the pre-trained encoder is frozen, and can also reduce the variance of the results when the model is trained with different seeds. The overall system consists of a pre-trained keywords estimation model and a CNN-Transformer audio captioning model. The captioning model is first trained via the cross-entropy loss and then fine-tuned with reinforcement learning to optimize the evaluation metric CIDEr. The proposed system significantly improves the scores of all the evaluation metrics as compared to the baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-mei2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Mei_117_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-mei2022_t6alabel" class="modal fade" id="bibtex-mei2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexmei2022_t6alabel">
        Automated audio captioning with keywords guidance
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{mei2022_t6a,
    Author = "Mei, Xinhao and Liu, Xubo and Liu, Haohe and Sun, Jianyuan and Plumbley, Mark D. and Wang, Wenwu",
    title = "Automated audio captioning with keywords guidance",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes an automated audio captioning system we submitted to Detection and Classification of Acoustic Scenes and Events (DCASE) Challenge 2022 Task 6a. The proposed system is built on an encoder-decoder architecture we submitted to DCASE 2021 Challenge Task 6 last year, where the encoder is a pre-trained 10-layer convolutional neural network and the decoder is a Transformer network. In this new submission, we investigate the use of keywords estimated from input audio clips to guide the caption generation process. The results show that keywords guidance can improve the system performance especially when the pre-trained encoder is frozen, and can also reduce the variance of the results when the model is trained with different seeds. The overall system consists of a pre-trained keywords estimation model and a CNN-Transformer audio captioning model. The captioning model is first trained via the cross-entropy loss and then fine-tuned with reinforcement learning to optimize the evaluation metric CIDEr. The proposed system significantly improves the scores of all the evaluation metrics as compared to the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="pan2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-pan2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Audio captioning using pre-trained model and data augmentation
       </h4>
<p style="text-align:left">
        Tianyang Huang<sup>1</sup>, Chaofan Pan<sup>1</sup>, Wenyao Chen<sup>1</sup>, Chenyang Zhu<sup>3</sup>, Shengchen Li<sup>2</sup>, Xi Shao<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China, <sup>2</sup>School of Advanced Technology, Xi’an Jiaotong-liverpool University, Suzhou, China, <sup>3</sup>School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">pan_t6a_1</span> <span class="label label-primary">pan_t6a_2</span> <span class="label label-primary">pan_t6a_3</span> <span class="label label-primary">pan_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-pan2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-pan2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-pan2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Pan_62_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-pan2022_t6a" class="panel-collapse collapse" id="collapse-pan2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Audio captioning using pre-trained model and data augmentation
      </h4>
<p style="text-align:left">
<small>
        Tianyang Huang<sup>1</sup>, Chaofan Pan<sup>1</sup>, Wenyao Chen<sup>1</sup>, Chenyang Zhu<sup>3</sup>, Shengchen Li<sup>2</sup>, Xi Shao<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China, <sup>2</sup>School of Advanced Technology, Xi’an Jiaotong-liverpool University, Suzhou, China, <sup>3</sup>School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes an automatic audio captioning system for task 6, Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Challenge. Based on an encoder-decoder architecture, the system is composed of convolutional neural network (CNN) encoder and transformer decoder. Instead of using pre-trained models only in audio modal, we try to introduce pretrained models in text modal as well. In addition, we consider using a data argumentation method with and without noise to improve the data quality and thus improve the generalization and robustness of the model. The experimental results show that our system can achieve the SPIDEr of 0.257 (official baseline: 0.233) on the Clotho evaluation set.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Mixture
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-pan2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Pan_62_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-pan2022_t6alabel" class="modal fade" id="bibtex-pan2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexpan2022_t6alabel">
        Audio captioning using pre-trained model and data augmentation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{pan2022_t6a,
    Author = "Huang, Tianyang and Pan, Chaofan and Chen, Wenyao and Zhu, Chenyang and Li, Shengchen and Shao, Xi",
    title = "Audio captioning using pre-trained model and data augmentation",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes an automatic audio captioning system for task 6, Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Challenge. Based on an encoder-decoder architecture, the system is composed of convolutional neural network (CNN) encoder and transformer decoder. Instead of using pre-trained models only in audio modal, we try to introduce pretrained models in text modal as well. In addition, we consider using a data argumentation method with and without noise to improve the data quality and thus improve the generalization and robustness of the model. The experimental results show that our system can achieve the SPIDEr of 0.257 (official baseline: 0.233) on the Clotho evaluation set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="primus2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-primus2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CP-JKU's submission to task 6a of the DCASE2022 challenge: a BART encoder-decoder for automatic audio captioning trained via the reinforce algorithm and transfer learning
       </h4>
<p style="text-align:left">
        Paul Primus<sup>1</sup>, Gerhard Widmer<sup>1,2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute of Computational Perception (CP-JKU), <sup>2</sup>LIT Artificial Intelligence Lab, Johannes Kepler University, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">primus_t6a_1</span> <span class="label label-primary">primus_t6a_2</span> <span class="label label-primary">primus_t6a_3</span> <span class="label label-primary">primus_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-primus2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-primus2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-primus2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Primus_97_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-primus2022_t6a" class="panel-collapse collapse" id="collapse-primus2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CP-JKU's submission to task 6a of the DCASE2022 challenge: a BART encoder-decoder for automatic audio captioning trained via the reinforce algorithm and transfer learning
      </h4>
<p style="text-align:left">
<small>
        Paul Primus<sup>1</sup>, Gerhard Widmer<sup>1,2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Institute of Computational Perception (CP-JKU), <sup>2</sup>LIT Artificial Intelligence Lab, Johannes Kepler University, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report details the CP-JKU submission to the automatic audio captioning task of the 2022’s DCASE challenge (task 6a). The objective of the task was to train a sequence-to-sequence model that automatically generates textual descriptions for given audio recordings. The approach described in this report enhances the BART-based encoder-decoder model used as the challenge’s baseline system in three directions: firstly, the VGGish embedding model was replaced with a custom CNN10-like model that we pretrained on AudioSet. Secondly, the BART encoder-decoder model was pre-trained on AudioCaps, which led to faster convergence. And finally, the best model was further fine-tuned by optimizing the non-differentiable CIDEr metric using the REINFORCE algorithm. Our best model achieves a SPIDEr score of .29 (single-model performance), which is an improvement of 6.6 pp. over the challenge’s baseline score.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-primus2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Primus_97_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-primus2022_t6alabel" class="modal fade" id="bibtex-primus2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexprimus2022_t6alabel">
        CP-JKU's submission to task 6a of the DCASE2022 challenge: a BART encoder-decoder for automatic audio captioning trained via the reinforce algorithm and transfer learning
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{primus2022_t6a,
    Author = "Primus, Paul and Widmer, Gerhard",
    title = "CP-JKU's submission to task 6a of the DCASE2022 challenge: a BART encoder-decoder for automatic audio captioning trained via the reinforce algorithm and transfer learning",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report details the CP-JKU submission to the automatic audio captioning task of the 2022’s DCASE challenge (task 6a). The objective of the task was to train a sequence-to-sequence model that automatically generates textual descriptions for given audio recordings. The approach described in this report enhances the BART-based encoder-decoder model used as the challenge’s baseline system in three directions: firstly, the VGGish embedding model was replaced with a custom CNN10-like model that we pretrained on AudioSet. Secondly, the BART encoder-decoder model was pre-trained on AudioCaps, which led to faster convergence. And finally, the best model was further fine-tuned by optimizing the non-differentiable CIDEr metric using the REINFORCE algorithm. Our best model achieves a SPIDEr score of .29 (single-model performance), which is an improvement of 6.6 pp. over the challenge’s baseline score."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="xu2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-xu2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        The SJTU System for DCASE2022 Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training
       </h4>
<p style="text-align:left">
        Xuenan Xu, Zeyu Xie, Mengyue Wu, Kai Yu
       </p>
<p style="text-align:left">
<em>
         MoE Key Lab of Artificial Intelligence, X-LANCE Lab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">xu_t6a_1</span> <span class="label label-primary">xu_t6a_2</span> <span class="label label-primary">xu_t6a_3</span> <span class="label label-primary">xu_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-xu2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-xu2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-xu2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Xu_106_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-xu2022_t6a" class="panel-collapse collapse" id="collapse-xu2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       The SJTU System for DCASE2022 Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training
      </h4>
<p style="text-align:left">
<small>
        Xuenan Xu, Zeyu Xie, Mengyue Wu, Kai Yu
       </small>
<br/>
<small>
<em>
         MoE Key Lab of Artificial Intelligence, X-LANCE Lab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the system submitted to the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 challenge Task 6. There are two involving subtasks: text-to-audio retrieval and automated audio captioning. The text-to-audio retrieval system adopts a bi-encoder architecture using pre-trained audio and text encoders. The system is first pre-trained on AudioCaps and then fine-tuned on the challenge dataset Clotho. For the audio captioning system, we first train a retrieval model on all public captioning data and then take the audio encoder as the feature extractor. Then a standard sequence-to-sequence model is trained on Clotho based on the pre-trained feature extractor. The captioning model is first trained by word-level cross entropy loss and then finetuned using self-critical sequence training. Our system achieves a SPIDEr of 32.5 on captioning and an mAP of 29.9 on text-to-audio retrieval.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         None
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-xu2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Xu_106_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-xu2022_t6alabel" class="modal fade" id="bibtex-xu2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexxu2022_t6alabel">
        The SJTU System for DCASE2022 Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{xu2022_t6a,
    Author = "Xu, Xuenan and Xie, Zeyu and Wu, Mengyue and Yu, Kai",
    title = "The {SJTU} System for {DCASE2022} Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes the system submitted to the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 challenge Task 6. There are two involving subtasks: text-to-audio retrieval and automated audio captioning. The text-to-audio retrieval system adopts a bi-encoder architecture using pre-trained audio and text encoders. The system is first pre-trained on AudioCaps and then fine-tuned on the challenge dataset Clotho. For the audio captioning system, we first train a retrieval model on all public captioning data and then take the audio encoder as the feature extractor. Then a standard sequence-to-sequence model is trained on Clotho based on the pre-trained feature extractor. The captioning model is first trained by word-level cross entropy loss and then finetuned using self-critical sequence training. Our system achieves a SPIDEr of 32.5 on captioning and an mAP of 29.9 on text-to-audio retrieval."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="zou2022_t6a" style="box-shadow: none">
<div class="panel-heading" id="heading-zou2022_t6a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Automated audio captioning with multi-task learning
       </h4>
<p style="text-align:left">
        Zhongjie Ye<sup>1</sup>, Yuexian Zou<sup>1</sup>, Fan Cui<sup>2</sup>, Yujun Wang<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>ADSPLAB, School of ECE, Peking University, Shenzhen, China, <sup>2</sup>Xiaomi Corporation, Beijing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">zou_t6a_1</span> <span class="label label-primary">zou_t6a_2</span> <span class="label label-primary">zou_t6a_3</span> <span class="label label-primary">zou_t6a_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-zou2022_t6a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-zou2022_t6a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-zou2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Zou_37_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-zou2022_t6a" class="panel-collapse collapse" id="collapse-zou2022_t6a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Automated audio captioning with multi-task learning
      </h4>
<p style="text-align:left">
<small>
        Zhongjie Ye<sup>1</sup>, Yuexian Zou<sup>1</sup>, Fan Cui<sup>2</sup>, Yujun Wang<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>ADSPLAB, School of ECE, Peking University, Shenzhen, China, <sup>2</sup>Xiaomi Corporation, Beijing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes an automated audio captioning (AAC) model for the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Task 6A Challenge. Our model consists of a convolution neural network (CNN) encoder and a single layer (LSTM) decoder with a temporal attention module. In order to enhance the representation in the domain dataset, we use the ResNet38 pretrained on the AudioSet dataset as our audio encoder and finetune it with keywords of nouns and verbs as labels which are extracted from the captions. For training the whole caption model, we first train the model with the standard cross entropy loss, and fine-tune it with reinforcement learning to directly optimize the CIDEr score. Experimental results show that our single model can achieve a SPIDEr score of 31.7 on the evaluation spilt.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment, SpecAugment++
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-zou2022_t6a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2022/technical_reports/DCASE2022_Zou_37_t6a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-zou2022_t6alabel" class="modal fade" id="bibtex-zou2022_t6a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexzou2022_t6alabel">
        Automated audio captioning with multi-task learning
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{zou2022_t6a,
    Author = "Ye, Zhongjie and Zou, Yuexian and Cui, Fan and Wang, Yujun",
    title = "Automated audio captioning with multi-task learning",
    institution = "DCASE2022 Challenge",
    year = "2022",
    month = "July",
    abstract = "This technical report describes an automated audio captioning (AAC) model for the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Task 6A Challenge. Our model consists of a convolution neural network (CNN) encoder and a single layer (LSTM) decoder with a temporal attention module. In order to enhance the representation in the domain dataset, we use the ResNet38 pretrained on the AudioSet dataset as our audio encoder and finetune it with keywords of nouns and verbs as labels which are extracted from the captions. For training the whole caption model, we first train the model with the standard cross entropy loss, and fine-tune it with reinforcement learning to directly optimize the CIDEr score. Experimental results show that our single model can achieve a SPIDEr score of 31.7 on the evaluation spilt."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>