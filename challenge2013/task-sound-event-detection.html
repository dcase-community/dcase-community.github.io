<!DOCTYPE html><html lang="en">
<head>
    <title>Sound event detection - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2013/task-sound-event-detection">
        <meta name="author" content="Toni Heittola" />
        <meta name="description" content="Challenge has ended. Full results for this task can be found here This page collects information from original DCASE2013 Challenge website to document DCASE challenge tasks in an uniform way. Description The event detection challenge will address the problem of identifying individual sound events that are prominent in an acoustic â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2013</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2013/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2013/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2013/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2013/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2013/task-sound-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2013/task-sound-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-ol"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OL</a>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-os"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OS</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2013/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2013/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2013/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/tiles-01.jpg);box-shadow: 0px 1000px rgba(0, 0, 0, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-synthetic fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Events</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 2</span></span><img src="../images/logos/dcase/dcase2013_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Sound event detection</h1><hr class="small right bold"><span class="subheading">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Dimitrios Giannoulis" class="img img-circle" src="/images/person/dimitrios_giannoulis.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Dimitrios Giannoulis</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Dan Stowell" class="img img-circle" src="/images/person/dan_stowell.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Dan Stowell</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Emmanouil Benetos" class="img img-circle" src="/images/person/emmanouil_benetos.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Emmanouil Benetos</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mathieu Lagrange" class="img img-circle" src="/images/person/mathieu_lagrange_.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mathieu Lagrange</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.irccyn.ec-nantes.fr/en/research-teams/adtsi">
                                IRCCYN
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mathias Rossignol" class="img img-circle" src="/images/person/default.png" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mathias Rossignol</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://anasynth.ircam.fr/home/english">
                                IRCAM
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mark D. Plumbley" class="img img-circle" src="/images/person/mark_plumbley.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mark D. Plumbley</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a></li>
<li><a href="#task-setup">Task setup</a>
<ul>
<li><a href="#subtask-ol---office-live">Subtask OL - Office live</a></li>
<li><a href="#subtask-os---office-synthetic">Subtask OS - Office synthetic</a></li>
</ul>
</li>
<li><a href="#submission">Submission</a>
<ul>
<li><a href="#submission-format">Submission format</a></li>
<li><a href="#packaging-submissions">Packaging submissions</a></li>
<li><a href="#time-and-hardware-limits">Time and Hardware limits</a></li>
</ul>
</li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#results">Results</a>
<ul>
<li><a href="#subtask-ol">Subtask OL</a></li>
<li><a href="#subtask-os">Subtask OS</a></li>
</ul>
</li>
<li><a href="#baseline-system">Baseline system</a>
<ul>
<li><a href="#matlab-implementation">Matlab implementation</a></li>
</ul>
</li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="alert alert-info">
<strong>Challenge has ended.</strong> Full results for this task can be found <a class="btn btn-default btn-xs" href="/challenge2013/task-sound-event-detection-results-ol">here <i class="fa fa-caret-right"></i></a>
<br/>This page collects information from original <a href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/" target="_blank">DCASE2013 Challenge website</a> to document DCASE challenge tasks in an uniform way.
</p>
<h1 id="description">Description</h1>
<p>The event detection challenge will address the problem of identifying individual sound events that are prominent in an acoustic scene. Two distinct experiments will take, one for simple acoustic scenes without overlapping sounds and the other using complex scenes in a polyphonic scenario. Three datasets will be used for the task.</p>
<figure>
<div class="row-fluid row-centered">
<div class="col-xs-10 col-md-5 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2016/task3_overview.png"/>
<figcaption>Figure 1: Overview of sound event detection system.</figcaption>
</div>
</div>
</figure>
<h1 id="task-setup">Task setup</h1>
<h2 id="subtask-ol---office-live">Subtask OL - Office live</h2>
<p>The first dataset for event detection will consist of 3 subsets (for development, training, and testing). The training set will contain instantiations of individual events for every class. The development and testing datasets, denoted as office live (OL), will consist of 1 min recordings of every-day audio events in a number of office environments.</p>
<p>The test data consists of 11 stereo recordings (WAV, 44.1 kHz, 24-bit), lasting between 1 and 3 minues, of scripted sequences containing non-overlapping acoustic events in an office environment. Recordings were made using a Soundfield microphone system, model SPS422B. The test dataset contains events from 16 different classes, which are as follows:</p>
<ul>
<li><code>alarm</code> (short alert (beep) sound)</li>
<li><code>clearthroat</code> (clearing throat)</li>
<li><code>cough</code></li>
<li><code>doorslam</code> (door slam)</li>
<li><code>drawer</code></li>
<li><code>keyboard</code> (keyboard clicks)</li>
<li><code>keys</code> (keys put on table)</li>
<li><code>knock</code> (door knock)</li>
<li><code>laughter</code></li>
<li><code>mouse</code> (mouse click)</li>
<li><code>pageturn</code> (page turning)</li>
<li><code>pendrop</code> (pen, pencil, or marker touching table surfaces)</li>
<li><code>phone</code></li>
<li><code>printer</code></li>
<li><code>speech</code></li>
<li><code>switch</code></li>
</ul>
<p>Submitted event detection systems can be tuned and trained using the publicly released training and
development datasets.</p>
<h3>Datasets</h3>
<p>Isolated events:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_training" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_training" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Training</strong> Dataset for Event Detection Task (subtasks OL, OS) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(678MB)</span>
<br/>
</div>
</div>
<p>Event sequences:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_development" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_development" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Development</strong> Dataset for Event Detection Task (subtask OL) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(197MB)</span>
<br/>
</div>
</div>
<p>Event sequences:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_testset_OL" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_testset_OL" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Testing</strong> Dataset for Event Detection Task (subtask OL) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(328MB)</span>
<br/>
</div>
</div>
<p><br/></p>
<h2 id="subtask-os---office-synthetic">Subtask OS - Office synthetic</h2>
<p>The second dataset will contain artificially sequenced sounds provided by the Analysis-Synthesis team of IRCAM, termed Office Synthetic (OS). The training set will be identical to the one for the first dataset. The development and testing sets will consist of artificial scenes built by sequencing recordings of individual events (different recordings from the ones used for the training dataset) and background recordings provided by C4DM.</p>
<p>The test data consists of mono recordings (WAV, 44.1 kHz) of sequences containing artificially concatenating overlapping acoustic events in an office environment. Original recordings of isolated acoustic events were made using a Soundfield microphone system, model SPS422B. The dataset contains various SNRs of events over background noise (+6, 0, and -6 dB) and different levels of "density" of events (low, medium, and high). The distribution of events in the scene is random, following high-level directives that specify the desired density of events. The average SNR of events over the background noise is also specified upon synthesis and, unlike in the natural scenes, is the same for all event types. The synthesized scenes are mixed down to mono in order to avoid having spatialization inconsistencies between successive occurrences of a same event. The test dataset contains events from 16 different classes, which are as follows:</p>
<ul>
<li><code>alarm</code> (short alert (beep) sound)</li>
<li><code>clearthroat</code> (clearing throat)</li>
<li><code>cough</code></li>
<li><code>doorslam</code> (door slam)</li>
<li><code>drawer</code></li>
<li><code>keyboard</code> (keyboard clicks)</li>
<li><code>keys</code> (keys put on table)</li>
<li><code>knock</code> (door knock)</li>
<li><code>laughter</code></li>
<li><code>mouse</code> (mouse click)</li>
<li><code>pageturn</code> (page turning)</li>
<li><code>pendrop</code> (pen, pencil, or marker touching table surfaces)</li>
<li><code>phone</code></li>
<li><code>printer</code></li>
<li><code>speech</code></li>
<li><code>switch</code></li>
</ul>
<p>Submitted event detection systems can be tuned and trained using the publicly released training and development datasets.</p>
<h3>Datasets</h3>
<p>Isolated events:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_training" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_training" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Training</strong> Dataset for Event Detection Task (subtasks OL, OS) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(678MB)</span>
<br/>
</div>
</div>
<p>Event sequences:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_development_OS" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_development_OS" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Development</strong> Dataset for Event Detection Task (subtask OS) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(54MB)</span>
<br/>
</div>
</div>
<p>Event sequences:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2013_event_detection_testset_OS" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2013_event_detection_testset_OS" target="_blank">
<span style="font-size:20px;">IEEE AASP CASA Challenge - <strong>Testing</strong> Dataset for Event Detection Task (subtask OS) <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(83MB)</span>
<br/>
</div>
</div>
<p><br/></p>
<h1 id="submission">Submission</h1>
<p>The challenge participants submit an executable for both subtasks.  </p>
<h2 id="submission-format">Submission format</h2>
<h3>Command line calling format</h3>
<p>Executables must accept command-line parameters which specify:</p>
<ul>
<li>A path to an input .wav file.</li>
<li>A path to an output .txt file.</li>
</ul>
<p>For example:</p>
<div class="highlight"><pre><span></span><code>&gt;./eventdetection /path/to/input.wav /path/to/output.txt
</code></pre></div>
<p>If parameters need to be set for the program, this can be done, provided the manner in which the parameters is set are well documented by the submitter. So if, for example, your program needs a specified frame rate, set by a -fr flag, an example calling format could be of the form:</p>
<div class="highlight"><pre><span></span><code>&gt;./eventdetection -fr 1024 /path/to/input.wav /path/to/output.txt
</code></pre></div>
<p>where the manner by which, as well as the desired parameters to be used are specified upon submission and in the corresponding readme file bundled with the submission of the algorithm. Programs can use their working directory if they need to keep temporary cache files or internal debugging info.</p>
<h3>Output file</h3>
<p>The output ASCII file should contain the onset, offset and the event ID separated by a tab, ordered in terms of onset times (onset/offset times in sec):</p>
<div class="highlight"><pre><span></span><code>&lt;onset1&gt;\t&lt;offset1&gt;\t&lt;EventID1&gt;
&lt;onset2&gt;\t&lt;offset2&gt;\t&lt;EventID2&gt;
...
</code></pre></div>
<p>E.g.</p>
<div class="highlight"><pre><span></span><code><span class="mf">1.387392290</span><span class="w"> </span><span class="mf">3.262403627</span><span class="w"> </span><span class="n">pageturn</span>
<span class="mf">5.073560090</span><span class="w"> </span><span class="mf">5.793378684</span><span class="w"> </span><span class="n">knock</span>
<span class="mf">...</span>
</code></pre></div>
<p>There should be no additional tab characters anywhere, and there should be no whitespace added after the label, just the newline.</p>
<h2 id="packaging-submissions">Packaging submissions</h2>
<p>For Python/R/C/C++/etc submissions, please ensure that the submission can run on the Linux disk image we provide, WITHOUT any additional configuration. You may have modified the virtual machine after downloading it, but we will not be using your modified disk image - we will be running your submission on the standard disk image. This means:</p>
<ul>
<li>if you have used additional Python/R script libraries, they must be included in your submission bundle, and your script should be able to use them without installing them systemwide.</li>
<li>if you have used any additional C/C++ libraries, they must be statically-linked to your executable. </li>
</ul>
<p>For Matlab submissions, ensure that the submission can run with the toolboxes and system that the organisers have specified. If you need any particular toolboxes or configuration please contact the organisers as soon as you can. Please aim to make MATLAB submissions compatible across multiple OS (usual problems exist in the file/path separators). All Matlab submissions should be written in the form of a function, e.g. eventdetection(input,output); which can allow calling the script from the command line very easily. Please provide some console output, which can provide a sanity check to the challenge team when running the code. This can be of the form of simply writing out a line corresponding to different stages of your algorithm All submissions should include a README file including the following the information:</p>
<ul>
<li>Command line calling format for all executables including examples</li>
<li>Number of threads/cores used or whether this should be specified on the command line</li>
<li>Expected memory footprint</li>
<li>Expected runtime</li>
<li>Approximately how much scratch disk space will the submission need to store any feature/cache files?</li>
<li>Any special notice regarding to running your algorithm </li>
</ul>
<p>Note that the information that you place in the README file is extremely important in ensuring that your submission is evaluated properly. </p>
<h2 id="time-and-hardware-limits">Time and Hardware limits</h2>
<p>Due to the potentially high resource requirements across all participants, hard limits on the runtime of submissions will be imposed. A hard limit of 48 hours will be imposed for each submission</p>
<h1 id="evaluation">Evaluation</h1>
<p>Participating algorithms will be evaluated using frame-based, event-based, and class-wise event-based metrics. The computed metrics will consist of the AEER, precision, recall, and F-measure for the frame-based, event-based, and class-wise event-based evaluations. For the event-based evaluations, both onset-based and onset-offset-based metrics will be computed. In addition, computation times of each participating algorithm will be measured.</p>
<p>Frame-based evaluation is using a 10ms step and metrics are averaged over the duration of the recordings. Main metric is the acoustic event error rate (AEER) also used in the CLEAR evaluations:</p>
<div class="math">\begin{equation*}
AEER=\frac{D+I+S} {N}
\end{equation*}</div>
<p>where <span class="math">\(N\)</span> is the number of events to detect for the current frame, <span class="math">\(D\)</span> is the number of deletions (missing events), <span class="math">\(I\)</span> is the number of insertions (extra events), and <span class="math">\(S\)</span> is the number of event substitutions. Substitutions is defined as <span class="math">\(S=\min(D,I)\)</span>.</p>
<p>More detailed description of used metrics see:</p>
<div class="btex-item" data-item="Stowell2015" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Stowell2015"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D.Â <span class="bibtex-protected">Stowell</span>, D.Â <span class="bibtex-protected">Giannoulis</span>, E.Â <span class="bibtex-protected">Benetos</span>, M.Â <span class="bibtex-protected">Lagrange</span>, and M.Â D. <span class="bibtex-protected">Plumbley</span>.
<em>Detection and classification of acoustic scenes and events.</em>
<em>IEEE Transactions on Multimedia</em>, 17(10):1733â€“1746, Oct 2015.
<a href="https://doi.org/10.1109/TMM.2015.2428998">doi:10.1109/TMM.2015.2428998</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexStowell201580b610a9657745219f020cd07b80c56c" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseStowell201580b610a9657745219f020cd07b80c56c" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseStowell201580b610a9657745219f020cd07b80c56c" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingStowell201580b610a9657745219f020cd07b80c56c" class="panel-collapse collapse" id="collapseStowell201580b610a9657745219f020cd07b80c56c" role="tabpanel">
<h4>Detection and Classification of Acoustic Scenes and Events</h4>
<h5>Abstract</h5>
<p class="text-justify">For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexStowell201580b610a9657745219f020cd07b80c56c" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexStowell201580b610a9657745219f020cd07b80c56clabel" class="modal fade" id="bibtexStowell201580b610a9657745219f020cd07b80c56c" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexStowell201580b610a9657745219f020cd07b80c56clabel">Detection and Classification of Acoustic Scenes and Events</h4>
</div>
<div class="modal-body">
<pre>@article{Stowell2015,
    author = "{Stowell}, D. and {Giannoulis}, D. and {Benetos}, E. and {Lagrange}, M. and {Plumbley}, M. D.",
    journal = "IEEE Transactions on Multimedia",
    title = "Detection and Classification of Acoustic Scenes and Events",
    year = "2015",
    volume = "17",
    number = "10",
    pages = "1733-1746",
    abstract = "For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.",
    keywords = "acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition",
    doi = "10.1109/TMM.2015.2428998",
    issn = "1520-9210",
    month = "Oct"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<p>Matlab implementation of metrics:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://code.soundsoftware.ac.uk/projects/aasp-d-case-metrics" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-info"></i>
<i class="fa fa-gears fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://code.soundsoftware.ac.uk/projects/aasp-d-case-metrics" target="_blank">
<span style="font-size:20px;">IEEE AASP D-CASE Challenge Metrics <i class="fa fa-download"></i></span>
</a>
<br/>
<span class="text-muted">
                
                
                (.git)
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="results">Results</h1>
<h2 id="subtask-ol">Subtask OL</h2>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-page-list="[10, 25, 50, All]" data-page-size="10" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="frame_aeer" data-scatter-y="frame_f" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="code" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="4">Submission Information</th>
<th class="sep-left-cell" colspan="2">Frame-based metrics</th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell" data-field="corresponding_author" data-sortable="false">
                Author
            </th>
<th class="sm-cell" data-field="corresponding_affiliation" data-sortable="false">
                Affiliation
            </th>
<th class="sep-left-cell text-center" data-field="external_anchor" data-sortable="false" data-value-type="url">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="frame_aeer" data-reversed="true" data-sortable="true" data-value-type="float4">
                AEER <small class="hidden">/ Frame-based</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="frame_f" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Frame-based</small>
</th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Dimitrios Giannoulis</td>
<td>Centre for Digital Music, Queen Mary University of London, London, UK</td>
<td>task-sound-event-detection-results-ol#Giannoulis2013</td>
<td>2.5900</td>
<td>10.7</td>
</tr>
<tr>
<td></td>
<td>CPS</td>
<td>Sameer Chauhan</td>
<td>Electrical Engineering, Cooper Union for the Advancement of Science and Art, New York, USA</td>
<td>task-sound-event-detection-results-ol#Chauhan2013</td>
<td>2.1160</td>
<td>3.8</td>
</tr>
<tr>
<td></td>
<td>DHV</td>
<td>Aleksandr Diment</td>
<td>Tampere University of Technology, Tampere, Finland</td>
<td>task-sound-event-detection-results-ol#Diment2013</td>
<td>3.1280</td>
<td>26.0</td>
</tr>
<tr>
<td></td>
<td>GVV</td>
<td>Jort F Gemmeke</td>
<td>ESAT-PSI, KU Leuven, Heverlee, Belgium</td>
<td>task-sound-event-detection-results-ol#Gemmeke2013</td>
<td>1.0840</td>
<td>31.9</td>
</tr>
<tr>
<td></td>
<td>NR2</td>
<td>Waldo Nogueira</td>
<td>Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain</td>
<td>task-sound-event-detection-results-ol#Nogueira2013</td>
<td>1.8850</td>
<td>34.7</td>
</tr>
<tr>
<td></td>
<td>NVM_1</td>
<td>Maria E. Niessen</td>
<td>AGT International, Darmstadt, Germany</td>
<td>task-sound-event-detection-results-ol#Niessen2013</td>
<td>1.1150</td>
<td>40.9</td>
</tr>
<tr>
<td></td>
<td>NVM_2</td>
<td>Maria E. Niessen</td>
<td>AGT International, Darmstadt, Germany</td>
<td>task-sound-event-detection-results-ol#Niessen2013</td>
<td>1.1020</td>
<td>42.8</td>
</tr>
<tr>
<td></td>
<td>NVM_3</td>
<td>Maria E. Niessen</td>
<td>AGT International, Darmstadt, Germany</td>
<td>task-sound-event-detection-results-ol#Niessen2013</td>
<td>1.2120</td>
<td>45.5</td>
</tr>
<tr>
<td></td>
<td>NVM_4</td>
<td>Maria E. Niessen</td>
<td>AGT International, Darmstadt, Germany</td>
<td>task-sound-event-detection-results-ol#Niessen2013</td>
<td>1.3600</td>
<td>42.9</td>
</tr>
<tr>
<td></td>
<td>SCS_1</td>
<td>Jens SchrÃ¶der</td>
<td>Project Group Hearing, Speech and Audio Technology, Fraunhofer IDMT, Oldenburg, Germany</td>
<td>task-sound-event-detection-results-ol#Schroeder2013</td>
<td>1.1670</td>
<td>53.0</td>
</tr>
<tr>
<td></td>
<td>SCS_2</td>
<td>Jens SchrÃ¶der</td>
<td>Project Group Hearing, Speech and Audio Technology, Fraunhofer IDMT, Oldenburg, Germany</td>
<td>task-sound-event-detection-results-ol#Schroeder2013</td>
<td>1.0160</td>
<td>61.5</td>
</tr>
<tr>
<td></td>
<td>VVK</td>
<td>Lode Vuegen</td>
<td>ESAT-PSI, KU Leuven, Heverlee, Belgium; Future Health Department, iMinds, Heverlee, Belgium; MOBILAB, TM Kempen, Geel, Belgium</td>
<td>task-sound-event-detection-results-ol#Vuegen2013</td>
<td>1.0010</td>
<td>43.4</td>
</tr>
</tbody>
</table>
<p><br/></p>
<p>Complete results and technical reports can be found at <a class="btn btn-primary" href="/challenge2013/task-sound-event-detection-results-ol">Subtask OL result page</a></p>
<h2 id="subtask-os">Subtask OS</h2>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-page-list="[10, 25, 50, All]" data-page-size="10" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="frame_aeer" data-scatter-y="frame_f" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="code" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="4">Submission Information</th>
<th class="sep-left-cell" colspan="2">Frame-based metrics</th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell" data-field="corresponding_author" data-sortable="false">
                Author
            </th>
<th class="sm-cell" data-field="corresponding_affiliation" data-sortable="false">
                Affiliation
            </th>
<th class="sep-left-cell text-center" data-field="external_anchor" data-sortable="false" data-value-type="url">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="frame_aeer" data-reversed="true" data-sortable="true" data-value-type="float4">
                AEER <small class="hidden">/ Frame-based</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="frame_f" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Frame-based</small>
</th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Dimitrios Giannoulis</td>
<td>Centre for Digital Music, Queen Mary University of London, London, UK</td>
<td>task-sound-event-detection-results-os#Giannoulis2013</td>
<td>2.8040</td>
<td>12.8</td>
</tr>
<tr>
<td></td>
<td>DHV</td>
<td>Aleksandr Diment</td>
<td>Tampere University of Technology, Tampere, Finland</td>
<td>task-sound-event-detection-results-os#Diment2013</td>
<td>7.9800</td>
<td>18.7</td>
</tr>
<tr>
<td></td>
<td>GVV</td>
<td>Jort F Gemmeke</td>
<td>ESAT-PSI, KU Leuven, Heverlee, Belgium</td>
<td>task-sound-event-detection-results-os#Gemmeke2013</td>
<td>1.3180</td>
<td>21.3</td>
</tr>
<tr>
<td></td>
<td>VVK</td>
<td>Lode Vuegen</td>
<td>ESAT-PSI, KU Leuven, Heverlee, Belgium; Future Health Department, iMinds, Heverlee, Belgium; MOBILAB, TM Kempen, Geel, Belgium</td>
<td>task-sound-event-detection-results-os#Vuegen2013</td>
<td>1.8880</td>
<td>13.5</td>
</tr>
</tbody>
</table>
<p><br/></p>
<p>Complete results and technical reports can be found at <a class="btn btn-primary" href="/challenge2013/task-sound-event-detection-results-os">Subtask OS result page</a></p>
<h1 id="baseline-system">Baseline system</h1>
<p>Audio Event Detection baseline system using NMF (MATLAB).</p>
<p>This is an event detection system that you can train on a set of labelled audio files with isolated sound events of various sounds, and then it is able to detect and classify audio activity related to these events from an audio files containing a series of different events and background noise. It is designed with two main aims:</p>
<ol>
<li>to provide a baseline against which to test more advanced systems;</li>
<li>to provide a simple code example of a system which people are free to build on.</li>
</ol>
<p>It follows a training/testing framework. A dictionary of spectral basis vectors is learned using NMF on the training data. This dictionary is subsequently set fixed and used to obtain an activation matrix of unlabelled audio files from the development set using NMF decomposition. The activation vectors per class are summed together and thresholded to give the activity for different classes.</p>
<p><strong>In publications using the baseline, cite as:</strong></p>
<div class="btex-item" data-item="Giannoulis2013" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Giannoulis2013"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D.Â <span class="bibtex-protected">Giannoulis</span>, D.Â <span class="bibtex-protected">Stowell</span>, E.Â <span class="bibtex-protected">Benetos</span>, M.Â <span class="bibtex-protected">Rossignol</span>, M.Â <span class="bibtex-protected">Lagrange</span>, and M.Â D. <span class="bibtex-protected">Plumbley</span>.
<em>A database and challenge for acoustic scene classification and event detection.</em>
In 21st European Signal Processing Conference (EUSIPCO 2013), volume, 1â€“5. Sep. 2013.
<a href="https://doi.org/">doi:</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexGiannoulis20138ead14aa54614e79b893a70662fca71c" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseGiannoulis20138ead14aa54614e79b893a70662fca71c" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseGiannoulis20138ead14aa54614e79b893a70662fca71c" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingGiannoulis20138ead14aa54614e79b893a70662fca71c" class="panel-collapse collapse" id="collapseGiannoulis20138ead14aa54614e79b893a70662fca71c" role="tabpanel">
<h4>A database and challenge for acoustic scene classification and event detection</h4>
<h5>Abstract</h5>
<p class="text-justify">An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexGiannoulis20138ead14aa54614e79b893a70662fca71c" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexGiannoulis20138ead14aa54614e79b893a70662fca71clabel" class="modal fade" id="bibtexGiannoulis20138ead14aa54614e79b893a70662fca71c" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexGiannoulis20138ead14aa54614e79b893a70662fca71clabel">A database and challenge for acoustic scene classification and event detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Giannoulis2013,
    author = "{Giannoulis}, D. and {Stowell}, D. and {Benetos}, E. and {Rossignol}, M. and {Lagrange}, M. and {Plumbley}, M. D.",
    booktitle = "21st European Signal Processing Conference (EUSIPCO 2013)",
    title = "A database and challenge for acoustic scene classification and event detection",
    year = "2013",
    volume = "",
    number = "",
    pages = "1-5",
    abstract = "An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.",
    keywords = "acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection",
    doi = "",
    issn = "2076-1465",
    month = "Sep."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<h2 id="matlab-implementation">Matlab implementation</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://code.soundsoftware.ac.uk/projects/d-case-event" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-info"></i>
<i class="fa fa-gears fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://code.soundsoftware.ac.uk/projects/d-case-event" target="_blank">
<span style="font-size:20px;">DCASE2013 Task2 Baseline, repository <i class="fa fa-download"></i></span>
</a>
<br/>
<span class="text-muted">
                
                
                (.git)
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="citation">Citation</h1>
<p>If you are using the <strong>dataset</strong> or <strong>baseline</strong> code please cite the following paper:</p>
<div class="btex-item" data-item="Giannoulis2013" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Giannoulis2013"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D.Â <span class="bibtex-protected">Giannoulis</span>, D.Â <span class="bibtex-protected">Stowell</span>, E.Â <span class="bibtex-protected">Benetos</span>, M.Â <span class="bibtex-protected">Rossignol</span>, M.Â <span class="bibtex-protected">Lagrange</span>, and M.Â D. <span class="bibtex-protected">Plumbley</span>.
<em>A database and challenge for acoustic scene classification and event detection.</em>
In 21st European Signal Processing Conference (EUSIPCO 2013), volume, 1â€“5. Sep. 2013.
<a href="https://doi.org/">doi:</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" class="panel-collapse collapse" id="collapseGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" role="tabpanel">
<h4>A database and challenge for acoustic scene classification and event detection</h4>
<h5>Abstract</h5>
<p class="text-justify">An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01123764/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29label" class="modal fade" id="bibtexGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexGiannoulis2013b5a612ba4ede46e7a84f9835a9817a29label">A database and challenge for acoustic scene classification and event detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Giannoulis2013,
    author = "{Giannoulis}, D. and {Stowell}, D. and {Benetos}, E. and {Rossignol}, M. and {Lagrange}, M. and {Plumbley}, M. D.",
    booktitle = "21st European Signal Processing Conference (EUSIPCO 2013)",
    title = "A database and challenge for acoustic scene classification and event detection",
    year = "2013",
    volume = "",
    number = "",
    pages = "1-5",
    abstract = "An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code.",
    keywords = "acoustic signal processing;feature extraction;Gaussian processes;mixture models;signal classification;computational auditory scene analysis;CASA;public evaluation challenge;acoustic scene classification;event detection;dataset creation;evaluation metrics;baseline methods;open-source code;Event detection;Measurement;Music;Speech;Educational institutions;Hidden Markov models;Computational auditory scene analysis;acoustic scene classification;acoustic event detection",
    doi = "",
    issn = "2076-1465",
    month = "Sep."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<p>When citing <strong>challenge task</strong> and <strong>results</strong> please cite the following paper:</p>
<div class="btex-item" data-item="Stowell2015" data-source="content/data/challenge2013/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Stowell2015"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D.Â <span class="bibtex-protected">Stowell</span>, D.Â <span class="bibtex-protected">Giannoulis</span>, E.Â <span class="bibtex-protected">Benetos</span>, M.Â <span class="bibtex-protected">Lagrange</span>, and M.Â D. <span class="bibtex-protected">Plumbley</span>.
<em>Detection and classification of acoustic scenes and events.</em>
<em>IEEE Transactions on Multimedia</em>, 17(10):1733â€“1746, Oct 2015.
<a href="https://doi.org/10.1109/TMM.2015.2428998">doi:10.1109/TMM.2015.2428998</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexStowell2015faf00c3f53f94064bd4f87dede5c6330" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseStowell2015faf00c3f53f94064bd4f87dede5c6330" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseStowell2015faf00c3f53f94064bd4f87dede5c6330" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingStowell2015faf00c3f53f94064bd4f87dede5c6330" class="panel-collapse collapse" id="collapseStowell2015faf00c3f53f94064bd4f87dede5c6330" role="tabpanel">
<h4>Detection and Classification of Acoustic Scenes and Events</h4>
<h5>Abstract</h5>
<p class="text-justify">For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexStowell2015faf00c3f53f94064bd4f87dede5c6330" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://hal.archives-ouvertes.fr/hal-01253912/document" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexStowell2015faf00c3f53f94064bd4f87dede5c6330label" class="modal fade" id="bibtexStowell2015faf00c3f53f94064bd4f87dede5c6330" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexStowell2015faf00c3f53f94064bd4f87dede5c6330label">Detection and Classification of Acoustic Scenes and Events</h4>
</div>
<div class="modal-body">
<pre>@article{Stowell2015,
    author = "{Stowell}, D. and {Giannoulis}, D. and {Benetos}, E. and {Lagrange}, M. and {Plumbley}, M. D.",
    journal = "IEEE Transactions on Multimedia",
    title = "Detection and Classification of Acoustic Scenes and Events",
    year = "2015",
    volume = "17",
    number = "10",
    pages = "1733-1746",
    abstract = "For intelligent systems to make best use of the audio modality, it is important that they can recognize not just speech and music, which have been researched as specific tasks, but also general sounds in everyday environments. To stimulate research in this field we conducted a public research challenge: the IEEE Audio and Acoustic Signal Processing Technical Committee challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). In this paper, we report on the state of the art in automatically classifying audio scenes, and automatically detecting and classifying audio events. We survey prior work as well as the state of the art represented by the submissions to the challenge from various research groups. We also provide detail on the organization of the challenge, so that our experience as challenge hosts may be useful to those organizing challenges in similar domains. We created new audio datasets and baseline systems for the challenge; these, as well as some submitted systems, are publicly available under open licenses, to serve as benchmarks for further research in general-purpose machine listening.",
    keywords = "acoustic signal processing;knowledge based systems;speech recognition;acoustic scenes detection;acoustic scenes classification;intelligent systems;audio modality;speech recognition;music;IEEE Audio and Acoustic Signal Processing Technical Committee;DCASE;Event detection;Speech;Speech recognition;Music;Microphones;Licenses;Audio databases;event detection;machine intelligence;pattern recognition",
    doi = "10.1109/TMM.2015.2428998",
    issn = "1520-9210",
    month = "Oct"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>