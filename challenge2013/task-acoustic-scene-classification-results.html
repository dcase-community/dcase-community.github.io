<!DOCTYPE html><html lang="en">
<head>
    <title>Acoustic scene classification - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2013/task-acoustic-scene-classification-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Official results are shown in original DCASE2013 Challenge website. Purpose of this page is to show results in an uniform way compared to more recent editions of the DCASE Challenge. Task description The scene classification (SC) challenge will address the problem of identifying and classifying acoustic scenes and soundscapes. More â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2013</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2013/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group  active">
        <a href="/challenge2013/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2013/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2013/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2013/task-sound-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2013/task-sound-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-ol"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OL</a>
    </li>
            <li class="">
        <a href="/challenge2013/task-sound-event-detection-results-os"><i class="fa fa-bar-chart"></i>&nbsp;Subtask OS</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2013/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2013/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2013/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/grid-08.jpg);box-shadow: 0px 1000px rgba(0, 0, 0, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-primary"></i><i class="fa dc-scene fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Scenes</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 1</span></span><img src="../images/logos/dcase/dcase2013_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Acoustic<br> scene classification</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a></li>
<li><a href="#system-characteristics">System characteristics</a></li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="alert alert-info">
   Official results are shown in original <a href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/" target="_blank">DCASE2013 Challenge website</a>. Purpose of this page is to show results in an uniform way compared to more recent editions of the DCASE Challenge.
</p>
<h1 id="task-description">Task description</h1>
<p>The scene classification (SC) challenge will address the problem of identifying and classifying acoustic scenes and soundscapes.</p>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2013/task-acoustic-scene-classification" style="">task description page</a></p>
<h1 id="systems-ranking">Systems ranking</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission <br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission <br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Baseline</td>
<td></td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>CHR_1</td>
<td>CHR_SVM</td>
<td>Chum2013</td>
<td>63.0 (53.5 - 72.5)</td>
</tr>
<tr>
<td></td>
<td>CHR_2</td>
<td>CHR_HMM</td>
<td>Chum2013</td>
<td>65.0 (55.7 - 74.3)</td>
</tr>
<tr>
<td></td>
<td>ELF</td>
<td>ELF</td>
<td>Elizalde2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>GSR</td>
<td>GSR</td>
<td>Geiger2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>KH</td>
<td>KH</td>
<td>Krijnders2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>LTT_1</td>
<td>LTT_1</td>
<td>Li2013</td>
<td>72.0 (63.2 - 80.8)</td>
</tr>
<tr>
<td></td>
<td>LTT_2</td>
<td>LTT_2</td>
<td>Li2013</td>
<td>70.0 (61.0 - 79.0)</td>
</tr>
<tr>
<td></td>
<td>LTT_3</td>
<td>LTT_2</td>
<td>Li2013</td>
<td>67.0 (57.8 - 76.2)</td>
</tr>
<tr>
<td></td>
<td>NHL</td>
<td>NHL</td>
<td>Nam2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_1</td>
<td>NR1_1</td>
<td>Nogueira2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_2</td>
<td>NR1_2</td>
<td>Nogueira2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_3</td>
<td>NR1_3</td>
<td>Nogueira2013</td>
<td>59.0 (49.4 - 68.6)</td>
</tr>
<tr>
<td></td>
<td>OE</td>
<td>OE</td>
<td>Olivetti2013</td>
<td>14.0 (7.2 - 20.8)</td>
</tr>
<tr>
<td></td>
<td>PE</td>
<td>PE</td>
<td>Patil2013</td>
<td>58.0 (48.3 - 67.7)</td>
</tr>
<tr>
<td></td>
<td>RG</td>
<td>RG</td>
<td>Rakotomamonjy2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>RNH_1</td>
<td>RNH1</td>
<td>Roma2013</td>
<td>71.0 (62.1 - 79.9)</td>
</tr>
<tr>
<td></td>
<td>RNH_2</td>
<td>RNH2</td>
<td>Roma2013</td>
<td>76.0 (67.6 - 84.4)</td>
</tr>
</tbody>
</table>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission <br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission <br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Baseline</td>
<td></td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>CHR_2</td>
<td>CHR_HMM</td>
<td>Chum2013</td>
<td>65.0 (55.7 - 74.3)</td>
</tr>
<tr>
<td></td>
<td>ELF</td>
<td>ELF</td>
<td>Elizalde2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>GSR</td>
<td>GSR</td>
<td>Geiger2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>KH</td>
<td>KH</td>
<td>Krijnders2013</td>
<td>55.0 (45.2 - 64.8)</td>
</tr>
<tr>
<td></td>
<td>LTT_1</td>
<td>LTT_1</td>
<td>Li2013</td>
<td>72.0 (63.2 - 80.8)</td>
</tr>
<tr>
<td></td>
<td>NHL</td>
<td>NHL</td>
<td>Nam2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>NR1_1</td>
<td>NR1_1</td>
<td>Nogueira2013</td>
<td>60.0 (50.4 - 69.6)</td>
</tr>
<tr>
<td></td>
<td>OE</td>
<td>OE</td>
<td>Olivetti2013</td>
<td>14.0 (7.2 - 20.8)</td>
</tr>
<tr>
<td></td>
<td>PE</td>
<td>PE</td>
<td>Patil2013</td>
<td>58.0 (48.3 - 67.7)</td>
</tr>
<tr>
<td></td>
<td>RG</td>
<td>RG</td>
<td>Rakotomamonjy2013</td>
<td>69.0 (59.9 - 78.1)</td>
</tr>
<tr>
<td></td>
<td>RNH_2</td>
<td>RNH2</td>
<td>Roma2013</td>
<td>76.0 (67.6 - 84.4)</td>
</tr>
</tbody>
</table>
<h1 id="class-wise-performance">Class-wise performance</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2013 baseline" data-comparison-active-set="Class-wise performance (all)" data-comparison-b-row="RNH_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (all)",
        "data_axis_title": "Accuracy",
        "fields": ["class_accuracy_eval_bus", "class_accuracy_eval_busystreet", "class_accuracy_eval_office", "class_accuracy_eval_openairmarket", "class_accuracy_eval_park", "class_accuracy_eval_quietstreet", "class_accuracy_eval_restaurant", "class_accuracy_eval_supermarket", "class_accuracy_eval_tube", "class_accuracy_eval_tubestation"]
        },
        {"title": "Class-wise performance (indoor)","data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_office", "class_accuracy_eval_restaurant", "class_accuracy_eval_supermarket", "class_accuracy_eval_tubestation"]
        },
        {"title": "Class-wise performance (outdoor)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_busystreet", "class_accuracy_eval_openairmarket", "class_accuracy_eval_park", "class_accuracy_eval_quietstreet"]
        },
        {"title": "Class-wise performance (transport)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_bus","class_accuracy_eval_tube"]
        }]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="accuracy_eval" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission<br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission<br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Evaluation dataset)
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_bus" data-sortable="true" data-value-type="float1-percentage">
                Bus
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="class_accuracy_eval_busystreet" data-sortable="true" data-value-type="float1-percentage">
                Busy <br/>street
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_office" data-sortable="true" data-value-type="float1-percentage">
                Office
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_openairmarket" data-sortable="true" data-value-type="float1-percentage">
                Open air<br/>Market
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_park" data-sortable="true" data-value-type="float1-percentage">
                Park
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_quietstreet" data-sortable="true" data-value-type="float1-percentage">
                Quiet <br/>street
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_restaurant" data-sortable="true" data-value-type="float1-percentage">
                Restaurant
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_supermarket" data-sortable="true" data-value-type="float1-percentage">
                Supermarket
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_tube" data-sortable="true" data-value-type="float1-percentage">
                Tube
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_tubestation" data-sortable="true" data-value-type="float1-percentage">
                Tube <br/>station
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td>Baseline</td>
<td></td>
<td>55.0</td>
<td>90.0</td>
<td>30.0</td>
<td>80.0</td>
<td>70.0</td>
<td>90.0</td>
<td>40.0</td>
<td>30.0</td>
<td>20.0</td>
<td>60.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>CHR_1</td>
<td>CHR_SVM</td>
<td>Chum2013</td>
<td>63.0</td>
<td>100.0</td>
<td>80.0</td>
<td>40.0</td>
<td>70.0</td>
<td>30.0</td>
<td>40.0</td>
<td>70.0</td>
<td>50.0</td>
<td>80.0</td>
<td>70.0</td>
</tr>
<tr>
<td></td>
<td>CHR_2</td>
<td>CHR_HMM</td>
<td>Chum2013</td>
<td>65.0</td>
<td>90.0</td>
<td>90.0</td>
<td>80.0</td>
<td>60.0</td>
<td>90.0</td>
<td>50.0</td>
<td>40.0</td>
<td>30.0</td>
<td>80.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>ELF</td>
<td>ELF</td>
<td>Elizalde2013</td>
<td>55.0</td>
<td>50.0</td>
<td>70.0</td>
<td>60.0</td>
<td>100.0</td>
<td>40.0</td>
<td>50.0</td>
<td>70.0</td>
<td>30.0</td>
<td>30.0</td>
<td>50.0</td>
</tr>
<tr>
<td></td>
<td>GSR</td>
<td>GSR</td>
<td>Geiger2013</td>
<td>69.0</td>
<td>90.0</td>
<td>90.0</td>
<td>90.0</td>
<td>90.0</td>
<td>70.0</td>
<td>40.0</td>
<td>80.0</td>
<td>50.0</td>
<td>70.0</td>
<td>20.0</td>
</tr>
<tr>
<td></td>
<td>KH</td>
<td>KH</td>
<td>Krijnders2013</td>
<td>55.0</td>
<td>60.0</td>
<td>90.0</td>
<td>70.0</td>
<td>50.0</td>
<td>30.0</td>
<td>50.0</td>
<td>50.0</td>
<td>20.0</td>
<td>80.0</td>
<td>50.0</td>
</tr>
<tr>
<td></td>
<td>LTT_1</td>
<td>LTT_1</td>
<td>Li2013</td>
<td>72.0</td>
<td>100.0</td>
<td>100.0</td>
<td>70.0</td>
<td>80.0</td>
<td>70.0</td>
<td>50.0</td>
<td>70.0</td>
<td>70.0</td>
<td>70.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>LTT_2</td>
<td>LTT_2</td>
<td>Li2013</td>
<td>70.0</td>
<td>100.0</td>
<td>100.0</td>
<td>70.0</td>
<td>80.0</td>
<td>70.0</td>
<td>60.0</td>
<td>70.0</td>
<td>40.0</td>
<td>70.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>LTT_3</td>
<td>LTT_2</td>
<td>Li2013</td>
<td>67.0</td>
<td>100.0</td>
<td>100.0</td>
<td>70.0</td>
<td>80.0</td>
<td>70.0</td>
<td>50.0</td>
<td>60.0</td>
<td>30.0</td>
<td>70.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>NHL</td>
<td>NHL</td>
<td>Nam2013</td>
<td>60.0</td>
<td>70.0</td>
<td>90.0</td>
<td>80.0</td>
<td>70.0</td>
<td>50.0</td>
<td>60.0</td>
<td>50.0</td>
<td>40.0</td>
<td>30.0</td>
<td>60.0</td>
</tr>
<tr>
<td></td>
<td>NR1_1</td>
<td>NR1_1</td>
<td>Nogueira2013</td>
<td>60.0</td>
<td>80.0</td>
<td>80.0</td>
<td>60.0</td>
<td>70.0</td>
<td>70.0</td>
<td>30.0</td>
<td>60.0</td>
<td>80.0</td>
<td>20.0</td>
<td>50.0</td>
</tr>
<tr>
<td></td>
<td>NR1_2</td>
<td>NR1_2</td>
<td>Nogueira2013</td>
<td>60.0</td>
<td>80.0</td>
<td>90.0</td>
<td>50.0</td>
<td>80.0</td>
<td>70.0</td>
<td>20.0</td>
<td>90.0</td>
<td>60.0</td>
<td>20.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>NR1_3</td>
<td>NR1_3</td>
<td>Nogueira2013</td>
<td>59.0</td>
<td>80.0</td>
<td>80.0</td>
<td>50.0</td>
<td>70.0</td>
<td>70.0</td>
<td>20.0</td>
<td>90.0</td>
<td>70.0</td>
<td>20.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>OE</td>
<td>OE</td>
<td>Olivetti2013</td>
<td>14.0</td>
<td>0.0</td>
<td>10.0</td>
<td>20.0</td>
<td>20.0</td>
<td>10.0</td>
<td>30.0</td>
<td>0.0</td>
<td>20.0</td>
<td>20.0</td>
<td>10.0</td>
</tr>
<tr>
<td></td>
<td>PE</td>
<td>PE</td>
<td>Patil2013</td>
<td>58.0</td>
<td>90.0</td>
<td>90.0</td>
<td>50.0</td>
<td>70.0</td>
<td>40.0</td>
<td>60.0</td>
<td>60.0</td>
<td>20.0</td>
<td>40.0</td>
<td>60.0</td>
</tr>
<tr>
<td></td>
<td>RG</td>
<td>RG</td>
<td>Rakotomamonjy2013</td>
<td>69.0</td>
<td>100.0</td>
<td>100.0</td>
<td>80.0</td>
<td>80.0</td>
<td>80.0</td>
<td>30.0</td>
<td>50.0</td>
<td>50.0</td>
<td>80.0</td>
<td>40.0</td>
</tr>
<tr>
<td></td>
<td>RNH_1</td>
<td>RNH1</td>
<td>Roma2013</td>
<td>71.0</td>
<td>80.0</td>
<td>100.0</td>
<td>60.0</td>
<td>40.0</td>
<td>70.0</td>
<td>60.0</td>
<td>100.0</td>
<td>70.0</td>
<td>70.0</td>
<td>60.0</td>
</tr>
<tr>
<td></td>
<td>RNH_2</td>
<td>RNH2</td>
<td>Roma2013</td>
<td>76.0</td>
<td>80.0</td>
<td>100.0</td>
<td>80.0</td>
<td>70.0</td>
<td>70.0</td>
<td>50.0</td>
<td>100.0</td>
<td>80.0</td>
<td>70.0</td>
<td>60.0</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Input
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Sampling <br/>rate
            </th>
<th class="text-center narrow-col" data-field="system_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Features
            </th>
<th class="text-center narrow-col" data-field="system_classifier" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Classifier
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2013 baseline</td>
<td></td>
<td>55.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC</td>
<td>GMM</td>
</tr>
<tr>
<td></td>
<td>CHR_1</td>
<td>Chum2013</td>
<td>63.0</td>
<td>mono</td>
<td>11.025kHz</td>
<td>Magnitude response, Loudness, Spectral sparsity, Temporal sparsity</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>CHR_2</td>
<td>Chum2013</td>
<td>65.0</td>
<td>mono</td>
<td>11.025kHz</td>
<td>Magnitude response, Loudness, Spectral sparsity, Temporal sparsity</td>
<td>HMM</td>
</tr>
<tr>
<td></td>
<td>ELF</td>
<td>Elizalde2013</td>
<td>55.0</td>
<td>left, right, difference, average</td>
<td>44.1kHz</td>
<td>MFCC</td>
<td>i-vector, pLDA</td>
</tr>
<tr>
<td></td>
<td>GSR</td>
<td>Geiger2013</td>
<td>69.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>openSMILE / emo_large</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>KH</td>
<td>Krijnders2013</td>
<td>55.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>tone-fit representation</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>LTT_1</td>
<td>Li2013</td>
<td>72.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Wavelet, MFCC</td>
<td>Treebagger, majority vote</td>
</tr>
<tr>
<td></td>
<td>LTT_2</td>
<td>Li2013</td>
<td>70.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Wavelet, MFCC</td>
<td>Treebagger, majority vote</td>
</tr>
<tr>
<td></td>
<td>LTT_3</td>
<td>Li2013</td>
<td>67.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Wavelet, MFCC</td>
<td>Treebagger, majority vote</td>
</tr>
<tr>
<td></td>
<td>NHL</td>
<td>Nam2013</td>
<td>60.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Feature learning, max-pooling</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>NR1_1</td>
<td>Nogueira2013</td>
<td>60.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC, temporal modulation, event density, binaural features</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>NR1_2</td>
<td>Nogueira2013</td>
<td>60.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC, temporal modulation, event density, binaural features</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>NR1_3</td>
<td>Nogueira2013</td>
<td>59.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC, temporal modulation, event density, binaural features</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>OE</td>
<td>Olivetti2013</td>
<td>14.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Normalized compression distance, Euclidean embedding</td>
<td>Random Forest</td>
</tr>
<tr>
<td></td>
<td>PE</td>
<td>Patil2013</td>
<td>58.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Spectrotemporal modulation</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>RG</td>
<td>Rakotomamonjy2013</td>
<td>69.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>CQT, HOG</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>RNH_1</td>
<td>Roma2013</td>
<td>71.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC, Recurrence Quantification Analysis</td>
<td>SVM</td>
</tr>
<tr>
<td></td>
<td>RNH_2</td>
<td>Roma2013</td>
<td>76.0</td>
<td>mono</td>
<td>44.1kHz</td>
<td>MFCC, Recurrence Quantification Analysis</td>
<td>SVM</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2013/technical_reports_task1.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Chum2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Chum2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        IEEE AASP Scene Classification Challenge Using Hidden Markov Models and Frame Based Classification
       </h4>
<p style="text-align:left">
        May Chum, Ariel Habshush, Abrar Rahman and Christopher Sang
       </p>
<p style="text-align:left">
<em>
         Electrical Engineering Department, The Cooper Union, New York, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">CHR_1</span> <span class="label label-primary">CHR_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Chum2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Chum2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Chum2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/CHR.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Chum2013').collapse('show');window.location.hash='#Chum2013';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Chum2013" class="panel-collapse collapse" id="collapse-Chum2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       IEEE AASP Scene Classification Challenge Using Hidden Markov Models and Frame Based Classification
      </h4>
<p style="text-align:left">
<small>
        May Chum, Ariel Habshush, Abrar Rahman and Christopher Sang
       </small>
<br/>
<small>
<em>
         Electrical Engineering Department, The Cooper Union, New York, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The IEEE AASP Challenge involves the detection and classification of acoustic scenes and events. The scene classification (SC) challenge consists of 10 different scenes of 10 audio files or length 30 seconds each, totaling a number of 100 audio clips. The list of scenes is: busy street, quiet street, park, open-air market, bus, subway-train, restaurant, shop/supermarket, office, and subway station. The goal is to test on a development set that is composed of audio clips of the same scenes as the training set and determine what scene the audio clips originated from. One of the algorithms presented in this paper to discriminate between these different scenes include the use of hidden Markov models (HMMs) and Gaussian mixture models (GMMs). The features that were used include the following: short time Fourier transform, loudness, and spectral sparsity. Using these features yielded 72% correct classification with 10 fold crossvalidation. The other algorithm implemented uses the same features as before plus temporal sparsity to classify individual frames of an audio clip, then vote on the class. This algorithm achieved 62% accuracy.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         11.025kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Magnitude response, Loudness, Spectral sparsity, Temporal sparsity
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM; HMM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Chum2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/CHR.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://code.soundsoftware.ac.uk/projects/dcase2013_sc_chrs" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Chum2013label" class="modal fade" id="bibtex-Chum2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChum2013label">
        IEEE AASP Scene Classification Challenge Using Hidden Markov Models and Frame Based Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Chum2013,
    Author = "Chum, May and Habshush, Ariel and Rahman, Abrar and Sang, Christopher",
    title = "{IEEE} {AASP} Scene Classification Challenge Using Hidden Markov Models and Frame Based Classification",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "The IEEE AASP Challenge involves the detection and classification of acoustic scenes and events. The scene classification (SC) challenge consists of 10 different scenes of 10 audio files or length 30 seconds each, totaling a number of 100 audio clips. The list of scenes is: busy street, quiet street, park, open-air market, bus, subway-train, restaurant, shop/supermarket, office, and subway station. The goal is to test on a development set that is composed of audio clips of the same scenes as the training set and determine what scene the audio clips originated from. One of the algorithms presented in this paper to discriminate between these different scenes include the use of hidden Markov models (HMMs) and Gaussian mixture models (GMMs). The features that were used include the following: short time Fourier transform, loudness, and spectral sparsity. Using these features yielded 72\% correct classification with 10 fold crossvalidation. The other algorithm implemented uses the same features as before plus temporal sparsity to classify individual frames of an audio clip, then vote on the class. This algorithm achieved 62\% accuracy."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Elizalde2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Elizalde2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        An I-Vector Based Approach for Audio Scene Detection
       </h4>
<p style="text-align:left">
        Benjamin Elizalde<sup>1</sup>, Howard Lei<sup>1</sup>, Gerald Friedland<sup>1</sup> and Nils Peters<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>International Computer Science Institute, Berkeley, USA, <sup>2</sup>Qualcomm Technologies Inc., San Diego, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">ELF</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Elizalde2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Elizalde2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Elizalde2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/ELF.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Elizalde2013" class="panel-collapse collapse" id="collapse-Elizalde2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       An I-Vector Based Approach for Audio Scene Detection
      </h4>
<p style="text-align:left">
<small>
        Benjamin Elizalde<sup>1</sup>, Howard Lei<sup>1</sup>, Gerald Friedland<sup>1</sup> and Nils Peters<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>International Computer Science Institute, Berkeley, USA, <sup>2</sup>Qualcomm Technologies Inc., San Diego, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The IEEE-ASSP Scene Classification challenge on user-generated content (UGC) aims to classify an audio recording that belongs to a specific scene such as busystreet, office or supermarket. The difficulty of scene content analysis on UGC lies in the lack of structure and acoustic variability of the data. The i-vector system is state-ofthe-art in Speaker Verification and Scene Detection, and is outperforming conventional Gaussian Mixture Model (GMM)-based approaches. The system compensates for undesired acoustic variability and extracts information from the acoustic environment, making it a meaningful choice for detection on UGC. This paper reports our results in the challenge by using a hand-tuned i-vector system and MFCC features. Compared to the MFCC+GMM baseline system, our system increased the classification accuracy by 26.4% to about 65.8%. We discuss our approach and highlight parameters in our system that showed to significantly improved our classification accuracy
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left, right, difference, average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         i-vector, pLDA
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Elizalde2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/ELF.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Elizalde2013label" class="modal fade" id="bibtex-Elizalde2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexElizalde2013label">
        An I-Vector Based Approach for Audio Scene Detection
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Elizalde2013,
    Author = "Elizalde, Benjamin and Lei, Howard and Friedland, Gerald and Peters, Nils",
    title = "An {I}-Vector Based Approach for Audio Scene Detection",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "The IEEE-ASSP Scene Classification challenge on user-generated content (UGC) aims to classify an audio recording that belongs to a specific scene such as busystreet, office or supermarket. The difficulty of scene content analysis on UGC lies in the lack of structure and acoustic variability of the data. The i-vector system is state-ofthe-art in Speaker Verification and Scene Detection, and is outperforming conventional Gaussian Mixture Model (GMM)-based approaches. The system compensates for undesired acoustic variability and extracts information from the acoustic environment, making it a meaningful choice for detection on UGC. This paper reports our results in the challenge by using a hand-tuned i-vector system and MFCC features. Compared to the MFCC+GMM baseline system, our system increased the classification accuracy by 26.4\% to about 65.8\%. We discuss our approach and highlight parameters in our system that showed to significantly improved our classification accuracy"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Geiger2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Geiger2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Recognising Acoustic Scenes with Large-Scale Audio Feature Extraction and SVM
       </h4>
<p style="text-align:left">
        JÃ¼rgen T. Geiger<sup>1</sup>, BjÃ¶rn Schuller<sup>1,2</sup> and Gerhard Rigoll<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute for Human-Machine Communication, Technische UniversitÃ¤t MÃ¼nchen, MÃ¼nchen, Germany, <sup>2</sup>University of Passau, Institute for Sensor Systems, Passau, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">GSR</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Geiger2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Geiger2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Geiger2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/GSR.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Geiger2013" class="panel-collapse collapse" id="collapse-Geiger2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Recognising Acoustic Scenes with Large-Scale Audio Feature Extraction and SVM
      </h4>
<p style="text-align:left">
<small>
        JÃ¼rgen T. Geiger<sup>1</sup>, BjÃ¶rn Schuller<sup>1,2</sup> and Gerhard Rigoll<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Institute for Human-Machine Communication, Technische UniversitÃ¤t MÃ¼nchen, MÃ¼nchen, Germany, <sup>2</sup>University of Passau, Institute for Sensor Systems, Passau, Germany
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This work describes our contribution to the IEEE AASP Challenge on classification of acoustic scenes. From the 30 second long highly variable recordings, spectral, cepstral, energy and voicing-related audio features are extracted. A sliding window approach is used to obtain statistical functionals of the low-level features on short segments. SVM are used for classification of these short segments, and a majority voting scheme is employed to get a decision for the whole recording. On the official development set of the challenge, an accuracy of 73% is achieved. A feature analysis using the t-statistic showed that mainly Mel spectra were the most relevant features.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         openSMILE / emo_large
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Geiger2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/GSR.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Geiger2013label" class="modal fade" id="bibtex-Geiger2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGeiger2013label">
        Recognising Acoustic Scenes with Large-Scale Audio Feature Extraction and SVM
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Geiger2013,
    Author = "Geiger, JÃ¼rgen T. and Schuller, BjÃ¶rn and Rigoll, Gerhard",
    title = "Recognising Acoustic Scenes with Large-Scale Audio Feature Extraction and {SVM}",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "This work describes our contribution to the IEEE AASP Challenge on classification of acoustic scenes. From the 30 second long highly variable recordings, spectral, cepstral, energy and voicing-related audio features are extracted. A sliding window approach is used to obtain statistical functionals of the low-level features on short segments. SVM are used for classification of these short segments, and a majority voting scheme is employed to get a decision for the whole recording. On the official development set of the challenge, an accuracy of 73\% is achieved. A feature analysis using the t-statistic showed that mainly Mel spectra were the most relevant features."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Krijnders2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Krijnders2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        A Tone-Fit Feature Representation for Scene Classification
       </h4>
<p style="text-align:left">
        Johannes D. Krijnders and Gineke A. ten Holt
       </p>
<p style="text-align:left">
<em>
         INCAS3, Assen, Netherlands
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">KH</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Krijnders2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Krijnders2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Krijnders2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/KH.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Krijnders2013" class="panel-collapse collapse" id="collapse-Krijnders2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       A Tone-Fit Feature Representation for Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Johannes D. Krijnders and Gineke A. ten Holt
       </small>
<br/>
<small>
<em>
         INCAS3, Assen, Netherlands
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We present an algorithm that classifies environmental sound recordings using a feature representation based on the human hearing. Specifically, we use a mathematical model of the human cochlea to transform a sound (wav) clip into a time-frequency representation called a cochleogram. From the cochleogram, we calculate the tone-fit of each time-frequency region by calculating the fit of the region to a pure tone. This gives us a representation of the â€™tonelikenessâ€™ of the sound at various moments and frequencies. Finally, to arrive at a summarized representation for the entire clip, we calculate 20 statistic components over the tone-fit matrix. The resulting 20-dimensional feature representation is then classified using a support vector machine. The accuracy of the resulting method is 0.53 (SE = 0.06). Similar results are obtained by using MFCC features and voting by frame (0.60, SE = 0.04). Future directions include separately identifying sound events and representing scenes in terms of component events.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         tone-fit representation
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Krijnders2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/KH.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Krijnders2013label" class="modal fade" id="bibtex-Krijnders2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKrijnders2013label">
        A Tone-Fit Feature Representation for Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Krijnders2013,
    Author = "Krijnders, Johannes D. and ten Holt, Gineke A.",
    title = "A Tone-Fit Feature Representation for Scene Classification",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "We present an algorithm that classifies environmental sound recordings using a feature representation based on the human hearing. Specifically, we use a mathematical model of the human cochlea to transform a sound (wav) clip into a time-frequency representation called a cochleogram. From the cochleogram, we calculate the tone-fit of each time-frequency region by calculating the fit of the region to a pure tone. This gives us a representation of the â€™tonelikenessâ€™ of the sound at various moments and frequencies. Finally, to arrive at a summarized representation for the entire clip, we calculate 20 statistic components over the tone-fit matrix. The resulting 20-dimensional feature representation is then classified using a support vector machine. The accuracy of the resulting method is 0.53 (SE = 0.06). Similar results are obtained by using MFCC features and voting by frame (0.60, SE = 0.04). Future directions include separately identifying sound events and representing scenes in terms of component events."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Li2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Li2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Auditory Scene Classification Using Machine Learning Techniques
       </h4>
<p style="text-align:left">
        David Li, Jason Tam and Derek Toub
       </p>
<p style="text-align:left">
<em>
         Cooper Union, New York, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">LTT_1</span> <span class="label label-primary">LTT_2</span> <span class="label label-primary">LTT_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Li2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Li2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Li2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/LTT.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Li2013" class="panel-collapse collapse" id="collapse-Li2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Auditory Scene Classification Using Machine Learning Techniques
      </h4>
<p style="text-align:left">
<small>
        David Li, Jason Tam and Derek Toub
       </small>
<br/>
<small>
<em>
         Cooper Union, New York, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Audio scene classification will play an important role in context-based organization of audio data in the future. With classified and labeled audio data, it will be possible to set up a searchable database where users can retrieve audio files based on their contents. In this paper, we introduce a system to extract features from such audio scenes and identify the environments in which they were recorded. This system makes use of wavelet and Mel-frequency cepstral coefficient (MFCC) features, and classifies scenes by first classifying segments of the scene, and deciding the overall classification with a vote. The system achieves a classification accuracy of 72% for the training dataset provided for the IEEE AASP CASA challenge [1].
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Wavelet, MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Treebagger, majority vote
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Li2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/LTT.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Li2013label" class="modal fade" id="bibtex-Li2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLi2013label">
        Auditory Scene Classification Using Machine Learning Techniques
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Li2013,
    Author = "Li, David and Tam, Jason and Toub, Derek",
    title = "Auditory Scene Classification Using Machine Learning Techniques",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "Audio scene classification will play an important role in context-based organization of audio data in the future. With classified and labeled audio data, it will be possible to set up a searchable database where users can retrieve audio files based on their contents. In this paper, we introduce a system to extract features from such audio scenes and identify the environments in which they were recorded. This system makes use of wavelet and Mel-frequency cepstral coefficient (MFCC) features, and classifies scenes by first classifying segments of the scene, and deciding the overall classification with a vote. The system achieves a classification accuracy of 72\% for the training dataset provided for the IEEE AASP CASA challenge [1]."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Nam2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Nam2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Sparse Feature Learning and Selective Max-Pooling by Event Detection
       </h4>
<p style="text-align:left">
        Juhan Nam<sup>1</sup>, Ziwon Hyung<sup>2</sup> and Kyogu Lee<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Stanford University, Stanford, USA, <sup>2</sup>Music and Audio Research Group, Seoul National University, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">NHL</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Nam2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Nam2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Nam2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/NHL.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Nam2013" class="panel-collapse collapse" id="collapse-Nam2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Sparse Feature Learning and Selective Max-Pooling by Event Detection
      </h4>
<p style="text-align:left">
<small>
        Juhan Nam<sup>1</sup>, Ziwon Hyung<sup>2</sup> and Kyogu Lee<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Stanford University, Stanford, USA, <sup>2</sup>Music and Audio Research Group, Seoul National University, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Feature representations by learning algorithms recently have shown promising results in music classification. In this work, we applied the feature learning approach to audio scene classification. Using a previously proposed method, we learn local acoustic features on mel-frequency spectrogram and performs max-pooling to form a scene-level feature vector. In order to adapt the method to environmental scene classification, where acoustic events occur in an irregular manner, we suggest a new pooling technique that detects events using mean feature activation and then selectively performs max-pooling for the events. Our experiments show that this method is effective in acoustic scene classification.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Feature learning, max-pooling
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Nam2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/NHL.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Nam2013label" class="modal fade" id="bibtex-Nam2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNam2013label">
        Acoustic Scene Classification Using Sparse Feature Learning and Selective Max-Pooling by Event Detection
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Nam2013,
    Author = "Nam, Juhan and Hyung, Ziwon and Lee, Kyogu",
    title = "Acoustic Scene Classification Using Sparse Feature Learning and Selective Max-Pooling by Event Detection",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "Feature representations by learning algorithms recently have shown promising results in music classification. In this work, we applied the feature learning approach to audio scene classification. Using a previously proposed method, we learn local acoustic features on mel-frequency spectrogram and performs max-pooling to form a scene-level feature vector. In order to adapt the method to environmental scene classification, where acoustic events occur in an irregular manner, we suggest a new pooling technique that detects events using mean feature activation and then selectively performs max-pooling for the events. Our experiments show that this method is effective in acoustic scene classification."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Nogueira2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Nogueira2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Sound Scene Identification Based on Mfcc, Binaural Features and a Support Vector Machine Classifier
       </h4>
<p style="text-align:left">
        Waldo Nogueira, Gerard Roma and Perfecto Herrera
       </p>
<p style="text-align:left">
<em>
         Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">NR1_1</span> <span class="label label-primary">NR1_2</span> <span class="label label-primary">NR1_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Nogueira2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Nogueira2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Nogueira2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/NR1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Nogueira2013" class="panel-collapse collapse" id="collapse-Nogueira2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Sound Scene Identification Based on Mfcc, Binaural Features and a Support Vector Machine Classifier
      </h4>
<p style="text-align:left">
<small>
        Waldo Nogueira, Gerard Roma and Perfecto Herrera
       </small>
<br/>
<small>
<em>
         Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This submission to the sub-task scene classification of the IEEE AASP Challenge: Detection and Classification of Acoustic Scenes and Events is based on a feature extraction module in three dimensions (spectral, temporal and spatial). Spectral features are based on Mel frequency cepstrums coefficients, temporal features are based on an event density extractor and the spatial features are based on the extraction of inter-aural differences (level and temporal) and the coherence between the two channels of stereo recordings. After feature selection, the features are used in conjunction with a supportvector-machine for the classification of the sound scenes. In this short paper the impact of different features is analyzed.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC, temporal modulation, event density, binaural features
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Nogueira2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/NR1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Nogueira2013label" class="modal fade" id="bibtex-Nogueira2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNogueira2013label">
        Sound Scene Identification Based on Mfcc, Binaural Features and a Support Vector Machine Classifier
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Nogueira2013,
    Author = "Nogueira, Waldo and Roma, Gerard and Herrera, Perfecto",
    title = "Sound Scene Identification Based on Mfcc, Binaural Features and a Support Vector Machine Classifier",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "This submission to the sub-task scene classification of the IEEE AASP Challenge: Detection and Classification of Acoustic Scenes and Events is based on a feature extraction module in three dimensions (spectral, temporal and spatial). Spectral features are based on Mel frequency cepstrums coefficients, temporal features are based on an event density extractor and the spatial features are based on the extraction of inter-aural differences (level and temporal) and the coherence between the two channels of stereo recordings. After feature selection, the features are used in conjunction with a supportvector-machine for the classification of the sound scenes. In this short paper the impact of different features is analyzed."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Olivetti2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Olivetti2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        The Wonders of the Normalized Compression Dissimilarity Representation
       </h4>
<p style="text-align:left">
        Emanuele Olivetti<sup>1,2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>NeuroInformatics Laboratory, Bruno Kessler Foundation, Trento, Italy, <sup>2</sup>Center for Mind and Brain Sciences, Trento, Italy
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">OE</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Olivetti2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Olivetti2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Olivetti2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/OE.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Olivetti2013').collapse('show');window.location.hash='#Olivetti2013';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Olivetti2013" class="panel-collapse collapse" id="collapse-Olivetti2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       The Wonders of the Normalized Compression Dissimilarity Representation
      </h4>
<p style="text-align:left">
<small>
        Emanuele Olivetti<sup>1,2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>NeuroInformatics Laboratory, Bruno Kessler Foundation, Trento, Italy, <sup>2</sup>Center for Mind and Brain Sciences, Trento, Italy
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We propose a method to effectively embed general objects, like audio samples, into a vectorial feature space, suitable for classification problems. From the practical point of view, the researcher adopting the proposed method is just required to provide two ingredients: an efficient compressor for those objects, and a way to combine two objects into a new one. The proposed method is based on two main elements: the dissimilarity representation and the normalized compression distance (NCD). The dissimilarity representation is an Euclidean embedding algorithm, i.e. a procedure to map generic objects into a vector space, which requires the definition of a distance function between the objects. The quality of the resulting embedding is strictly dependent on the choice of this distance. The NCD is a distance between objects based on the concept of Kolmogorov complexity. In practice the NCD is based on two building blocks: a compression function and a method to combine two objects into a new one. We claim that, as soon as a good compressor and a meaningful way to combine two objects are available, then it is possible to build an effective feature space in which classification algorithms can be accurate. As our submission to the IEEE AASP Challenge, we show a practical application of the proposed method in the context of acoustic scene classification where the compressor is the free and open source Vorbis lossy audio compressor and the combination of two audio samples is their simple concatenation.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Normalized compression distance, Euclidean embedding
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Random Forest
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Olivetti2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/OE.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://code.soundsoftware.ac.uk/projects/dcase2013_sc_olivetti" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Olivetti2013label" class="modal fade" id="bibtex-Olivetti2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexOlivetti2013label">
        The Wonders of the Normalized Compression Dissimilarity Representation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Olivetti2013,
    Author = "Olivetti, Emanuele",
    title = "The Wonders of the Normalized Compression Dissimilarity Representation",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "We propose a method to effectively embed general objects, like audio samples, into a vectorial feature space, suitable for classification problems. From the practical point of view, the researcher adopting the proposed method is just required to provide two ingredients: an efficient compressor for those objects, and a way to combine two objects into a new one. The proposed method is based on two main elements: the dissimilarity representation and the normalized compression distance (NCD). The dissimilarity representation is an Euclidean embedding algorithm, i.e. a procedure to map generic objects into a vector space, which requires the definition of a distance function between the objects. The quality of the resulting embedding is strictly dependent on the choice of this distance. The NCD is a distance between objects based on the concept of Kolmogorov complexity. In practice the NCD is based on two building blocks: a compression function and a method to combine two objects into a new one. We claim that, as soon as a good compressor and a meaningful way to combine two objects are available, then it is possible to build an effective feature space in which classification algorithms can be accurate. As our submission to the IEEE AASP Challenge, we show a practical application of the proposed method in the context of acoustic scene classification where the compressor is the free and open source Vorbis lossy audio compressor and the combination of two audio samples is their simple concatenation."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Patil2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Patil2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Multiresolution Auditory Representations for Scene Classification
       </h4>
<p style="text-align:left">
        Kailash Patil and Mounya Elhilali
       </p>
<p style="text-align:left">
<em>
         Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">PE</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Patil2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Patil2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Patil2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/PE.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Patil2013" class="panel-collapse collapse" id="collapse-Patil2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Multiresolution Auditory Representations for Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Kailash Patil and Mounya Elhilali
       </small>
<br/>
<small>
<em>
         Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Here, we propose a framework that provides a detailed analysis of the spectrotemporal modulations in the acoustic signal, augmented with a discriminative classifier using support vector machines. We have seen that such representation is successful at capturing the nontrivial commonalties within a sound class and differences between different classes[1, 2, 3].
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Spectrotemporal modulation
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Patil2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/PE.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Patil2013label" class="modal fade" id="bibtex-Patil2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPatil2013label">
        Multiresolution Auditory Representations for Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Patil2013,
    Author = "Patil, Kailash and Elhilali, Mounya",
    title = "Multiresolution Auditory Representations for Scene Classification",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "Here, we propose a framework that provides a detailed analysis of the spectrotemporal modulations in the acoustic signal, augmented with a discriminative classifier using support vector machines. We have seen that such representation is successful at capturing the nontrivial commonalties within a sound class and differences between different classes[1, 2, 3]."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Rakotomamonjy2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Rakotomamonjy2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Histogram of Gradients of Time-Frequency Representations for Audio Scene Classification
       </h4>
<p style="text-align:left">
        Alain Rakotomamonjy and Gilles Gasso
       </p>
<p style="text-align:left">
<em>
         Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Normandie Universite, Rouen, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">RG</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Rakotomamonjy2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Rakotomamonjy2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Rakotomamonjy2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/RG.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Rakotomamonjy2013" class="panel-collapse collapse" id="collapse-Rakotomamonjy2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Histogram of Gradients of Time-Frequency Representations for Audio Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Alain Rakotomamonjy and Gilles Gasso
       </small>
<br/>
<small>
<em>
         Center for Language and Speech Processing, Department of Electrical and Computer Engineering, Normandie Universite, Rouen, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This abstract presents our entry to the Detection and Classification of Acoustic Scenes challenge. The approach we propose for classifying acoustic scenes is based on transforming the audio signal into a time-frequency representation and then in extracting relevant features about shapes and evolutions of time-frequency structures. These features are based on histogram of gradients that are subsequently fed to a multi-class linear support vector machines.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         CQT, HOG
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Rakotomamonjy2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/RG.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Rakotomamonjy2013label" class="modal fade" id="bibtex-Rakotomamonjy2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexRakotomamonjy2013label">
        Histogram of Gradients of Time-Frequency Representations for Audio Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Rakotomamonjy2013,
    Author = "Rakotomamonjy, Alain and Gasso, Gilles",
    title = "Histogram of Gradients of Time-Frequency Representations for Audio Scene Classification",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "This abstract presents our entry to the Detection and Classification of Acoustic Scenes challenge. The approach we propose for classifying acoustic scenes is based on transforming the audio signal into a time-frequency representation and then in extracting relevant features about shapes and evolutions of time-frequency structures. These features are based on histogram of gradients that are subsequently fed to a multi-class linear support vector machines."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Roma2013" style="box-shadow: none">
<div class="panel-heading" id="heading-Roma2013" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Recurrence Quantification Analysis Features for Auditory Scene Classification
       </h4>
<p style="text-align:left">
        Gerard Roma, Waldo Nogueira and Perfecto Herrera
       </p>
<p style="text-align:left">
<em>
         Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">RNH_1</span> <span class="label label-primary">RNH_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Roma2013" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Roma2013" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Roma2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/RNH.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Roma2013').collapse('show');window.location.hash='#Roma2013';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Roma2013" class="panel-collapse collapse" id="collapse-Roma2013" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Recurrence Quantification Analysis Features for Auditory Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Gerard Roma, Waldo Nogueira and Perfecto Herrera
       </small>
<br/>
<small>
<em>
         Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This extended abstract describes our submission for the scene classification task of the IEEE AASP Challenge for Detection and Classification of Acoustic Scenes and Events. We explore the use of Recurrence Quantification Analysis (RQA) features for this task. These features are computed over a thresholded similarity matrix computed from windows of MFCC features. Added to traditional MFCC statistics, they improve accuracy when using a standard SVM classifier.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC, Recurrence Quantification Analysis
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Roma2013" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/abstracts/SC/RNH.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://code.soundsoftware.ac.uk/projects/dcase2013_sc_rnh" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Roma2013label" class="modal fade" id="bibtex-Roma2013" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexRoma2013label">
        Recurrence Quantification Analysis Features for Auditory Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Roma2013,
    Author = "Roma, Gerard and Nogueira, Waldo and Herrera, Perfecto",
    title = "Recurrence Quantification Analysis Features for Auditory Scene Classification",
    institution = "DCASE2013 Challenge",
    year = "2013",
    month = "June",
    abstract = "This extended abstract describes our submission for the scene classification task of the IEEE AASP Challenge for Detection and Classification of Acoustic Scenes and Events. We explore the use of Recurrence Quantification Analysis (RQA) features for this task. These features are computed over a thresholded similarity matrix computed from windows of MFCC features. Added to traditional MFCC statistics, they improve accuracy when using a standard SVM classifier."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>