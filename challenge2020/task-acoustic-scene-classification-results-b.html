<!DOCTYPE html><html lang="en">
<head>
    <title>Low-Complexity Acoustic Scene Classification - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2020/task-acoustic-scene-classification-results-b">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description This subtask is concerned with the classification of data into three higher-level classes while focusing on low-complexity solutions. All submitted systems had to comply with the task rules by limiting the size of the acoustic model size to be under 500 KB (only classification related non-zero parameters counted â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2020</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2020/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group  active">
        <a href="/challenge2020/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class=" active">
        <a href="/challenge2020/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-urban text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2020/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2020/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge awards">
        <a href="/challenge2020/awards"><i class="fa fa-trophy"></i>&nbsp;Awards</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/grid-08.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-info"></i><strong class="fa-stack-1x icon-text">B</strong><strong class="fa-stack-1x dcase-icon-top-text">Complexity</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 1</span></span><img src="../images/logos/dcase/dcase2020_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Low-Complexity Acoustic <br>Scene Classification</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#system-complexity">System complexity</a></li>
<li><a href="#generalization-performance">Generalization performance</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a></li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#general-characteristics">General characteristics</a></li>
<li><a href="#machine-learning-characteristics">Machine learning characteristics</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>This subtask is concerned with the classification of data into three higher-level classes while focusing on low-complexity solutions. All submitted systems had to comply with the task rules by limiting the size of the acoustic model size to be under 500 KB (only classification related non-zero parameters counted). See model size calculation examples <a href="/challenge2020/task-acoustic-scene-classification#task-setup-1">here</a>. </p>
<p>The development set contains data from 10 cities. The total amount of audio in the development set is 40 hours. The evaluation set contains data from 12 cities (2 cities unseen in the development set). Evaluation data contains 30 hours of audio. </p>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2020/task-acoustic-scene-classification#subtask-b" style="">task description page</a></p>
<h1 id="systems-ranking">Systems ranking</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>QTI1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0 (94.6 - 95.5)</td>
<td>0.228</td>
<td>97.9</td>
<td>0.172</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>QTI2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2 (92.9 - 93.5)</td>
<td>0.232</td>
<td>97.8</td>
<td>0.159</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>QTI3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8 (94.2 - 95.3)</td>
<td>0.224</td>
<td>98.0</td>
<td>0.144</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>QTI4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4 (93.8 - 95.1)</td>
<td>0.237</td>
<td>97.8</td>
<td>0.170</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>HCM_Group</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5 (89.5 - 89.5)</td>
<td>0.648</td>
<td>94.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>IMT_BRAINa</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4 (84.9 - 85.8)</td>
<td>0.379</td>
<td>87.6</td>
<td>0.360</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>IMT_BRAINb</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6 (90.0 - 91.2)</td>
<td>0.270</td>
<td>90.9</td>
<td>0.288</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>IMT_BRAINc</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6 (85.9 - 87.3)</td>
<td>0.384</td>
<td>87.6</td>
<td>0.380</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>IMT_BRAINd</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4 (87.9 - 88.9)</td>
<td>0.286</td>
<td>91.2</td>
<td>0.269</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>CNN-BDG</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3 (73.9 - 70.7)</td>
<td>1.728</td>
<td>91.8</td>
<td>0.469</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>CNN-BDG</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9 (82.2 - 81.6)</td>
<td>1.189</td>
<td>90.6</td>
<td>0.594</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>CNN-BDG</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7 (81.0 - 80.4)</td>
<td>1.302</td>
<td>90.6</td>
<td>0.644</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>CNN-BDG</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9 (80.4 - 79.3)</td>
<td>1.281</td>
<td>90.2</td>
<td>0.629</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td>89.5 (88.8 - 90.2)</td>
<td>0.401</td>
<td>88.0</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Helin1b</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6 (91.1 - 92.0)</td>
<td>0.227</td>
<td>92.1</td>
<td>0.312</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Helin2b</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6 (91.2 - 92.0)</td>
<td>0.233</td>
<td>92.1</td>
<td>0.312</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Helin3b</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6 (91.1 - 92.0)</td>
<td>0.230</td>
<td>92.1</td>
<td>0.312</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Helin4b</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3 (91.0 - 91.6)</td>
<td>0.264</td>
<td>92.1</td>
<td>0.312</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu_GT_1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8 (95.5 - 96.1)</td>
<td>0.357</td>
<td>96.3</td>
<td>0.349</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu_GT_1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5 (95.1 - 95.8)</td>
<td>0.367</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu_GT_1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0 (95.5 - 96.5)</td>
<td>0.122</td>
<td>96.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu_GT_1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8 (95.3 - 96.3)</td>
<td>0.131</td>
<td>96.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>kalinowski</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1 (92.7 - 93.5)</td>
<td>1.532</td>
<td>95.4</td>
<td>0.217</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>decomposed</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7 (94.5 - 94.9)</td>
<td>0.164</td>
<td>96.1</td>
<td>0.140</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>RFD-prune</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5 (96.2 - 96.8)</td>
<td>0.101</td>
<td>97.3</td>
<td>0.080</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>RFDsmall</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7 (95.5 - 95.9)</td>
<td>0.113</td>
<td>97.1</td>
<td>0.090</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>RFensem</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2 (95.9 - 96.5)</td>
<td>0.105</td>
<td>97.0</td>
<td>0.090</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>pkowdcase</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1 (89.6 - 90.7)</td>
<td>0.356</td>
<td>92.8</td>
<td>0.256</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>ens3-10mix</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6 (92.0 - 93.2)</td>
<td>0.200</td>
<td>94.6</td>
<td>0.175</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>ens3to10</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5 (93.0 - 94.0)</td>
<td>0.168</td>
<td>94.5</td>
<td>0.170</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>LamPham</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4 (89.2 - 89.7)</td>
<td>0.332</td>
<td>93.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>LamPham</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0 (86.1 - 87.8)</td>
<td>0.349</td>
<td>91.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>LamPham</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7 (85.0 - 84.5)</td>
<td>0.402</td>
<td>90.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7 (90.7 - 90.7)</td>
<td>0.302</td>
<td>95.3</td>
<td>0.167</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9 (93.7 - 94.1)</td>
<td>0.156</td>
<td>95.3</td>
<td>0.167</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1 (91.0 - 91.2)</td>
<td>0.246</td>
<td>93.7</td>
<td>0.193</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2 (91.2 - 91.2)</td>
<td>0.864</td>
<td>92.8</td>
<td>0.500</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>INT8CNN</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4 (89.6 - 91.1)</td>
<td>0.681</td>
<td>90.9</td>
<td>0.645</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>PrunCNN</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1 (89.7 - 90.5)</td>
<td>0.677</td>
<td>91.5</td>
<td>0.637</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>KD-CNN</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5 (89.8 - 91.2)</td>
<td>0.276</td>
<td>90.3</td>
<td>0.673</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>GCC-CNN</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7 (88.8 - 90.5)</td>
<td>0.983</td>
<td>91.2</td>
<td>0.510</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>UniSA_1b1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9 (94.9 - 95.0)</td>
<td>0.135</td>
<td>97.1</td>
<td>0.094</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>UniSA_1b2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5 (95.3 - 95.7)</td>
<td>0.118</td>
<td>97.1</td>
<td>0.094</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>UniSA_1b3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9 (95.7 - 96.1)</td>
<td>0.117</td>
<td>97.1</td>
<td>0.094</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>UniSA_1b4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8 (95.6 - 96.0)</td>
<td>0.119</td>
<td>97.1</td>
<td>0.094</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>MelCNN</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4 (86.5 - 88.3)</td>
<td>0.327</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6 (93.4 - 93.7)</td>
<td>0.202</td>
<td>97.1</td>
<td>0.132</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6 (93.4 - 93.8)</td>
<td>0.190</td>
<td>97.0</td>
<td>0.104</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>NHD_1B_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1 (92.6 - 93.5)</td>
<td>0.215</td>
<td>92.4</td>
<td>0.230</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>NHD_1B_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3 (91.9 - 92.6)</td>
<td>0.214</td>
<td>92.3</td>
<td>0.230</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi_model1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8 (87.1 - 88.6)</td>
<td>0.337</td>
<td>89.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi_model2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3 (86.6 - 88.1)</td>
<td>0.367</td>
<td>88.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi_model3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8 (89.0 - 90.5)</td>
<td>0.257</td>
<td>91.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi_model4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8 (89.1 - 90.5)</td>
<td>0.305</td>
<td>90.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Pan_UPM</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4 (89.0 - 89.8)</td>
<td>0.347</td>
<td>87.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>PATKI</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0 (85.8 - 86.3)</td>
<td>1.372</td>
<td>88.7</td>
<td>0.000</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>PATKI</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4 (89.0 - 89.7)</td>
<td>0.951</td>
<td>88.9</td>
<td>0.000</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>PATKI</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7 (81.8 - 85.7)</td>
<td>1.837</td>
<td>87.0</td>
<td>0.170</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>DD_1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5 (87.8 - 89.2)</td>
<td>0.319</td>
<td>89.5</td>
<td>0.289</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>DD_1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2 (88.7 - 89.8)</td>
<td>0.283</td>
<td>89.5</td>
<td>0.292</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>DD_1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0 (88.7 - 89.3)</td>
<td>0.301</td>
<td>90.3</td>
<td>0.254</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>DD_1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5 (88.9 - 90.0)</td>
<td>0.282</td>
<td>90.4</td>
<td>0.275</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>AALNet-94</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5 (87.1 - 87.9)</td>
<td>0.864</td>
<td>89.4</td>
<td>0.635</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>IITMandi</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5 (83.5 - 85.6)</td>
<td>0.418</td>
<td>84.9</td>
<td>0.422</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>IITMandi</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7 (83.5 - 85.9)</td>
<td>0.420</td>
<td>85.9</td>
<td>0.416</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>IITMandi</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2 (84.6 - 85.8)</td>
<td>0.402</td>
<td>86.8</td>
<td>0.399</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>IITMandi</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4 (85.0 - 87.8)</td>
<td>0.385</td>
<td>87.2</td>
<td>0.378</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Incep_Dev</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3 (93.2 - 93.4)</td>
<td>0.302</td>
<td>97.6</td>
<td>0.259</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Incep_Eval</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6 (94.4 - 94.7)</td>
<td>0.270</td>
<td>97.6</td>
<td>0.259</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Incep_Ensb</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1 (94.9 - 95.2)</td>
<td>0.277</td>
<td>97.5</td>
<td>0.271</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Incep_wEsb</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6 (94.5 - 94.8)</td>
<td>0.271</td>
<td>97.7</td>
<td>0.260</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>VilFCN</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8 (91.2 - 92.5)</td>
<td>0.215</td>
<td>92.3</td>
<td>0.211</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>LogMBE-LBP</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6 (88.2 - 89.1)</td>
<td>7.923</td>
<td>90.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>CNN4Blocks</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2 (94.0 - 94.3)</td>
<td>0.188</td>
<td>95.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>ensemble_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2 (94.1 - 94.3)</td>
<td>0.201</td>
<td>96.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>ensemble_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3 (94.3 - 94.4)</td>
<td>0.185</td>
<td>96.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>diff_feat2</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9 (94.7 - 95.1)</td>
<td>0.218</td>
<td>96.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>CNNs</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1 (91.7 - 92.4)</td>
<td>0.272</td>
<td>94.9</td>
<td>0.237</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>CNNs_PAE</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5 (93.3 - 93.7)</td>
<td>0.247</td>
<td>95.9</td>
<td>0.200</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>CNNs_Cyc</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5 (93.3 - 93.8)</td>
<td>0.228</td>
<td>96.0</td>
<td>0.187</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>CNNs_4CV</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4 (88.7 - 92.0)</td>
<td>0.327</td>
<td>92.0</td>
<td>0.305</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>BUPTSystem</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0 (91.6 - 92.4)</td>
<td>0.346</td>
<td>93.5</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>BUPTSystem</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7 (92.1 - 93.2)</td>
<td>0.334</td>
<td>93.5</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>BUPTSystem</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9 (92.3 - 93.5)</td>
<td>0.316</td>
<td>93.5</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>BUPTSystem</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0 (92.4 - 93.6)</td>
<td>0.316</td>
<td>93.5</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>DD-CNN</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6 (86.5 - 86.7)</td>
<td>0.867</td>
<td>92.0</td>
<td>0.257</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>DD-CNN</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9 (86.8 - 87.0)</td>
<td>0.873</td>
<td>91.1</td>
<td>0.343</td>
</tr>
</tbody>
</table>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_confidence" data-scatter-y="accuracy_dev" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="4">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_team" data-sortable="true" data-value-type="int">
                Team rank
            </th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>QTI1</td>
<td>Chang2020</td>
<td>12</td>
<td>5</td>
<td>95.0 (94.6 - 95.5)</td>
<td>0.228</td>
<td>97.9</td>
<td>0.172</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>HCM_Group</td>
<td>Dat2020</td>
<td>57</td>
<td>20</td>
<td>89.5 (89.5 - 89.5)</td>
<td>0.648</td>
<td>94.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>IMT_BRAINb</td>
<td>Pajusco2020</td>
<td>48</td>
<td>16</td>
<td>90.6 (90.0 - 91.2)</td>
<td>0.270</td>
<td>90.9</td>
<td>0.288</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>CNN-BDG</td>
<td>Feng2020</td>
<td>83</td>
<td>30</td>
<td>81.9 (82.2 - 81.6)</td>
<td>1.189</td>
<td>90.6</td>
<td>0.594</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td></td>
<td>89.5 (88.8 - 90.2)</td>
<td>0.401</td>
<td>88.0</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Helin2b</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>15</td>
<td>91.6 (91.2 - 92.0)</td>
<td>0.233</td>
<td>92.1</td>
<td>0.312</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu_GT_1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>2</td>
<td>96.0 (95.5 - 96.5)</td>
<td>0.122</td>
<td>96.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>kalinowski</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>11</td>
<td>93.1 (92.7 - 93.5)</td>
<td>1.532</td>
<td>95.4</td>
<td>0.217</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>RFD-prune</td>
<td>Koutini2020</td>
<td>1</td>
<td>1</td>
<td>96.5 (96.2 - 96.8)</td>
<td>0.101</td>
<td>97.3</td>
<td>0.080</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>pkowdcase</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>18</td>
<td>90.1 (89.6 - 90.7)</td>
<td>0.356</td>
<td>92.8</td>
<td>0.256</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>ens3to10</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>10</td>
<td>93.5 (93.0 - 94.0)</td>
<td>0.168</td>
<td>94.5</td>
<td>0.170</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>LamPham</td>
<td>Pham2020</td>
<td>59</td>
<td>22</td>
<td>89.4 (89.2 - 89.7)</td>
<td>0.332</td>
<td>93.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>CAUET</td>
<td>Lee2020</td>
<td>23</td>
<td>7</td>
<td>93.9 (93.7 - 94.1)</td>
<td>0.156</td>
<td>95.3</td>
<td>0.167</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>KD-CNN</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>17</td>
<td>90.5 (89.8 - 91.2)</td>
<td>0.276</td>
<td>90.3</td>
<td>0.673</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>UniSA_1b3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>3</td>
<td>95.9 (95.7 - 96.1)</td>
<td>0.117</td>
<td>97.1</td>
<td>0.094</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>MelCNN</td>
<td>Joao2020</td>
<td>69</td>
<td>27</td>
<td>87.4 (86.5 - 88.3)</td>
<td>0.327</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>ASCCSSE</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>8</td>
<td>93.6 (93.4 - 93.7)</td>
<td>0.202</td>
<td>97.1</td>
<td>0.132</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>NHD_1B_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>12</td>
<td>93.1 (92.6 - 93.5)</td>
<td>0.215</td>
<td>92.4</td>
<td>0.230</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi_model4</td>
<td>Ooi2020</td>
<td>54</td>
<td>19</td>
<td>89.8 (89.1 - 90.5)</td>
<td>0.305</td>
<td>90.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Pan_UPM</td>
<td>Paniagua2020</td>
<td>60</td>
<td>23</td>
<td>89.4 (89.0 - 89.8)</td>
<td>0.347</td>
<td>87.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>PATKI</td>
<td>Patki2020</td>
<td>61</td>
<td>24</td>
<td>89.4 (89.0 - 89.7)</td>
<td>0.951</td>
<td>88.9</td>
<td>0.000</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>DD_1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>21</td>
<td>89.5 (88.9 - 90.0)</td>
<td>0.282</td>
<td>90.4</td>
<td>0.275</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>AALNet-94</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>26</td>
<td>87.5 (87.1 - 87.9)</td>
<td>0.864</td>
<td>89.4</td>
<td>0.635</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>IITMandi</td>
<td>Singh2020</td>
<td>75</td>
<td>29</td>
<td>86.4 (85.0 - 87.8)</td>
<td>0.385</td>
<td>87.2</td>
<td>0.378</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Incep_Ensb</td>
<td>Suh2020</td>
<td>11</td>
<td>4</td>
<td>95.1 (94.9 - 95.2)</td>
<td>0.277</td>
<td>97.5</td>
<td>0.271</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>VilFCN</td>
<td>Vilouras2020</td>
<td>40</td>
<td>14</td>
<td>91.8 (91.2 - 92.5)</td>
<td>0.215</td>
<td>92.3</td>
<td>0.211</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>LogMBE-LBP</td>
<td>Waldekar2020</td>
<td>64</td>
<td>25</td>
<td>88.6 (88.2 - 89.1)</td>
<td>7.923</td>
<td>90.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>diff_feat2</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>6</td>
<td>94.9 (94.7 - 95.1)</td>
<td>0.218</td>
<td>96.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>CNNs_Cyc</td>
<td>Haocong2020</td>
<td>26</td>
<td>9</td>
<td>93.5 (93.3 - 93.8)</td>
<td>0.228</td>
<td>96.0</td>
<td>0.187</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>BUPTSystem</td>
<td>Zhang2020</td>
<td>33</td>
<td>13</td>
<td>93.0 (92.4 - 93.6)</td>
<td>0.316</td>
<td>93.5</td>
<td>0.481</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>DD-CNN</td>
<td>Zhao2020</td>
<td>72</td>
<td>28</td>
<td>86.9 (86.8 - 87.0)</td>
<td>0.873</td>
<td>91.1</td>
<td>0.343</td>
</tr>
</tbody>
</table>
<h1 id="system-complexity">System complexity</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="system_complexity_total" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="4">Acoustic model</th>
<th class="sep-left-cell text-center">System</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Accuracy (Eval)" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Eval)</small>
</th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Eval)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Parameters" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Parameters
            </th>
<th class="text-center" data-axis-label="Non-zero parameters" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total_non_zero" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Non-zero <br/>parameters  
            </th>
<th class="text-center" data-axis-label="Sparsity" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_sparsity" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Sparsity
            </th>
<th class="text-center" data-axis-label="Model size" data-chartable="true" data-field="system_complexity_model_size" data-reversed="true" data-sortable="true">
                Size <br/>(KB) *
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_complexity_management" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Complexity <br/>management
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0</td>
<td>0.228</td>
<td>601866</td>
<td>245591</td>
<td>0.5919506999896986</td>
<td>491.2</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2</td>
<td>0.232</td>
<td>601866</td>
<td>245591</td>
<td>0.5919506999896986</td>
<td>491.2</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8</td>
<td>0.224</td>
<td>601866</td>
<td>245591</td>
<td>0.5919506999896986</td>
<td>491.2</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4</td>
<td>0.237</td>
<td>601866</td>
<td>245591</td>
<td>0.5919506999896986</td>
<td>491.2</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5</td>
<td>0.648</td>
<td>111366</td>
<td>111366</td>
<td>0.0</td>
<td>445.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4</td>
<td>0.379</td>
<td>13632</td>
<td>12160</td>
<td>0.107981220657277</td>
<td>23.8</td>
<td>float16, quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6</td>
<td>0.270</td>
<td>29888</td>
<td>29888</td>
<td>0.0</td>
<td>58.4</td>
<td>float16, quantization</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6</td>
<td>0.384</td>
<td>398400</td>
<td>130730</td>
<td>0.6718624497991967</td>
<td>255.3</td>
<td>float16, quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4</td>
<td>0.286</td>
<td>373696</td>
<td>238896</td>
<td>0.3607210138722384</td>
<td>466.6</td>
<td>float16, quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3</td>
<td>1.728</td>
<td>35059</td>
<td>35059</td>
<td>0.0</td>
<td>136.9</td>
<td>optimize the convolution operation and the network structure</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9</td>
<td>1.189</td>
<td>60403</td>
<td>60403</td>
<td>0.0</td>
<td>235.9</td>
<td>optimize the convolution operation and the network structure</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7</td>
<td>1.302</td>
<td>85747</td>
<td>85747</td>
<td>0.0</td>
<td>334.9</td>
<td>optimize the convolution operation and the network structure</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9</td>
<td>1.281</td>
<td>111091</td>
<td>111091</td>
<td>0.0</td>
<td>433.9</td>
<td>optimize the convolution operation and the network structure</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>89.5</td>
<td>0.401</td>
<td>115219</td>
<td>115219</td>
<td>0.0</td>
<td>450.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6</td>
<td>0.227</td>
<td>123576</td>
<td>123576</td>
<td>0.0</td>
<td>490.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6</td>
<td>0.233</td>
<td>123576</td>
<td>123576</td>
<td>0.0</td>
<td>490.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6</td>
<td>0.230</td>
<td>123576</td>
<td>123576</td>
<td>0.0</td>
<td>490.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3</td>
<td>0.264</td>
<td>123576</td>
<td>123576</td>
<td>0.0</td>
<td>490.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8</td>
<td>0.357</td>
<td>94028</td>
<td>94028</td>
<td>0.0</td>
<td>375.0</td>
<td>int8, quantization</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5</td>
<td>0.367</td>
<td>122900</td>
<td>122900</td>
<td>0.0</td>
<td>490.0</td>
<td>int8, quantization</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0</td>
<td>0.122</td>
<td>122900</td>
<td>122900</td>
<td>0.0</td>
<td>490.0</td>
<td>int8, quantization</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8</td>
<td>0.131</td>
<td>125121</td>
<td>125121</td>
<td>0.0</td>
<td>499.0</td>
<td>int8, quantization</td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1</td>
<td>1.532</td>
<td>110899</td>
<td>110899</td>
<td>0.0</td>
<td>433.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7</td>
<td>0.164</td>
<td>17520</td>
<td>17520</td>
<td>0.0</td>
<td>34.2</td>
<td>float16, conv layers decomposition</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5</td>
<td>0.101</td>
<td>345990</td>
<td>247562</td>
<td>0.28448221046851063</td>
<td>483.5</td>
<td>pruning, float16</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7</td>
<td>0.113</td>
<td>242592</td>
<td>242592</td>
<td>0.0</td>
<td>473.8</td>
<td>float16, smaller width/depth</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2</td>
<td>0.105</td>
<td>556480</td>
<td>249386</td>
<td>0.5518509200690052</td>
<td>487.1</td>
<td>float16, smaller width/depth</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1</td>
<td>0.356</td>
<td>110899</td>
<td>110899</td>
<td>0.0</td>
<td>433.2</td>
<td>using rectangular convolution kernels</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6</td>
<td>0.200</td>
<td>107494</td>
<td>107494</td>
<td>0.0</td>
<td>421.0</td>
<td>constraints-aware modelling</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5</td>
<td>0.168</td>
<td>107494</td>
<td>107494</td>
<td>0.0</td>
<td>421.0</td>
<td>constraints-aware modelling</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4</td>
<td>0.332</td>
<td>61636</td>
<td>61636</td>
<td>0.0</td>
<td>246.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0</td>
<td>0.349</td>
<td>61636</td>
<td>61636</td>
<td>0.0</td>
<td>61.6</td>
<td>quantization</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7</td>
<td>0.402</td>
<td>61636</td>
<td>30818</td>
<td>0.5</td>
<td>123.2</td>
<td>pruning</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7</td>
<td>0.302</td>
<td>126979</td>
<td>126528</td>
<td>0.003551768402649258</td>
<td>494.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9</td>
<td>0.156</td>
<td>126979</td>
<td>126528</td>
<td>0.003551768402649258</td>
<td>494.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1</td>
<td>0.246</td>
<td>125827</td>
<td>125376</td>
<td>0.003584286361432709</td>
<td>489.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2</td>
<td>0.864</td>
<td>127539</td>
<td>126864</td>
<td>0.005292498765083642</td>
<td>495.6</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4</td>
<td>0.681</td>
<td>317038</td>
<td>317038</td>
<td>0.0</td>
<td>309.6</td>
<td>quantization</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1</td>
<td>0.677</td>
<td>317038</td>
<td>255740</td>
<td>0.1933459080614942</td>
<td>499.5</td>
<td>pruning, quantization</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5</td>
<td>0.276</td>
<td>252712</td>
<td>252712</td>
<td>0.0</td>
<td>493.6</td>
<td>knowledge distillation, quantization</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7</td>
<td>0.983</td>
<td>252491</td>
<td>252491</td>
<td>0.0</td>
<td>493.1</td>
<td>quantization</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9</td>
<td>0.135</td>
<td>3987000</td>
<td>3987000</td>
<td>0.0</td>
<td>486.7</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5</td>
<td>0.118</td>
<td>3987000</td>
<td>3987000</td>
<td>0.0</td>
<td>486.7</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9</td>
<td>0.117</td>
<td>3987000</td>
<td>3987000</td>
<td>0.0</td>
<td>486.7</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8</td>
<td>0.119</td>
<td>3987000</td>
<td>3987000</td>
<td>0.0</td>
<td>486.7</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4</td>
<td>0.327</td>
<td>54468</td>
<td>54468</td>
<td>0.0</td>
<td>218.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6</td>
<td>0.202</td>
<td>127055</td>
<td>127055</td>
<td>0.0</td>
<td>496.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6</td>
<td>0.190</td>
<td>126927</td>
<td>126927</td>
<td>0.0</td>
<td>495.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1</td>
<td>0.215</td>
<td>122999</td>
<td>122493</td>
<td>0.004113854584183563</td>
<td>478.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3</td>
<td>0.214</td>
<td>77028</td>
<td>77028</td>
<td>0.0</td>
<td>300.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8</td>
<td>0.337</td>
<td>80839</td>
<td>17115</td>
<td>0.788282883261792</td>
<td>66.9</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3</td>
<td>0.367</td>
<td>167571</td>
<td>34181</td>
<td>0.7960207911870192</td>
<td>133.5</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8</td>
<td>0.257</td>
<td>571766</td>
<td>119756</td>
<td>0.7905506798235642</td>
<td>467.8</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8</td>
<td>0.305</td>
<td>571766</td>
<td>119756</td>
<td>0.7905506798235642</td>
<td>467.8</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4</td>
<td>0.347</td>
<td>13197</td>
<td>13197</td>
<td>0.0</td>
<td>103.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0</td>
<td>1.372</td>
<td>9010</td>
<td>9010</td>
<td>0.0</td>
<td>17.5</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4</td>
<td>0.951</td>
<td>18020</td>
<td>18020</td>
<td>0.0</td>
<td>26.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7</td>
<td>1.837</td>
<td>9010</td>
<td>9010</td>
<td>0.0</td>
<td>8.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5</td>
<td>0.319</td>
<td>6979</td>
<td>6944</td>
<td>0.005015045135406182</td>
<td>27.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2</td>
<td>0.283</td>
<td>6979</td>
<td>6944</td>
<td>0.005015045135406182</td>
<td>27.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0</td>
<td>0.301</td>
<td>17859</td>
<td>17792</td>
<td>0.003751609832577385</td>
<td>69.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5</td>
<td>0.282</td>
<td>17859</td>
<td>17792</td>
<td>0.003751609832577385</td>
<td>69.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5</td>
<td>0.864</td>
<td>123487</td>
<td>122387</td>
<td>0.008907820256383259</td>
<td>489.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5</td>
<td>0.418</td>
<td>52467</td>
<td>52467</td>
<td>0.0</td>
<td>204.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7</td>
<td>0.420</td>
<td>18611</td>
<td>18611</td>
<td>0.0</td>
<td>72.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2</td>
<td>0.402</td>
<td>19763</td>
<td>19763</td>
<td>0.0</td>
<td>77.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4</td>
<td>0.385</td>
<td>70947</td>
<td>70947</td>
<td>0.0</td>
<td>277.1</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3</td>
<td>0.302</td>
<td>103778</td>
<td>103778</td>
<td>0.0</td>
<td>405.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6</td>
<td>0.270</td>
<td>103778</td>
<td>103778</td>
<td>0.0</td>
<td>405.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1</td>
<td>0.277</td>
<td>207556</td>
<td>207556</td>
<td>0.0</td>
<td>413.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6</td>
<td>0.271</td>
<td>207556</td>
<td>207556</td>
<td>0.0</td>
<td>413.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8</td>
<td>0.215</td>
<td>127467</td>
<td>127021</td>
<td>0.0034989448249350685</td>
<td>496.2</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6</td>
<td>7.923</td>
<td>10092</td>
<td>10092</td>
<td>0.0</td>
<td>40.0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2</td>
<td>0.188</td>
<td>76611</td>
<td>76611</td>
<td>0.0</td>
<td>299.3</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2</td>
<td>0.201</td>
<td>187917</td>
<td>187917</td>
<td>0.0</td>
<td>367.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3</td>
<td>0.185</td>
<td>229883</td>
<td>229883</td>
<td>0.0</td>
<td>449.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9</td>
<td>0.218</td>
<td>153222</td>
<td>153222</td>
<td>0.0</td>
<td>299.3</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1</td>
<td>0.272</td>
<td>119382</td>
<td>119382</td>
<td>0.0</td>
<td>258.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5</td>
<td>0.247</td>
<td>119382</td>
<td>119382</td>
<td>0.0</td>
<td>258.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5</td>
<td>0.228</td>
<td>119382</td>
<td>119382</td>
<td>0.0</td>
<td>258.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4</td>
<td>0.327</td>
<td>182184</td>
<td>182184</td>
<td>0.0</td>
<td>448.0</td>
<td>float16</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0</td>
<td>0.346</td>
<td>83974</td>
<td>83974</td>
<td>0.0</td>
<td>83.4</td>
<td>8-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7</td>
<td>0.334</td>
<td>83974</td>
<td>83974</td>
<td>0.0</td>
<td>83.4</td>
<td>8-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9</td>
<td>0.316</td>
<td>83974</td>
<td>83974</td>
<td>0.0</td>
<td>83.4</td>
<td>8-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0</td>
<td>0.316</td>
<td>83974</td>
<td>83974</td>
<td>0.0</td>
<td>83.4</td>
<td>8-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6</td>
<td>0.867</td>
<td>127491</td>
<td>127491</td>
<td>0.0</td>
<td>498.0</td>
<td>disout</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9</td>
<td>0.873</td>
<td>127491</td>
<td>127491</td>
<td>0.0</td>
<td>498.0</td>
<td>disout</td>
</tr>
</tbody>
</table>
<p><br/>
*) Model size is calculated accordingly to the task specific rules, and will differ from a real model storage size. See model size calculation examples <a href="/challenge2020/task-acoustic-scene-classification#task-setup-1">here</a>. </p>
<h1 id="generalization-performance">Generalization performance</h1>
<p>All results with evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_city_seen" data-scatter-y="accuracy_eval_city_unseen" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval_confidence" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2">Submission information</th>
<th class="sep-left-cell text-center" colspan="2">Overall</th>
<th class="sep-left-cell text-center" colspan="2">Cities</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Accuracy" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Evaluation dataset)
            </th>
<th class="sep-left-cell text-center" data-axis-label="Accuracy / unseen cities" data-chartable="true" data-field="accuracy_eval_city_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>unseen<small class="hidden"> cities (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / seen cities" data-chartable="true" data-field="accuracy_eval_city_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>seen<small class="hidden"> cities (Evaluation dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0</td>
<td>91.3</td>
<td>95.8</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2</td>
<td>91.8</td>
<td>93.5</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8</td>
<td>91.6</td>
<td>95.4</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4</td>
<td>90.8</td>
<td>95.2</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5</td>
<td>88.0</td>
<td>89.8</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4</td>
<td>79.8</td>
<td>86.5</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6</td>
<td>87.3</td>
<td>91.3</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6</td>
<td>83.3</td>
<td>87.3</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4</td>
<td>81.4</td>
<td>89.8</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3</td>
<td>74.9</td>
<td>71.8</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9</td>
<td>82.4</td>
<td>81.8</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7</td>
<td>79.1</td>
<td>81.0</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9</td>
<td>77.8</td>
<td>80.3</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>89.5</td>
<td>84.9</td>
<td>90.4</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6</td>
<td>85.9</td>
<td>92.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6</td>
<td>86.1</td>
<td>92.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6</td>
<td>86.1</td>
<td>92.6</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3</td>
<td>85.9</td>
<td>92.4</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8</td>
<td>93.3</td>
<td>96.3</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5</td>
<td>92.1</td>
<td>96.1</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0</td>
<td>93.0</td>
<td>96.7</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8</td>
<td>93.5</td>
<td>96.3</td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1</td>
<td>90.1</td>
<td>93.7</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7</td>
<td>91.1</td>
<td>95.4</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5</td>
<td>95.3</td>
<td>96.7</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7</td>
<td>94.7</td>
<td>95.9</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2</td>
<td>94.4</td>
<td>96.6</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1</td>
<td>86.8</td>
<td>90.8</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6</td>
<td>88.7</td>
<td>93.4</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5</td>
<td>88.9</td>
<td>94.4</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4</td>
<td>85.5</td>
<td>90.2</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0</td>
<td>84.6</td>
<td>87.4</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7</td>
<td>82.1</td>
<td>85.3</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7</td>
<td>87.4</td>
<td>91.3</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9</td>
<td>90.0</td>
<td>94.6</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1</td>
<td>87.3</td>
<td>91.8</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2</td>
<td>87.5</td>
<td>91.9</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4</td>
<td>88.2</td>
<td>90.8</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1</td>
<td>87.1</td>
<td>90.7</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5</td>
<td>85.2</td>
<td>91.6</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7</td>
<td>89.1</td>
<td>89.8</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9</td>
<td>93.8</td>
<td>95.1</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5</td>
<td>92.9</td>
<td>96.0</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9</td>
<td>94.7</td>
<td>96.2</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8</td>
<td>93.8</td>
<td>96.2</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4</td>
<td>83.9</td>
<td>88.1</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6</td>
<td>90.8</td>
<td>94.1</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6</td>
<td>91.3</td>
<td>94.0</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1</td>
<td>90.0</td>
<td>93.7</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3</td>
<td>90.0</td>
<td>92.7</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8</td>
<td>81.1</td>
<td>89.1</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3</td>
<td>85.7</td>
<td>87.7</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8</td>
<td>86.0</td>
<td>90.5</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8</td>
<td>87.7</td>
<td>90.2</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4</td>
<td>89.4</td>
<td>89.4</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0</td>
<td>89.7</td>
<td>85.3</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4</td>
<td>89.7</td>
<td>89.3</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7</td>
<td>84.9</td>
<td>83.5</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5</td>
<td>84.2</td>
<td>89.4</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2</td>
<td>86.8</td>
<td>89.7</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0</td>
<td>85.4</td>
<td>89.7</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5</td>
<td>85.4</td>
<td>90.3</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5</td>
<td>85.7</td>
<td>87.8</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5</td>
<td>81.8</td>
<td>85.1</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7</td>
<td>81.1</td>
<td>85.4</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2</td>
<td>80.8</td>
<td>86.1</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4</td>
<td>82.8</td>
<td>87.1</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3</td>
<td>89.9</td>
<td>94.0</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6</td>
<td>91.6</td>
<td>95.2</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1</td>
<td>92.8</td>
<td>95.5</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6</td>
<td>91.6</td>
<td>95.2</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8</td>
<td>89.6</td>
<td>92.3</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6</td>
<td>84.6</td>
<td>89.4</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2</td>
<td>92.9</td>
<td>94.4</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2</td>
<td>93.5</td>
<td>94.3</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3</td>
<td>93.1</td>
<td>94.5</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9</td>
<td>94.1</td>
<td>95.1</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1</td>
<td>86.1</td>
<td>93.2</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5</td>
<td>89.3</td>
<td>94.3</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5</td>
<td>89.5</td>
<td>94.3</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4</td>
<td>86.3</td>
<td>91.2</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0</td>
<td>86.3</td>
<td>93.1</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7</td>
<td>87.1</td>
<td>93.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9</td>
<td>87.5</td>
<td>94.0</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0</td>
<td>87.5</td>
<td>94.1</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6</td>
<td>84.3</td>
<td>87.0</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9</td>
<td>84.9</td>
<td>87.4</td>
</tr>
</tbody>
</table>
<h1 id="class-wise-performance">Class-wise performance</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2020 baseline" data-comparison-active-set="Class-wise performance (all)" data-comparison-b-row="Koutini_CPJKU_task1b_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (all)",
        "data_axis_title": "Accuracy",
        "fields": ["class_accuracy_eval_indoor", "class_accuracy_eval_outdoor", "class_accuracy_eval_transportation"]
        }]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="accuracy_eval" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="class_accuracy_eval_indoor" data-sortable="true" data-value-type="float1-percentage">
                Indoor
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_outdoor" data-sortable="true" data-value-type="float1-percentage">
                Outdoor
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_transportation" data-sortable="true" data-value-type="float1-percentage">
                Transportation
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0</td>
<td>91.5</td>
<td>95.3</td>
<td>98.3</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2</td>
<td>86.1</td>
<td>95.3</td>
<td>98.1</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8</td>
<td>91.2</td>
<td>94.3</td>
<td>98.8</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4</td>
<td>92.2</td>
<td>92.8</td>
<td>98.2</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5</td>
<td>78.9</td>
<td>95.5</td>
<td>94.1</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4</td>
<td>75.8</td>
<td>88.5</td>
<td>91.9</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6</td>
<td>87.7</td>
<td>90.7</td>
<td>93.5</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6</td>
<td>79.8</td>
<td>87.2</td>
<td>92.7</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4</td>
<td>81.1</td>
<td>90.2</td>
<td>93.9</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3</td>
<td>41.8</td>
<td>97.5</td>
<td>77.5</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9</td>
<td>68.7</td>
<td>92.4</td>
<td>84.6</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7</td>
<td>66.2</td>
<td>91.8</td>
<td>84.1</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9</td>
<td>59.0</td>
<td>93.5</td>
<td>87.2</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>89.5</td>
<td>84.5</td>
<td>89.1</td>
<td>94.9</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6</td>
<td>85.0</td>
<td>93.0</td>
<td>96.8</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6</td>
<td>84.7</td>
<td>93.5</td>
<td>96.7</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6</td>
<td>84.5</td>
<td>93.3</td>
<td>96.9</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3</td>
<td>83.1</td>
<td>94.3</td>
<td>96.6</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8</td>
<td>91.9</td>
<td>96.6</td>
<td>98.8</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5</td>
<td>92.8</td>
<td>96.3</td>
<td>97.3</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0</td>
<td>95.3</td>
<td>95.3</td>
<td>97.5</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8</td>
<td>94.8</td>
<td>95.1</td>
<td>97.5</td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1</td>
<td>88.7</td>
<td>94.5</td>
<td>96.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7</td>
<td>89.1</td>
<td>97.0</td>
<td>98.0</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5</td>
<td>92.7</td>
<td>97.4</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7</td>
<td>90.1</td>
<td>97.8</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2</td>
<td>92.2</td>
<td>97.3</td>
<td>99.0</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1</td>
<td>91.0</td>
<td>90.6</td>
<td>88.9</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6</td>
<td>89.0</td>
<td>91.9</td>
<td>96.9</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5</td>
<td>89.0</td>
<td>93.7</td>
<td>97.8</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4</td>
<td>77.2</td>
<td>93.2</td>
<td>97.9</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0</td>
<td>84.8</td>
<td>85.9</td>
<td>90.2</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7</td>
<td>67.4</td>
<td>94.9</td>
<td>91.9</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7</td>
<td>78.1</td>
<td>96.9</td>
<td>97.0</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9</td>
<td>86.7</td>
<td>97.1</td>
<td>97.9</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1</td>
<td>81.1</td>
<td>96.3</td>
<td>95.9</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2</td>
<td>80.3</td>
<td>96.7</td>
<td>96.5</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4</td>
<td>87.9</td>
<td>88.9</td>
<td>94.3</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1</td>
<td>82.5</td>
<td>92.6</td>
<td>95.2</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5</td>
<td>85.8</td>
<td>89.6</td>
<td>96.2</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7</td>
<td>84.4</td>
<td>88.0</td>
<td>96.6</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9</td>
<td>87.7</td>
<td>98.8</td>
<td>98.3</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5</td>
<td>90.4</td>
<td>97.5</td>
<td>98.7</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9</td>
<td>90.7</td>
<td>97.9</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8</td>
<td>90.2</td>
<td>98.1</td>
<td>99.1</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4</td>
<td>82.6</td>
<td>85.8</td>
<td>93.7</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6</td>
<td>85.0</td>
<td>97.0</td>
<td>98.7</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6</td>
<td>86.0</td>
<td>96.7</td>
<td>98.0</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1</td>
<td>88.8</td>
<td>93.8</td>
<td>96.6</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3</td>
<td>85.8</td>
<td>94.4</td>
<td>96.5</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8</td>
<td>82.6</td>
<td>87.2</td>
<td>93.6</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3</td>
<td>86.5</td>
<td>86.8</td>
<td>88.6</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8</td>
<td>86.1</td>
<td>89.1</td>
<td>94.1</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8</td>
<td>85.6</td>
<td>89.3</td>
<td>94.4</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4</td>
<td>82.5</td>
<td>91.7</td>
<td>94.0</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0</td>
<td>75.9</td>
<td>90.7</td>
<td>91.6</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4</td>
<td>84.2</td>
<td>92.4</td>
<td>91.4</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7</td>
<td>82.1</td>
<td>72.3</td>
<td>96.9</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5</td>
<td>82.8</td>
<td>88.6</td>
<td>94.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2</td>
<td>84.0</td>
<td>89.9</td>
<td>93.9</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0</td>
<td>78.8</td>
<td>92.5</td>
<td>95.6</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5</td>
<td>82.4</td>
<td>90.2</td>
<td>95.8</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5</td>
<td>76.5</td>
<td>90.2</td>
<td>95.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5</td>
<td>77.0</td>
<td>81.8</td>
<td>94.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7</td>
<td>79.9</td>
<td>80.3</td>
<td>93.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2</td>
<td>75.4</td>
<td>86.7</td>
<td>93.6</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4</td>
<td>85.0</td>
<td>79.9</td>
<td>94.3</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3</td>
<td>83.5</td>
<td>97.2</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6</td>
<td>87.0</td>
<td>97.6</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1</td>
<td>88.3</td>
<td>97.9</td>
<td>99.1</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6</td>
<td>87.0</td>
<td>97.7</td>
<td>99.2</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8</td>
<td>87.2</td>
<td>91.1</td>
<td>97.2</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6</td>
<td>82.9</td>
<td>90.8</td>
<td>92.2</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2</td>
<td>86.1</td>
<td>97.9</td>
<td>98.5</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2</td>
<td>86.1</td>
<td>97.8</td>
<td>98.6</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3</td>
<td>85.9</td>
<td>98.5</td>
<td>98.5</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9</td>
<td>88.8</td>
<td>97.3</td>
<td>98.6</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1</td>
<td>86.6</td>
<td>94.1</td>
<td>95.5</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5</td>
<td>89.4</td>
<td>96.3</td>
<td>94.8</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5</td>
<td>89.9</td>
<td>96.0</td>
<td>94.7</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4</td>
<td>95.0</td>
<td>80.8</td>
<td>95.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0</td>
<td>84.3</td>
<td>93.5</td>
<td>98.2</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7</td>
<td>88.0</td>
<td>92.6</td>
<td>97.4</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9</td>
<td>88.3</td>
<td>92.6</td>
<td>97.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0</td>
<td>88.9</td>
<td>92.5</td>
<td>97.7</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6</td>
<td>70.4</td>
<td>92.6</td>
<td>96.7</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9</td>
<td>71.0</td>
<td>92.9</td>
<td>96.9</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<h2 id="general-characteristics">General characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label 
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Input
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data <br/>augmentation
            </th>
<th class="text-center narrow-col" data-field="system_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Features
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0</td>
<td>binaural</td>
<td>22.05kHz</td>
<td>mixup+FreqMix</td>
<td>perceptual weighted power spectrogram</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2</td>
<td>binaural</td>
<td>22.05kHz</td>
<td>mixup+FreqMix</td>
<td>perceptual weighted power spectrogram</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8</td>
<td>binaural</td>
<td>22.05kHz</td>
<td>mixup+FreqMix</td>
<td>perceptual weighted power spectrogram</td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4</td>
<td>binaural</td>
<td>22.05kHz</td>
<td>mixup+FreqMix</td>
<td>perceptual weighted power spectrogram</td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5</td>
<td>left, right, average of left+right</td>
<td>48kHz</td>
<td>Random oversample &amp; mixup</td>
<td>Gammatone energy</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4</td>
<td>binaural</td>
<td>18kHz</td>
<td>temporal masking, filtering, additive noise</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6</td>
<td>binaural</td>
<td>18kHz</td>
<td>temporal masking, filtering, additive noise</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6</td>
<td>binaural</td>
<td>18kHz</td>
<td>cutmix</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4</td>
<td>binaural</td>
<td>18kHz</td>
<td>cutmix</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3</td>
<td>mono</td>
<td>48kHz</td>
<td>same class mix</td>
<td>mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9</td>
<td>mono</td>
<td>48kHz</td>
<td>same class mix</td>
<td>mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7</td>
<td>mono</td>
<td>48kHz</td>
<td>same class mix</td>
<td>mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9</td>
<td>mono</td>
<td>48kHz</td>
<td>same class mix</td>
<td>mel spectrogram</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>89.5</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6</td>
<td>mono</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, CQT, Gammatone</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6</td>
<td>mono</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, CQT, Gammatone</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6</td>
<td>mono</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, CQT, Gammatone</td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3</td>
<td>mono</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, CQT, Gammatone</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup, channel confusion, SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup, channel confusion, SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup, channel confusion, SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup, channel confusion, SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1</td>
<td>mono</td>
<td>48kHz</td>
<td>time warping, frequency warping, loudness control, time length control, time masking, frequency masking</td>
<td>log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7</td>
<td>stereo</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5</td>
<td>stereo</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7</td>
<td>stereo</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2</td>
<td>stereo</td>
<td>22.05kHz</td>
<td>mixup</td>
<td>Perceptually-weighted log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6</td>
<td>mono</td>
<td>48kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4</td>
<td>left</td>
<td>48kHz</td>
<td>mixup</td>
<td>Gammatone energy</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0</td>
<td>left</td>
<td>48kHz</td>
<td>mixup</td>
<td>Gammatone energy</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7</td>
<td>left</td>
<td>48kHz</td>
<td>mixup</td>
<td>Gammatone energy</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>HPSS</td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2</td>
<td>binaural</td>
<td>48kHz</td>
<td></td>
<td>HPSS, log-mel energies, deltas, delta-deltas</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4</td>
<td>mono</td>
<td>16kHz</td>
<td>random noise, random gain, random cropping, mixup</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1</td>
<td>mono</td>
<td>16kHz</td>
<td>random noise, random gain, random cropping, mixup</td>
<td>raw waveform</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5</td>
<td>mono</td>
<td>48kHz</td>
<td>SpecAugment</td>
<td>mel filterbank</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7</td>
<td>binaural</td>
<td>16kHz</td>
<td>SpecAugment</td>
<td>log-mel filterbanks, GCC-grams</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9</td>
<td>left, right</td>
<td>48kHz</td>
<td>mixup, temporal cropping, channel swapping</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5</td>
<td>left, right</td>
<td>48kHz</td>
<td>mixup, temporal cropping, channel swapping</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9</td>
<td>left, right</td>
<td>48kHz</td>
<td>mixup, temporal cropping, channel swapping</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8</td>
<td>left, right</td>
<td>48kHz</td>
<td>mixup, temporal cropping, channel swapping</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4</td>
<td>mono</td>
<td>44.1kHz</td>
<td>Sox distortions, SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6</td>
<td>left, right, difference</td>
<td>48kHz</td>
<td></td>
<td>gammatone</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6</td>
<td>left, right, difference, mono</td>
<td>48kHz</td>
<td></td>
<td>gammatone, HPSS, log-mel energies</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1</td>
<td>mono, binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>RMS level, third-octave levels, Leq, interaural cross correlation coefficient, hardness, depth, brightness, roughness, warmth, sharpness, boominess, reverb, log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3</td>
<td>mono, binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>RMS level, third-octave levels, Leq, interaural cross correlation coefficient, hardness, depth, brightness, roughness, warmth, sharpness, boominess, reverb, log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8</td>
<td>mono</td>
<td>48kHz</td>
<td>block mixing</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4</td>
<td></td>
<td>48kHz</td>
<td></td>
<td>LTAS, envelope modulation spectrum, cepstrum of cross-correlation</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0</td>
<td>left+right, left-right</td>
<td>48kHz</td>
<td></td>
<td>log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4</td>
<td>left+right, left-right</td>
<td>48kHz</td>
<td></td>
<td>log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel spectrogram</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5</td>
<td>mono</td>
<td>16kHz</td>
<td></td>
<td>raw waveform segment</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7</td>
<td>mono</td>
<td>16kHz</td>
<td></td>
<td>raw waveform segment</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2</td>
<td>mono</td>
<td>16kHz</td>
<td></td>
<td>raw waveform segment</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4</td>
<td>mono</td>
<td>16kHz</td>
<td></td>
<td>raw waveform segment</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3</td>
<td>stereo</td>
<td>48kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6</td>
<td>stereo</td>
<td>48kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1</td>
<td>stereo</td>
<td>48kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6</td>
<td>stereo</td>
<td>48kHz</td>
<td>temporal cropping, mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6</td>
<td>mono</td>
<td>48kHz</td>
<td></td>
<td>histogram of uniform LBP of log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9</td>
<td>binaural</td>
<td>48kHz</td>
<td>mixup</td>
<td>wavelet filter-bank features</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1</td>
<td>binaural</td>
<td>22.05kHz</td>
<td></td>
<td>CQT</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5</td>
<td>mixed</td>
<td>22.05kHz</td>
<td></td>
<td>CQT</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5</td>
<td>binaural</td>
<td>22.05kHz</td>
<td></td>
<td>CQT</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4</td>
<td>binaural</td>
<td>22.05kHz</td>
<td></td>
<td>CQT</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0</td>
<td>mixed</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7</td>
<td>mixed</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9</td>
<td>mixed</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0</td>
<td>mixed</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6</td>
<td>mono</td>
<td>48kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9</td>
<td>mono</td>
<td>48kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="machine-learning-characteristics">Machine learning characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="system_complexity_total" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_external_data_usage" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data usage
            </th>
<th class="text-center narrow-col" data-field="external_data_sources" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data sources
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_classifier" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Classifier
            </th>
<th class="text-center narrow-col" data-chartable="true" data-field="system_ensemble_method_subsystem_count" data-sortable="true" data-value-type="int">
                Ensemble <br/>subsystems
            </th>
<th class="text-center narrow-col" data-field="system_decision_making" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Decision <br/>making
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Chang_QTI_task1b_1</td>
<td>Chang2020</td>
<td>12</td>
<td>95.0</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_2</td>
<td>Chang2020</td>
<td>30</td>
<td>93.2</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_3</td>
<td>Chang2020</td>
<td>15</td>
<td>94.8</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Chang_QTI_task1b_4</td>
<td>Chang2020</td>
<td>19</td>
<td>94.4</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Dat_HCMUni_task1b_1</td>
<td>Dat2020</td>
<td>57</td>
<td>89.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_1</td>
<td>Pajusco2020</td>
<td>77</td>
<td>85.4</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_2</td>
<td>Pajusco2020</td>
<td>48</td>
<td>90.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_3</td>
<td>Pajusco2020</td>
<td>73</td>
<td>86.6</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Farrugia_IMT-Atlantique-BRAIn_task1b_4</td>
<td>Pajusco2020</td>
<td>66</td>
<td>88.4</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_1</td>
<td>Feng2020</td>
<td>86</td>
<td>72.3</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_2</td>
<td>Feng2020</td>
<td>83</td>
<td>81.9</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_3</td>
<td>Feng2020</td>
<td>84</td>
<td>80.7</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Feng_TJU_task1b_4</td>
<td>Feng2020</td>
<td>85</td>
<td>79.9</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2020 baseline</td>
<td></td>
<td></td>
<td>89.5</td>
<td>embeddings</td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_1</td>
<td>Wang2020_t1</td>
<td>42</td>
<td>91.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_2</td>
<td>Wang2020_t1</td>
<td>41</td>
<td>91.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_3</td>
<td>Wang2020_t1</td>
<td>43</td>
<td>91.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Helin_ADSPLAB_task1b_4</td>
<td>Wang2020_t1</td>
<td>44</td>
<td>91.3</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_1</td>
<td>Hu2020</td>
<td>7</td>
<td>95.8</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_2</td>
<td>Hu2020</td>
<td>10</td>
<td>95.5</td>
<td></td>
<td></td>
<td>CNN, MobileNet, ensemble</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_3</td>
<td>Hu2020</td>
<td>3</td>
<td>96.0</td>
<td></td>
<td></td>
<td>CNN, MobileNet, ensemble</td>
<td>2</td>
<td>logistical regression</td>
</tr>
<tr>
<td></td>
<td>Hu_GT_task1b_4</td>
<td>Hu2020</td>
<td>5</td>
<td>95.8</td>
<td></td>
<td></td>
<td>CNN, ensemble</td>
<td>2</td>
<td>logistical regression</td>
</tr>
<tr>
<td></td>
<td>Kalinowski_SRPOL_task1b_4</td>
<td>Kalinowski2020</td>
<td>31</td>
<td>93.1</td>
<td></td>
<td></td>
<td>CNN, VGG</td>
<td></td>
<td>softmax</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_1</td>
<td>Koutini2020</td>
<td>16</td>
<td>94.7</td>
<td></td>
<td></td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_2</td>
<td>Koutini2020</td>
<td>1</td>
<td>96.5</td>
<td></td>
<td></td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_3</td>
<td>Koutini2020</td>
<td>8</td>
<td>95.7</td>
<td></td>
<td></td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1b_4</td>
<td>Koutini2020</td>
<td>2</td>
<td>96.2</td>
<td></td>
<td></td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kowaleczko_SRPOL_task1b_3</td>
<td>Kalinowski2020</td>
<td>52</td>
<td>90.1</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td>softmax</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_1</td>
<td>Kalinowski2020</td>
<td>36</td>
<td>92.6</td>
<td></td>
<td></td>
<td>CNN, ensemble</td>
<td>2</td>
<td>soft voting</td>
</tr>
<tr>
<td></td>
<td>Kwiatkowska_SRPOL_task1b_2</td>
<td>Kalinowski2020</td>
<td>27</td>
<td>93.5</td>
<td></td>
<td></td>
<td>CNN, ensemble</td>
<td>2</td>
<td>soft voting</td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_1</td>
<td>Pham2020</td>
<td>59</td>
<td>89.4</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_2</td>
<td>Pham2020</td>
<td>71</td>
<td>87.0</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>LamPham_Kent_task1b_3</td>
<td>Pham2020</td>
<td>79</td>
<td>84.7</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_1</td>
<td>Lee2020</td>
<td>47</td>
<td>90.7</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_2</td>
<td>Lee2020</td>
<td>23</td>
<td>93.9</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_3</td>
<td>Lee2020</td>
<td>46</td>
<td>91.1</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lee_CAU_task1b_4</td>
<td>Lee2020</td>
<td>45</td>
<td>91.2</td>
<td></td>
<td></td>
<td>Multi-input model, ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_1</td>
<td>Lopez-Meyer2020_t1b</td>
<td>50</td>
<td>90.4</td>
<td>directly</td>
<td>Audioset</td>
<td>CNN</td>
<td></td>
<td>maximum softmax</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_2</td>
<td>Lopez-Meyer2020_t1b</td>
<td>53</td>
<td>90.1</td>
<td>directly</td>
<td>Audioset</td>
<td>CNN</td>
<td></td>
<td>maximum softmax</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_3</td>
<td>Lopez-Meyer2020_t1b</td>
<td>49</td>
<td>90.5</td>
<td>directly</td>
<td>Audioset</td>
<td>CNN</td>
<td></td>
<td>maximum softmax</td>
</tr>
<tr>
<td></td>
<td>Lopez-Meyer_IL_task1b_4</td>
<td>Lopez-Meyer2020_t1b</td>
<td>56</td>
<td>89.7</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td>maximum softmax</td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_1</td>
<td>McDonnell2020</td>
<td>13</td>
<td>94.9</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_2</td>
<td>McDonnell2020</td>
<td>9</td>
<td>95.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_3</td>
<td>McDonnell2020</td>
<td>4</td>
<td>95.9</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>McDonnell_USA_task1b_4</td>
<td>McDonnell2020</td>
<td>6</td>
<td>95.8</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Monteiro_INRS_task1b_1</td>
<td>Joao2020</td>
<td>69</td>
<td>87.4</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_1</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>24</td>
<td>93.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_Vfy_task1b_2</td>
<td>Naranjo-Alcazar2020_t1</td>
<td>25</td>
<td>93.6</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_1</td>
<td>Nguyen_Hong_Duc2020</td>
<td>32</td>
<td>93.1</td>
<td>directly</td>
<td></td>
<td>CNN, GRU, MLP</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>NguyenHongDuc_SU_task1b_2</td>
<td>Nguyen_Hong_Duc2020</td>
<td>37</td>
<td>92.3</td>
<td>directly</td>
<td></td>
<td>CNN, GRU, MLP</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_1</td>
<td>Ooi2020</td>
<td>67</td>
<td>87.8</td>
<td></td>
<td></td>
<td>VGGNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_2</td>
<td>Ooi2020</td>
<td>70</td>
<td>87.3</td>
<td></td>
<td></td>
<td>InceptionNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_3</td>
<td>Ooi2020</td>
<td>55</td>
<td>89.8</td>
<td></td>
<td></td>
<td>VGGNet, InceptionNet, ensemble</td>
<td>6</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Ooi_NTU_task1b_4</td>
<td>Ooi2020</td>
<td>54</td>
<td>89.8</td>
<td></td>
<td></td>
<td>VGGNet, InceptionNet, ensemble</td>
<td>6</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Paniagua_UPM_task1b_1</td>
<td>Paniagua2020</td>
<td>60</td>
<td>89.4</td>
<td></td>
<td></td>
<td>MLP</td>
<td></td>
<td>average log-likelihood</td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_1</td>
<td>Patki2020</td>
<td>76</td>
<td>86.0</td>
<td>embeddings</td>
<td></td>
<td>SVM</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_2</td>
<td>Patki2020</td>
<td>61</td>
<td>89.4</td>
<td>embeddings</td>
<td></td>
<td>SVM</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Patki_SELF_task1b_3</td>
<td>Patki2020</td>
<td>82</td>
<td>83.7</td>
<td>embeddings</td>
<td></td>
<td>SVM</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_1</td>
<td>Phan2020_t1</td>
<td>65</td>
<td>88.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_2</td>
<td>Phan2020_t1</td>
<td>62</td>
<td>89.2</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_3</td>
<td>Phan2020_t1</td>
<td>63</td>
<td>89.0</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1b_4</td>
<td>Phan2020_t1</td>
<td>58</td>
<td>89.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task1b_1</td>
<td>Sampathkumar2020</td>
<td>68</td>
<td>87.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_1</td>
<td>Singh2020</td>
<td>81</td>
<td>84.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_2</td>
<td>Singh2020</td>
<td>80</td>
<td>84.7</td>
<td>pre-trained weights of SoundNet</td>
<td></td>
<td>CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_3</td>
<td>Singh2020</td>
<td>78</td>
<td>85.2</td>
<td>pre-trained weights of SoundNet for initilization</td>
<td>SoundNet</td>
<td>CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1b_4</td>
<td>Singh2020</td>
<td>75</td>
<td>86.4</td>
<td>pre-trained weights of SoundNet</td>
<td>SoundNet</td>
<td>CNN</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_1</td>
<td>Suh2020</td>
<td>29</td>
<td>93.3</td>
<td></td>
<td></td>
<td>CNN(Inception)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_2</td>
<td>Suh2020</td>
<td>18</td>
<td>94.6</td>
<td></td>
<td></td>
<td>CNN(Inception)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_3</td>
<td>Suh2020</td>
<td>11</td>
<td>95.1</td>
<td></td>
<td></td>
<td>CNN(Inception)</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Suh_ETRI_task1b_4</td>
<td>Suh2020</td>
<td>17</td>
<td>94.6</td>
<td></td>
<td></td>
<td>CNN(Inception)</td>
<td>2</td>
<td>weighted score average</td>
</tr>
<tr>
<td></td>
<td>Vilouras_AUTh_task1b_1</td>
<td>Vilouras2020</td>
<td>40</td>
<td>91.8</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Waldekar_IITKGP_task1b_1</td>
<td>Waldekar2020</td>
<td>64</td>
<td>88.6</td>
<td></td>
<td></td>
<td>SVM</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_1</td>
<td>Wu2020_t1b</td>
<td>22</td>
<td>94.2</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_2</td>
<td>Wu2020_t1b</td>
<td>21</td>
<td>94.2</td>
<td></td>
<td></td>
<td>CNN</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_3</td>
<td>Wu2020_t1b</td>
<td>20</td>
<td>94.3</td>
<td></td>
<td></td>
<td>CNN</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Wu_CUHK_task1b_4</td>
<td>Wu2020_t1b</td>
<td>14</td>
<td>94.9</td>
<td></td>
<td></td>
<td>CNN</td>
<td>3</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_1</td>
<td>Haocong2020</td>
<td>38</td>
<td>92.1</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_2</td>
<td>Haocong2020</td>
<td>28</td>
<td>93.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_3</td>
<td>Haocong2020</td>
<td>26</td>
<td>93.5</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_UESTC_task1b_4</td>
<td>Haocong2020</td>
<td>51</td>
<td>90.4</td>
<td></td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_1</td>
<td>Zhang2020</td>
<td>39</td>
<td>92.0</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_2</td>
<td>Zhang2020</td>
<td>35</td>
<td>92.7</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_3</td>
<td>Zhang2020</td>
<td>34</td>
<td>92.9</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT_task1b_4</td>
<td>Zhang2020</td>
<td>33</td>
<td>93.0</td>
<td></td>
<td></td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_1</td>
<td>Zhao2020</td>
<td>74</td>
<td>86.6</td>
<td>embeddings</td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_JNU_task1b_2</td>
<td>Zhao2020</td>
<td>72</td>
<td>86.9</td>
<td>embeddings</td>
<td></td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2020/technical_reports_task1b.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Chang2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Chang2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        QTI Submission to DCASE 2020: Model Efficient Acoustic Scene
       </h4>
<p style="text-align:left">
        Simyung Chang, Janghoon Cho, Hyoungwoo Park, Hyunsin Park, Sungrack Yun and Kyuwoong Hwang
       </p>
<p style="text-align:left">
<em>
         Qualcomm AI Research, Qualcomm Korea YH, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Chang_QTI_task1b_1</span> <span class="label label-info">Chang_QTI_task1b_2</span> <span class="label label-info">Chang_QTI_task1b_3</span> <span class="label label-info">Chang_QTI_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Chang2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Chang2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Chang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Chang_46.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Chang2020" class="panel-collapse collapse" id="collapse-Chang2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       QTI Submission to DCASE 2020: Model Efficient Acoustic Scene
      </h4>
<p style="text-align:left">
<small>
        Simyung Chang, Janghoon Cho, Hyoungwoo Park, Hyunsin Park, Sungrack Yun and Kyuwoong Hwang
       </small>
<br/>
<small>
<em>
         Qualcomm AI Research, Qualcomm Korea YH, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the details of our submission (QAIR teamâ€™s submission) for Task1B of the DCASE 2020 challenge. In this report, we introduce three methods for the efficient acoustic scene classification with low model complexity. First, inspired by CutMix which is proposed for image recognition tasks, we consider FreqMix for the data augmentation of mixing specific frequency bands of two different samples instead of cutting and pasting box patches. Second, as a novel feature normalization, we consider SubSpectral Normalization, which can reduce the correlation between the sub-spectral groups by performing the normalization on each separated group. Last, to reduce the number of model parameters, we propose a Shared Residual architecture where the weights of all layers (except the normalization layer) are shared. All submission models were trained without any external data, and our model is not based on an ensemble of multiple models but a single model to satisfy the model complexity condition.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup+FreqMix
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         perceptual weighted power spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         sparsity
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Chang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Chang_46.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Chang2020label" class="modal fade" id="bibtex-Chang2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChang2020label">
        QTI Submission to DCASE 2020: Model Efficient Acoustic Scene
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Chang2020,
    Author = "Chang, Simyung and Cho, Janghoon and Park, Hyoungwoo and Park, Hyunsin and Yun, Sungrack and Hwang, Kyuwoong",
    title = "{QTI} Submission to {DCASE} 2020: Model Efficient Acoustic Scene",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the details of our submission (QAIR teamâ€™s submission) for Task1B of the DCASE 2020 challenge. In this report, we introduce three methods for the efficient acoustic scene classification with low model complexity. First, inspired by CutMix which is proposed for image recognition tasks, we consider FreqMix for the data augmentation of mixing specific frequency bands of two different samples instead of cutting and pasting box patches. Second, as a novel feature normalization, we consider SubSpectral Normalization, which can reduce the correlation between the sub-spectral groups by performing the normalization on each separated group. Last, to reduce the number of model parameters, we propose a Shared Residual architecture where the weights of all layers (except the normalization layer) are shared. All submission models were trained without any external data, and our model is not based on an ensemble of multiple models but a single model to satisfy the model complexity condition."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Dat2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Dat2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CNN-Based Framework for DCASE 2020 Task 1B Challenge
       </h4>
<p style="text-align:left">
        Ngo Dat, Pham Lam, Nguyen Anh and Hoang Hao
       </p>
<p style="text-align:left">
<em>
         Electrical &amp; Electronic Engineering, Ho Chi Minh University of Technology, Ho Chi Minh, Vietnam
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Dat_HCMUni_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Dat2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Dat2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Dat2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_HCM_60.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Dat2020" class="panel-collapse collapse" id="collapse-Dat2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CNN-Based Framework for DCASE 2020 Task 1B Challenge
      </h4>
<p style="text-align:left">
<small>
        Ngo Dat, Pham Lam, Nguyen Anh and Hoang Hao
       </small>
<br/>
<small>
<em>
         Electrical &amp; Electronic Engineering, Ho Chi Minh University of Technology, Ho Chi Minh, Vietnam
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report presents a low-complexity CNN-based deep learning framework for acoustic scene classification. Particularly, the proposed architecture constitute of two main steps front-end feature extraction and back-end network. Firstly, spectrogram representation is approached as front-end feature extraction in this framework. Next, the spectrograms extracted are fed into a CNN-based architecture for classification. Obtained experimental results conducted over the DCASE 2020 Task 1B dataset improve DCASE baseline by 7.2%.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left, right, average of left+right
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Random oversample &amp; mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Gammatone energy
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Dat2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_HCM_60.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Dat2020label" class="modal fade" id="bibtex-Dat2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexDat2020label">
        CNN-Based Framework for DCASE 2020 Task 1B Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Dat2020,
    Author = "Dat, Ngo and Lam, Pham and Anh, Nguyen and Hao, Hoang",
    title = "{CNN}-Based Framework for {DCASE} 2020 Task {1B} Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report presents a low-complexity CNN-based deep learning framework for acoustic scene classification. Particularly, the proposed architecture constitute of two main steps front-end feature extraction and back-end network. Firstly, spectrogram representation is approached as front-end feature extraction in this framework. Next, the spectrograms extracted are fed into a CNN-based architecture for classification. Obtained experimental results conducted over the DCASE 2020 Task 1B dataset improve DCASE baseline by 7.2\%."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Feng2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Feng2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Based on Lightweight CNN with Efficient Convolutions
       </h4>
<p style="text-align:left">
        Guoqing Feng, Jinhua Liang and Biyun Ding
       </p>
<p style="text-align:left">
<em>
         School of Electrical and Information Engineering, Tianjin University, Tianjin, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Feng_TJU_task1b_1</span> <span class="label label-info">Feng_TJU_task1b_2</span> <span class="label label-info">Feng_TJU_task1b_3</span> <span class="label label-info">Feng_TJU_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Feng2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Feng2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Feng2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Feng_12.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Feng2020" class="panel-collapse collapse" id="collapse-Feng2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Based on Lightweight CNN with Efficient Convolutions
      </h4>
<p style="text-align:left">
<small>
        Guoqing Feng, Jinhua Liang and Biyun Ding
       </small>
<br/>
<small>
<em>
         School of Electrical and Information Engineering, Tianjin University, Tianjin, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report is for the Task 1B Acoustic scene classification of the IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). Targeting low complexity solutions for the classification problem in term of model size, a kind of lightweight Convolutional Neural Network (CNN) with efficient convolutions is designed. The network is constructed by the improved bottleneck block based on the inverted residual linear bottleneck block. In the improved bottleneck block, the operations of Detpthwise Channel Ascent (DCA) and Group Channel Descent (GCD) are used to replace pointwise convolution to realize efficient channel transformation. The designed network is denoted by CNN-BDG in this report. CNN-BDF realizes a better performance which is 4.46% higher than the baseline model in the validation set. Besides, the parameters are reduced to about 30% compared to the baseline model.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         same class mix
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         optimize the convolution operation and the network structure
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Feng2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Feng_12.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Feng2020label" class="modal fade" id="bibtex-Feng2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexFeng2020label">
        Acoustic Scene Classification Based on Lightweight CNN with Efficient Convolutions
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Feng2020,
    Author = "Feng, Guoqing and Liang, Jinhua and Ding, Biyun",
    title = "Acoustic Scene Classification Based on Lightweight {CNN} with Efficient Convolutions",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report is for the Task 1B Acoustic scene classification of the IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). Targeting low complexity solutions for the classification problem in term of model size, a kind of lightweight Convolutional Neural Network (CNN) with efficient convolutions is designed. The network is constructed by the improved bottleneck block based on the inverted residual linear bottleneck block. In the improved bottleneck block, the operations of Detpthwise Channel Ascent (DCA) and Group Channel Descent (GCD) are used to replace pointwise convolution to realize efficient channel transformation. The designed network is denoted by CNN-BDG in this report. CNN-BDF realizes a better performance which is 4.46\% higher than the baseline model in the validation set. Besides, the parameters are reduced to about 30\% compared to the baseline model."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Haocong2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Haocong2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification Using Primary Ambient Extraction and Cyclegan
       </h4>
<p style="text-align:left">
        Yang Haocong, Shi Chuang and Li Huiyong
       </p>
<p style="text-align:left">
<em>
         Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Yang_UESTC_task1b_1</span> <span class="label label-info">Yang_UESTC_task1b_2</span> <span class="label label-info">Yang_UESTC_task1b_3</span> <span class="label label-info">Yang_UESTC_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Haocong2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Haocong2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Haocong2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Yang_59.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Haocong2020" class="panel-collapse collapse" id="collapse-Haocong2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification Using Primary Ambient Extraction and Cyclegan
      </h4>
<p style="text-align:left">
<small>
        Yang Haocong, Shi Chuang and Li Huiyong
       </small>
<br/>
<small>
<em>
         Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our submissions for DCASE2020 Challenge task 1b (Low-Complexity Acoustic Scene Classification). In each submission, constant-Q transform is used as acoustic feature, and the corresponding classifier is a full convolution neural network based on residual blocks. The classifier parameters use half-precision (16 bit) float-point number to limit the model size and accelerate training. We use primary ambient extraction in the audio front-end processing, and generate virtual samples according to the phase information of binaural audio. These virtual samples will be used for one of the submissions. We also used the virtual samples generated by CycleGAN for another submission. Finally, we give a 4-fold cross validation submission that meets the complexity limit. The highest macro recognition accuracy of the above methods in the development dataset is 96.05%, and the log loss is 0.120.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural; mixed
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         CQT
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Haocong2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Yang_59.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Haocong2020label" class="modal fade" id="bibtex-Haocong2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHaocong2020label">
        Low-Complexity Acoustic Scene Classification Using Primary Ambient Extraction and Cyclegan
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Haocong2020,
    Author = "Haocong, Yang and Chuang, Shi and Huiyong, Li",
    title = "Low-Complexity Acoustic Scene Classification Using Primary Ambient Extraction and Cyclegan",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes our submissions for DCASE2020 Challenge task 1b (Low-Complexity Acoustic Scene Classification). In each submission, constant-Q transform is used as acoustic feature, and the corresponding classifier is a full convolution neural network based on residual blocks. The classifier parameters use half-precision (16 bit) float-point number to limit the model size and accelerate training. We use primary ambient extraction in the audio front-end processing, and generate virtual samples according to the phase information of binaural audio. These virtual samples will be used for one of the submissions. We also used the virtual samples generated by CycleGAN for another submission. Finally, we give a 4-fold cross validation submission that meets the complexity limit. The highest macro recognition accuracy of the above methods in the development dataset is 96.05\%, and the log loss is 0.120."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Hu2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Hu2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
       </h4>
<p style="text-align:left">
        Hu Hu<sup>1</sup>, Chao-Han Huck Yang<sup>1</sup>, Xianjun Xia<sup>2</sup>, Xue Bai<sup>3</sup>, Xin Tang<sup>3</sup>, Yajian Wang<sup>3</sup>, Shutong Niu<sup>3</sup>, Li Chai<sup>3</sup>, Juanjuan Li<sup>2</sup>, Hongning Zhu<sup>2</sup>, Feng Bao<sup>4</sup>, Yuanjun Zhao<sup>2</sup>, Sabato Marco Siniscalchi<sup>5</sup>, Yannan Wang<sup>2</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA, <sup>2</sup>Tencent Media Lab, Shenzhen, China, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Beijing, China, <sup>5</sup>Computer Engineering School, University of Enna Kore, Italy
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Hu_GT_task1b_1</span> <span class="label label-info">Hu_GT_task1b_2</span> <span class="label label-info">Hu_GT_task1b_3</span> <span class="label label-info">Hu_GT_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Hu2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Hu2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Hu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Hu_114.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Hu2020').collapse('show');window.location.hash='#Hu2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Hu2020" class="panel-collapse collapse" id="collapse-Hu2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
      </h4>
<p style="text-align:left">
<small>
        Hu Hu<sup>1</sup>, Chao-Han Huck Yang<sup>1</sup>, Xianjun Xia<sup>2</sup>, Xue Bai<sup>3</sup>, Xin Tang<sup>3</sup>, Yajian Wang<sup>3</sup>, Shutong Niu<sup>3</sup>, Li Chai<sup>3</sup>, Juanjuan Li<sup>2</sup>, Hongning Zhu<sup>2</sup>, Feng Bao<sup>4</sup>, Yuanjun Zhao<sup>2</sup>, Sabato Marco Siniscalchi<sup>5</sup>, Yannan Wang<sup>2</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA, <sup>2</sup>Tencent Media Lab, Shenzhen, China, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Beijing, China, <sup>5</sup>Computer Engineering School, University of Enna Kore, Italy
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we present a joint effort of four groups, namely GT, USTC, Tencent, and UKE, to tackle Task 1 - Acoustic Scene Classification (ASC) in the DCASE 2020 Challenge. Task 1 comprises two different sub-tasks: (i) Task 1a focuses on ASC of audio signals recorded with multiple (real and simulated) devices into ten different fine-grained classes, and (ii) Task 1b concerns with classification of data into three higher-level classes using lowcomplexity solutions. For Task 1a, we propose a novel two-stage ASC system leveraging upon ad-hoc score combination of two convolutional neural networks (CNNs), classifying the acoustic input according to three classes, and then ten classes, respectively. Four different CNN-based architectures are explored to implement the two-stage classifiers, and several data augmentation techniques are also investigated. For Task 1b, we leverage upon a quantization method to reduce the complexity of two of our top-accuracy three-classes CNN-based architectures. On Task 1a development data set, an ASC accuracy of 76.9% is attained using our best single classifier and data augmentation. An accuracy of 81.9% is then attained by a final model fusion of our two-stage ASC classifiers. On Task 1b development data set, we achieve an accuracy of 96.7% with a model size smaller than 500KB
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, channel confusion, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN; CNN, MobileNet, ensemble; CNN, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average; logistical regression
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         int8, quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Hu2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Hu_114.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/MihawkHu/DCASE2020_task1" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Hu2020label" class="modal fade" id="bibtex-Hu2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHu2020label">
        Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Hu2020,
    Author = "Hu, Hu and Yang, Chao-Han Huck and Xia, Xianjun and Bai, Xue and Tang, Xin and Wang, Yajian and Niu, Shutong and Chai, Li and Li, Juanjuan and Zhu, Hongning and Bao, Feng and Zhao, Yuanjun and Siniscalchi, Sabato Marco and Wang, Yannan and Du, Jun and Lee, Chin-Hui",
    title = "Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this technical report, we present a joint effort of four groups, namely GT, USTC, Tencent, and UKE, to tackle Task 1 - Acoustic Scene Classification (ASC) in the DCASE 2020 Challenge. Task 1 comprises two different sub-tasks: (i) Task 1a focuses on ASC of audio signals recorded with multiple (real and simulated) devices into ten different fine-grained classes, and (ii) Task 1b concerns with classification of data into three higher-level classes using lowcomplexity solutions. For Task 1a, we propose a novel two-stage ASC system leveraging upon ad-hoc score combination of two convolutional neural networks (CNNs), classifying the acoustic input according to three classes, and then ten classes, respectively. Four different CNN-based architectures are explored to implement the two-stage classifiers, and several data augmentation techniques are also investigated. For Task 1b, we leverage upon a quantization method to reduce the complexity of two of our top-accuracy three-classes CNN-based architectures. On Task 1a development data set, an ASC accuracy of 76.9\% is attained using our best single classifier and data augmentation. An accuracy of 81.9\% is then attained by a final model fusion of our two-stage ASC classifiers. On Task 1b development data set, we achieve an accuracy of 96.7\% with a model size smaller than 500KB"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Joao2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Joao2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
       </h4>
<p style="text-align:left">
        Monteiro Joao, Shruti Kshirsagar, Anderson Avila, Amr Aaballah, Parth Tiwari and Tiago Falk
       </p>
<p style="text-align:left">
<em>
         EMT, Institut National de la Recherche Scientifique, Montreal, Canada
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Monteiro_INRS_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Joao2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Joao2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Joao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Montreiro_73.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Joao2020').collapse('show');window.location.hash='#Joao2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Joao2020" class="panel-collapse collapse" id="collapse-Joao2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
      </h4>
<p style="text-align:left">
<small>
        Monteiro Joao, Shruti Kshirsagar, Anderson Avila, Amr Aaballah, Parth Tiwari and Tiago Falk
       </small>
<br/>
<small>
<em>
         EMT, Institut National de la Recherche Scientifique, Montreal, Canada
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report we provide a brief overview of a set of submissions for the scene classification sub-tasks of the 2020 edition of the DCASE challenge. Our submissions comprise efforts at the feature representation level, where we explored the use of modulation spectra and i-vectors (extracted from mel cepstral coefficients, as well as modulation spectra) and modeling strategies, where recent convolutional deep neural network models were used. Results on the Challenge validation set show several of the submitted methods outperforming the baseline model.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         Sox distortions, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Joao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Montreiro_73.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/joaomonteirof/dcase" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Joao2020label" class="modal fade" id="bibtex-Joao2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJoao2020label">
        Development of the INRS-EMT Scene Classification Systems for the 2020 Edition of the DCASE Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Joao2020,
    Author = "Joao, Monteiro and Kshirsagar, Shruti and Avila, Anderson and Aaballah, Amr and Tiwari, Parth and Falk, Tiago",
    title = "Development of the {INRS-EMT} Scene Classification Systems for the 2020 Edition of the {DCASE} Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this report we provide a brief overview of a set of submissions for the scene classification sub-tasks of the 2020 edition of the DCASE challenge. Our submissions comprise efforts at the feature representation level, where we explored the use of modulation spectra and i-vectors (extracted from mel cepstral coefficients, as well as modulation spectra) and modeling strategies, where recent convolutional deep neural network models were used. Results on the Challenge validation set show several of the submitted methods outperforming the baseline model."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kalinowski2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Kalinowski2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification with Small Convolutional Neural Networks and Curriculum Learning
       </h4>
<p style="text-align:left">
        Beniamin Kalinowski
       </p>
<p style="text-align:left">
<em>
         Audio Intelligence, Samsung R&amp;D Poland, Warsaw, Poland
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Kalinowski_SRPOL_task1b_4</span> <span class="label label-info">Kowaleczko_SRPOL_task1b_3</span> <span class="label label-info">Kwiatkowska_SRPOL_task1b_1</span> <span class="label label-info">Kwiatkowska_SRPOL_task1b_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kalinowski2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kalinowski2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kalinowski2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Kalinowski_141.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kalinowski2020" class="panel-collapse collapse" id="collapse-Kalinowski2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification with Small Convolutional Neural Networks and Curriculum Learning
      </h4>
<p style="text-align:left">
<small>
        Beniamin Kalinowski
       </small>
<br/>
<small>
<em>
         Audio Intelligence, Samsung R&amp;D Poland, Warsaw, Poland
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The report presents the results of submission to Task 1B of Detection and Classification of Acoustic Scenes and Events Challenge (DCASE) 2020. Main issue in this task was size limitation of 500 KB for each of submitted models. Such limitations are important when model ought to be implemented on device with low memory size. For this task four different models based on convolutional neural networks were developed, varying from data preprocessing methods, data architectures etc. Crucial techniques used in complexity management were curriculum learning and the use of depth-wise and separable convolutions, along with ensembling models trained on 3 and 10 classes for performance preservation. Best models improved baseline by 10% increase in accuracy and by 60% decrease in log-loss.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time warping, frequency warping, loudness control, time length control, time masking, frequency masking; mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel spectrogram; log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, VGG; CNN; CNN, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         softmax; soft voting
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         using rectangular convolution kernels; constraints-aware modelling
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kalinowski2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Kalinowski_141.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kalinowski2020label" class="modal fade" id="bibtex-Kalinowski2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKalinowski2020label">
        Low-Complexity Acoustic Scene Classification with Small Convolutional Neural Networks and Curriculum Learning
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kalinowski2020,
    Author = "Kalinowski, Beniamin",
    title = "Low-Complexity Acoustic Scene Classification with Small Convolutional Neural Networks and Curriculum Learning",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "The report presents the results of submission to Task 1B of Detection and Classification of Acoustic Scenes and Events Challenge (DCASE) 2020. Main issue in this task was size limitation of 500 KB for each of submitted models. Such limitations are important when model ought to be implemented on device with low memory size. For this task four different models based on convolutional neural networks were developed, varying from data preprocessing methods, data architectures etc. Crucial techniques used in complexity management were curriculum learning and the use of depth-wise and separable convolutions, along with ensembling models trained on 3 and 10 classes for performance preservation. Best models improved baseline by 10\% increase in accuracy and by 60\% decrease in log-loss."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Koutini2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Koutini2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CP-JKU Submissions to DCASEâ€™20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
       </h4>
<p style="text-align:left">
        Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh and Gerhard Widmer
       </p>
<p style="text-align:left">
<em>
         Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Koutini_CPJKU_task1b_1</span> <span class="label label-info">Koutini_CPJKU_task1b_2</span> <span class="label label-info">Koutini_CPJKU_task1b_3</span> <span class="label label-info">Koutini_CPJKU_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Koutini2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Koutini2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Koutini2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Koutini_142.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Koutini2020').collapse('show');window.location.hash='#Koutini2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Koutini2020" class="panel-collapse collapse" id="collapse-Koutini2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CP-JKU Submissions to DCASEâ€™20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
      </h4>
<p style="text-align:left">
<small>
        Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh and Gerhard Widmer
       </small>
<br/>
<small>
<em>
         Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the CP-JKU teamâ€™s submission for Task 1 - Subtask A (Acoustic Scene Classification with Multiple Devices) and Subtask B (Low-Complexity Acoustic Scene Classification) of the DCASE-2020 challenge. For Subtask 1A, we provide our Receptive Field (RF) regularized CNN model as a baseline, and additionally explore the use of two different domain adaption objectives in the form of the Maximum Mean Discrepancy (MMD) and the Sliced Wasserstein Distance (SWD). For Subtask 1B, we investigate different parameter reduction methods such as Pruning and Knowledge Distillation (KD). Additionally, we incorporate a decomposed convolutional layer that reduces the number of nonezero parameters in our models while only slightly decreasing the accuracy compared to full-parameter baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         stereo
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Perceptually-weighted log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RF-regularized CNNs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16, conv layers decomposition; pruning, float16; float16, smaller width/depth
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Koutini2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Koutini_142.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/kkoutini/cpjku_dcase19" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Koutini2020label" class="modal fade" id="bibtex-Koutini2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKoutini2020label">
        CP-JKU Submissions to DCASEâ€™20: Low-Complexity Cross-Device Acoustic Scene Classification with RF-Regularized CNNs
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Koutini2020,
    Author = "Koutini, Khaled and Henkel, Florian and Eghbal-zadeh, Hamid and Widmer, Gerhard",
    title = "{CP-JKU} Submissions to {DCASEâ€™20}: Low-Complexity Cross-Device Acoustic Scene Classification with {RF}-Regularized {CNNs}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the CP-JKU teamâ€™s submission for Task 1 - Subtask A (Acoustic Scene Classification with Multiple Devices) and Subtask B (Low-Complexity Acoustic Scene Classification) of the DCASE-2020 challenge. For Subtask 1A, we provide our Receptive Field (RF) regularized CNN model as a baseline, and additionally explore the use of two different domain adaption objectives in the form of the Maximum Mean Discrepancy (MMD) and the Sliced Wasserstein Distance (SWD). For Subtask 1B, we investigate different parameter reduction methods such as Pruning and Knowledge Distillation (KD). Additionally, we incorporate a decomposed convolutional layer that reduces the number of nonezero parameters in our models while only slightly decreasing the accuracy compared to full-parameter baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lee2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Lee2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
       </h4>
<p style="text-align:left">
        Yerin Lee<sup>1</sup>, Soyoung Lim<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Statistics, Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Lee_CAU_task1b_1</span> <span class="label label-info">Lee_CAU_task1b_2</span> <span class="label label-info">Lee_CAU_task1b_3</span> <span class="label label-info">Lee_CAU_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lee2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lee2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lee2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_143.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lee2020" class="panel-collapse collapse" id="collapse-Lee2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
      </h4>
<p style="text-align:left">
<small>
        Yerin Lee<sup>1</sup>, Soyoung Lim<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Statistics, Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The acoustic scenry classification problem is an interesting topic that has been studied for a long time through the DCASE competition. This technical report presents the CAU-ETâ€™s submitted scenery detection system to the DCASE 2020 challenge, Task 1. In our method we generate mel-spectrogram from audio. From log-mel spectrogram, we got Deltas, Delta-deltas and Harmonic-percussive source seperation(HPSS) feature as inputs of our deep neural network models. The classification result of the proposed system was 66.26% for development dataset in subtask A and 95.27% in subtask B
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas; HPSS; HPSS, log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; Multi-input model, ResNet
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lee2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lee_143.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lee2020label" class="modal fade" id="bibtex-Lee2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLee2020label">
        The CAU-ET Acoustic Scenery Classification System for DCASE 2020 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lee2020,
    Author = "Lee, Yerin and Lim, Soyoung and Kwak, Il-Youp",
    title = "The {CAU-ET} Acoustic Scenery Classification System for {DCASE} 2020 Challenge",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "The acoustic scenry classification problem is an interesting topic that has been studied for a long time through the DCASE competition. This technical report presents the CAU-ETâ€™s submitted scenery detection system to the DCASE 2020 challenge, Task 1. In our method we generate mel-spectrogram from audio. From log-mel spectrogram, we got Deltas, Delta-deltas and Harmonic-percussive source seperation(HPSS) feature as inputs of our deep neural network models. The classification result of the proposed system was 66.26\% for development dataset in subtask A and 95.27\% in subtask B"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lopez-Meyer2020_t1b" style="box-shadow: none">
<div class="panel-heading" id="heading-Lopez-Meyer2020_t1b" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Memory Convolutional Neural Networks for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Paulo Lopez-Meyer<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>1</sup>, Hong Lu<sup>2</sup>, Hector Alfonso Cordourier Maruri<sup>1</sup>, Georg Stemmer<sup>3</sup>, Lama Nachman<sup>2</sup> and Jonathan Huang<sup>4</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, California, USA, <sup>3</sup>Intel Labs, Intel Corporation, Neubiberg, Germany, <sup>4</sup>California, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Lopez-Meyer_IL_task1b_1</span> <span class="label label-info">Lopez-Meyer_IL_task1b_2</span> <span class="label label-info">Lopez-Meyer_IL_task1b_3</span> <span class="label label-info">Lopez-Meyer_IL_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lopez-Meyer2020_t1b" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lopez-Meyer2020_t1b" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lopez-Meyer2020_t1b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lopez-Meyer_228_t1b.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lopez-Meyer2020_t1b" class="panel-collapse collapse" id="collapse-Lopez-Meyer2020_t1b" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Memory Convolutional Neural Networks for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Paulo Lopez-Meyer<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>1</sup>, Hong Lu<sup>2</sup>, Hector Alfonso Cordourier Maruri<sup>1</sup>, Georg Stemmer<sup>3</sup>, Lama Nachman<sup>2</sup> and Jonathan Huang<sup>4</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, California, USA, <sup>3</sup>Intel Labs, Intel Corporation, Neubiberg, Germany, <sup>4</sup>California, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this work, we describe the implementation of four different convolutional neural networks for acoustic scene classification, complying with the memory size restrictions defined in the DCASE2020 Task 1b challenge guidelines. Quantization, pruning, knowledge distillation, and GCC-grams as input features, were explored as means to achieve the highest accuracy possible while reducing the number of resources in terms of the models trainable parameters and memory. Our experimental results yield to higher than the 87.30% reported accuracy in the challengeâ€™s baseline, where our four submissions managed to achieve &gt; 90.00% of acoustic classification accuracy using CNN models with &lt; 500 KB .
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono; binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz; 48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         random noise, random gain, random cropping, mixup; SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         raw waveform; mel filterbank; log-mel filterbanks, GCC-grams
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         maximum softmax
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         quantization; pruning, quantization; knowledge distillation, quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lopez-Meyer2020_t1b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Lopez-Meyer_228_t1b.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lopez-Meyer2020_t1blabel" class="modal fade" id="bibtex-Lopez-Meyer2020_t1b" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLopez-Meyer2020_t1blabel">
        Low-Memory Convolutional Neural Networks for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lopez-Meyer2020_t1b,
    Author = "Lopez-Meyer, Paulo and Del Hoyo Ontiveros, Juan Antonio and Lu, Hong and Cordourier Maruri, Hector Alfonso and Stemmer, Georg and Nachman, Lama and Huang, Jonathan",
    title = "Low-Memory Convolutional Neural Networks for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this work, we describe the implementation of four different convolutional neural networks for acoustic scene classification, complying with the memory size restrictions defined in the DCASE2020 Task 1b challenge guidelines. Quantization, pruning, knowledge distillation, and GCC-grams as input features, were explored as means to achieve the highest accuracy possible while reducing the number of resources in terms of the models trainable parameters and memory. Our experimental results yield to higher than the 87.30\% reported accuracy in the challengeâ€™s baseline, where our four submissions managed to achieve &gt; 90.00\% of acoustic classification accuracy using CNN models with &lt; 500 KB ."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="McDonnell2020" style="box-shadow: none">
<div class="panel-heading" id="heading-McDonnell2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification Using One-Bit-Per-Weight Deep Convolutional Neural Networks
       </h4>
<p style="text-align:left">
        Mark McDonnell
       </p>
<p style="text-align:left">
<em>
         Computational Learning Systems Laboratory, University of South Australia, Mawson Lakes, Australia
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">McDonnell_USA_task1b_1</span> <span class="label label-info">McDonnell_USA_task1b_2</span> <span class="label label-info">McDonnell_USA_task1b_3</span> <span class="label label-info">McDonnell_USA_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-McDonnell2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-McDonnell2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-McDonnell2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_McDonnell_109.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-McDonnell2020').collapse('show');window.location.hash='#McDonnell2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-McDonnell2020" class="panel-collapse collapse" id="collapse-McDonnell2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification Using One-Bit-Per-Weight Deep Convolutional Neural Networks
      </h4>
<p style="text-align:left">
<small>
        Mark McDonnell
       </small>
<br/>
<small>
<em>
         Computational Learning Systems Laboratory, University of South Australia, Mawson Lakes, Australia
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes a submission to Task 1b (â€œLowComplexity Acoustic Scene Classificationâ€) in the DCASE2020 Acoustic Scene Challenge. Solutions for this task were required to be constrained to have parameters totalling no more than 500 KB. The strategy described in this report was to train a deep convolutional neural network applied to spectrograms formed from the acoustic scene files, such that each convolutional weight was set to one of two values following training, and hence could be stored using a single bit. This strategy allowed a single 36-layer all-convolutional deep neural network to be trained, consisting of a total of 3,987,000 binary weights, totalling 486.69KB. The model achieved a macro-average accuracy (balanced accuracy score) across the three classes of 96.6Â±0.5% on the 2020 DCASE Task 1b validation set.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left, right
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping, channel swapping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         1-bit quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-McDonnell2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_McDonnell_109.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/McDonnell-Lab/DCASE2020_Task1b" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-McDonnell2020label" class="modal fade" id="bibtex-McDonnell2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexMcDonnell2020label">
        Low-Complexity Acoustic Scene Classification Using One-Bit-Per-Weight Deep Convolutional Neural Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{McDonnell2020,
    Author = "McDonnell, Mark",
    title = "Low-Complexity Acoustic Scene Classification Using One-Bit-Per-Weight Deep Convolutional Neural Networks",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes a submission to Task 1b (â€œLowComplexity Acoustic Scene Classificationâ€) in the DCASE2020 Acoustic Scene Challenge. Solutions for this task were required to be constrained to have parameters totalling no more than 500 KB. The strategy described in this report was to train a deep convolutional neural network applied to spectrograms formed from the acoustic scene files, such that each convolutional weight was set to one of two values following training, and hence could be stored using a single bit. This strategy allowed a single 36-layer all-convolutional deep neural network to be trained, consisting of a total of 3,987,000 binary weights, totalling 486.69KB. The model achieved a macro-average accuracy (balanced accuracy score) across the three classes of 96.6Â±0.5\% on the 2020 DCASE Task 1b validation set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Naranjo-Alcazar2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Naranjo-Alcazar2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
       </h4>
<p style="text-align:left">
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>3</sup>, Pedro Zuccarello<sup>3</sup> and Maximo Cobos<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>AI department, Visualfy, Benisano, Spain, <sup>2</sup>Computer Science Department, Universitat de Valencia, Burjassot, Spain, <sup>3</sup>AI department, Visualfy, Benisano, Valencia
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Naranjo-Alcazar_Vfy_task1b_1</span> <span class="label label-info">Naranjo-Alcazar_Vfy_task1b_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Naranjo-Alcazar2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Naranjo-Alcazar2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Naranjo-Alcazar2020_t1" class="panel-collapse collapse" id="collapse-Naranjo-Alcazar2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
      </h4>
<p style="text-align:left">
<small>
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>3</sup>, Pedro Zuccarello<sup>3</sup> and Maximo Cobos<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>AI department, Visualfy, Benisano, Spain, <sup>2</sup>Computer Science Department, Universitat de Valencia, Burjassot, Spain, <sup>3</sup>AI department, Visualfy, Benisano, Valencia
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Acoustic Scene Classification (ASC) is a problem related to the field of machine listening whose objective is to classify/tag an audio clip in a predefined label describing a scene location such as park, airport among others. Due to the emergence of more extensive audio datasets, solutions based on Deep Learning techniques have become the state-of-the-art. The most common choice are those that implement a convolutional neural network (CNN) having previously transformed the audio signal into a 2D representation. This twodimensional audio representation is currently a subject of research. In addition, there are solutions that propose several concatenated 2D representations, thus creating a representation with several input channels. This article proposes two novel stereo audio representations to maximize the accuracy of an ASC framework. These representations correspond to the 3-channel representations such as the left channel, the right channel and the difference between channels (L âˆ’ R) using the Gammatone filter bank and the harmonic, percussive and difference between channels sources using the Mel filter bank. Both representations are also concatenated creating a 6-channel with different audio filter banks. Furthermore, the proposed CNN is a residual network that employs squeeze-excitation techniques in its residual blocks in a novel way to force the network to extract meaningful features from the audio representation. The proposed network is used in both subtasks with different modifications to meet the requirements of each one. However, since stereo audio is not available in Subtask A, the representations are slightly modified in that task. This technical report first presents the overlaps of the two tasks and then makes the relevant changes to each task in one section per task. The baselines are surpassed in both tasks by approximately 10 percentage points.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left, right, difference; left, right, difference, mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         gammatone; gammatone, HPSS, log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Naranjo-Alcazar2020_t1label" class="modal fade" id="bibtex-Naranjo-Alcazar2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNaranjo-Alcazar2020_t1label">
        Task 1 DCASE 2020: ASC with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation CNNs
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Naranjo-Alcazar2020_t1,
    Author = "Naranjo-Alcazar, Javier and Perez-Castanos, Sergi and Zuccarello, Pedro and Cobos, Maximo",
    title = "Task 1 {DCASE} 2020: {ASC} with Mismatch Devices and Reduced Size Model Using Residual Squeeze-Excitation {CNNs}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "Acoustic Scene Classification (ASC) is a problem related to the field of machine listening whose objective is to classify/tag an audio clip in a predefined label describing a scene location such as park, airport among others. Due to the emergence of more extensive audio datasets, solutions based on Deep Learning techniques have become the state-of-the-art. The most common choice are those that implement a convolutional neural network (CNN) having previously transformed the audio signal into a 2D representation. This twodimensional audio representation is currently a subject of research. In addition, there are solutions that propose several concatenated 2D representations, thus creating a representation with several input channels. This article proposes two novel stereo audio representations to maximize the accuracy of an ASC framework. These representations correspond to the 3-channel representations such as the left channel, the right channel and the difference between channels (L âˆ’ R) using the Gammatone filter bank and the harmonic, percussive and difference between channels sources using the Mel filter bank. Both representations are also concatenated creating a 6-channel with different audio filter banks. Furthermore, the proposed CNN is a residual network that employs squeeze-excitation techniques in its residual blocks in a novel way to force the network to extract meaningful features from the audio representation. The proposed network is used in both subtasks with different modifications to meet the requirements of each one. However, since stereo audio is not available in Subtask A, the representations are slightly modified in that task. This technical report first presents the overlaps of the two tasks and then makes the relevant changes to each task in one section per task. The baselines are surpassed in both tasks by approximately 10 percentage points."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Nguyen_Hong_Duc2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Nguyen_Hong_Duc2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Long-Term and Fine-Scale Audio Representations
       </h4>
<p style="text-align:left">
        Paul Nguyen Hong Duc<sup>1</sup>, Dorian Cazau<sup>2</sup>, Olivier Adam<sup>3</sup>, Odile Gerard<sup>4</sup> and Paul R. White<sup>5</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institut dâ€™Alembert, Sorbonne Universite, Paris, France, <sup>2</sup>Lab-Sticc, ENSTA Bretagne, Brest, France, <sup>3</sup>Institut d'Alembert, Sorbonne UniversitÃ©, Paris, France, <sup>4</sup>Techniques Navales, DGA-TN, Toulon, France, <sup>5</sup>ISVR, University of Southampton, Southampton, United Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">NguyenHongDuc_SU_task1b_1</span> <span class="label label-info">NguyenHongDuc_SU_task1b_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Nguyen_Hong_Duc2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Nguyen_Hong_Duc2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Nguyen_Hong_Duc2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_NguyenHongDuc_106.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Nguyen_Hong_Duc2020" class="panel-collapse collapse" id="collapse-Nguyen_Hong_Duc2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Long-Term and Fine-Scale Audio Representations
      </h4>
<p style="text-align:left">
<small>
        Paul Nguyen Hong Duc<sup>1</sup>, Dorian Cazau<sup>2</sup>, Olivier Adam<sup>3</sup>, Odile Gerard<sup>4</sup> and Paul R. White<sup>5</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Institut dâ€™Alembert, Sorbonne Universite, Paris, France, <sup>2</sup>Lab-Sticc, ENSTA Bretagne, Brest, France, <sup>3</sup>Institut d'Alembert, Sorbonne UniversitÃ©, Paris, France, <sup>4</sup>Techniques Navales, DGA-TN, Toulon, France, <sup>5</sup>ISVR, University of Southampton, Southampton, United Kingdom
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Audio scene classification (ASC) is an emerging filed of research in different scientific communities such as urban soundscape characterization or bioacoustics. It has gained visibility and relevance with open challenges especially with the benchmark dataset and evaluation from DCASE. This paper present our deep learning model to address the ASC task of the DCASE 2020 challenge edition. The model exploits multiple long-term and fine-scale audio representations as inputs of the neural network. Each representation is fed into a different network. The audio embedding of each branch are fused before a Multi-Layer Perceptron to predict the final classes.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono, binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         RMS level, third-octave levels, Leq, interaural cross correlation coefficient, hardness, depth, brightness, roughness, warmth, sharpness, boominess, reverb, log-mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, GRU, MLP
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Nguyen_Hong_Duc2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_NguyenHongDuc_106.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Nguyen_Hong_Duc2020label" class="modal fade" id="bibtex-Nguyen_Hong_Duc2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNguyen_Hong_Duc2020label">
        Acoustic Scene Classification Using Long-Term and Fine-Scale Audio Representations
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Nguyen_Hong_Duc2020,
    Author = "Nguyen Hong Duc, Paul and Cazau, Dorian and Adam, Olivier and Gerard, Odile and White, Paul R.",
    title = "Acoustic Scene Classification Using Long-Term and Fine-Scale Audio Representations",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "Audio scene classification (ASC) is an emerging filed of research in different scientific communities such as urban soundscape characterization or bioacoustics. It has gained visibility and relevance with open challenges especially with the benchmark dataset and evaluation from DCASE. This paper present our deep learning model to address the ASC task of the DCASE 2020 challenge edition. The model exploits multiple long-term and fine-scale audio representations as inputs of the neural network. Each representation is fed into a different network. The audio embedding of each branch are fused before a Multi-Layer Perceptron to predict the final classes."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Ooi2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Ooi2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Ensemble of Pruned Models for Low-Complexity Acoustic Scene Classifcation
       </h4>
<p style="text-align:left">
        Kenneth Ooi, Santi Peksi and Gan Woon-Seng
       </p>
<p style="text-align:left">
<em>
         School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Ooi_NTU_task1b_1</span> <span class="label label-info">Ooi_NTU_task1b_2</span> <span class="label label-info">Ooi_NTU_task1b_3</span> <span class="label label-info">Ooi_NTU_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Ooi2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Ooi2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Ooi2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Ooi_88.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Ooi2020').collapse('show');window.location.hash='#Ooi2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Ooi2020" class="panel-collapse collapse" id="collapse-Ooi2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Ensemble of Pruned Models for Low-Complexity Acoustic Scene Classifcation
      </h4>
<p style="text-align:left">
<small>
        Kenneth Ooi, Santi Peksi and Gan Woon-Seng
       </small>
<br/>
<small>
<em>
         School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       For the DCASE 2020 Challenge, the focus of Task 1B is to develop low-complexity models for classification of 3 different types of acoustic scenes, which have potential applications in resource-scarce edge devices deployed in a large-scale acoustic network. For this report, we present the training methodology for our submissions for the challenge, with the best-performing system consisting of an ensemble of VGGNet- and InceptionNet-based lightweight classification models. The subsystems in the ensemble classifier were trained with log-mel spectrograms of the raw audio data, and were subsequently pruned by setting low-magnitude weights periodically to zero with a polynomial decay schedule for an 80% reduction in individual subsystem size. The resultant ensemble classifier outperformed the baseline model on the validation set over 5 runs and had 119758 nonzero parameters which took up 468 KB of memory, thus showing the efficacy of the pruning technique. No external data was used, and source code for the submission can be found at https://github.com/kenowr/DCASE-2020-Task-1B.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         block mixing
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         VGGNet; InceptionNet; VGGNet, InceptionNet, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         sparsity
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Ooi2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Ooi_88.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/kenowr/DCASE-2020-Task-1B" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Ooi2020label" class="modal fade" id="bibtex-Ooi2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexOoi2020label">
        Ensemble of Pruned Models for Low-Complexity Acoustic Scene Classifcation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Ooi2020,
    Author = "Ooi, Kenneth and Peksi, Santi and Woon-Seng, Gan",
    title = "Ensemble of Pruned Models for Low-Complexity Acoustic Scene Classifcation",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "For the DCASE 2020 Challenge, the focus of Task 1B is to develop low-complexity models for classification of 3 different types of acoustic scenes, which have potential applications in resource-scarce edge devices deployed in a large-scale acoustic network. For this report, we present the training methodology for our submissions for the challenge, with the best-performing system consisting of an ensemble of VGGNet- and InceptionNet-based lightweight classification models. The subsystems in the ensemble classifier were trained with log-mel spectrograms of the raw audio data, and were subsequently pruned by setting low-magnitude weights periodically to zero with a polynomial decay schedule for an 80\% reduction in individual subsystem size. The resultant ensemble classifier outperformed the baseline model on the validation set over 5 runs and had 119758 nonzero parameters which took up 468 KB of memory, thus showing the efficacy of the pruning technique. No external data was used, and source code for the submission can be found at https://github.com/kenowr/DCASE-2020-Task-1B."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Pajusco2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Pajusco2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Lightweight Convolutional Neural Networks on Binaural Waveforms for Low Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Nicolas Pajusco, Richard Huang and Nicolas Farrugia
       </p>
<p style="text-align:left">
<em>
         Electronics, IMT Atlantique, Brest, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Farrugia_IMT-Atlantique-BRAIn_task1b_1</span> <span class="label label-info">Farrugia_IMT-Atlantique-BRAIn_task1b_2</span> <span class="label label-info">Farrugia_IMT-Atlantique-BRAIn_task1b_3</span> <span class="label label-info">Farrugia_IMT-Atlantique-BRAIn_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Pajusco2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Pajusco2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Pajusco2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Farrugia_99.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Pajusco2020').collapse('show');window.location.hash='#Pajusco2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Pajusco2020" class="panel-collapse collapse" id="collapse-Pajusco2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Lightweight Convolutional Neural Networks on Binaural Waveforms for Low Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Nicolas Pajusco, Richard Huang and Nicolas Farrugia
       </small>
<br/>
<small>
<em>
         Electronics, IMT Atlantique, Brest, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our submission to DCASE 2020 task 1, subtask B, which is an acoustic scene classification task with the objective of minimizing parameter count. While the vast majority of proposed approaches rely on fixed feature extraction based on time-frequency representations such as spectrograms, we propose to fully exploit the information in binaural waveforms directly. To do so, we train one dimensional Convolutional Neural Networks (1D-CNN) on raw, subsampled binaural audio waveforms, thus exploiting phase information within and across the two input channels. In addition, our approach relies heavily on data augmentation in the temporal domain. Finally, we apply iterative structured parameter pruning to remove the least important convolutional kernels, and perform weight quantization in floating point half precision. We apply this approach to train two network architectures: a 1D-CNN based on VGG-like blocks, as well as a ResNet architecture with 1D convolutions. Our results show that we can train, prune and quantify a small VGG model to make it 20 times smaller than the 500 KB limit (model A) with an accuracy at baseline level (87.6 %), as well as a larger model achieving 91 % of accuracy while being 8 times smaller than the challenge limit. ResNets could be successfully trained, pruned and quantify in order to be below the 500 KB limit, achieving up to 91.2 % accuracy
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         18kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         temporal masking, filtering, additive noise; cutmix
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         raw waveform
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN; ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16, quantization, pruning; float16, quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Pajusco2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Farrugia_99.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/brain-bzh/dcase-2020-task1-subtaskB" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Pajusco2020label" class="modal fade" id="bibtex-Pajusco2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPajusco2020label">
        Lightweight Convolutional Neural Networks on Binaural Waveforms for Low Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Pajusco2020,
    Author = "Pajusco, Nicolas and Huang, Richard and Farrugia, Nicolas",
    title = "Lightweight Convolutional Neural Networks on Binaural Waveforms for Low Complexity Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes our submission to DCASE 2020 task 1, subtask B, which is an acoustic scene classification task with the objective of minimizing parameter count. While the vast majority of proposed approaches rely on fixed feature extraction based on time-frequency representations such as spectrograms, we propose to fully exploit the information in binaural waveforms directly. To do so, we train one dimensional Convolutional Neural Networks (1D-CNN) on raw, subsampled binaural audio waveforms, thus exploiting phase information within and across the two input channels. In addition, our approach relies heavily on data augmentation in the temporal domain. Finally, we apply iterative structured parameter pruning to remove the least important convolutional kernels, and perform weight quantization in floating point half precision. We apply this approach to train two network architectures: a 1D-CNN based on VGG-like blocks, as well as a ResNet architecture with 1D convolutions. Our results show that we can train, prune and quantify a small VGG model to make it 20 times smaller than the 500 KB limit (model A) with an accuracy at baseline level (87.6 \%), as well as a larger model achieving 91 \% of accuracy while being 8 times smaller than the challenge limit. ResNets could be successfully trained, pruned and quantify in order to be below the 500 KB limit, achieving up to 91.2 \% accuracy"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Paniagua2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Paniagua2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
       </h4>
<p style="text-align:left">
        Arturo Paniagua, RubÃ©n Fraile, Juana M. GutiÃ©rrez-Arriola, NicolÃ¡s SÃ¡enz-lechÃ³n and VÃ­ctor J- Osma-Ruiz
       </p>
<p style="text-align:left">
<em>
         CITSEM, Universidad PolitÃ©ctica de Madrid, Madrid, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Paniagua_UPM_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Paniagua2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Paniagua2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Paniagua2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Paniagua_97.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Paniagua2020" class="panel-collapse collapse" id="collapse-Paniagua2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
      </h4>
<p style="text-align:left">
<small>
        Arturo Paniagua, RubÃ©n Fraile, Juana M. GutiÃ©rrez-Arriola, NicolÃ¡s SÃ¡enz-lechÃ³n and VÃ­ctor J- Osma-Ruiz
       </small>
<br/>
<small>
<em>
         CITSEM, Universidad PolitÃ©ctica de Madrid, Madrid, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       A system for the automatic classification of acoustic scenes is proposed that uses one audio channel for calculating the spectral distribution of energy across auditory-relevant frequency bands, and some descriptors of the envelope modulation spectrum (EMS) obtained by means of the discrete cosine transform. When the stereophonic signal captured by a binaural microphone is available, this parameter set is augmented by including the first coefficients of the cepstrum of the cross-correlation between both audio channels. This cross-correlation contains information on the angular distribution of acoustic sources. These three types of features (energy spectrum, EMS and cepstrum of cross-correlation) are used as inputs for a multilayer perceptron with two hidden layers and a number of adjustable parameters below 15,000.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         LTAS, envelope modulation spectrum, cepstrum of cross-correlation
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MLP
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average log-likelihood
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Paniagua2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Paniagua_97.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Paniagua2020label" class="modal fade" id="bibtex-Paniagua2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPaniagua2020label">
        Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Paniagua2020,
    Author = "Paniagua, Arturo and Fraile, RubÃ©n and GutiÃ©rrez-Arriola, Juana M. and SÃ¡enz-lechÃ³n, NicolÃ¡s and Osma-Ruiz, VÃ­ctor J-",
    title = "Classification of Acoustic Scenes Based on Modulation Spectra and the Cepstrum of the Cross Correlation Between Binarual Audio Channels",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "A system for the automatic classification of acoustic scenes is proposed that uses one audio channel for calculating the spectral distribution of energy across auditory-relevant frequency bands, and some descriptors of the envelope modulation spectrum (EMS) obtained by means of the discrete cosine transform. When the stereophonic signal captured by a binaural microphone is available, this parameter set is augmented by including the first coefficients of the cepstrum of the cross-correlation between both audio channels. This cross-correlation contains information on the angular distribution of acoustic sources. These three types of features (energy spectrum, EMS and cepstrum of cross-correlation) are used as inputs for a multilayer perceptron with two hidden layers and a number of adjustable parameters below 15,000."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Patki2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Patki2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Exploring Compact Alternatives to Deep Learning in Task 1B
       </h4>
<p style="text-align:left">
        Prachi Patki
       </p>
<p style="text-align:left">
<em>
</em>
</p>
<p style="text-align:left">
<span class="label label-info">Patki_SELF_task1b_1</span> <span class="label label-info">Patki_SELF_task1b_2</span> <span class="label label-info">Patki_SELF_task1b_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Patki2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Patki2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Patki2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Patki_104.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Patki2020" class="panel-collapse collapse" id="collapse-Patki2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Exploring Compact Alternatives to Deep Learning in Task 1B
      </h4>
<p style="text-align:left">
<small>
        Prachi Patki
       </small>
<br/>
<small>
<em>
</em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Task 1b appeared primarily geared toward finding compact deep learning models; however, our experience is that other methodologies may sometimes achieve similar accuracies with substantially smaller parameter counts. We focused on finding alternative classifier formulations that significantly reduce complexity while still achieving superior results. Our primary submission, based on a multi-channel SVM formulation, performs better than the reference design on test data, but requires only ~17.5 KB in parameter complexity.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left+right, left-right; mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Patki2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Patki_104.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Patki2020label" class="modal fade" id="bibtex-Patki2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPatki2020label">
        Exploring Compact Alternatives to Deep Learning in Task 1B
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Patki2020,
    Author = "Patki, Prachi",
    title = "Exploring Compact Alternatives to Deep Learning in Task {1B}",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "Task 1b appeared primarily geared toward finding compact deep learning models; however, our experience is that other methodologies may sometimes achieve similar accuracies with substantially smaller parameter counts. We focused on finding alternative classifier formulations that significantly reduce complexity while still achieving superior results. Our primary submission, based on a multi-channel SVM formulation, performs better than the reference design on test data, but requires only \textasciitilde 17.5 KB in parameter complexity."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Pham2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Pham2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2020 Challenge Task 1B: Low-Complexity CNN-Based Framework for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Lam Pham<sup>1</sup>, Ngo Dat<sup>2</sup>, Phan Huy<sup>3</sup> and Duong Ngoc<sup>4</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of Computing, University of Kent, Kent, UK, <sup>2</sup>Electrical &amp; Electronic Engineering, Ho Chi Minh University of Technology, Ho Chi Minh, Vietnam, <sup>3</sup>School of Electronic Engineering and Computer Science, Queen Mary University of London, London, UK, <sup>4</sup>InterDigital R&amp;D, InterDigital Company, Rennes, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">LamPham_Kent_task1b_1</span> <span class="label label-info">LamPham_Kent_task1b_2</span> <span class="label label-info">LamPham_Kent_task1b_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Pham2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Pham2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Pham2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_LamPham_77.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Pham2020" class="panel-collapse collapse" id="collapse-Pham2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2020 Challenge Task 1B: Low-Complexity CNN-Based Framework for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Lam Pham<sup>1</sup>, Ngo Dat<sup>2</sup>, Phan Huy<sup>3</sup> and Duong Ngoc<sup>4</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of Computing, University of Kent, Kent, UK, <sup>2</sup>Electrical &amp; Electronic Engineering, Ho Chi Minh University of Technology, Ho Chi Minh, Vietnam, <sup>3</sup>School of Electronic Engineering and Computer Science, Queen Mary University of London, London, UK, <sup>4</sup>InterDigital R&amp;D, InterDigital Company, Rennes, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report presents a low-complexity CNN-based deep learning framework for acoustic scene classification task (ASC). In particular, the framework approaches spectrogram representation referred to as front-end feature extraction. The spectrograms extracted are fed into a CNN-based architecture for classification, referred to as the baseline. Next, quantization and pruning techniques are applied on the pre-trained baseline to fine-tune and further compress the network size, eventually achieve low-complexity models with competitive performance.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         left
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Gammatone energy
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         quantization; pruning
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Pham2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_LamPham_77.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Pham2020label" class="modal fade" id="bibtex-Pham2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPham2020label">
        DCASE 2020 Challenge Task 1B: Low-Complexity CNN-Based Framework for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Pham2020,
    Author = "Pham, Lam and Dat, Ngo and Huy, Phan and Ngoc, Duong",
    title = "{DCASE} 2020 Challenge Task {1B}: Low-Complexity {CNN}-Based Framework for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report presents a low-complexity CNN-based deep learning framework for acoustic scene classification task (ASC). In particular, the framework approaches spectrogram representation referred to as front-end feature extraction. The spectrograms extracted are fed into a CNN-based architecture for classification, referred to as the baseline. Next, quantization and pruning techniques are applied on the pre-trained baseline to fine-tune and further compress the network size, eventually achieve low-complexity models with competitive performance."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Phan2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Phan2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2020 Task 1 Subtask B: Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Duc Phan and Douglas Jones
       </p>
<p style="text-align:left">
<em>
         ECE, University of Illinois at Urbana Champaign, Illinois, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Phan_UIUC_task1b_1</span> <span class="label label-info">Phan_UIUC_task1b_2</span> <span class="label label-info">Phan_UIUC_task1b_3</span> <span class="label label-info">Phan_UIUC_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Phan2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Phan2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Phan2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Phan_94_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Phan2020_t1" class="panel-collapse collapse" id="collapse-Phan2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2020 Task 1 Subtask B: Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Duc Phan and Douglas Jones
       </small>
<br/>
<small>
<em>
         ECE, University of Illinois at Urbana Champaign, Illinois, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       A deep network with depth-wise separable convolutions [1] and skip connections is introduced for low complexity acoustic scenes classification. The proposed network is not only more than 15 times smaller than the baseline convolution neural network [2] but also outperforms the baseline by two percents on average.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Phan2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Phan_94_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Phan2020_t1label" class="modal fade" id="bibtex-Phan2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPhan2020_t1label">
        DCASE 2020 Task 1 Subtask B: Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Phan2020_t1,
    Author = "Phan, Duc and Jones, Douglas",
    title = "{DCASE} 2020 Task 1 Subtask B: Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "A deep network with depth-wise separable convolutions [1] and skip connections is introduced for low complexity acoustic scenes classification. The proposed network is not only more than 15 times smaller than the baseline convolution neural network [2] but also outperforms the baseline by two percents on average."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Sampathkumar2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Sampathkumar2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low Complexity Acoustic Scene Classification Using Aalnet-94
       </h4>
<p style="text-align:left">
        Arunodhayan Sampathkumar and Danny Kowerko
       </p>
<p style="text-align:left">
<em>
         Juniorprofessur MEDIA COMPUTING, Techniche universitÃ¤t Chemnitz, Chemnitz, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Sampathkumar_TUC_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Sampathkumar2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Sampathkumar2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Sampathkumar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Sampathkumar_42.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Sampathkumar2020" class="panel-collapse collapse" id="collapse-Sampathkumar2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low Complexity Acoustic Scene Classification Using Aalnet-94
      </h4>
<p style="text-align:left">
<small>
        Arunodhayan Sampathkumar and Danny Kowerko
       </small>
<br/>
<small>
<em>
         Juniorprofessur MEDIA COMPUTING, Techniche universitÃ¤t Chemnitz, Chemnitz, Germany
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       One of the manifold application fields of Deep Neural Networks (DNN) is the classification of audio signals such as indoor, outdoor, transportation, humans and animals sounds. DCASE2020 provided a dataset consisting of 3 classes to perform classification using low complexity solutions. The dataset was trained using AALNet-94 from our previous research work that performed well in publicly available datasets such as ESC-50, Ultrasound 8K and audioset. The results obtained performed well when compared with the baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Sampathkumar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Sampathkumar_42.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Sampathkumar2020label" class="modal fade" id="bibtex-Sampathkumar2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSampathkumar2020label">
        Low Complexity Acoustic Scene Classification Using Aalnet-94
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Sampathkumar2020,
    Author = "Sampathkumar, Arunodhayan and Kowerko, Danny",
    title = "Low Complexity Acoustic Scene Classification Using Aalnet-94",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "One of the manifold application fields of Deep Neural Networks (DNN) is the classification of audio signals such as indoor, outdoor, transportation, humans and animals sounds. DCASE2020 provided a dataset consisting of 3 classes to perform classification using low complexity solutions. The dataset was trained using AALNet-94 from our previous research work that performed well in publicly available datasets such as ESC-50, Ultrasound 8K and audioset. The results obtained performed well when compared with the baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Singh2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Singh2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        End2end CNN-Based Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Arshdeep Singh, Dhanunjaya Varma Devalraju and Padmanabhan Rajan
       </p>
<p style="text-align:left">
<em>
         School of Computing and Electrical engineering, Indian institute of technology, Mandi, Mandi, India
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Singh_IITMandi_task1b_1</span> <span class="label label-info">Singh_IITMandi_task1b_2</span> <span class="label label-info">Singh_IITMandi_task1b_3</span> <span class="label label-info">Singh_IITMandi_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Singh2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Singh2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Singh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Singh_18.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Singh2020').collapse('show');window.location.hash='#Singh2020';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Singh2020" class="panel-collapse collapse" id="collapse-Singh2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       End2end CNN-Based Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Arshdeep Singh, Dhanunjaya Varma Devalraju and Padmanabhan Rajan
       </small>
<br/>
<small>
<em>
         School of Computing and Electrical engineering, Indian institute of technology, Mandi, Mandi, India
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the IITMandi AudioTeamâ€™s submission for ASC Task 1, Subtask B of DCASE2020 challenge. This report aims to design low-complexity systems for acoustic scene classification. We propose a convolution neural network based endto-end classification framework. The proposed framework learns from raw audio directly. We present performance analysis of various frameworks with model size lesser than 500KB for classification. The three acoustic scenes namely indoor, outdoor and transportation are considered. Our experimental analysis shows that the proposed end-to-end framework, where features are being learned from raw audio directly, with a model size of approx. 77KB gives similar performance on development dataset as that of baseline1 system proposed for the same task.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         raw waveform segment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         Singh_IITMandi_task1b_1, Singh_IITMandi_task1b_3
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         maximum likelihood
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Singh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Singh_18.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://cloud.iitmandi.ac.in/d/bd487a2974f24e6fabf1/" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Singh2020label" class="modal fade" id="bibtex-Singh2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSingh2020label">
        End2end CNN-Based Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Singh2020,
    Author = "Singh, Arshdeep and Devalraju, Dhanunjaya Varma and Rajan, Padmanabhan",
    title = "End2end {CNN}-Based Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the IITMandi AudioTeamâ€™s submission for ASC Task 1, Subtask B of DCASE2020 challenge. This report aims to design low-complexity systems for acoustic scene classification. We propose a convolution neural network based endto-end classification framework. The proposed framework learns from raw audio directly. We present performance analysis of various frameworks with model size lesser than 500KB for classification. The three acoustic scenes namely indoor, outdoor and transportation are considered. Our experimental analysis shows that the proposed end-to-end framework, where features are being learned from raw audio directly, with a model size of approx. 77KB gives similar performance on development dataset as that of baseline1 system proposed for the same task."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Suh2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Suh2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Designing Acoustic Scene Classification Models with CNN Variants
       </h4>
<p style="text-align:left">
        Sangwon Suh, Sooyoung Park, Youngho Jeong and Taejin Lee
       </p>
<p style="text-align:left">
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Suh_ETRI_task1b_1</span> <span class="label label-info">Suh_ETRI_task1b_2</span> <span class="label label-info">Suh_ETRI_task1b_3</span> <span class="label label-info">Suh_ETRI_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Suh2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Suh2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Suh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Suh_101.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Suh2020" class="panel-collapse collapse" id="collapse-Suh2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Designing Acoustic Scene Classification Models with CNN Variants
      </h4>
<p style="text-align:left">
<small>
        Sangwon Suh, Sooyoung Park, Youngho Jeong and Taejin Lee
       </small>
<br/>
<small>
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our Acoustic Scene Classification systems for DCASE2020 challenge Task1. For subtask A, we designed a single model implemented with three parallel ResNets, which is named Trident ResNet. We have confirmed that this structure is beneficial when analyzing samples collected from minority or unseen devices, and confirmed 73.7% classification accuracy for the test split. For subtask B, we used the Inception module to build a Shallow Inception model that has fewer parameters than the CNN of the DCASE baseline system. Due to the sparse structure of the Inception module, we have enhanced the accuracy of the model up to 97.6%, while reducing the number of parameters.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         stereo
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         temporal cropping, mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN(Inception)
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average; weighted score average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Suh2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Suh_101.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Suh2020label" class="modal fade" id="bibtex-Suh2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSuh2020label">
        Designing Acoustic Scene Classification Models with CNN Variants
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Suh2020,
    Author = "Suh, Sangwon and Park, Sooyoung and Jeong, Youngho and Lee, Taejin",
    title = "Designing Acoustic Scene Classification Models with {CNN} Variants",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our Acoustic Scene Classification systems for DCASE2020 challenge Task1. For subtask A, we designed a single model implemented with three parallel ResNets, which is named Trident ResNet. We have confirmed that this structure is beneficial when analyzing samples collected from minority or unseen devices, and confirmed 73.7\% classification accuracy for the test split. For subtask B, we used the Inception module to build a Shallow Inception model that has fewer parameters than the CNN of the DCASE baseline system. Due to the sparse structure of the Inception module, we have enhanced the accuracy of the model up to 97.6\%, while reducing the number of parameters."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Vilouras2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Vilouras2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
       </h4>
<p style="text-align:left">
        Konstantinos Vilouras
       </p>
<p style="text-align:left">
<em>
         Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Vilouras_AUTh_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Vilouras2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Vilouras2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Vilouras2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Vilouras_3.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Vilouras2020" class="panel-collapse collapse" id="collapse-Vilouras2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
      </h4>
<p style="text-align:left">
<small>
        Konstantinos Vilouras
       </small>
<br/>
<small>
<em>
         Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approach to Task 1 ''Acoustic Scene Classification'' of the DCASE 2020 challenge. For subtask A, we introduce per-channel energy normalization (PCEN) as an additional preprocessing step along with log-Mel spectrograms. We also propose two residual network architectures utilizing â€œShake-Shakeâ€ regularization and the â€œSqueeze-and-Excitationâ€ block, respectively. Our best submission (ensemble of 8 classifiers) outperforms the corresponding baseline system by 16.2% in terms of macro-average accuracy. For subtask B, we mainly focus on a low complexity, fully convolutional neural network architecture, which leads to 5% relative improvement over baseline accuracy.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Vilouras2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Vilouras_3.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Vilouras2020label" class="modal fade" id="bibtex-Vilouras2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexVilouras2020label">
        Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Vilouras2020,
    Author = "Vilouras, Konstantinos",
    title = "Acoustic Scene Classification Using Fully Convolutional Neural Networks and Per-Channel Energy Normalization",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our approach to Task 1 ''Acoustic Scene Classification'' of the DCASE 2020 challenge. For subtask A, we introduce per-channel energy normalization (PCEN) as an additional preprocessing step along with log-Mel spectrograms. We also propose two residual network architectures utilizing â€œShake-Shakeâ€ regularization and the â€œSqueeze-and-Excitationâ€ block, respectively. Our best submission (ensemble of 8 classifiers) outperforms the corresponding baseline system by 16.2\% in terms of macro-average accuracy. For subtask B, we mainly focus on a low complexity, fully convolutional neural network architecture, which leads to 5\% relative improvement over baseline accuracy."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Waldekar2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Waldekar2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
       </h4>
<p style="text-align:left">
        Shefali Waldekar, Kishore Kumar A and Goutam Saha
       </p>
<p style="text-align:left">
<em>
         Electronics and Electrical Communication Engineering Dept., Indian Institute of Technology Kharagpur, Kharagpur, India
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Waldekar_IITKGP_task1b_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Waldekar2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Waldekar2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Waldekar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Waldekar_148.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Waldekar2020" class="panel-collapse collapse" id="collapse-Waldekar2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
      </h4>
<p style="text-align:left">
<small>
        Shefali Waldekar, Kishore Kumar A and Goutam Saha
       </small>
<br/>
<small>
<em>
         Electronics and Electrical Communication Engineering Dept., Indian Institute of Technology Kharagpur, Kharagpur, India
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes a submission for IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 for Task 1 (acoustic scene classification (ASC)), sub-task A (ASC with Multiple Devices) and sub-task B (LowComplexity ASC). The systems exploit time-frequency representation of audio to obtain the scene labels. The system for Task1A follows a simple pattern classification framework employing wavelet transform based mel-scaled features along with support vector machine (SVM) as classifier. Texture features, namely Local Binary Pattern (LBP) extracted from log of mel-band energies is used in a similar classification framework for Task 1B. The proposed systems outperform the deep-learning based baseline system with the development dataset provided for the respective sub-tasks.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         histogram of uniform LBP of log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SVM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Waldekar2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Waldekar_148.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Waldekar2020label" class="modal fade" id="bibtex-Waldekar2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWaldekar2020label">
        Mel-Scaled Wavelet-Based Features for Sub-Task A and Texture Features for Sub-Task B of DCASE 2020 Task 1
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Waldekar2020,
    Author = "Waldekar, Shefali and Kumar A, Kishore and Saha, Goutam",
    title = "Mel-Scaled Wavelet-Based Features for Sub-Task {A} and Texture Features for Sub-Task {B} of {DCASE} 2020 Task 1",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes a submission for IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 for Task 1 (acoustic scene classification (ASC)), sub-task A (ASC with Multiple Devices) and sub-task B (LowComplexity ASC). The systems exploit time-frequency representation of audio to obtain the scene labels. The system for Task1A follows a simple pattern classification framework employing wavelet transform based mel-scaled features along with support vector machine (SVM) as classifier. Texture features, namely Local Binary Pattern (LBP) extracted from log of mel-band energies is used in a similar classification framework for Task 1B. The proposed systems outperform the deep-learning based baseline system with the development dataset provided for the respective sub-tasks."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wang2020_t1" style="box-shadow: none">
<div class="panel-heading" id="heading-Wang2020_t1" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Multiple Decision Schemes
       </h4>
<p style="text-align:left">
        Helin Wang, Dading Chong and Yuexian Zou
       </p>
<p style="text-align:left">
<em>
         School of ECE, Peking University, Shenzhen, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Helin_ADSPLAB_task1b_1</span> <span class="label label-info">Helin_ADSPLAB_task1b_2</span> <span class="label label-info">Helin_ADSPLAB_task1b_3</span> <span class="label label-info">Helin_ADSPLAB_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wang2020_t1" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wang2020_t1" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wang2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Helin_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wang2020_t1" class="panel-collapse collapse" id="collapse-Wang2020_t1" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Multiple Decision Schemes
      </h4>
<p style="text-align:left">
<small>
        Helin Wang, Dading Chong and Yuexian Zou
       </small>
<br/>
<small>
<em>
         School of ECE, Peking University, Shenzhen, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the ADSPLAB teamâ€™s submission for Task1 of DCASE2020 challenge. Our acoustic scene classifi- cation (ASC) system is based on the convolutional neural networks (CNN). Multiple decision schemes are proposed in our system, in- cluding the decision schemes in multiple representations, multiple frequency bands, and multiple temporal frames. The final system is the fusion of models with multiple decision schemes and mod- els pre-trained on AudioSet. The experimental results show that our system could achieve the accuracy of 84.5 %(official baseline: 54.1%) and 92.1% (official baseline: 87.3%) on the officially provided fold 1 evaluation dataset of Task1A and Task1B, respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, CQT, Gammatone
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wang2020_t1" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Helin_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wang2020_t1label" class="modal fade" id="bibtex-Wang2020_t1" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWang2020_t1label">
        Acoustic Scene Classification with Multiple Decision Schemes
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wang2020_t1,
    Author = "Wang, Helin and Chong, Dading and Zou, Yuexian",
    title = "Acoustic Scene Classification with Multiple Decision Schemes",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes the ADSPLAB teamâ€™s submission for Task1 of DCASE2020 challenge. Our acoustic scene classifi- cation (ASC) system is based on the convolutional neural networks (CNN). Multiple decision schemes are proposed in our system, in- cluding the decision schemes in multiple representations, multiple frequency bands, and multiple temporal frames. The final system is the fusion of models with multiple decision schemes and mod- els pre-trained on AudioSet. The experimental results show that our system could achieve the accuracy of 84.5 \%(official baseline: 54.1\%) and 92.1\% (official baseline: 87.3\%) on the officially provided fold 1 evaluation dataset of Task1A and Task1B, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wu2020_t1b" style="box-shadow: none">
<div class="panel-heading" id="heading-Wu2020_t1b" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Searching for Efficient Network Architectures for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Yuzhong Wu and Tan Lee
       </p>
<p style="text-align:left">
<em>
         Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Wu_CUHK_task1b_1</span> <span class="label label-info">Wu_CUHK_task1b_2</span> <span class="label label-info">Wu_CUHK_task1b_3</span> <span class="label label-info">Wu_CUHK_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wu2020_t1b" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wu2020_t1b" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wu2020_t1b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wu_11_t1b.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Wu2020_t1b').collapse('show');window.location.hash='#Wu2020_t1b';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wu2020_t1b" class="panel-collapse collapse" id="collapse-Wu2020_t1b" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Searching for Efficient Network Architectures for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Yuzhong Wu and Tan Lee
       </small>
<br/>
<small>
<em>
         Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for Task 1B of DCASE2020 challenge. The objective of task 1B is to construct an acoustic scene classification (ASC) system with low model complexity. In our ASC system, the average-difference time-frequency features are extracted from binaural audio waveforms. A random search policy is used to find the best-performing CNN architecture while satisfying the requirement of model size. The search is limited to several predefined efficient convolutional modules based on depth-wise convolution and swish activation function to constrain the size of search space. Experimental results on development dataset shows that CNN model obtained by this search strategy has higher accuracy compared to an AlexNet-like CNN benchmark.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         wavelet filter-bank features
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wu2020_t1b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Wu_11_t1b.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/yzwu2017/DCASE2020_task1b" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wu2020_t1blabel" class="modal fade" id="bibtex-Wu2020_t1b" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWu2020_t1blabel">
        Searching for Efficient Network Architectures for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wu2020_t1b,
    Author = "Wu, Yuzhong and Lee, Tan",
    title = "Searching for Efficient Network Architectures for Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This technical report describes our submission for Task 1B of DCASE2020 challenge. The objective of task 1B is to construct an acoustic scene classification (ASC) system with low model complexity. In our ASC system, the average-difference time-frequency features are extracted from binaural audio waveforms. A random search policy is used to find the best-performing CNN architecture while satisfying the requirement of model size. The search is limited to several predefined efficient convolutional modules based on depth-wise convolution and swish activation function to constrain the size of search space. Experimental results on development dataset shows that CNN model obtained by this search strategy has higher accuracy compared to an AlexNet-like CNN benchmark."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zhang2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Zhang2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Bupt Submissions to DCASE 2020: Low-Complexity Acoustic Scene Classification with Post Training Static Quantization and Prune
       </h4>
<p style="text-align:left">
        Jiawang Zhang, Chunxia Ren and Shengchen Li
       </p>
<p style="text-align:left">
<em>
         BUPT, Beijing University of Posts and Telecommunications, Beijing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Zhang_BUPT_task1b_1</span> <span class="label label-info">Zhang_BUPT_task1b_2</span> <span class="label label-info">Zhang_BUPT_task1b_3</span> <span class="label label-info">Zhang_BUPT_task1b_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zhang2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zhang2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zhang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_78.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zhang2020" class="panel-collapse collapse" id="collapse-Zhang2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Bupt Submissions to DCASE 2020: Low-Complexity Acoustic Scene Classification with Post Training Static Quantization and Prune
      </h4>
<p style="text-align:left">
<small>
        Jiawang Zhang, Chunxia Ren and Shengchen Li
       </small>
<br/>
<small>
<em>
         BUPT, Beijing University of Posts and Telecommunications, Beijing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes a method for Task 1b (Low-Complexity Acoustic Scene Classification) of the DCASE 2020 challenge, which targets low complexity solutions for the classification problem. The proposed model has five residual block with average pooling. To improve the performance of the proposed system, binaural features from the dataset are used, and with Log Mel Spectrogram, mix-up data augmentation. To reduce system complexity, the proposed method uses Post Training Static Quantization and Prune methods, Post Training Static Quantization are used to do the 8-bits quantization, this method can reduce the model size by four times. Pruning can reduce redundant weights by prune the low weights, the process allows only a small part of the original weight parameters performance close to the original network. The accuracy of the method proposed in this report on the development data set is 92.9%, which is 5.6% higher than the baseline, but 81% lower than the baseline model.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mixed
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         8-bit quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zhang2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhang_78.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zhang2020label" class="modal fade" id="bibtex-Zhang2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZhang2020label">
        Bupt Submissions to DCASE 2020: Low-Complexity Acoustic Scene Classification with Post Training Static Quantization and Prune
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zhang2020,
    Author = "Zhang, Jiawang and Ren, Chunxia and Li, Shengchen",
    title = "Bupt Submissions to {DCASE} 2020: Low-Complexity Acoustic Scene Classification with Post Training Static Quantization and Prune",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report describes a method for Task 1b (Low-Complexity Acoustic Scene Classification) of the DCASE 2020 challenge, which targets low complexity solutions for the classification problem. The proposed model has five residual block with average pooling. To improve the performance of the proposed system, binaural features from the dataset are used, and with Log Mel Spectrogram, mix-up data augmentation. To reduce system complexity, the proposed method uses Post Training Static Quantization and Prune methods, Post Training Static Quantization are used to do the 8-bits quantization, this method can reduce the model size by four times. Pruning can reduce redundant weights by prune the low weights, the process allows only a small part of the original weight parameters performance close to the original network. The accuracy of the method proposed in this report on the development data set is 92.9\%, which is 5.6\% higher than the baseline, but 81\% lower than the baseline model."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zhao2020" style="box-shadow: none">
<div class="panel-heading" id="heading-Zhao2020" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Dd-CNN: Depthwise Disout Convolutional Neural Network for Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Jingqiao Zhao<sup>1</sup>, Xiao-Jun Wu<sup>1</sup>, Xiaoning Song<sup>1</sup>, Zhen-Hua Feng<sup>2</sup> and Qiuqiang Kong<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China, <sup>2</sup>Centre for Vision, Speech and Signal Processin, University of Surrey, Guildford, UK, <sup>3</sup>AI Lab,, ByteDance, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-info">Zhao_JNU_task1b_1</span> <span class="label label-info">Zhao_JNU_task1b_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zhao2020" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zhao2020" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zhao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhao_40.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zhao2020" class="panel-collapse collapse" id="collapse-Zhao2020" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Dd-CNN: Depthwise Disout Convolutional Neural Network for Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Jingqiao Zhao<sup>1</sup>, Xiao-Jun Wu<sup>1</sup>, Xiaoning Song<sup>1</sup>, Zhen-Hua Feng<sup>2</sup> and Qiuqiang Kong<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China, <sup>2</sup>Centre for Vision, Speech and Signal Processin, University of Surrey, Guildford, UK, <sup>3</sup>AI Lab,, ByteDance, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report presents our Depthwise Disout Convolutional Neural Network (DD-CNN) used for the detection and classification of urban acoustic scenes in the DCASE2020 Challenge (Task 1 - Subtask B). Specifically, we use log-mel as feature representations of acoustic signals for the inputs of our network. In DD-CNN, depthwise separable convolution is used to reduce the network complexity. Besides, SpecAugment and Disout are used for further performance boosting. Experimental results demonstrate that our DD-CNN can learn discriminative acoustic characteristics from audio fragments and effectively reduce the network complexity. Our method achieves 92.04% accuracy on the validation set.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         mono
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         48kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         disout
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zhao2020" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Zhao_40.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zhao2020label" class="modal fade" id="bibtex-Zhao2020" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZhao2020label">
        Dd-CNN: Depthwise Disout Convolutional Neural Network for Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zhao2020,
    Author = "Zhao, Jingqiao and Wu, Xiao-Jun and Song, Xiaoning and Feng, Zhen-Hua and Kong, Qiuqiang",
    title = "Dd-{CNN}: Depthwise Disout Convolutional Neural Network for Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report presents our Depthwise Disout Convolutional Neural Network (DD-CNN) used for the detection and classification of urban acoustic scenes in the DCASE2020 Challenge (Task 1 - Subtask B). Specifically, we use log-mel as feature representations of acoustic signals for the inputs of our network. In DD-CNN, depthwise separable convolution is used to reduce the network complexity. Besides, SpecAugment and Disout are used for further performance boosting. Experimental results demonstrate that our DD-CNN can learn discriminative acoustic characteristics from audio fragments and effectively reduce the network complexity. Our method achieves 92.04\% accuracy on the validation set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>