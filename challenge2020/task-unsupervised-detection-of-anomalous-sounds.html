<!DOCTYPE html><html lang="en">
<head>
    <title>Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Challenge has ended. Full results for this task can be found in the Results page. Description Anomalous sound detection (ASD) is the task to identify whether the sound emitted from a target machine is normal or anomalous.. Automatically detecting mechanical failure is an essential technology in the fourth industrial revolution …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2020</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2020/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-urban text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2020/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2020/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge awards">
        <a href="/challenge2020/awards"><i class="fa fa-trophy"></i>&nbsp;Awards</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/wall-08.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-large-scale fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Monitoring</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 2</span></span><img src="../images/logos/dcase/dcase2020_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Yuma Koizumi" class="img img-circle" src="/images/person/yuma_koizumi.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yuma Koizumi</strong>
<a class="icon" href="mailto:koizumi.yuma@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.ntt.co.jp/md/e/">
                                NTT Corporation
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Yohei Kawaguchi" class="img img-circle" src="/images/person/yohei_kawaguchi.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yohei Kawaguchi</strong>
<a class="icon" href="mailto:yohei.kawaguchi.xk@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Keisuke Imoto" class="img img-circle" src="/images/person/keisuke_imoto.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Keisuke Imoto</strong>
<a class="icon" href="mailto:keisuke.imoto@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Doshisha University
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Toshiki Nakamura" class="img img-circle" src="/images/person/toshiki_nakamura.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Toshiki Nakamura</strong>
<a class="icon" href="mailto:toshiki.nakamura.yg@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Yuki Nikaido" class="img img-circle" src="/images/person/yuki_nikaido.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yuki Nikaido</strong>
<a class="icon" href="mailto:yuki.nikaido.cw@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Ryo Tanabe" class="img img-circle" src="/images/person/ryo_tanabe.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Ryo Tanabe</strong>
<a class="icon" href="mailto:ryo.tanabe.rw@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Harsh Purohit" class="img img-circle" src="/images/person/harsh_purohit.jpeg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Harsh Purohit</strong>
<a class="icon" href="mailto:harsh_pramodbhai.purohit.yf@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Kaori Suefusa" class="img img-circle" src="/images/person/kaori_suefusa.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Kaori Suefusa</strong>
<a class="icon" href="mailto:kaori.suefusa.fz@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Takashi Endo" class="img img-circle" src="/images/person/takashi_endo.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Takashi Endo</strong>
<a class="icon" href="mailto:takashi.endo.qf@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Masahiro Yasuda" class="img img-circle" src="/images/person/masahiro_yasuda.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Masahiro Yasuda</strong>
<a class="icon" href="mailto:masahiro.yasuda.hd@hco.ntt.co.jp"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.ntt.co.jp/md/e/">
                                NTT Corporation
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Noboru Harada" class="img img-circle" src="/images/person/noboru_harada.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Noboru Harada</strong>
<a class="icon" href="mailto:noboru@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.ntt.co.jp/md/e/">
                                NTT Corporation
                                </a>
</p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a>
<ul>
<li><a href="#schedule">Schedule</a></li>
</ul>
</li>
<li><a href="#audio-dataset">Audio dataset</a>
<ul>
<li><a href="#recording-procedure">Recording procedure</a></li>
<li><a href="#development-and-evaluation-datasets">Development and evaluation datasets</a></li>
<li><a href="#reference-labels">Reference labels</a></li>
<li><a href="#external-data-resources">External data resources</a></li>
<li><a href="#download">Download</a></li>
</ul>
</li>
<li><a href="#task-setup-and-rules">Task setup and rules</a></li>
<li><a href="#submission">Submission</a></li>
<li><a href="#evaluation">Evaluation</a>
<ul>
<li><a href="#ranking">Ranking</a></li>
</ul>
</li>
<li><a href="#results">Results</a></li>
<li><a href="#baseline-system">Baseline system</a>
<ul>
<li><a href="#system-description">System description</a></li>
<li><a href="#repository">Repository</a></li>
<li><a href="#results-for-the-development-dataset">Results for the development dataset</a></li>
</ul>
</li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="lead"></p>
<p class="alert alert-info">
<strong>Challenge has ended.</strong> Full results for this task can be found in the <a class="btn btn-default btn-xs" href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results">Results <i class="fa fa-caret-right"></i></a> page.
</p>
<h1 id="description">Description</h1>
<p><strong>Anomalous sound detection (ASD) is the task to identify whether the sound emitted from a target machine is normal or anomalous.</strong>. Automatically detecting mechanical failure is an essential technology in the fourth industrial revolution, including artificial intelligence (AI)-based factory automation. Prompt detection of machine anomaly by observing its sounds may be useful for machine condition monitoring.</p>
<p><strong>The main challenge of this task is to detect unknown anomalous sounds under the condition that only normal sound samples have been provided as training data</strong>.
In real-world factories, actual anomalous sounds rarely occur and are highly diverse.
Therefore, exhaustive patterns of anomalous sounds are impossible to deliberately make and/or collect.
This means we have to detect <em>unknown</em> anomalous sounds that were not observed in the given training data.
This point is one of the major differences in premise between ASD for industrial equipment and the past supervised DCASE tasks for detecting <em>defined</em> anomalous sounds such as gunshots or a baby crying.</p>
<p><strong>This task cannot be solved as a simple classification problem</strong>, even though the simplified task description shown in Fig. 1 seems to be a two-class classification problem. Please refer to the “Task setup and rules” section for the details of the task.</p>
<figure>
<div class="row row-centered">
<div class="col-xs-7 col-md-5 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2020/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_01.png"/>
<figcaption>Figure 1: Overview of ASD system.</figcaption>
</div>
</div>
</figure>
<p><br/></p>
<h2 id="schedule">Schedule</h2>
<p>Based on the DCASE challenge 2020 schedule, the task important days will be as follows.</p>
<ul>
<li>Task open: <strong>2nd of March 2020</strong></li>
<li>Additional training dataset release: <strong>1st of April 2020</strong></li>
<li>Evaluation dataset release: <strong>1st of June 2020</strong></li>
<li>External resource list lock: <strong>1st of June 2020</strong></li>
<li>Challenge deadline: <strong>15th of June 2020</strong></li>
<li>Challenge results: <strong>1st of July 2020</strong></li>
</ul>
<p>External resources on the "List of external datasets and models allowed" can be used (cf. external data resource section).
List of external datasets and models allowed will be updated upon request.
Any external resource which are freely accessed before <strong>1st of April 2020</strong> can be added.
Please send a request email to the task organizers.
The list will be locked after the release date of Evaluation dataset (<strong>1st of June 2020</strong>).
To avoid developing new external resources using machine information in the evaluation dataset, we will release the additional training dataset after <strong>1st of April 2020</strong>.
Note that the additional training dataset contains matching training data of machines used in the evaluation dataset (cf. dataset section).</p>
<h1 id="audio-dataset">Audio dataset</h1>
<p>The data used for this task comprises parts of <strong>ToyADMOS</strong> and the <strong>MIMII Dataset</strong> consisting of the normal/anomalous operating sounds of six types of toy/real machines.
Each recording is a single-channel (approximately) 10-sec length audio that includes both a target machine's operating sound and environmental noise.
The following six types of toy/real machines are used in this task:</p>
<ul>
<li>Toy-car (ToyADMOS)</li>
<li>Toy-conveyor (ToyADMOS)</li>
<li>Valve (MIMII Dataset)</li>
<li>Pump (MIMII Dataset)</li>
<li>Fan (MIMII Dataset)</li>
<li>Slide rail (MIMII Dataset)</li>
</ul>
<div class="btex-item" data-item="Koizumi_WASPAA2019_01" data-source="content/data/challenge2020/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Koizumi_WASPAA2019_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Yuma Koizumi, Shoichiro Saito, Hisashi Uematsu, Noboru Harada, and Keisuke Imoto.
<em>ToyADMOS: a dataset of miniature-machine operating sounds for anomalous sound detection.</em>
In Proceedings of <span class="bibtex-protected">IEEE</span> Workshop on Applications of Signal Processing to Audio and Acoustics (<span class="bibtex-protected">WASPAA</span>), 308–312. November 2019.
URL: <a href="https://ieeexplore.ieee.org/document/8937164">https://ieeexplore.ieee.org/document/8937164</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://arxiv.org/abs/1908.03299" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" class="panel-collapse collapse" id="collapseKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" role="tabpanel">
<h4>ToyADMOS: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection</h4>
<h5>Abstract</h5>
<p class="text-justify">This paper introduces a new dataset called ``{ToyADMOS}'' designed for anomaly detection in machine operating sounds (ADMOS). To the best our knowledge, no large-scale datasets are available for ADMOS, although large-scale datasets have contributed to recent advancements in acoustic signal processing. This is because anomalous sound data are difficult to collect. To build a large-scale dataset for ADMOS, we collected anomalous operating sounds of miniature machines (toys) by deliberately damaging them. The released dataset consists of three sub-datasets for machine-condition inspection, fault diagnosis of machines with geometrically fixed tasks, and fault diagnosis of machines with moving tasks. Each sub-dataset includes over 180 hours of normal machine-operating sounds and over 4,000 samples of anomalous sounds collected with four microphones at a 48-kHz sampling rate. The dataset is freely available for download at https://github.com/YumaKoizumi/ToyADMOS-dataset.</p>
<h5>Keywords</h5>
<p class="text-justify">Anomaly detection in sounds, machine operating sounds, product inspection, dataset</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://arxiv.org/abs/1908.03299" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86aelabel" class="modal fade" id="bibtexKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86ae" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexKoizumi_WASPAA2019_0130791cebbf20438c9b5deae0abfc86aelabel">ToyADMOS: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Koizumi_WASPAA2019_01,
    Author = "Koizumi, Yuma and Saito, Shoichiro and Uematsu, Hisashi and Harada, Noboru and Imoto, Keisuke",
    title = "{ToyADMOS}: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection",
    year = "2019",
    booktitle = "Proceedings of {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics ({WASPAA})",
    month = "November",
    pages = "308--312",
    keywords = "Anomaly detection in sounds, machine operating sounds, product inspection, dataset",
    abstract = "This paper introduces a new dataset called ``{ToyADMOS}'' designed for anomaly detection in machine operating sounds (ADMOS). To the best our knowledge, no large-scale datasets are available for ADMOS, although large-scale datasets have contributed to recent advancements in acoustic signal processing. This is because anomalous sound data are difficult to collect. To build a large-scale dataset for ADMOS, we collected anomalous operating sounds of miniature machines (toys) by deliberately damaging them. The released dataset consists of three sub-datasets for machine-condition inspection, fault diagnosis of machines with geometrically fixed tasks, and fault diagnosis of machines with moving tasks. Each sub-dataset includes over 180 hours of normal machine-operating sounds and over 4,000 samples of anomalous sounds collected with four microphones at a 48-kHz sampling rate. The dataset is freely available for download at https://github.com/YumaKoizumi/ToyADMOS-dataset.",
    url = "https://ieeexplore.ieee.org/document/8937164"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Purohit_DCASE2019_01" data-source="content/data/challenge2020/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Purohit_DCASE2019_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Harsh Purohit, Ryo Tanabe, Takeshi Ichige, Takashi Endo, Yuki Nikaido, Kaori Suefusa, and Yohei Kawaguchi.
<em>MIMII Dataset: sound dataset for malfunctioning industrial machine investigation and inspection.</em>
In Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (<span class="bibtex-protected">DCASE2019</span>), 209–213. November 2019.
URL: <a href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf">http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapsePurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapsePurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" class="panel-collapse collapse" id="collapsePurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" role="tabpanel">
<h4>MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection</h4>
<h5>Abstract</h5>
<p class="text-justify">Factory machinery is prone to failure or breakdown, resulting in significant expenses for companies. Hence, there is a rising interest in machine monitoring using different sensors including microphones. In scientific community, the emergence of public datasets has been promoting the advancement in acoustic detection and classification of scenes and events, but there are no public datasets that focus on the sound of industrial machines under normal and anomalous operating conditions in real factory environments. In this paper, we present a new dataset of industrial machine sounds which we call a sound dataset for malfunctioning industrial machine investigation and inspection (MIMII dataset). Normal and anomalous sounds were recorded for different types of industrial machines, i.e. valves, pumps, fans and slide rails. To resemble the real-life scenario, various anomalous sounds have been recorded, for instance, contamination, leakage, rotating unbalance, rail damage, etc. The purpose of releasing the MIMII dataset is to help the machine-learning and signal-processing community to advance the development of automated facility maintenance.</p>
<h5>Keywords</h5>
<p class="text-justify">Machine sound dataset, acoustic scene classification, anomaly detection, unsupervised anomalous sound detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769label" class="modal fade" id="bibtexPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexPurohit_DCASE2019_0184910590f1d74b5b90682c969d8bc769label">MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Purohit_DCASE2019_01,
    Author = "Purohit, Harsh and Tanabe, Ryo and Ichige, Takeshi and Endo, Takashi and Nikaido, Yuki and Suefusa, Kaori and Kawaguchi, Yohei",
    title = "{MIMII Dataset}: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection",
    year = "2019",
    booktitle = "Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop ({DCASE2019})",
    month = "November",
    pages = "209--213",
    keywords = "Machine sound dataset, acoustic scene classification, anomaly detection, unsupervised anomalous sound detection",
    abstract = "Factory machinery is prone to failure or breakdown, resulting in significant expenses for companies. Hence, there is a rising interest in machine monitoring using different sensors including microphones. In scientific community, the emergence of public datasets has been promoting the advancement in acoustic detection and classification of scenes and events, but there are no public datasets that focus on the sound of industrial machines under normal and anomalous operating conditions in real factory environments. In this paper, we present a new dataset of industrial machine sounds which we call a sound dataset for malfunctioning industrial machine investigation and inspection (MIMII dataset). Normal and anomalous sounds were recorded for different types of industrial machines, i.e. valves, pumps, fans and slide rails. To resemble the real-life scenario, various anomalous sounds have been recorded, for instance, contamination, leakage, rotating unbalance, rail damage, etc. The purpose of releasing the MIMII dataset is to help the machine-learning and signal-processing community to advance the development of automated facility maintenance.",
    url = "http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop\_Purohit\_21.pdf"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<h2 id="recording-procedure">Recording procedure</h2>
<p>The ToyADMOS consists of normal/anomalous operating sounds of miniature machines (toys) collected with four microphones, and the MIMII dataset consists of those of real-machines collected with eight microphones. Anomalous sounds in these datasets were collected by deliberately damaging target machines.
For simplifying the task, we used only the first channel of multi-channel recordings; all recordings are regarded as single-channel recordings of a fixed microphone.
The sampling rate of all signals has been downsampled to 16 kHz.
From ToyADMOS, we used only IND-type data that contain the operating sounds of the entire operation (i.e., from start to stop) in a recording.
We mixed a target machine sound with environmental noise, and only noisy recordings are provided as training/test data.
The environmental noise samples were recorded in several real factory environments.
For the details of the recording procedure, please refer to the papers of <a href="https://ieeexplore.ieee.org/document/8937164">ToyADMOS</a> and <a href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf">MIMII Dataset</a>.</p>
<h2 id="development-and-evaluation-datasets">Development and evaluation datasets</h2>
<p>We first define two important terms in this task: Machine Type and Machine ID. Machine Type means the kind of machine, which in this task can be one of six: toy-car, toy-conveyor, valve, pump, fan, and slide rail. Machine ID is the identifier of each individual of the same type of machine, which in the training dataset can be of three or four.</p>
<p>Figure 2 shows an overview of our dataset, which consists of a development dataset, an additional training dataset, and an evaluation dataset.</p>
<p><strong>Development dataset</strong>: Each Machine Type has three or four Machine IDs. Each machine ID's dataset consists of (i) around 1,000 samples of normal sounds for training and (ii) 100-200 samples each of normal and anomalous sounds for the test. The normal and anomalous sound samples in (ii) are only for checking performance therefore the sound samples in (ii) shall not be used for training.<br/>
<strong>Evaluation dataset</strong>: This dataset consists of the same Machine Types' test samples as the development dataset. The number of test samples for each Machine ID is around 400, none of which have a condition label (i.e., normal or anomaly). Note that the Machine IDs of the evaluation dataset are different from those of the development dataset.<br/>
<strong>Additional training dataset</strong>: This dataset includes around 1,000 normal samples for each Machine Type and Machine ID used in the evaluation dataset. The participants can also use this dataset for training. The additional training dataset will be open on <strong>April 1st</strong>.</p>
<figure>
<div class="row row-centered">
<div class="col-xs-20 col-md-11 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2020/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_02.png"/>
<figcaption>Figure 2: Overview of development and evaluation datasets.</figcaption>
</div>
</div>
</figure>
<p><br/></p>
<h2 id="reference-labels">Reference labels</h2>
<p>The given labels for each training/test sample are Machine Type, Machine ID, and condition (normal/anomaly). Machine Type information is given by directory name, and Machine ID and condition information are given by their respective file names.
Note that the condition information of the test samples in the evaluation dataset is not given. Their condition labels will be released after the challenge results open. The detailed information is in the Repository section.</p>
<h2 id="external-data-resources">External data resources</h2>
<p>Based on the past DCASE's external data resource policy, we allow the use of external datasets and trained models under the following conditions:</p>
<ol>
<li>Test data in both development and evaluation datasets shall not be used for training.  </li>
<li>ToyADMOS and MIMII Dataset except for provided development/additional training/evaluation dataset for this challenge shall not be used. Because the datasets of this task are part of these datasets, thus, information on anomalous sounds in the test dataset might leak to the model.  </li>
<li>Datasets/trained models on the "List of external data resources allowed" can be used. The list will be updated upon request. Datasets/trained models, which are freely accessed by any other research group before <strong>1st of April 2020</strong>, can be added to the list.  </li>
<li>To add sources of external datasets/trained models to the list, send a request to the organizers by the evaluation set publishing date. To give an equal opportunity to use them for all competitors, we will update the "list of external data resources allowed" on the web page accordingly.  </li>
<li>Once the evaluation set is published, no further external sources will be added. The list will be locked after <strong>1st of June 2020</strong> which is the same date as Task 1.</li>
</ol>
<h3>List of external data resources allowed:</h3>
<table class="datatable table table-hover table-condensed" data-filter-control="false" data-filter-show-clear="false" data-id-field="name" data-pagination="false" data-show-pagination-switch="false" data-sort-name="name" data-sort-order="asc">
<thead>
<tr>
<th data-field="name" data-sortable="true">Dataset name</th>
<th data-field="type" data-filter-control="select" data-sortable="true" data-tag="true">Type</th>
<th data-field="date" data-sortable="true">Added</th>
<th data-field="link" data-value-type="url">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>IDMT-ISA-ELECTRIC-ENGINE</td>
<td>audio</td>
<td>01.03.2020</td>
<td>https://www.idmt.fraunhofer.de/en/publications/isa-electric-engine.html</td>
</tr>
<tr>
<td>AudioSet</td>
<td>audio</td>
<td>01.03.2020</td>
<td>https://research.google.com/audioset/</td>
</tr>
<tr>
<td>VGGish</td>
<td>model</td>
<td>01.03.2020</td>
<td>https://github.com/tensorflow/models/tree/master/research/audioset/vggish</td>
</tr>
<tr>
<td>OpenL3</td>
<td>model</td>
<td>11.03.2020</td>
<td>https://openl3.readthedocs.io/en/latest/</td>
</tr>
<tr>
<td>PANNs</td>
<td>model</td>
<td>26.05.2020</td>
<td>https://zenodo.org/record/3576403/</td>
</tr>
</tbody>
</table>
<p><br/></p>
<h2 id="download">Download</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/3678171" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/3678171" target="_blank">
<span style="font-size:20px;">Development dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(8.1 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.3678171">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.3678171.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/3727685" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/3727685" target="_blank">
<span style="font-size:20px;">Additional training dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(4.2 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.3727685">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.3727685.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/3841772" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/3841772" target="_blank">
<span style="font-size:20px;">Evaluation dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(1.9 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.3841772">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.3841772.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="task-setup-and-rules">Task setup and rules</h1>
<p>In order to calculate several metrics used in the anomaly detection research area, participants will calculate and submit <strong>anomaly scores</strong> for each test sample instead of a decision result.
Here, the anomaly score takes a large value when the input signal seems to be anomalous, and vice versa.
To calculate the anomaly score, participants need to train an <strong>anomaly score calculator</strong> <span class="math">\(\mathcal{A}\)</span> with parameter <span class="math">\(\theta\)</span>.
The input of <span class="math">\(\mathcal{A}\)</span> is a target machine's operating sound <span class="math">\(x \in \mathbb{R}^{L}\)</span> and its machine information including Machine Type and Machine ID, and <span class="math">\(\mathcal{A}\)</span> outputs one anomaly score for the whole audio-clip <span class="math">\(x\)</span> as <span class="math">\(\mathcal{A}_{\theta} (x) \in \mathbb{R}\)</span>.
Then, <span class="math">\(x\)</span> is determined to be anomalous when the anomaly score exceeds the pre-defined threshold value.
Thus, <span class="math">\(\mathcal{A}\)</span> needs to be trained so that <span class="math">\(\mathcal{A}_{\theta} (x)\)</span> takes a large value not only when the whole audio-clip <span class="math">\(x\)</span> is anomalous but also when a part of <span class="math">\(x\)</span> is anomalous, such as with collision anomalous sounds.
The decision procedure of the threshold is described in the Evaluation section.</p>
<p>Figure 3 shows the overview of this task, where the example is a procedure for calculating anomaly scores of the test samples of fan-id01.
First, the participants train an anomaly score calculator <span class="math">\(\mathcal{A}\)</span> using training data and optional external data resources.
Then, by using <span class="math">\(\mathcal{A}\)</span>, participants calculate anomaly scores of all test samples of fan-id01.
By repeating this procedure, participants calculate the anomaly score of all test samples of all Machine Types and Machine IDs.</p>
<p>Arbitral numbers of anomaly score calculator <span class="math">\(\mathcal{A}\)</span> can be used for calculating anomaly scores of test samples.
The simplest strategy is to use a single <span class="math">\(\mathcal{A}\)</span> for calculating the anomaly scores of all test samples of a single target Machine ID. In this case, <span class="math">\(\mathcal{A}\)</span> is <em>specialized</em> to a single target machine. Thus, participants need to train <span class="math">\(\mathcal{A}\)</span> for each Machine Type and each Machine ID.
A more challenging strategy is to use a single <span class="math">\(\mathcal{A}\)</span> for calculating the anomaly scores of all test samples of all Machine Types and all Machine IDs.
The advantage of this strategy is that participants can use all provided training samples for training; however, they need to consider the generalization of the model.</p>
<p>All training data with arbitrary splittings can be used to train an anomaly score calculator.
For example, to train <span class="math">\(\mathcal{A}\)</span> for calculating the anomaly score of "toy-car ID 5",
participants can opt to use only toy-car ID 5's training data, the training data of all toy-car's IDs, all provided training data, and/or other strategies.
Of course, normal/anomalous samples in test data cannot be used for training; however, simulating anomalous samples using the listed external data resources is allowed.</p>
<p>Changing the model (model/architecture/hyperparameters) between machine types within a single submission is allowed.
However, we expect participants to develop a simple ASD system, i.e. keep the model and hyperparameters fixed and just change the training data to adapt to each machine type.</p>
<figure>
<div class="row row-centered">
<div class="col-xs-20 col-md-10 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2020/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_03.png"/>
<figcaption>Figure 3: Task overview.
            </figcaption>
</div>
</div>
</figure>
<p><br/></p>
<h1 id="submission">Submission</h1>
<p>The official challenge submission consists of</p>
<ul>
<li>System output for the evaluation data</li>
<li>Meta information files</li>
</ul>
<p>System output should be presented as a text-file corresponding to each <strong>Machine Type</strong> and <strong>Machine ID</strong>, and its file name should be  <code>anomaly_score_&lt;type&gt;_id_&lt;ID&gt;.csv</code>.
The file (in CSV format, without header row) contains anomaly scores for each audio file in the test data of the evaluation dataset.
Result items can be in any order. All rows must be the following format:</p>
<div class="highlight"><pre><span></span><code>[filename (string)],[anomaly score (real value)]
</code></pre></div>
<p>Anomaly scores in the second column can take a negative value.
For example, typical auto-encoder-based anomaly score calculators use the squared reconstruction error, which takes a non-negative value, while statistical model-based methods (such as GMM) use the negative log-likelihood as the anomaly score, which can take both positive and negative values.</p>
<p>We allow up to four system output submissions per participant/team.
For each system, meta information should be provided in a separate file containing the task-specific information.
All files should be packaged into a zip file for submission.
Detailed information on the submission process can be found on the <a href="http://dcase.community/challenge2020/submission">Submission page</a>.</p>
<h1 id="evaluation">Evaluation</h1>
<p>This task is evaluated with the area under the receiver operating characteristic (ROC) curve (AUC) and the partial-AUC (pAUC).
The pAUC is an AUC calculated from a portion of the ROC curve over the pre-specified range of interest.
In our metric, the pAUC is calculated as the AUC over a low false-positive-rate (FPR) range <span class="math">\([0, p]\)</span>. The AUC and pAUC are defined as</p>
<div class="math">$$ {\rm AUC} = \frac{1}{N_{-}N_{+}} \sum_{i=1}^{N_{-}} \sum_{j=1}^{N_{+}} \mathcal{H} (\mathcal{A}_{\theta} (x_{j}^{+}) - \mathcal{A}_{\theta} (x_{i}^{-})), $$</div>
<div class="math">$$ {\rm pAUC} = \frac{1}{\lfloor p N_{-} \rfloor N_{+}} \sum_{i=1}^{\lfloor p N_{-} \rfloor} \sum_{j=1}^{N_{+}} \mathcal{H} (\mathcal{A}_{\theta} (x_{j}^{+}) - \mathcal{A}_{\theta} (x_{i}^{-})) $$</div>
<p>where <span class="math">\(\lfloor \cdot \rfloor\)</span> is the flooring function and <span class="math">\(\mathcal{H} (x)\)</span> returns 1 when <span class="math">\(x\)</span> &gt; 0 and 0 otherwise.
Here, <span class="math">\(\{x_{i}^{−}\}_{i=1}^{N_{−}}\)</span> and <span class="math">\(\{x_{j}^{+}\}_{j=1}^{N_{+}}\)</span> are normal and anomalous test samples, respectively, and have been sorted so that their anomaly scores are in descending order.
Here, <span class="math">\(N_{−}\)</span> and <span class="math">\(N_{+}\)</span> are the number of normal and anomalous test samples, respectively.
According to the above formulas, <strong>the anomaly scores of normal test samples are used as the threshold</strong>. This is why participants need to submit anomaly scores of all test samples instead of the decision results.</p>
<p>The reason for the additional use of the pAUC is based on practical requirements.
If an ASD system gives false alerts frequently, we cannot trust it, just as "the boy who cried wolf" could not be trusted.
Therefore, it is especially important to increase the true-positive-rate under low FPR conditions. In this task, we will use <span class="math">\(p=0.1\)</span>.</p>
<h2 id="ranking">Ranking</h2>
<p>In order to compare the submitted systems on all kinds of machines, the final rankings of the systems will be decided by using all Machine Types and Machine IDs.
However, the AUC averaged over Machine Types should not be used because the difficulty varies greatly depending on the Machine Type.
Therefore, we rank systems by the following procedure:</p>
<p><strong>Step 1</strong>: Calculate AUC and pAUC. AUC and pAUC for all Machine Types and Machine IDs are individually calculated using the above formula.<br/>
<strong>Step 2</strong>: Average AUC and pAUC. The average of AUC and pAUC are calculated for each Machine Type.<br/>
<strong>Step 3</strong>: Rank systems for each Machine Type. The AUC and pAUC rankings for each Machine Type are each determined by these averages obtained in the second step. Then, the rank of the system for each Machine Type is determined by the average of the AUC and pAUC ranks. In the case of the averaged rank is the same, the system with the higher pAUC rank wins.<br/>
<strong>Step 4</strong>: Decide final position. The final positions is determined by the rank averaged over Machine Types.<br/></p>
<h1 id="results">Results</h1>
<p>Complete results and technical reports can be found in the <a class="btn btn-primary" href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results">results page</a></p>
<h1 id="baseline-system">Baseline system</h1>
<p>The baseline system provides a simple entry-level approach that gives a reasonable performance in the dataset of Task 2.
It is a good starting point, especially for entry-level researchers who want to get familiar with the ASD task.</p>
<h2 id="system-description">System description</h2>
<p>The baseline system is a simple autoencoder (AE)-based anomaly score calculator.
The anomaly score is calculated as the reconstruction error of the observed sound. To obtain small anomaly scores for normal sounds, the AE is trained to minimize the reconstruction error of the normal training data.
This method is based on the assumption that the AE cannot reconstruct sounds that are not used in training, that is, unknown anomalous sounds.</p>
<p>In the baseline system, we first calculate a log-mel-spectrogram of the input <span class="math">\(X = \{X_t\}_{t=1}^{T}\)</span> where <span class="math">\(X_t \in \mathbb{R}^{F}\)</span>, and <span class="math">\(F\)</span> and <span class="math">\(T\)</span> are the number of mel-filters and time-frames, respectively.
Then, the acoustic feature at <span class="math">\(t\)</span> is obtained by concatenating before/after several frames of log-mel-filterbank outputs as
<span class="math">\(\psi_{t} = ( X_{t-P}, ..., X_{t+P} ) \in \mathbb{R}^{D}\)</span>,
where <span class="math">\(D = F \times (2P+1)\)</span> and <span class="math">\(P\)</span> is the context window size.
Then, anomaly score is calculated as</p>
<div class="math">$$A_{\theta} (x) = \frac{1}{DT} \sum_{t=1}^{T} \| \psi_{t} - {\rm AE}_{\theta} (\psi_{t}) \|_{2}^{2},$$</div>
<p>where <span class="math">\({\rm AE}\)</span> is an autoencoder and <span class="math">\(\parallel \cdot \parallel_{2}\)</span> is <span class="math">\(\ell_{2}\)</span> norm.</p>
<h3>Parameters</h3>
<h4>Acoustic features</h4>
<ul>
<li>Analysis frame 64 ms (50 % hop size)</li>
<li>Log mel-band energies (128 bands)</li>
<li>5 (<span class="math">\( = 2 P + 1\)</span>) frames are concatenated (i.e., <span class="math">\(P = 2\)</span>).</li>
<li>640 (<span class="math">\(= D = F \times (2 P + 1)\)</span>) dimensions are input to the autoencoder.</li>
</ul>
<h4>Network Architecture</h4>
<ul>
<li>Input shape: 640</li>
<li>Architecture:<ul>
<li>Dense layer #1<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #2<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #3<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #4<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Bottleneck layer<ul>
<li>Dense layer (units: 8)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #5<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #6<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #7<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #8<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Output layer<ul>
<li>Dense layer (units: 640)</li>
</ul>
</li>
</ul>
</li>
<li>Learning (epochs: 100, batch size: 512, data shuffling between epochs)<ul>
<li>Optimizer: Adam (learning rate: 0.001)</li>
</ul>
</li>
</ul>
<h2 id="repository">Repository</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://github.com/y-kawagu/dcase2020_task2_baseline" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x"></i>
<i class="fa fa-github fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://github.com/y-kawagu/dcase2020_task2_baseline" target="_blank">
<span style="font-size:20px;">DCASE2020 Task 2 <strong>baseline</strong>, repository <i class="fa fa-download"></i></span>
</a>
<br/>
</div>
</div>
<p><br/></p>
<p>The detailed information can be found on the Github repository. As a reference for label information, the directory structure is briefly described here.
When you unzip the downloaded files from the Github repository and Zenodo, you can see the following directory structure. As described in the Audio dataset section, Machine Type  information is given by directory name, and Machine  ID and condition information are given by file name, as:</p>
<ul>
<li>./dcase2020_task2_baseline  <ul>
<li>/00_train.py  </li>
<li>/01_test.py  </li>
<li>/common.py  </li>
<li>/keras_model.py  </li>
<li>/baseline.yaml  </li>
<li>/readme.md  </li>
<li>/dev_data  <ul>
<li>/ToyCar  <ul>
<li>/train (Only normal data for all Machine IDs are included.)  <ul>
<li>/normal_id_01_00000000.wav  </li>
<li>...  </li>
<li>/normal_id_01_00000999.wav  </li>
<li>/normal_id_02_00000000.wav  </li>
<li>...  </li>
<li>/normal_id_04_00000999.wav  </li>
</ul>
</li>
<li>/test (Normal and anomaly data for all Machine IDs are included.)  <ul>
<li>/normal_id_01_00000000.wav  </li>
<li>...  </li>
<li>/normal_id_01_00000349.wav  </li>
<li>/anomaly_id_01_00000000.wav  </li>
<li>...  </li>
<li>/anomaly_id_01_00000263.wav  </li>
<li>/normal_id_02_00000000.wav  </li>
<li>...  </li>
<li>/anomaly_id_04_00000264.wav  </li>
</ul>
</li>
</ul>
</li>
<li>/ToyConveyor (The other Machine Types have the same directory structure as ToyCar.)  </li>
<li>/fan  </li>
<li>/pump  </li>
<li>/slider  </li>
<li>/valve  </li>
</ul>
</li>
<li>/eval_data (after launch of the evaluation dataset)  <ul>
<li>/ToyCar  <ul>
<li>/train (Only normal data for all Machine IDs are included.)  <ul>
<li>/normal_id_05_00000000.wav  </li>
<li>...  </li>
<li>/normal_id_05_00000999.wav  </li>
<li>/normal_id_06_00000000.wav  </li>
<li>...  </li>
<li>/normal_id_07_00000999.wav  </li>
</ul>
</li>
<li>/test (Normal and anomaly data for all Machine IDs are included, but there is no information about normal or anomaly.)  <ul>
<li>/id_05_00000000.wav  </li>
<li>...  </li>
<li>/id_05_00000411.wav  </li>
<li>/id_06_00000000.wav  </li>
<li>...  </li>
<li>/id_07_00000411.wav  </li>
</ul>
</li>
</ul>
</li>
<li>/ToyConveyor (The other machine types have the same directory structure as ToyCar.)  </li>
<li>/fan  </li>
<li>/pump  </li>
<li>/slider  </li>
<li>/valve  </li>
</ul>
</li>
</ul>
</li>
</ul>
<p>After you run the training script <code>00_train.py</code> and the test script <code>01_test.py</code>, the csv files for each machine ID including the anomaly scores will be saved in the directory <strong>result/</strong>.
You can check more detailed information on the Github repository.</p>
<h2 id="results-for-the-development-dataset">Results for the development dataset</h2>
<p>The AUC and pAUC on the development dataset was evaluated using several types of GPUs (RTX 2080, etc.). Because the results produced with a GPU are generally non-deterministic, the average and standard deviation from these 10 independent trials (training and testing) are shown in the following table.</p>
<div class="table-responsive col-md-10">
<table class="table table-striped table-condensed">
<tbody>
<tr>
<td><strong>ToyCar</strong><br/><strong>Machine ID</strong><br/>1<br/>2<br/>3<br/>4<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>81.36 %<br/>85.97 %<br/>63.30 %<br/>84.45 %<br/>78.77 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>1.15 %<br/>0.58 %<br/>1.03 %<br/>1.87 %<br/>1.03 %<br/></td>
<td><br/><strong>pAUC (Ave.)</strong><br/>68.40 %<br/>77.72 %<br/>55.21 %<br/>68.97 %<br/>67.58 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.92 %<br/>0.90 %<br/>0.37 %<br/>2.37 %<br/>1.04 %</td>
</tr>
<tr>
<td><strong>ToyConveyor</strong><br/><strong>Machine ID</strong><br/>1<br/>2<br/>3<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>78.07 %<br/>64.16 %<br/>75.35 %<br/>72.53 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.79 %<br/>0.53 %<br/>1.39 %<br/>0.67 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>64.25 %<br/>56.01 %<br/>61.03 %<br/>60.43 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.99 %<br/>0.71 %<br/>1.00 %<br/>0.74 %</td>
</tr>
<tr>
<td><strong>fan</strong><br/><strong>Machine ID</strong><br/>0<br/>2<br/>4<br/>6<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>54.41 %<br/>73.40 %<br/>61.61 %<br/>73.92 %<br/>65.83 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.47 %<br/>0.58 %<br/>1.08 %<br/>0.54 %<br/>0.53 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>49.37 %<br/>54.81 %<br/>53.26 %<br/>52.35 %<br/>52.45 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.10 %<br/>0.34 %<br/>0.40 %<br/>0.51 %<br/>0.21 %</td>
</tr>
<tr>
<td><strong>pump</strong><br/><strong>Machine ID</strong><br/>0<br/>2<br/>4<br/>6<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>67.15 %<br/>61.53 %<br/>88.33 %<br/>74.55 %<br/>72.89 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.87 %<br/>0.97 %<br/>0.66 %<br/>1.24 %<br/>0.70 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>56.74 %<br/>58.10 %<br/>67.10 %<br/>58.02 %<br/>59.99 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.82 %<br/>0.93 %<br/>1.09 %<br/>1.21 %<br/>0.77 %</td>
</tr>
<tr>
<td><strong>slider</strong><br/><strong>Machine ID</strong><br/>0<br/>2<br/>4<br/>6<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>96.19 %<br/>78.97 %<br/>94.30 %<br/>69.59 %<br/>84.76 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.43 %<br/>0.28 %<br/>0.64 %<br/>1.45 %<br/>0.29 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>81.44 %<br/>63.68 %<br/>71.98 %<br/>49.02 %<br/>66.53 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>1.89 %<br/>0.72 %<br/>2.20 %<br/>0.41 %<br/>0.62 %</td>
</tr>
<tr>
<td><strong>valve</strong><br/><strong>Machine ID</strong><br/>0<br/>2<br/>4<br/>6<br/>Average</td>
<td><br/><strong>AUC (Ave.)</strong><br/>68.76 %<br/>68.18 %<br/>74.30 %<br/>53.90 %<br/>66.28 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.65 %<br/>0.86 %<br/>0.71 %<br/>0.38 %<br/>0.49 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>51.70 %<br/>51.83 %<br/>51.97 %<br/>48.43 %<br/>50.98 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.19 %<br/>0.31 %<br/>0.20 %<br/>0.20 %<br/>0.15 %</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h1 id="citation">Citation</h1>
<p>If you are participating in this task or using the <strong>ToyADMOS</strong>, <strong>MIMII Dataset</strong>, and/or <strong>baseline code</strong>, please cite the following papers:</p>
<div class="btex-item" data-item="Koizumi_WASPAA2019_01" data-source="content/data/challenge2020/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Koizumi_WASPAA2019_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Yuma Koizumi, Shoichiro Saito, Hisashi Uematsu, Noboru Harada, and Keisuke Imoto.
<em>ToyADMOS: a dataset of miniature-machine operating sounds for anomalous sound detection.</em>
In Proceedings of <span class="bibtex-protected">IEEE</span> Workshop on Applications of Signal Processing to Audio and Acoustics (<span class="bibtex-protected">WASPAA</span>), 308–312. November 2019.
URL: <a href="https://ieeexplore.ieee.org/document/8937164">https://ieeexplore.ieee.org/document/8937164</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://arxiv.org/abs/1908.03299" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" class="panel-collapse collapse" id="collapseKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" role="tabpanel">
<h4>ToyADMOS: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection</h4>
<h5>Abstract</h5>
<p class="text-justify">This paper introduces a new dataset called ``{ToyADMOS}'' designed for anomaly detection in machine operating sounds (ADMOS). To the best our knowledge, no large-scale datasets are available for ADMOS, although large-scale datasets have contributed to recent advancements in acoustic signal processing. This is because anomalous sound data are difficult to collect. To build a large-scale dataset for ADMOS, we collected anomalous operating sounds of miniature machines (toys) by deliberately damaging them. The released dataset consists of three sub-datasets for machine-condition inspection, fault diagnosis of machines with geometrically fixed tasks, and fault diagnosis of machines with moving tasks. Each sub-dataset includes over 180 hours of normal machine-operating sounds and over 4,000 samples of anomalous sounds collected with four microphones at a 48-kHz sampling rate. The dataset is freely available for download at https://github.com/YumaKoizumi/ToyADMOS-dataset.</p>
<h5>Keywords</h5>
<p class="text-justify">Anomaly detection in sounds, machine operating sounds, product inspection, dataset</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://arxiv.org/abs/1908.03299" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583flabel" class="modal fade" id="bibtexKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583f" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexKoizumi_WASPAA2019_019e44d87567a54f51aa390b16923c583flabel">ToyADMOS: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Koizumi_WASPAA2019_01,
    Author = "Koizumi, Yuma and Saito, Shoichiro and Uematsu, Hisashi and Harada, Noboru and Imoto, Keisuke",
    title = "{ToyADMOS}: A Dataset of Miniature-machine Operating Sounds for Anomalous Sound Detection",
    year = "2019",
    booktitle = "Proceedings of {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics ({WASPAA})",
    month = "November",
    pages = "308--312",
    keywords = "Anomaly detection in sounds, machine operating sounds, product inspection, dataset",
    abstract = "This paper introduces a new dataset called ``{ToyADMOS}'' designed for anomaly detection in machine operating sounds (ADMOS). To the best our knowledge, no large-scale datasets are available for ADMOS, although large-scale datasets have contributed to recent advancements in acoustic signal processing. This is because anomalous sound data are difficult to collect. To build a large-scale dataset for ADMOS, we collected anomalous operating sounds of miniature machines (toys) by deliberately damaging them. The released dataset consists of three sub-datasets for machine-condition inspection, fault diagnosis of machines with geometrically fixed tasks, and fault diagnosis of machines with moving tasks. Each sub-dataset includes over 180 hours of normal machine-operating sounds and over 4,000 samples of anomalous sounds collected with four microphones at a 48-kHz sampling rate. The dataset is freely available for download at https://github.com/YumaKoizumi/ToyADMOS-dataset.",
    url = "https://ieeexplore.ieee.org/document/8937164"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Purohit_DCASE2019_01" data-source="content/data/challenge2020/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Purohit_DCASE2019_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Harsh Purohit, Ryo Tanabe, Takeshi Ichige, Takashi Endo, Yuki Nikaido, Kaori Suefusa, and Yohei Kawaguchi.
<em>MIMII Dataset: sound dataset for malfunctioning industrial machine investigation and inspection.</em>
In Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (<span class="bibtex-protected">DCASE2019</span>), 209–213. November 2019.
URL: <a href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf">http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapsePurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapsePurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" class="panel-collapse collapse" id="collapsePurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" role="tabpanel">
<h4>MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection</h4>
<h5>Abstract</h5>
<p class="text-justify">Factory machinery is prone to failure or breakdown, resulting in significant expenses for companies. Hence, there is a rising interest in machine monitoring using different sensors including microphones. In scientific community, the emergence of public datasets has been promoting the advancement in acoustic detection and classification of scenes and events, but there are no public datasets that focus on the sound of industrial machines under normal and anomalous operating conditions in real factory environments. In this paper, we present a new dataset of industrial machine sounds which we call a sound dataset for malfunctioning industrial machine investigation and inspection (MIMII dataset). Normal and anomalous sounds were recorded for different types of industrial machines, i.e. valves, pumps, fans and slide rails. To resemble the real-life scenario, various anomalous sounds have been recorded, for instance, contamination, leakage, rotating unbalance, rail damage, etc. The purpose of releasing the MIMII dataset is to help the machine-learning and signal-processing community to advance the development of automated facility maintenance.</p>
<h5>Keywords</h5>
<p class="text-justify">Machine sound dataset, acoustic scene classification, anomaly detection, unsupervised anomalous sound detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7label" class="modal fade" id="bibtexPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexPurohit_DCASE2019_01907eb3f740c845aa8193b2c6756410b7label">MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Purohit_DCASE2019_01,
    Author = "Purohit, Harsh and Tanabe, Ryo and Ichige, Takeshi and Endo, Takashi and Nikaido, Yuki and Suefusa, Kaori and Kawaguchi, Yohei",
    title = "{MIMII Dataset}: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection",
    year = "2019",
    booktitle = "Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop ({DCASE2019})",
    month = "November",
    pages = "209--213",
    keywords = "Machine sound dataset, acoustic scene classification, anomaly detection, unsupervised anomalous sound detection",
    abstract = "Factory machinery is prone to failure or breakdown, resulting in significant expenses for companies. Hence, there is a rising interest in machine monitoring using different sensors including microphones. In scientific community, the emergence of public datasets has been promoting the advancement in acoustic detection and classification of scenes and events, but there are no public datasets that focus on the sound of industrial machines under normal and anomalous operating conditions in real factory environments. In this paper, we present a new dataset of industrial machine sounds which we call a sound dataset for malfunctioning industrial machine investigation and inspection (MIMII dataset). Normal and anomalous sounds were recorded for different types of industrial machines, i.e. valves, pumps, fans and slide rails. To resemble the real-life scenario, various anomalous sounds have been recorded, for instance, contamination, leakage, rotating unbalance, rail damage, etc. The purpose of releasing the MIMII dataset is to help the machine-learning and signal-processing community to advance the development of automated facility maintenance.",
    url = "http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop\_Purohit\_21.pdf"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Koizumi_DCASE2020_01" data-source="content/data/challenge2020/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Koizumi_DCASE2020_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Yuma Koizumi, Yohei Kawaguchi, Keisuke Imoto, Toshiki Nakamura, Yuki Nikaido, Ryo Tanabe, Harsh Purohit, Kaori Suefusa, Takashi Endo, Masahiro Yasuda, and Noboru Harada.
<em>Description and discussion on DCASE2020 challenge task2: unsupervised anomalous sound detection for machine condition monitoring.</em>
In Proceedings of the Detection and Classification of Acoustic Scenes and Events 2020 Workshop (DCASE2020), 81–85. November 2020.
URL: <a href="http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Koizumi_3.pdf">http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Koizumi_3.pdf</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Koizumi_3.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" class="panel-collapse collapse" id="collapseKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" role="tabpanel">
<h4>Description and Discussion on DCASE2020 Challenge Task2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring</h4>
<h5>Abstract</h5>
<p class="text-justify">In this paper, we present the task description and discuss the results of the DCASE 2020 Challenge Task 2: Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring. The goal of anomalous sound detection (ASD) is to identify whether the sound emitted from a target machine is normal or anomalous. The main challenge of this task is to detect unknown anomalous sounds under the condition that only normal sound samples have been provided as training data. We have designed this challenge as the first benchmark of ASD research, which includes a large-scale dataset, evaluation metrics, and a simple baseline system. We received 117 submissions from 40 teams, and several novel approaches have been developed as a result of this challenge. On the basis of the analysis of the evaluation results, we discuss two new approaches and their problems.</p>
<h5>Keywords</h5>
<p class="text-justify">Anomaly detection, dataset, acoustic condition monitoring, DCASE Challenge</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Koizumi_3.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4label" class="modal fade" id="bibtexKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexKoizumi_DCASE2020_01eb9e0398349743589d10cf8b0038afb4label">Description and Discussion on DCASE2020 Challenge Task2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Koizumi_DCASE2020_01,
    Author = "Koizumi, Yuma and Kawaguchi, Yohei and Imoto, Keisuke and Nakamura, Toshiki and Nikaido, Yuki and Tanabe, Ryo and Purohit, Harsh and Suefusa, Kaori and Endo, Takashi and Yasuda, Masahiro and Harada, Noboru",
    title = "Description and Discussion on {DCASE}2020 Challenge Task2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring",
    year = "2020",
    booktitle = "Proceedings of the Detection and Classification of Acoustic Scenes and Events 2020 Workshop (DCASE2020)",
    month = "November",
    pages = "81--85",
    keywords = "Anomaly detection, dataset, acoustic condition monitoring, DCASE Challenge",
    abstract = "In this paper, we present the task description and discuss the results of the DCASE 2020 Challenge Task 2: Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring. The goal of anomalous sound detection (ASD) is to identify whether the sound emitted from a target machine is normal or anomalous. The main challenge of this task is to detect unknown anomalous sounds under the condition that only normal sound samples have been provided as training data. We have designed this challenge as the first benchmark of ASD research, which includes a large-scale dataset, evaluation metrics, and a simple baseline system. We received 117 submissions from 40 teams, and several novel approaches have been developed as a result of this challenge. On the basis of the analysis of the evaluation results, we discuss two new approaches and their problems.",
    url = "http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop\_Koizumi\_3.pdf"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/>
<br/></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>