<!DOCTYPE html><html lang="en">
<head>
    <title>Bird audio detection - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2018/task-bird-audio-detection">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Detecting bird sounds in audio is an important task for automatic wildlife monitoring, as well as in citizen science and audio library management. Bird sound detection is a very common required first step before further analysis (e.g. classification, counting), and makes it possible to conduct work with large datasets …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2018</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2018/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2018/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2018/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2018/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-acoustic-scene-classification-results-c"><i class="fa fa-bar-chart"></i>&nbsp;Subtask C</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2018/task-general-purpose-audio-tagging" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-tags text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2018/task-general-purpose-audio-tagging"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-general-purpose-audio-tagging-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2018/task-bird-audio-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2018/task-bird-audio-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-bird-audio-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2018/task-monitoring-domestic-activities" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-home text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2018/task-monitoring-domestic-activities"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2018/task-monitoring-domestic-activities-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2018/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2018/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/dunes-02.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-warning"></i><i class="fa dc-bird fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Birds</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 3</span></span><img src="../images/logos/dcase/dcase2018_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Bird audio detection</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Dan Stowell" class="img img-circle" src="/images/person/dan_stowell.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Dan Stowell</strong>
<a class="icon" href="mailto:dan.stowell@qmul.ac.uk"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Hervé Glotin" class="img img-circle" src="/images/person/herve_glotin.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Hervé Glotin</strong>
<a class="icon" href="mailto:glotin@univ-tln.fr"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.univ-tln.fr/">
                                University of Toulon
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Yannis Stylianou" class="img img-circle" src="/images/person/yannis_stylianou.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yannis Stylianou</strong>
<a class="icon" href="mailto:tragani@ics.forth.gr"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.ics.forth.gr/">
                                University of Crete
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mike Wood" class="img img-circle" src="/images/person/mike_wood.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mike Wood</strong>
<a class="icon" href="mailto:m.d.wood@salford.ac.uk;"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.salford.ac.uk/">
                                University of Salford
                                </a>
</p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a></li>
<li><a href="#audio-datasets">Audio datasets</a>
<ul>
<li><a href="#development-datasets">Development datasets</a></li>
<li><a href="#evaluation-datasets">Evaluation datasets</a></li>
<li><a href="#recommended-cross-validation-procedure">Recommended cross-validation procedure</a></li>
</ul>
</li>
<li><a href="#submission">Submission</a></li>
<li><a href="#task-rules">Task rules</a>
<ul>
<li><a href="#a-adapting-to-the-evaluation-data">(a) Adapting to the evaluation data</a></li>
<li><a href="#b-use-of-external-data">(b) Use of external data</a></li>
</ul>
</li>
<li><a href="#evaluation-measure">Evaluation measure</a></li>
<li><a href="#prizes">Prizes</a></li>
<li><a href="#baseline-system">Baseline system</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="lead">Detecting bird sounds in audio is an important task for automatic wildlife monitoring, as well as in citizen science and audio library management. Bird sound detection is a very common required first step before further analysis (e.g. classification, counting), and makes it possible to conduct work with large datasets (e.g. continuous 24h monitoring) by filtering data down to regions of interest. </p>
<p>This task is an expanded version of the <a href="http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/">Bird Audio Detection challenge</a> which ran in 2016/2017.</p>
<h1 id="description">Description</h1>
<p>The task is to design a system that, given a short audio recording, returns a binary decision for the presence/absence of bird sound (bird sound of any kind). The output can be just "0" or "1", but we encourage weighted/probability outputs in the continuous range [0,1] for the purposes of evaluation.
For the main assessment we will use the well-known "Area Under the ROC Curve" (<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve">AUC</a>) measure of classification performance.</p>
<p>An important goal of this task is <strong>generalisation to new conditions</strong>. To explore this we provide 3 separate development datasets, and 3 evaluation datasets, <em>each recorded under differing conditions</em>. The datasets will have different balances of positive/negative cases, different bird species, different background sounds, different recording equipment. To solve this task well, you will need an approach which either inherently generalises across conditions (including conditions not seen in the training data), or which can self-adapt to new datasets ("domain adaptation").</p>
<p>Note that for every audio clip, you <strong>will</strong> be told which dataset it belongs to. This means that adapting to the overall characteristics of each dataset separately is possible. The evaluation will also consider each dataset separately and combine the outcomes, rather than treating them as a single pooled dataset.</p>
<h1 id="audio-datasets">Audio datasets</h1>
<p>We provide three development datasets, and three evaluation datasets, each from a separate bird sound monitoring project.
All of the datasets contain 10-second-long WAV files (44.1 kHz mono PCM), and are manually labelled with a 0 or 1 to indicate the absence/presence of any birds within that 10-second audio clip.</p>
<p>Note that there will in general be some low level of error/disagreement in "ground truth" manual labelling. For BirdVox the accuracy of the labeling is estimated to be 99.5% or better, while for our other datasets it is estimated as 96.7%.</p>
<p>The sampling strategy differs across datasets. Crowdsourced recordings are opportunistic, having sampling bias of users (e.g. good weather conditions, daytime). The remote-monitoring sets contain clips extracted according to fixed recording schedules, and are typically evenly sampled across times of day and diverse weather conditions.</p>
<figure>
<div class="row row-centered">
<div class="col-xs-10 col-md-8 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2018/task3_bird_datasets.png"/>
</div>
</div>
</figure>
<p><br/></p>
<p>Download links are below, next to the description of each dataset.</p>
<p>All datasets are published under the Creative Commons Attribution licence <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>.</p>
<h2 id="development-datasets">Development datasets</h2>
<ol>
<li>
<p><strong>Field recordings, worldwide ("freefield1010")</strong> - a collection of 7,690 excerpts from field recordings around the world, gathered by the <a href="http://freesound.org/">FreeSound</a> project, and then <a href="https://arxiv.org/abs/1309.5275">standardised</a> for research. This collection is very diverse in location and environment, and for the BAD Challenge we have annotated it for the presence/absence of birds.<br/>
- Download: [<strong><a href="https://ndownloader.figshare.com/files/10853303">data labels</a></strong>] • [<strong><a href="https://archive.org/download/ff1010bird/ff1010bird_wav.zip">audio files (5.8 Gb zip)</a></strong>] (or [<a href="https://archive.org/download/ff1010bird/ff1010bird_archive.torrent">via bittorrent</a>])  </p>
</li>
<li>
<p><strong>Crowdsourced dataset, UK ("warblrb10k")</strong> - 8,000 smartphone audio recordings from around the UK, crowdsourced by users of <a href="http://warblr.net/">Warblr the bird recognition app</a>. The audio covers a wide distribution of UK locations and environments, and includes weather noise, traffic noise, human speech and even human bird imitations.<br/>
- Download: [<strong><a href="https://ndownloader.figshare.com/files/10853306">data labels</a></strong>] • [<strong><a href="https://archive.org/download/warblrb10k_public/warblrb10k_public_wav.zip">audio files (4.3 Gb zip)</a></strong>] (or [<a href="https://archive.org/download/warblrb10k_public/warblrb10k_public_archive.torrent">via bittorrent</a>])  </p>
</li>
<li>
<p><strong>Remote monitoring flight calls, USA ("BirdVox-DCASE-20k")</strong> - 20,000 audio clips collected from remote monitoring units placed near Ithaca, NY, USA during the autumn of 2015, by <a href="http://wp.nyu.edu/birdvox">the BirdVox project</a>. <a href="https://zenodo.org/record/1208080">More info about BirdVox-DCASE-20k</a><br/>
- Download: [<strong><a href="https://ndownloader.figshare.com/files/10853300">data labels</a></strong>] • [<strong><a href="https://zenodo.org/record/1208080/files/BirdVox-DCASE-20k.zip">audio files (15.4 Gb zip)</a></strong>]</p>
</li>
</ol>
<p><em>(Thanks to <a href="https://archive.org/search.php?query=subject%3A%22badchallenge%22">Internet Archive</a>, <a href="https://zenodo.org/">Zenodo</a> and <a href="https://figshare.com/articles/Bird_Audio_Detection_public_data_for_DCASE_Challenge_2018_Task_3/6026471">Figshare</a> for dataset hosting)</em></p>
<h2 id="evaluation-datasets">Evaluation datasets</h2>
<ol>
<li>
<p><strong>Crowdsourced dataset, UK ("warblrb10k")</strong> - a held-out set of 2,000 recordings from the same conditions as the Warblr development dataset.<br/>
- Download: <a href="https://zenodo.org/record/1298604/files/wabrlrb10k_test_wav.zip?download=1">audio files (1.3 GB zip)</a></p>
</li>
<li>
<p><strong>Remote monitoring dataset, Chernobyl ("Chernobyl")</strong> - 6,620 audio clips collected from unattended remote monitoring equipment in the Chernobyl Exclusion Zone (CEZ). This data was collected as part of the <a href="https://wiki.ceh.ac.uk/display/NRT/NERC+RATE+TREE+Home">TREE</a> (Transfer-Exposure-Effects) research project into the long-term effects of the Chernobyl accident on local ecology. The audio covers a range of birds and includes weather, large mammal and insect noise sampled across various CEZ environments, including abandoned village, grassland and forest areas.<br/>
- Download: <a href="https://zenodo.org/record/1298604/files/chern_wav.zip?download=1">audio files (5.3 GB zip)</a></p>
</li>
<li>
<p><strong>Remote monitoring night-flight calls, Poland ("PolandNFC")</strong> - 4,000 recordings from Hanna Pamuɫa's PhD project of monitoring autumn nocturnal bird migration. The recordings were collected every night, from September to November 2016 on the Baltic Sea coast, Poland, using Song Meter SM2 units with microphones mounted on 3–5 m poles. For this challenge, we use a subset derived from 15 nights with different weather conditions and background noise including wind, rain, sea noise, insect calls, human voice and deer calls.<br/>
- Download: <a href="https://zenodo.org/record/1298604/files/PolandNFC_test_wav.zip?download=1">audio files (2.3 Gb zip)</a></p>
</li>
</ol>
<p><em>(Thanks to <a href="https://zenodo.org/record/1298604">Zenodo</a> for dataset hosting)</em></p>
<h2 id="recommended-cross-validation-procedure">Recommended cross-validation procedure</h2>
<p>In standard machine learning studies, you take only one dataset and divide it into "folds" for cross-validation. However in this task, we recommend that you perform <strong>stratified 3-way cross-validation</strong> and in each fold you use two sets for training and the other one for testing. This allows you to study the way your method behaves when exposed to data from unseen conditions, just like in the final evaluation.</p>
<h1 id="submission">Submission</h1>
<p>The <a href="http://lsis-argo.lsis.org:8005">interface</a> for submitting results files is a Kaggle-like interface designed for academic users.</p>
<p>Your system should output a results file in the following CSV format:</p>
<div class="highlight"><pre><span></span><code>filename1,decision1
filename2,decision2
...
</code></pre></div>
<p>Two columns, separated by a comma (and rows separated by a "newline"). Filenames are <em>without</em> the .wav extension. Note that the public development data has only 0 or 1 as the annotation, while we encourage your submission to make use of the continuous range between 0 and 1, given as ordinary floating-point numbers. There should be no additional whitespace in the file, except for the newlines. The development data also has an extra column indicating which file belongs to which dataset, but this column is not needed for submission.</p>
<p>Note that you should submit a single CSV file, containing predictions for <strong>all of the evaluation datasets</strong> combined into one file.
Participants <em>must</em> submit predictions for all of our testing datasets, since otherwise that would allow
for less-general solutions.</p>
<ul>
<li>Here is a <a href="https://ndownloader.figshare.com/files/12208850">blank example submission file</a></li>
</ul>
<p>During the challenge, a public leaderboard will be provided using a small amount of evaluation data to provide a "preview" of what the overall results might be like. (The preview score is calculated using approx 1000 files randomly selected from the Chernobyl and warblrb10k data.)</p>
<p>You may submit outputs from multiple variants of your system - one per day, with an overall maximum of 20 per team - until the challenge deadline. Each time, you will see how the results appear with a small subset of the evaluation data, a clue about your performance. You will then be asked to select your preferred four submissions to go into the final evaluation.</p>
<ul>
<li><strong><a href="http://lsis-argo.lsis.org:8005">Make a submission via the online leaderboard here</a></strong></li>
</ul>
<p>At the end of the challenge, you should <em>also</em> submit your final tech report and predictions using the submission system for the main DCASE challenge.</p>
<h1 id="task-rules">Task rules</h1>
<p>There are general rules valid for all tasks; these, along with information on technical report and submission requirements can be found <a href="/challenge2018/rules">here</a>.</p>
<p>Task specific rules:</p>
<h2 id="a-adapting-to-the-evaluation-data">(a) Adapting to the evaluation data</h2>
<p>Although the main rules state that "the use of statistics about the evaluation data in the decision making is also forbidden", for this task it is <strong>allowed</strong> and even <em>encouraged</em> that the algorithms developed can adapt their behaviour based on overall statistics of each dataset. However participants are <strong>not allowed</strong> to make subjective judgments of the evaluation data, nor to annotate it.</p>
<h2 id="b-use-of-external-data">(b) Use of external data</h2>
<p>Use of external data and transfer learning is allowed in this task under the following conditions:</p>
<ul>
<li>The used dataset must be public and freely available </li>
<li>Participants must inform/suggest such data to be listed on the task webpage, so that all competitors know about them and have equal opportunity to use them</li>
<li>Once the evaluation set is published, the list of allowed external datasets is locked (no further external sources allowed)</li>
<li>Participants should list in their technical report the external data sources they used</li>
</ul>
<p>As one specific example, Google's "<em>AudioSet</em>" includes labelled bird examples, and we have prepared a metadata file for participants who wish to use AudioSet. However there are some important warnings: (1) AudioSet does not provide raw audio - instead it provides pre-computed features, which you might not wish to work with; (2) the labelling is crowdsourced and not intended for bird detection, so there are likely to be many false negatives and unusual items; (3) even the "balanced" AudioSet is very unbalanced for our purposes: less than 1.6% of the items are tagged with bird tags.</p>
<p>Here are external datasets that have been suggested by challenge participants:</p>
<ul>
<li>Development and test data from the <a href="http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/">first Bird Audio Detection challenge</a> (note that there is some overlap with this year)</li>
<li><a href="https://research.google.com/audioset/">Audioset</a> (here are pre-prepared annotation files for <a href="https://ndownloader.figshare.com/files/10853309">"bird, balanced train"</a> and <a href="https://ndownloader.figshare.com/files/10853312">"bird, unbalanced train"</a>)</li>
<li><a href="https://wp.nyu.edu/birdvox/codedata/#datasets">Birdvox datasets</a> (note that there is already BirdVox data included in the challenge)</li>
<li><a href="https://archive.org/details/xccoverbl_2014">XCCoverbl</a>, British birds from Xeno Canto. It appears Kaggle has <a href="https://www.kaggle.com/rtatman/british-birdsong-dataset/data">republished</a> the data</li>
<li>NIPS 2013 bird species classification <a href="https://www.kaggle.com/c/multilabel-bird-species-classification-nips2013/data">dataset</a></li>
<li>Birdclef 2017 bird species classification <a href="http://www.imageclef.org/lifeclef/2017/bird">dataset</a></li>
</ul>
<h1 id="evaluation-measure">Evaluation measure</h1>
<p>The scoring on this task will use the "Area Under the ROC Curve" (<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve">AUC</a>) measure of classification performance (we use the implementation from the sklearn.metrics Python package). More precisely, we will use a <strong>stratified AUC</strong>: we calculate AUC separately for each of the evaluation datasets, and then take the average (the harmonic mean). This gives two improvements over the "simple" AUC: firstly the calculation allows that the "detection threshold" for each dataset might be different; secondly it combines performance across datasets in an explicit weighted fashion, not merely influenced by the number of files in each dataset.</p>
<p>During development, you can perform a similar stratified AUC simply by calculating the AUC for each of the three "folds" as recommended above, and then taking the harmonic mean.</p>
<h1 id="prizes">Prizes</h1>
<p>For the bird detection task we offer <strong>two awards</strong>, with cash prizes, for the following:</p>
<ul>
<li><strong>£250: Highest-scoring reproducible method award</strong> for the high-scoring submission that is open-source and fully reproducible.</li>
<li><strong>£250: Judges' award</strong> for the method considered by the judges to be the most interesting or innovative.</li>
</ul>
<p>The decisions will be made after the closing date, and will be based on the scores attained as well as the information supplied about how your method is done.</p>
<h1 id="baseline-system">Baseline system</h1>
<p>As a baseline, we have published <a href="https://github.com/DCASE-REPO/bulbul_bird_detection_dcase2018">a modified version of "bulbul" the strongest-scoring system in the original Bird Audio Detection challenge</a>. Our modified version will work with the updated 2018 metadata format, and also performs stratified crossvalidation across datasets, in the manner we recommend.</p>
<h1 id="results">Results</h1>
<p>Complete results and technical reports can be found at <a class="btn btn-info" href="/challenge2018/task-bird-audio-detection-results">DCASE2018 Bird Audio Detection results page</a>.</p>
<h1 id="citation">Citation</h1>
<p>If you are using the <strong>dataset</strong> code, or want to refer <strong>challenge task</strong> please cite the following paper:</p>
<div class="btex-item" data-item="Stowell_2018badchj" data-source="content/data/challenge2018/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Stowell_2018badchj"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            D. Stowell, Y. Stylianou, M. Wood, H. Pamu<span class="bibtex-protected">ł</span>a, and H. Glotin.
<em>Automatic acoustic detection of birds through deep learning: the first bird audio detection challenge.</em>
<em>Methods in Ecology and Evolution</em>, 2018.
URL: <a href="https://arxiv.org/abs/1807.05812]">https://arxiv.org/abs/1807.05812]</a>, <a href="https://arxiv.org/abs/1807.05812">arXiv:1807.05812</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://arxiv.org/pdf/1807.05812" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" class="panel-collapse collapse" id="collapseStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" role="tabpanel">
<h4>Automatic acoustic detection of birds through deep learning: the first Bird Audio Detection challenge</h4>
<h5>Abstract</h5>
<p class="text-justify">Assessing the presence and abundance of birds is important for monitoring specific species as well as overall ecosystem health. Many birds are most readily detected by their sounds, and thus passive acoustic monitoring is highly appropriate. Yet acoustic monitoring is often held back by practical limitations such as the need for manual configuration, reliance on example sound libraries, low accuracy, low robustness, and limited ability to generalise to novel acoustic conditions. Here we report outcomes from a collaborative data challenge showing that with modern machine learning including deep learning, general-purpose acoustic bird detection can achieve very high retrieval rates in remote monitoring data --- with no manual recalibration, and no pre-training of the detector for the target species or the acoustic conditions in the target environment. Multiple methods were able to attain performance of around 88% AUC (area under the ROC curve), much higher performance than previous general-purpose methods. We present new acoustic monitoring datasets, summarise the machine learning techniques proposed by challenge teams, conduct detailed performance evaluation, and discuss how such approaches to detection can be integrated into remote monitoring projects.</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://arxiv.org/pdf/1807.05812" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0label" class="modal fade" id="bibtexStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexStowell_2018badchj59921d6005e74d53a8d36f08bcc967e0label">Automatic acoustic detection of birds through deep learning: the first Bird Audio Detection challenge</h4>
</div>
<div class="modal-body">
<pre>@article{Stowell_2018badchj,
    Author = "Stowell, D. and Stylianou, Y. and Wood, M. and Pamu{\l}a, H. and Glotin, H.",
    title = "Automatic acoustic detection of birds through deep learning: the first Bird Audio Detection challenge",
    journal = "Methods in Ecology and Evolution",
    archiveprefix = "arXiv",
    eprint = "1807.05812",
    year = "2018",
    url = "https://arxiv.org/abs/1807.05812]",
    abstract = "Assessing the presence and abundance of birds is important for monitoring specific species as well as overall ecosystem health. Many birds are most readily detected by their sounds, and thus passive acoustic monitoring is highly appropriate. Yet acoustic monitoring is often held back by practical limitations such as the need for manual configuration, reliance on example sound libraries, low accuracy, low robustness, and limited ability to generalise to novel acoustic conditions. Here we report outcomes from a collaborative data challenge showing that with modern machine learning including deep learning, general-purpose acoustic bird detection can achieve very high retrieval rates in remote monitoring data --- with no manual recalibration, and no pre-training of the detector for the target species or the acoustic conditions in the target environment. Multiple methods were able to attain performance of around 88\% AUC (area under the ROC curve), much higher performance than previous general-purpose methods. We present new acoustic monitoring datasets, summarise the machine learning techniques proposed by challenge teams, conduct detailed performance evaluation, and discuss how such approaches to detection can be integrated into remote monitoring projects."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p>The paper describes the previous bird challenge (2016-2017), but also specifies much of how this Task 3 was conducted.</p>
<p><br/>
<br/></p>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>