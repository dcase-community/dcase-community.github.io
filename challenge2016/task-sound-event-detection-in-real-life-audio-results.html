<!DOCTYPE html><html lang="en">
<head>
    <title>Sound event detection in real life audio - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2016/task-sound-event-detection-in-real-life-audio-results">
        <meta name="author" content="Toni Heittola" />
        <meta name="description" content="Task description Detailed task description in task description page Challenge results Here you can find complete information on the submissions for Task 3: results on evaluation and development set (when reported by authors), class-wise results, technical reports and bibtex citations. Detailed description of metrics used can be found here. System â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2016</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2016/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-events text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-audio-tagging" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-tags text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-audio-tagging"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-audio-tagging-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2016/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2016/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2016/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2016/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/marina-bay-01.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-events fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Events</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 3</span></span><img src="../images/logos/dcase/dcase2016_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Sound event detection <br>in real life audio</h1><hr class="small right bold"><span class="subheading">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#challenge-results">Challenge results</a>
<ul>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a></li>
</ul>
</li>
<li><a href="#system-characteristics">System characteristics</a></li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h2 id="task-description">Task description</h2>
<p>Detailed task description in <a class="btn btn-primary" href="/challenge2016/task-sound-event-detection-in-real-life-audio">task description page</a></p>
<h2 id="challenge-results">Challenge results</h2>
<p>Here you can find complete information on the submissions for Task 3: results on evaluation and development set (when reported by authors), class-wise results, technical reports and bibtex citations.</p>
<p>Detailed description of metrics used can be found <a href="sound-event-detection-metrics">here</a>.</p>
<p>System outputs:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/926660" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-muted"></i>
<i class="fa fa-file-text-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/926660" target="_blank">
<span style="font-size:20px;">DCASE2016 Challenge Submissions Package <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(28.7 MB)</span>
<br/>
<a href="http://dx.doi.org/10.5281/zenodo.926660">
<img alt="10.5281/zenodo.926660" src="https://zenodo.org/badge/doi/10.5281/zenodo.926660.svg"/>
</a>
</div>
</div>
<p><br/></p>
<h3 id="systems-ranking">Systems ranking</h3>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="segment_based_F1_overall_eval" data-scatter-y="segment_based_ER_overall_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_overall_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell text-center" colspan="2">Submission Information</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/>(overall / evaluation dataset)</th>
<th class="sep-left-cell text-center" colspan="2">Event-based <br/>(overall / onset-only evaluation dataset)</th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/>(overall / development dataset)</th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="event_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="event_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_dev" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_overall_dev" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_1</td>
<td>adavanne_IID</td>
<td>0.8051</td>
<td>47.8</td>
<td>5.1248</td>
<td>4.8</td>
<td>0.9100</td>
<td>31.0</td>
</tr>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_2</td>
<td>adavanne_IITD</td>
<td>0.8887</td>
<td>37.9</td>
<td>7.5286</td>
<td>4.7</td>
<td>0.8500</td>
<td>34.3</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Heittola2016</td>
<td>DCASE2016 baseline</td>
<td>DCASE2016_baseline</td>
<td>0.8773</td>
<td>34.3</td>
<td>1.7303</td>
<td>6.3</td>
<td>0.9100</td>
<td>23.7</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_1</td>
<td>CMU_G_v3</td>
<td>1.0730</td>
<td>22.5</td>
<td>3.3496</td>
<td>4.2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_2</td>
<td>CMU_G_v4</td>
<td>1.1056</td>
<td>20.8</td>
<td>3.1804</td>
<td>2.9</td>
<td>0.8100</td>
<td>34.8</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_3</td>
<td>CMU_G+P_v3</td>
<td>0.9635</td>
<td>33.3</td>
<td>2.0445</td>
<td>4.2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_4</td>
<td>CMU_G+P_v4</td>
<td>0.9613</td>
<td>33.6</td>
<td>1.8700</td>
<td>3.6</td>
<td>0.7600</td>
<td>38.5</td>
</tr>
<tr>
<td></td>
<td>Gorin2016</td>
<td>Gorin_task3_1</td>
<td>act</td>
<td>0.9799</td>
<td>41.1</td>
<td>1.8483</td>
<td>2.9</td>
<td>0.8400</td>
<td>38.1</td>
</tr>
<tr>
<td></td>
<td>Kong2016</td>
<td>Kong_task3_1</td>
<td>QK</td>
<td>0.9557</td>
<td>36.3</td>
<td>2.8819</td>
<td>7.3</td>
<td></td>
<td>38.1</td>
</tr>
<tr>
<td></td>
<td>Kroos2016</td>
<td>Kroos_task3_1</td>
<td>RandB</td>
<td>1.1488</td>
<td>16.8</td>
<td>3.1469</td>
<td>3.4</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lai2016</td>
<td>Liu_task3_1</td>
<td>BW#3</td>
<td>0.9287</td>
<td>34.5</td>
<td>2.4283</td>
<td>8.1</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Dai2016</td>
<td>Pham_task3_1</td>
<td></td>
<td>0.9583</td>
<td>11.6</td>
<td>1.2886</td>
<td>1.8</td>
<td>1.2450</td>
<td>18.1</td>
</tr>
<tr>
<td></td>
<td>Phan2016</td>
<td>Phan_task3_1</td>
<td>CaR-FOREST</td>
<td>0.9644</td>
<td>23.9</td>
<td>1.0634</td>
<td>1.5</td>
<td>0.8304</td>
<td>31.6</td>
</tr>
<tr>
<td></td>
<td>Schroeder2016</td>
<td>Schroeder_task3_1</td>
<td></td>
<td>1.3092</td>
<td>33.6</td>
<td>12.0766</td>
<td>3.7</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ubskii2016</td>
<td>Ubskii_task3_1</td>
<td></td>
<td>0.9971</td>
<td>39.6</td>
<td>2.9518</td>
<td>6.7</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Vu2016</td>
<td>Vu_task3_1</td>
<td></td>
<td>0.9124</td>
<td>41.9</td>
<td>2.0949</td>
<td>6.3</td>
<td>0.8150</td>
<td>49.8</td>
</tr>
<tr>
<td></td>
<td>Zoehrer2016</td>
<td>Zoehrer_task3_1</td>
<td></td>
<td>0.9056</td>
<td>39.6</td>
<td>3.0879</td>
<td>6.0</td>
<td>0.7300</td>
<td>47.6</td>
</tr>
</tbody>
</table>
<h3 id="teams-ranking">Teams ranking</h3>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="segment_based_F1_overall_eval" data-scatter-y="segment_based_ER_overall_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_overall_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell text-center" colspan="2">Submission Information</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/><small>(overall / evaluation dataset)</small></th>
<th class="sep-left-cell text-center" colspan="2">Event-based <br/><small>(overall / onset-only evaluation dataset)</small></th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/><small>(overall / development dataset)</small></th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="event_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="event_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_dev" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_overall_dev" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_1</td>
<td>adavanne_IID</td>
<td>0.8051</td>
<td>47.8</td>
<td>5.1248</td>
<td>4.8</td>
<td>0.9100</td>
<td>31.0</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Heittola2016</td>
<td>DCASE2016 baseline</td>
<td>DCASE2016_baseline</td>
<td>0.8773</td>
<td>34.3</td>
<td>1.7303</td>
<td>6.3</td>
<td>0.9100</td>
<td>23.7</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_4</td>
<td>CMU_G+P_v4</td>
<td>0.9613</td>
<td>33.6</td>
<td>1.8700</td>
<td>3.6</td>
<td>0.7600</td>
<td>38.5</td>
</tr>
<tr>
<td></td>
<td>Gorin2016</td>
<td>Gorin_task3_1</td>
<td>act</td>
<td>0.9799</td>
<td>41.1</td>
<td>1.8483</td>
<td>2.9</td>
<td>0.8400</td>
<td>38.1</td>
</tr>
<tr>
<td></td>
<td>Kong2016</td>
<td>Kong_task3_1</td>
<td>QK</td>
<td>0.9557</td>
<td>36.3</td>
<td>2.8819</td>
<td>7.3</td>
<td></td>
<td>38.1</td>
</tr>
<tr>
<td></td>
<td>Kroos2016</td>
<td>Kroos_task3_1</td>
<td>RandB</td>
<td>1.1488</td>
<td>16.8</td>
<td>3.1469</td>
<td>3.4</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lai2016</td>
<td>Liu_task3_1</td>
<td>BW#3</td>
<td>0.9287</td>
<td>34.5</td>
<td>2.4283</td>
<td>8.1</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Dai2016</td>
<td>Pham_task3_1</td>
<td></td>
<td>0.9583</td>
<td>11.6</td>
<td>1.2886</td>
<td>1.8</td>
<td>1.2450</td>
<td>18.1</td>
</tr>
<tr>
<td></td>
<td>Phan2016</td>
<td>Phan_task3_1</td>
<td>CaR-FOREST</td>
<td>0.9644</td>
<td>23.9</td>
<td>1.0634</td>
<td>1.5</td>
<td>0.8304</td>
<td>31.6</td>
</tr>
<tr>
<td></td>
<td>Schroeder2016</td>
<td>Schroeder_task3_1</td>
<td></td>
<td>1.3092</td>
<td>33.6</td>
<td>12.0766</td>
<td>3.7</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ubskii2016</td>
<td>Ubskii_task3_1</td>
<td></td>
<td>0.9971</td>
<td>39.6</td>
<td>2.9518</td>
<td>6.7</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Vu2016</td>
<td>Vu_task3_1</td>
<td></td>
<td>0.9124</td>
<td>41.9</td>
<td>2.0949</td>
<td>6.3</td>
<td>0.8150</td>
<td>49.8</td>
</tr>
<tr>
<td></td>
<td>Zoehrer2016</td>
<td>Zoehrer_task3_1</td>
<td></td>
<td>0.9056</td>
<td>39.6</td>
<td>3.0879</td>
<td>6.0</td>
<td>0.7300</td>
<td>47.6</td>
</tr>
</tbody>
</table>
<h3 id="class-wise-performance">Class-wise performance</h3>
<h4>Home</h4>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-comparison-a-row="DCASE2016 baseline" data-comparison-active-set="Class-wise performance (ER)" data-comparison-b-row="Adavanne_task3_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (ER)",
        "data_axis_title": "ER",
        "fields": ["segment_based_ER_home_class_cupboard_eval","segment_based_ER_home_class_cutlery_eval","segment_based_ER_home_class_dishes_eval","segment_based_ER_home_class_drawer_eval","segment_based_ER_home_class_glass_jingling_eval","segment_based_ER_home_class_object_impact_eval","impact;segment_based_ER_home_class_object_rustling_eval","segment_based_ER_home_class_object_snapping_eval","segment_based_ER_home_class_people_walking_eval","segment_based_ER_home_class_washing_dishes_eval","segment_based_ER_home_class_water_tap_running_eval"],
        "field_titles": ["Cupboard","Cutlery","Dishes","Drawer","Glass jingling","Object impact","Object rustling","Object snapping","People walking","Washing dishes","Water tap running"]
        },
        {"title": "Class-wise performance (F1)",
        "data_axis_title": "F1",
        "fields": ["segment_based_F1_home_class_cupboard_eval","segment_based_F1_home_class_cutlery_eval","segment_based_F1_home_class_dishes_eval","segment_based_F1_home_class_drawer_eval","segment_based_F1_home_class_glass_jingling_eval","segment_based_F1_home_class_object_impact_eval","impact;segment_based_F1_home_class_object_rustling_eval","segment_based_F1_home_class_object_snapping_eval","segment_based_F1_home_class_people_walking_eval","segment_based_F1_home_class_washing_dishes_eval","segment_based_F1_home_class_water_tap_running_eval"],
        "field_titles": ["Cupboard","Cutlery","Dishes","Drawer","Glass jingling","Object impact","Object rustling","Object snapping","People walking","Washing dishes","Water tap running"]
        }]' data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="segment_based_F1_home_class_wise_average_eval" data-scatter-y="segment_based_ER_home_class_wise_average_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_home_class_wise_average_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell text-center" colspan="2">Submission Information</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/>(Class-based average)</th>
<th class="sep-left-cell text-center" colspan="2">Cupboard</th>
<th class="sep-left-cell text-center" colspan="2">Cutlery</th>
<th class="sep-left-cell text-center" colspan="2">Dishes</th>
<th class="sep-left-cell text-center" colspan="2">Drawer</th>
<th class="sep-left-cell text-center" colspan="2">Glass jingling</th>
<th class="sep-left-cell text-center" colspan="2">Object impact</th>
<th class="sep-left-cell text-center" colspan="2">Object rustling</th>
<th class="sep-left-cell text-center" colspan="2">Object snapping</th>
<th class="sep-left-cell text-center" colspan="2">People walking</th>
<th class="sep-left-cell text-center" colspan="2">Washing dishes</th>
<th class="sep-left-cell text-center" colspan="2">Water tap running</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th data-field="name" data-sortable="true">
                Name
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_wise_average_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">(class avg/eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_home_class_wise_average_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">(class avg/eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_cupboard_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Cupboard (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_cupboard_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Cupboard (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_cutlery_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Cutlery (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_cutlery_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Cutlery (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_dishes_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Dishes (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_dishes_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Dishes (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_drawer_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Drawer (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_drawer_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Drawer (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_glass_jingling_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Glass jingling (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_glass_jingling_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Glass jingling (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_object_impact_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Object impact (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_object_impact_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Object impact (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_object_rustling_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Object rustling (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_object_rustling_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Object rustling (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_object_snapping_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Object snapping (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_object_snapping_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Object snapping (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_people_walking_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ People walking (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_people_walking_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ People walking (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_washing_dishes_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Washing dishes (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_washing_dishes_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Washing dishes (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_home_class_water_tap_running_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Washing dishes (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_home_class_water_tap_running_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Washing dishes (eval/seg)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_1</td>
<td>adavanne_IID</td>
<td>0.9887</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.2785</td>
<td>0.2</td>
<td>0.5973</td>
<td>0.8</td>
</tr>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_2</td>
<td>adavanne_IITD</td>
<td>1.0682</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>2.0127</td>
<td>0.2</td>
<td>0.7372</td>
<td>0.7</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Heittola2016</td>
<td>DCASE2016 baseline</td>
<td>DCASE2016_baseline</td>
<td>0.9783</td>
<td>0.2</td>
<td>1.0385</td>
<td>0.0</td>
<td>1.0571</td>
<td>0.0</td>
<td>1.0744</td>
<td>0.2</td>
<td>0.9811</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.1574</td>
<td>0.1</td>
<td>0.6786</td>
<td>0.6</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0833</td>
<td>0.2</td>
<td>1.0190</td>
<td>0.0</td>
<td>0.6724</td>
<td>0.6</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_1</td>
<td>CMU_G_v3</td>
<td>1.9262</td>
<td>0.1</td>
<td>2.1538</td>
<td>0.0</td>
<td>1.9714</td>
<td>0.0</td>
<td>1.7851</td>
<td>0.1</td>
<td>2.5094</td>
<td>0.1</td>
<td>2.0667</td>
<td>0.1</td>
<td>1.6294</td>
<td>0.2</td>
<td>1.5714</td>
<td>0.0</td>
<td>3.0476</td>
<td>0.1</td>
<td>1.9479</td>
<td>0.1</td>
<td>1.4747</td>
<td>0.2</td>
<td>1.0307</td>
<td>0.3</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_2</td>
<td>CMU_G_v4</td>
<td>4.2003</td>
<td>0.0</td>
<td>1.0385</td>
<td>0.0</td>
<td>6.7143</td>
<td>0.0</td>
<td>1.3636</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>27.1333</td>
<td>0.0</td>
<td>1.9949</td>
<td>0.3</td>
<td>1.0000</td>
<td>0.0</td>
<td>2.9048</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0063</td>
<td>0.0</td>
<td>1.0478</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_3</td>
<td>CMU_G+P_v3</td>
<td>1.5296</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.5429</td>
<td>0.0</td>
<td>1.3802</td>
<td>0.1</td>
<td>1.4528</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>2.2741</td>
<td>0.3</td>
<td>1.3393</td>
<td>0.0</td>
<td>3.0000</td>
<td>0.0</td>
<td>1.5208</td>
<td>0.1</td>
<td>1.3671</td>
<td>0.2</td>
<td>0.9488</td>
<td>0.4</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_4</td>
<td>CMU_G+P_v4</td>
<td>1.5768</td>
<td>0.1</td>
<td>1.0385</td>
<td>0.0</td>
<td>1.6857</td>
<td>0.0</td>
<td>1.4050</td>
<td>0.1</td>
<td>1.8113</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>2.1269</td>
<td>0.3</td>
<td>1.5893</td>
<td>0.0</td>
<td>2.6667</td>
<td>0.0</td>
<td>1.5312</td>
<td>0.1</td>
<td>1.4494</td>
<td>0.2</td>
<td>1.0410</td>
<td>0.4</td>
</tr>
<tr>
<td></td>
<td>Gorin2016</td>
<td>Gorin_task3_1</td>
<td>act</td>
<td>1.0834</td>
<td>0.2</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.1653</td>
<td>0.2</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0863</td>
<td>0.1</td>
<td>0.8929</td>
<td>0.6</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0104</td>
<td>0.1</td>
<td>1.8101</td>
<td>0.4</td>
<td>0.9522</td>
<td>0.5</td>
</tr>
<tr>
<td></td>
<td>Kong2016</td>
<td>Kong_task3_1</td>
<td>QK</td>
<td>1.1803</td>
<td>0.2</td>
<td>1.0385</td>
<td>0.0</td>
<td>1.2857</td>
<td>0.0</td>
<td>1.2479</td>
<td>0.1</td>
<td>1.0755</td>
<td>0.0</td>
<td>0.9333</td>
<td>0.3</td>
<td>1.4569</td>
<td>0.2</td>
<td>1.4821</td>
<td>0.2</td>
<td>1.2381</td>
<td>0.0</td>
<td>0.9792</td>
<td>0.1</td>
<td>1.3481</td>
<td>0.1</td>
<td>0.8976</td>
<td>0.5</td>
</tr>
<tr>
<td></td>
<td>Kroos2016</td>
<td>Kroos_task3_1</td>
<td>RandB</td>
<td>1.6394</td>
<td>0.1</td>
<td>1.6538</td>
<td>0.0</td>
<td>1.9429</td>
<td>0.1</td>
<td>1.5950</td>
<td>0.1</td>
<td>1.3396</td>
<td>0.0</td>
<td>2.1333</td>
<td>0.1</td>
<td>1.3147</td>
<td>0.2</td>
<td>1.9821</td>
<td>0.1</td>
<td>2.1429</td>
<td>0.0</td>
<td>1.2500</td>
<td>0.0</td>
<td>1.5190</td>
<td>0.1</td>
<td>1.1604</td>
<td>0.1</td>
</tr>
<tr>
<td></td>
<td>Lai2016</td>
<td>Liu_task3_1</td>
<td>BW#3</td>
<td>1.2249</td>
<td>0.2</td>
<td>1.1538</td>
<td>0.1</td>
<td>1.2286</td>
<td>0.0</td>
<td>1.2810</td>
<td>0.1</td>
<td>1.0377</td>
<td>0.0</td>
<td>1.0667</td>
<td>0.0</td>
<td>1.4822</td>
<td>0.3</td>
<td>1.0357</td>
<td>0.4</td>
<td>2.3333</td>
<td>0.0</td>
<td>1.0417</td>
<td>0.0</td>
<td>1.1139</td>
<td>0.1</td>
<td>0.6997</td>
<td>0.7</td>
</tr>
<tr>
<td></td>
<td>Dai2016</td>
<td>Pham_task3_1</td>
<td></td>
<td>1.0055</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>0.9848</td>
<td>0.0</td>
<td>1.0179</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0208</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0375</td>
<td>0.2</td>
</tr>
<tr>
<td></td>
<td>Phan2016</td>
<td>Phan_task3_1</td>
<td>CaR-FOREST</td>
<td>1.0449</td>
<td>0.0</td>
<td>1.0769</td>
<td>0.1</td>
<td>1.3143</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.1333</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>0.9693</td>
<td>0.3</td>
</tr>
<tr>
<td></td>
<td>Schroeder2016</td>
<td>Schroeder_task3_1</td>
<td></td>
<td>2.2534</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.2571</td>
<td>0.1</td>
<td>7.5455</td>
<td>0.2</td>
<td>1.0000</td>
<td>0.0</td>
<td>3.2000</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>5.7848</td>
<td>0.3</td>
<td>1.0000</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Ubskii2016</td>
<td>Ubskii_task3_1</td>
<td></td>
<td>1.4109</td>
<td>0.2</td>
<td>1.4231</td>
<td>0.1</td>
<td>1.0571</td>
<td>0.0</td>
<td>2.1818</td>
<td>0.2</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.8223</td>
<td>0.3</td>
<td>2.0000</td>
<td>0.4</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.7500</td>
<td>0.2</td>
<td>1.3608</td>
<td>0.2</td>
<td>0.9249</td>
<td>0.7</td>
</tr>
<tr>
<td></td>
<td>Vu2016</td>
<td>Vu_task3_1</td>
<td></td>
<td>1.3479</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.6286</td>
<td>0.0</td>
<td>1.1322</td>
<td>0.1</td>
<td>1.4340</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.5939</td>
<td>0.2</td>
<td>2.5536</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.8542</td>
<td>0.2</td>
<td>1.0570</td>
<td>0.0</td>
<td>0.5734</td>
<td>0.8</td>
</tr>
<tr>
<td></td>
<td>Zoehrer2016</td>
<td>Zoehrer_task3_1</td>
<td></td>
<td>1.0797</td>
<td>0.1</td>
<td>1.1154</td>
<td>0.1</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0189</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.5025</td>
<td>0.4</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.7658</td>
<td>0.3</td>
<td>0.4744</td>
<td>0.8</td>
</tr>
</tbody>
</table>
<h4>Residential Area</h4>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-comparison-a-row="DCASE2016 baseline" data-comparison-active-set="Class-wise performance (ER)" data-comparison-b-row="Adavanne_task3_1" data-comparison-row-id-field="code" data-comparison-sets="Class-wise performance (ER):ER:segment_based_ER_residential_area_class_bird_singing_eval#Bird singing;segment_based_ER_residential_area_class_car_passing_by_eval#Car passing by;segment_based_ER_residential_area_class_children_shouting_eval#Children shouting;segment_based_ER_residential_area_class_object_banging_eval#Object banging;segment_based_ER_residential_area_class_people_speaking_eval#People speaking;segment_based_ER_residential_area_class_people_walking_eval#People walking;segment_based_ER_residential_area_class_wind_blowing_eval#Wind blowing,
Class-wise performance (F1):ER:segment_based_F1_residential_area_class_bird_singing_eval#Bird singing;segment_based_F1_residential_area_class_car_passing_by_eval#Car passing by;segment_based_F1_residential_area_class_children_shouting_eval#Children shouting;segment_based_F1_residential_area_class_object_banging_eval#Object banging;segment_based_F1_residential_area_class_people_speaking_eval#People speaking;segment_based_F1_residential_area_class_people_walking_eval#People walking;segment_based_F1_residential_area_class_wind_blowing_eval#Wind blowing" data-comparison-sets-json='[
        {"title": "Class-wise performance (ER)",
        "data_axis_title": "ER",
        "fields": ["segment_based_ER_residential_area_class_bird_singing_eval","segment_based_ER_residential_area_class_car_passing_by_eval","segment_based_ER_residential_area_class_children_shouting_eval","segment_based_ER_residential_area_class_object_banging_eval","segment_based_ER_residential_area_class_people_speaking_eval","segment_based_ER_residential_area_class_people_walking_eval","segment_based_ER_residential_area_class_wind_blowing_eval"],
        "field_titles": ["Bird singing","Car passing by","Children shouting","Object banging","People speaking","People walking","Wind blowing"]
        },
        {"title": "Class-wise performance (F1)",
        "data_axis_title": "F1",
        "fields": ["segment_based_F1_residential_area_class_bird_singing_eval","segment_based_F1_residential_area_class_car_passing_by_eval","segment_based_F1_residential_area_class_children_shouting_eval","segment_based_F1_residential_area_class_object_banging_eval","segment_based_F1_residential_area_class_people_speaking_eval","segment_based_F1_residential_area_class_people_walking_eval","segment_based_F1_residential_area_class_wind_blowing_eval"],
        "field_titles": ["Bird singing","Car passing by","Children shouting","Object banging","People speaking","People walking","Wind blowing"]
        }]' data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="segment_based_F1_residential_area_class_wise_average_eval" data-scatter-y="segment_based_ER_residential_area_class_wise_average_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_residential_area_class_wise_average_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell text-center" colspan="2">Submission Information</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="2">Segment-based <br/>(Class-based average)</th>
<th class="sep-left-cell text-center" colspan="2">Bird singing</th>
<th class="sep-left-cell text-center" colspan="2">Car passing by</th>
<th class="sep-left-cell text-center" colspan="2">Children shouting</th>
<th class="sep-left-cell text-center" colspan="2">Object banging</th>
<th class="sep-left-cell text-center" colspan="2">People speaking</th>
<th class="sep-left-cell text-center" colspan="2">People walking</th>
<th class="sep-left-cell text-center" colspan="2">Wind blowing</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th data-field="name" data-sortable="true">
                Name
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_wise_average_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">(class avg/eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_wise_average_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">(class avg/eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_bird_singing_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Bird singing (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_bird_singing_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Bird singing (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_car_passing_by_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Car passing by (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_car_passing_by_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Car passing by (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_children_shouting_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Children shouting (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_children_shouting_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Children shouting (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_object_banging_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Object banging (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_object_banging_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Object banging (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_people_speaking_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ People speaking (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_people_speaking_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ People speaking (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_people_walking_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ People walking (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_people_walking_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ People walking (eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_residential_area_class_wind_blowing_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">/ Wind blowing (eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_residential_area_class_wind_blowing_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">/ Wind blowing (eval/seg)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_1</td>
<td>adavanne_IID</td>
<td>1.0159</td>
<td>0.2</td>
<td>1.1332</td>
<td>0.6</td>
<td>0.5634</td>
<td>0.8</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.1228</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.2917</td>
<td>0.3</td>
</tr>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_2</td>
<td>adavanne_IITD</td>
<td>1.1661</td>
<td>0.1</td>
<td>1.5884</td>
<td>0.6</td>
<td>1.0188</td>
<td>0.0</td>
<td>1.2000</td>
<td>0.1</td>
<td>1.2727</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0205</td>
<td>0.0</td>
<td>1.0625</td>
<td>0.0</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Heittola2016</td>
<td>DCASE2016 baseline</td>
<td>DCASE2016_baseline</td>
<td>1.3188</td>
<td>0.2</td>
<td>0.9637</td>
<td>0.3</td>
<td>0.4836</td>
<td>0.7</td>
<td>1.1333</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>2.6667</td>
<td>0.0</td>
<td>1.1096</td>
<td>0.1</td>
<td>1.8750</td>
<td>0.2</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_1</td>
<td>CMU_G_v3</td>
<td>2.7125</td>
<td>0.1</td>
<td>1.2034</td>
<td>0.4</td>
<td>0.9531</td>
<td>0.4</td>
<td>5.4667</td>
<td>0.0</td>
<td>5.2727</td>
<td>0.0</td>
<td>2.3860</td>
<td>0.0</td>
<td>1.6849</td>
<td>0.1</td>
<td>2.0208</td>
<td>0.1</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_2</td>
<td>CMU_G_v4</td>
<td>2.0883</td>
<td>0.2</td>
<td>1.2107</td>
<td>0.5</td>
<td>0.8357</td>
<td>0.4</td>
<td>2.8667</td>
<td>0.0</td>
<td>3.6364</td>
<td>0.0</td>
<td>2.6667</td>
<td>0.1</td>
<td>1.5479</td>
<td>0.1</td>
<td>1.8542</td>
<td>0.1</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_3</td>
<td>CMU_G+P_v3</td>
<td>1.3496</td>
<td>0.2</td>
<td>1.3341</td>
<td>0.5</td>
<td>0.8075</td>
<td>0.5</td>
<td>1.1333</td>
<td>0.0</td>
<td>1.5455</td>
<td>0.0</td>
<td>2.5439</td>
<td>0.0</td>
<td>1.0411</td>
<td>0.0</td>
<td>1.0417</td>
<td>0.2</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_4</td>
<td>CMU_G+P_v4</td>
<td>1.2472</td>
<td>0.2</td>
<td>1.2857</td>
<td>0.6</td>
<td>0.7653</td>
<td>0.5</td>
<td>1.0667</td>
<td>0.0</td>
<td>1.3636</td>
<td>0.0</td>
<td>2.3333</td>
<td>0.0</td>
<td>1.0411</td>
<td>0.0</td>
<td>0.8750</td>
<td>0.3</td>
</tr>
<tr>
<td></td>
<td>Gorin2016</td>
<td>Gorin_task3_1</td>
<td>act</td>
<td>1.3456</td>
<td>0.3</td>
<td>1.0944</td>
<td>0.6</td>
<td>1.1502</td>
<td>0.6</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>3.1754</td>
<td>0.1</td>
<td>1.0822</td>
<td>0.3</td>
<td>0.9167</td>
<td>0.4</td>
</tr>
<tr>
<td></td>
<td>Kong2016</td>
<td>Kong_task3_1</td>
<td>QK</td>
<td>1.1055</td>
<td>0.2</td>
<td>1.2131</td>
<td>0.5</td>
<td>0.7042</td>
<td>0.7</td>
<td>1.0667</td>
<td>0.0</td>
<td>1.1818</td>
<td>0.0</td>
<td>1.4211</td>
<td>0.0</td>
<td>1.0685</td>
<td>0.0</td>
<td>1.0833</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Kroos2016</td>
<td>Kroos_task3_1</td>
<td>RandB</td>
<td>1.6154</td>
<td>0.1</td>
<td>1.1695</td>
<td>0.3</td>
<td>1.4789</td>
<td>0.2</td>
<td>2.2000</td>
<td>0.1</td>
<td>1.0909</td>
<td>0.0</td>
<td>2.3158</td>
<td>0.1</td>
<td>1.2192</td>
<td>0.1</td>
<td>1.8333</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Lai2016</td>
<td>Liu_task3_1</td>
<td>BW#3</td>
<td>1.7348</td>
<td>0.1</td>
<td>1.0266</td>
<td>0.4</td>
<td>0.7324</td>
<td>0.5</td>
<td>1.5333</td>
<td>0.0</td>
<td>2.0909</td>
<td>0.0</td>
<td>2.4561</td>
<td>0.0</td>
<td>1.1164</td>
<td>0.1</td>
<td>3.1875</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Dai2016</td>
<td>Pham_task3_1</td>
<td></td>
<td>0.9808</td>
<td>0.1</td>
<td>1.0024</td>
<td>0.1</td>
<td>0.8216</td>
<td>0.4</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0417</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Phan2016</td>
<td>Phan_task3_1</td>
<td>CaR-FOREST</td>
<td>1.0576</td>
<td>0.1</td>
<td>1.4673</td>
<td>0.4</td>
<td>0.8263</td>
<td>0.5</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.1096</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Schroeder2016</td>
<td>Schroeder_task3_1</td>
<td></td>
<td>1.0164</td>
<td>0.2</td>
<td>0.9952</td>
<td>0.5</td>
<td>0.6995</td>
<td>0.7</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.3860</td>
<td>0.0</td>
<td>1.0342</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.1</td>
</tr>
<tr>
<td></td>
<td>Ubskii2016</td>
<td>Ubskii_task3_1</td>
<td></td>
<td>1.0218</td>
<td>0.2</td>
<td>1.0508</td>
<td>0.4</td>
<td>0.5164</td>
<td>0.7</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.5439</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0417</td>
<td>0.0</td>
</tr>
<tr>
<td></td>
<td>Vu2016</td>
<td>Vu_task3_1</td>
<td></td>
<td>1.1772</td>
<td>0.2</td>
<td>1.2567</td>
<td>0.5</td>
<td>0.6854</td>
<td>0.7</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.5789</td>
<td>0.0</td>
<td>1.2192</td>
<td>0.0</td>
<td>1.5000</td>
<td>0.2</td>
</tr>
<tr>
<td></td>
<td>Zoehrer2016</td>
<td>Zoehrer_task3_1</td>
<td></td>
<td>0.9892</td>
<td>0.2</td>
<td>1.2131</td>
<td>0.4</td>
<td>0.6761</td>
<td>0.6</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0351</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
<td>1.0000</td>
<td>0.0</td>
</tr>
</tbody>
</table>
<h2 id="system-characteristics">System characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="accuracy_eval" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_overall_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell text-center" colspan="2">Submission Information</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="2">Segment-based (overall)</th>
<th class="sep-left-cell text-center" colspan="3">System characteristics</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER <small class="hidden">(eval/seg)</small>
</th>
<th class="text-center" data-chartable="true" data-field="segment_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1 <small class="hidden">(eval/seg)</small>
</th>
<th class="sep-left-cell text-center" data-field="system_input" data-filter-control="select" data-sortable="true" data-tag="true">
                Input
            </th>
<th class="text-center" data-field="system_features" data-filter-control="select" data-sortable="true" data-tag="true">
                Features
            </th>
<th class="text-center" data-field="system_classifier" data-filter-control="select" data-sortable="true" data-tag="true">
                Classifier
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_1</td>
<td>adavanne_IID</td>
<td>0.8051</td>
<td>47.8</td>
<td>binaural</td>
<td>mel energy</td>
<td>RNN</td>
</tr>
<tr>
<td></td>
<td>Adavanne2016</td>
<td>Adavanne_task3_2</td>
<td>adavanne_IITD</td>
<td>0.8887</td>
<td>37.9</td>
<td>binaural</td>
<td>mel energy + TDOA</td>
<td>RNN</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Heittola2016</td>
<td>DCASE2016 baseline</td>
<td>DCASE2016_baseline</td>
<td>0.8773</td>
<td>34.3</td>
<td>monophonic</td>
<td>MFCC</td>
<td>GMM</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_1</td>
<td>CMU_G_v3</td>
<td>1.0730</td>
<td>22.5</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Random forests</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_2</td>
<td>CMU_G_v4</td>
<td>1.1056</td>
<td>20.8</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Random forests</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_3</td>
<td>CMU_G+P_v3</td>
<td>0.9635</td>
<td>33.3</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Random forests</td>
</tr>
<tr>
<td></td>
<td>Elizalde2016</td>
<td>Elizalde_task3_4</td>
<td>CMU_G+P_v4</td>
<td>0.9613</td>
<td>33.6</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Random forests</td>
</tr>
<tr>
<td></td>
<td>Gorin2016</td>
<td>Gorin_task3_1</td>
<td>act</td>
<td>0.9799</td>
<td>41.1</td>
<td>monophonic</td>
<td>mel energy</td>
<td>CNN</td>
</tr>
<tr>
<td></td>
<td>Kong2016</td>
<td>Kong_task3_1</td>
<td>QK</td>
<td>0.9557</td>
<td>36.3</td>
<td>monophonic</td>
<td>MFCC</td>
<td>DNN</td>
</tr>
<tr>
<td></td>
<td>Kroos2016</td>
<td>Kroos_task3_1</td>
<td>RandB</td>
<td>1.1488</td>
<td>16.8</td>
<td></td>
<td></td>
<td>Random</td>
</tr>
<tr>
<td></td>
<td>Lai2016</td>
<td>Liu_task3_1</td>
<td>BW#3</td>
<td>0.9287</td>
<td>34.5</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Fusion</td>
</tr>
<tr>
<td></td>
<td>Dai2016</td>
<td>Pham_task3_1</td>
<td></td>
<td>0.9583</td>
<td>11.6</td>
<td>monophonic</td>
<td>MFCC</td>
<td>DNN</td>
</tr>
<tr>
<td></td>
<td>Phan2016</td>
<td>Phan_task3_1</td>
<td>CaR-FOREST</td>
<td>0.9644</td>
<td>23.9</td>
<td>monophonic</td>
<td>GCC</td>
<td>Random forests</td>
</tr>
<tr>
<td></td>
<td>Schroeder2016</td>
<td>Schroeder_task3_1</td>
<td></td>
<td>1.3092</td>
<td>33.6</td>
<td>monophonic</td>
<td>GFB</td>
<td>GMM-HMM</td>
</tr>
<tr>
<td></td>
<td>Ubskii2016</td>
<td>Ubskii_task3_1</td>
<td></td>
<td>0.9971</td>
<td>39.6</td>
<td>monophonic</td>
<td>MFCC</td>
<td>Fusion</td>
</tr>
<tr>
<td></td>
<td>Vu2016</td>
<td>Vu_task3_1</td>
<td></td>
<td>0.9124</td>
<td>41.9</td>
<td>monophonic</td>
<td>mel energy</td>
<td>RNN</td>
</tr>
<tr>
<td></td>
<td>Zoehrer2016</td>
<td>Zoehrer_task3_1</td>
<td></td>
<td>0.9056</td>
<td>39.6</td>
<td>monophonic</td>
<td>spectrogram</td>
<td>GRNN</td>
</tr>
</tbody>
</table>
<h2 id="technical-reports">Technical reports</h2>
<div class="btex" data-source="content/data/challenge2016/technical_reports_task3.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Adavanne2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Adavanne2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Sound Event Detection in Multichannel Audio Using Spatial and Harmonic Features
       </h4>
<p style="text-align:left">
        Sharath Adavanne, Giambattista Parascandolo, Pasi PertilÃ¤, Toni Heittola and Tuomas Virtanen
       </p>
<p style="text-align:left">
<em>
         Department of Signal Processing, Tampere University of Technology, Tampere, Finland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Adavanne_task3_1</span> <span class="label label-primary">Adavanne_task3_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Adavanne2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Adavanne2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Adavanne2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Adavanne_3009.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Adavanne2016" class="panel-collapse collapse" id="collapse-Adavanne2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Sound Event Detection in Multichannel Audio Using Spatial and Harmonic Features
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       In this paper, we propose the use of spatial and harmonic features in combination with long short term memory (LSTM) recurrent neural network (RNN) for automatic sound event detection (SED) task. Real life sound recordings typically have many overlapping sound events, making it hard to recognize with just mono channel audio. Human listeners have been successfully recognizing the mixture of overlapping sound events using pitch cues and exploiting the stereo (multichannel) audio signal available at their ears to spatially localize these events. Traditionally SED systems have only been using mono channel audio, motivated by the human listener we propose to extend them to use multichannel audio. The proposed SED system is compared against the state of the art mono channel meth od on the development subset of TUT sound events detection 2016 database [1]. The proposed method improves the F-score by 3.75% while reducing the error rate by 6%.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         binaural
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel energy; mel energy + TDOA
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Adavanne2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Adavanne_3009.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Adavanne2016label" class="modal fade" id="bibtex-Adavanne2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexAdavanne2016label">
        Sound Event Detection in Multichannel Audio Using Spatial and Harmonic Features
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Adavanne2016,
    Author = "Adavanne, Sharath and Parascandolo, Giambattista and PertilÃ¤, Pasi and Heittola, Toni and Virtanen, Tuomas",
    title = "Sound Event Detection in Multichannel Audio Using Spatial and Harmonic Features",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "In this paper, we propose the use of spatial and harmonic features in combination with long short term memory (LSTM) recurrent neural network (RNN) for automatic sound event detection (SED) task. Real life sound recordings typically have many overlapping sound events, making it hard to recognize with just mono channel audio. Human listeners have been successfully recognizing the mixture of overlapping sound events using pitch cues and exploiting the stereo (multichannel) audio signal available at their ears to spatially localize these events. Traditionally SED systems have only been using mono channel audio, motivated by the human listener we propose to extend them to use multichannel audio. The proposed SED system is compared against the state of the art mono channel meth od on the development subset of TUT sound events detection 2016 database [1]. The proposed method improves the F-score by 3.75\% while reducing the error rate by 6\%."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Dai2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Dai2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Sound Event Detection for Real Life Audio DCASE Challenge
       </h4>
<p style="text-align:left">
        Wei Dai<sup>1</sup>, Juncheng Li<sup>2</sup>, Phuong Pham<sup>3</sup>, Samarjit Das<sup>2</sup> and Shuhui Qu<sup>4</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Carnegie Mellon University, Pittsburgh, USA, <sup>2</sup>Robert Bosch Research and Technology Center, USA, <sup>3</sup>University of Pittsburgh, Pittsburgh, USA, <sup>4</sup>Stanford University, Stanford, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Pham_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Dai2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Dai2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Dai2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Pham_3005.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Dai2016" class="panel-collapse collapse" id="collapse-Dai2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Sound Event Detection for Real Life Audio DCASE Challenge
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       We explore logistic regression classifier (LogReg) and deep neural network (DNN) on the DCASE 2016 Challenge for task 3, i.e., sound event detection in real life audio. Our models use the Mel Frequency Cepstral Coefficients (MFCCs) and their deltas and accelerations as detection features. The error rate metric favors the simple logistic regression model with high activation threshold on both segment- and event-based contexts. On the other hand, DNN model outperforms the baseline in frame-based context.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         DNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Dai2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Pham_3005.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Dai2016label" class="modal fade" id="bibtex-Dai2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexDai2016label">
        Sound Event Detection for Real Life Audio DCASE Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Dai2016,
    Author = "Dai, Wei and Li, Juncheng and Pham, Phuong and Das, Samarjit and Qu, Shuhui",
    title = "Sound Event Detection for Real Life Audio {DCASE} Challenge",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "We explore logistic regression classifier (LogReg) and deep neural network (DNN) on the DCASE 2016 Challenge for task 3, i.e., sound event detection in real life audio. Our models use the Mel Frequency Cepstral Coefficients (MFCCs) and their deltas and accelerations as detection features. The error rate metric favors the simple logistic regression model with high activation threshold on both segment- and event-based contexts. On the other hand, DNN model outperforms the baseline in frame-based context."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Elizalde2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Elizalde2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Experimentation on The DCASE Challenge 2016: Task 1 - Acoustic Scene Classification and Task 3 - Sound Event Detection in Real Life Audio
       </h4>
<p style="text-align:left">
        Benjamin Elizalde<sup>1</sup>, Anurag Kumar<sup>1</sup>, Ankit Shah<sup>2</sup>, Rohan Badlani<sup>3</sup>, Emmanuel Vincent<sup>4</sup>, Bhiksha Raj<sup>1</sup> and Ian Lane<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Carnegie Mellon University, Pittsburgh, USA, <sup>2</sup>NIT Surathkal, India, <sup>3</sup>BITS, Pilani, India, <sup>4</sup>Inria, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Elizalde_task3_1</span> <span class="label label-primary">Elizalde_task3_2</span> <span class="label label-primary">Elizalde_task3_3</span> <span class="label label-primary">Elizalde_task3_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Elizalde2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Elizalde2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Elizalde2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Elizalde_3001.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Elizalde2016" class="panel-collapse collapse" id="collapse-Elizalde2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Experimentation on The DCASE Challenge 2016: Task 1 - Acoustic Scene Classification and Task 3 - Sound Event Detection in Real Life Audio
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       Audio carries substantial information about the contents of our environment. In a recording, sound events can occur in isolation, such as car passing by or footsteps and/or there could be a collection of sounds events, often collectively referred to as scenes, such as busy street or park. The 2016 DCASE challenge aims to foster standardized development in both of these areas. In this paper we present our work on Task 1 Acoustic Scene Classification and Task 3 Sound Event Detection in Real Life Recordings. Among our experiments we have low-level and high-level features, classifier optimization and other heuristics specific to each task. Our performance for both tasks improved the baseline published by DCASE. For Task 1 we achieved an overall accuracy of 78.9% compared to the baseline of 72.6% and for Task 3 we achieved a Segment-Based Error Rate of 0.48 compared to the baseline of 0.91.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Random forests
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Elizalde2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Elizalde_3001.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Elizalde2016label" class="modal fade" id="bibtex-Elizalde2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexElizalde2016label">
        Experimentation on The DCASE Challenge 2016: Task 1 - Acoustic Scene Classification and Task 3 - Sound Event Detection in Real Life Audio
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Elizalde2016,
    Author = "Elizalde, Benjamin and Kumar, Anurag and Shah, Ankit and Badlani, Rohan and Vincent, Emmanuel and Raj, Bhiksha and Lane, Ian",
    title = "Experimentation on The {DCASE} Challenge 2016: Task 1 - Acoustic Scene Classification and Task 3 - Sound Event Detection in Real Life Audio",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "Audio carries substantial information about the contents of our environment. In a recording, sound events can occur in isolation, such as car passing by or footsteps and/or there could be a collection of sounds events, often collectively referred to as scenes, such as busy street or park. The 2016 DCASE challenge aims to foster standardized development in both of these areas. In this paper we present our work on Task 1 Acoustic Scene Classification and Task 3 Sound Event Detection in Real Life Recordings. Among our experiments we have low-level and high-level features, classifier optimization and other heuristics specific to each task. Our performance for both tasks improved the baseline published by DCASE. For Task 1 we achieved an overall accuracy of 78.9\% compared to the baseline of 72.6\% and for Task 3 we achieved a Segment-Based Error Rate of 0.48 compared to the baseline of 0.91."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Gorin2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Gorin2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2016 Sound Event Detection System Based on Convolutional Neural Network
       </h4>
<p style="text-align:left">
        Arseniy Gorin, Nurtas Makhazhanov and Nickolay Shmyrev
       </p>
<p style="text-align:left">
<em>
         ACTechnologies LLC, Moscow, Russia
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Gorin_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Gorin2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Gorin2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Gorin2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Gorin_3012.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Gorin2016').collapse('show');window.location.hash='#Gorin2016';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Gorin2016" class="panel-collapse collapse" id="collapse-Gorin2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2016 Sound Event Detection System Based on Convolutional Neural Network
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       The report describes a sound event detection system submitted to DCASE 2016 challenge. In this work a convolutional neural network is used for detecting and classifying polyphonic events in a long temporal context of filter bank acoustic features. Given a small amount of training resources, data augmentation was explored. The system achieves an average 7.7% relative error rate improvement, but is still unable to detect short events with limited training data.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel energy
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Gorin2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Gorin_3012.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/gorinars/dcase16-cnn" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Gorin2016label" class="modal fade" id="bibtex-Gorin2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGorin2016label">
        DCASE 2016 Sound Event Detection System Based on Convolutional Neural Network
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Gorin2016,
    Author = "Gorin, Arseniy and Makhazhanov, Nurtas and Shmyrev, Nickolay",
    title = "{DCASE} 2016 Sound Event Detection System Based on Convolutional Neural Network",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "The report describes a sound event detection system submitted to DCASE 2016 challenge. In this work a convolutional neural network is used for detecting and classifying polyphonic events in a long temporal context of filter bank acoustic features. Given a small amount of training resources, data augmentation was explored. The system achieves an average 7.7\% relative error rate improvement, but is still unable to detect short events with limited training data."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Heittola2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Heittola2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE2016 Baseline System
       </h4>
<p style="text-align:left">
        Toni Heittola, Annamaria Mesaros and Tuomas Virtanen
       </p>
<p style="text-align:left">
<em>
         Department of Signal Processing, Tampere University of Technology, Tampere, Finland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2016_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Heittola2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Heittola2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Heittola2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="documents/mesaros_eusipco2016-dcase.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Heittola2016').collapse('show');window.location.hash='#Heittola2016';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Heittola2016" class="panel-collapse collapse" id="collapse-Heittola2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE2016 Baseline System
      </h4>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         GMM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Heittola2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="documents/mesaros_eusipco2016-dcase.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/TUT-ARG/DCASE2016-baseline-system-python" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Heittola2016label" class="modal fade" id="bibtex-Heittola2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHeittola2016label">
        DCASE2016 Baseline System
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Heittola2016,
    Author = "Heittola, Toni and Mesaros, Annamaria and Virtanen, Tuomas",
    title = "{DCASE}2016 Baseline System",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kong2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Kong2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Deep Neural Network Baseline for DCASE Challenge 2016
       </h4>
<p style="text-align:left">
        Qiuqiang Kong, Iwona Sobieraj, Wenwu Wang and Mark Plumbley
       </p>
<p style="text-align:left">
<em>
         Centre for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kong_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kong2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kong2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kong2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kong_3008.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Kong2016').collapse('show');window.location.hash='#Kong2016';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kong2016" class="panel-collapse collapse" id="collapse-Kong2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Deep Neural Network Baseline for DCASE Challenge 2016
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       The DCASE Challenge 2016 contains tasks for Acoustic Acene Classification (ASC), Acoustic Event Detection (AED), and audio tagging. Since 2006, Deep Neural Networks (DNNs) have been widely applied to computer visions, speech recognition and natural language processing tasks. In this paper, we provide DNN baselines for the DCASE Challenge 2016. For feature extraction, 40 Melfilter bank features are used. Two kinds of Mel banks, same area bank and same height bank are discussed. Experimental results show that the same height bank is better than the same area bank. DNNs with the same structure are applied to all four tasks in the DCASE Challenge 2016. In Task 1 we obtained accuracy of 76.4% using Mel + DNN against 72.5% by using Mel Frequency Ceptral Coefficient (MFCC) + Gaussian Mixture Model (GMM). In Task 2 we obtained F value of 17.4% using Mel + DNN against 41.6% by using Constant Q Transform (CQT) + Nonnegative Matrix Factorization (NMF). In Task 3 we obtained F value of 38.1% using Mel + DNN against 26.6% by using MFCC + GMM. In task 4 we obtained Equal Error Rate (ERR) of 20.9% using Mel + DNN against 21.0% by using MFCC + GMM. Therefore the DNN improves the baseline in Task 1 and Task 3, and is similar to the baseline in Task 4, although is worse than the baseline in Task 2. This indicates that DNNs can be successful in many of these tasks, but may not always work.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         DNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kong2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kong_3008.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/qiuqiangkong/DCASE2016_Task3" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kong2016label" class="modal fade" id="bibtex-Kong2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKong2016label">
        Deep Neural Network Baseline for DCASE Challenge 2016
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kong2016,
    Author = "Kong, Qiuqiang and Sobieraj, Iwona and Wang, Wenwu and Plumbley, Mark",
    title = "Deep Neural Network Baseline for {DCASE} Challenge 2016",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "The DCASE Challenge 2016 contains tasks for Acoustic Acene Classification (ASC), Acoustic Event Detection (AED), and audio tagging. Since 2006, Deep Neural Networks (DNNs) have been widely applied to computer visions, speech recognition and natural language processing tasks. In this paper, we provide DNN baselines for the DCASE Challenge 2016. For feature extraction, 40 Melfilter bank features are used. Two kinds of Mel banks, same area bank and same height bank are discussed. Experimental results show that the same height bank is better than the same area bank. DNNs with the same structure are applied to all four tasks in the DCASE Challenge 2016. In Task 1 we obtained accuracy of 76.4\% using Mel + DNN against 72.5\% by using Mel Frequency Ceptral Coefficient (MFCC) + Gaussian Mixture Model (GMM). In Task 2 we obtained F value of 17.4\% using Mel + DNN against 41.6\% by using Constant Q Transform (CQT) + Nonnegative Matrix Factorization (NMF). In Task 3 we obtained F value of 38.1\% using Mel + DNN against 26.6\% by using MFCC + GMM. In task 4 we obtained Equal Error Rate (ERR) of 20.9\% using Mel + DNN against 21.0\% by using MFCC + GMM. Therefore the DNN improves the baseline in Task 1 and Task 3, and is similar to the baseline in Task 4, although is worse than the baseline in Task 2. This indicates that DNNs can be successful in many of these tasks, but may not always work."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kroos2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Kroos2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Random System Performance in Task 3
       </h4>
<p style="text-align:left">
        Christian Kroos and Mark Plumbley
       </p>
<p style="text-align:left">
<em>
         Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, Surrey, SUnited Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kroos_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kroos2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kroos2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kroos2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kroos_3006.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kroos2016" class="panel-collapse collapse" id="collapse-Kroos2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Random System Performance in Task 3
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       In this report we describe briefly the creation of a random, datablind systems to provide a random baseline for Task 3 in the DCASE 2016 challenge. Particular attention is paid to the results for two sound events occurring in the residential area scene, one very rare, the other very frequent.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Random
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kroos2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kroos_3006.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kroos2016label" class="modal fade" id="bibtex-Kroos2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKroos2016label">
        Random System Performance in Task 3
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kroos2016,
    Author = "Kroos, Christian and Plumbley, Mark",
    title = "Random System Performance in Task 3",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "In this report we describe briefly the creation of a random, datablind systems to provide a random baseline for Task 3 in the DCASE 2016 challenge. Particular attention is paid to the results for two sound events occurring in the residential area scene, one very rare, the other very frequent."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lai2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Lai2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE Report for Task 3: Sound Event Detection in Real Life Audio
       </h4>
<p style="text-align:left">
        Ying-Hui Lai<sup>1,2</sup>, Chun-Hao Wang<sup>3</sup>, Shi-Yan Hou<sup>3</sup>, Bang-Yin Chen<sup>3</sup>, Yu Tsao<sup>1</sup> and Yi-Wen Liu<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Research Center for Information Technology, Academia Sinica, Taipei, Taiwan, <sup>2</sup>Department of Electrical Engineering, Yuan Ze University, Taoyuan City, Taiwan, <sup>3</sup>National Tsing Hua University, Hsinchu City, Taiwan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Liu_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lai2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lai2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lai2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Liu_3011.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lai2016" class="panel-collapse collapse" id="collapse-Lai2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE Report for Task 3: Sound Event Detection in Real Life Audio
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       Our team has built an acoustic event classifier solely using short-time features. Signals were first de-noised by a log minimum square error (logMMSE) procedure. Then, Mel-frequency cepstral coefficients (MFCCs) extracted from the de-noised signal at every 20 ms were used to train two classifiers based on support vector machine (SVMs) and neural networks (NN), respectively. Optimal parameters for the classifiers were exhaustively searched to maximize the frame-wise recognition accuracy in cross validation. Frame-wise recognition rates of 93.0% and 91.8% were thus obtained from the SVM and NN, respectively, for the home events (and 86.2% and 85.7% respectively for the residential events). To process the evaluation data, the same signal processing procedures were applied so both classifiers produce their classification result for every frame. Whenever SVM and NN gives different answers, we resort to the confusion matrices obtained during the supervised learning phase so a final answer could be produced based on a maximal a posteriori (MAP) principle. Finally, a heuristic smoothing procedure was applied to the jointly decided recognition results so the event onsets and offsets could be determined
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Fusion
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lai2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Liu_3011.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lai2016label" class="modal fade" id="bibtex-Lai2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLai2016label">
        DCASE Report for Task 3: Sound Event Detection in Real Life Audio
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lai2016,
    Author = "Lai, Ying-Hui and Wang, Chun-Hao and Hou, Shi-Yan and Chen, Bang-Yin and Tsao, Yu and Liu, Yi-Wen",
    title = "{DCASE} Report for Task 3: Sound Event Detection in Real Life Audio",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "Our team has built an acoustic event classifier solely using short-time features. Signals were first de-noised by a log minimum square error (logMMSE) procedure. Then, Mel-frequency cepstral coefficients (MFCCs) extracted from the de-noised signal at every 20 ms were used to train two classifiers based on support vector machine (SVMs) and neural networks (NN), respectively. Optimal parameters for the classifiers were exhaustively searched to maximize the frame-wise recognition accuracy in cross validation. Frame-wise recognition rates of 93.0\% and 91.8\% were thus obtained from the SVM and NN, respectively, for the home events (and 86.2\% and 85.7\% respectively for the residential events). To process the evaluation data, the same signal processing procedures were applied so both classifiers produce their classification result for every frame. Whenever SVM and NN gives different answers, we resort to the confusion matrices obtained during the supervised learning phase so a final answer could be produced based on a maximal a posteriori (MAP) principle. Finally, a heuristic smoothing procedure was applied to the jointly decided recognition results so the event onsets and offsets could be determined"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Phan2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Phan2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Car-Forest: Joint Classification-Regression Decision Forests for Overlapping Audio Event Detection
       </h4>
<p style="text-align:left">
        Huy Phan<sup>1,2</sup>, Lars Hertel<sup>1</sup>, Marco Maass<sup>1</sup>, Philipp Koch<sup>1</sup> and Alfred Mertins<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute for Signal Processing, University of Luebeck, Luebeck, Germany, <sup>2</sup>Graduate School for Computing in Medicine and Life Sciences, University of Luebeck, Luebeck, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Phan_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Phan2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Phan2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Phan2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Phan_3010.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Phan2016" class="panel-collapse collapse" id="collapse-Phan2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Car-Forest: Joint Classification-Regression Decision Forests for Overlapping Audio Event Detection
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       This report describes our submissions to Task2 and Task3 of the DCASE 2016 challenge [1]. The systems aim at dealing with the detection of overlapping audio events in continuous streams, where the detectors are based on random decision forests. The proposed forests are jointly trained for classification and regression simultaneously. Initially, the training is classification-oriented to encourage the trees to select discriminative features from overlapping mixtures to separate positive audio segments from the negative ones. The regression phase is then carried out to let the positive audio segments vote for the event onsets and offsets, and therefore model the temporal structure of audio events. One random decision forest is specifically trained for each event category of interest. Experimental results on the development data show that our systems outperform the DCASE 2016 challenge baselines with absolute gains of 64.4% and 8.0% on Task2 and Task3, respectively.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         GCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Random forests
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Phan2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Phan_3010.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Phan2016label" class="modal fade" id="bibtex-Phan2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPhan2016label">
        Car-Forest: Joint Classification-Regression Decision Forests for Overlapping Audio Event Detection
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Phan2016,
    Author = "Phan, Huy and Hertel, Lars and Maass, Marco and Koch, Philipp and Mertins, Alfred",
    title = "Car-Forest: Joint Classification-Regression Decision Forests for Overlapping Audio Event Detection",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "This report describes our submissions to Task2 and Task3 of the DCASE 2016 challenge [1]. The systems aim at dealing with the detection of overlapping audio events in continuous streams, where the detectors are based on random decision forests. The proposed forests are jointly trained for classification and regression simultaneously. Initially, the training is classification-oriented to encourage the trees to select discriminative features from overlapping mixtures to separate positive audio segments from the negative ones. The regression phase is then carried out to let the positive audio segments vote for the event onsets and offsets, and therefore model the temporal structure of audio events. One random decision forest is specifically trained for each event category of interest. Experimental results on the development data show that our systems outperform the DCASE 2016 challenge baselines with absolute gains of 64.4\% and 8.0\% on Task2 and Task3, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Schroeder2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Schroeder2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Performance Comparison of GMM, HMM and DNN Based Approaches for Acoustic Event Detection Within Task 3 of The DCASE 2016 Challenge
       </h4>
<p style="text-align:left">
        Jens SchrÃ¶der<sup>1,2</sup>, JÃ¶rn AnemÃ¼ller<sup>2,3</sup> and Stefan Goetze<sup>1,2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Fraunhofer Institute for Digital Media Technology IDMT, Oldenburg, Germany, <sup>2</sup>Cluster of Excellence, Hearing4all, Germany, <sup>3</sup>Department of Medical Physics and Acoustics, University of Oldenburg, Oldenburg, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Schroeder_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Schroeder2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Schroeder2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Schroeder2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Schroeder_3002.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Schroeder2016" class="panel-collapse collapse" id="collapse-Schroeder2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Performance Comparison of GMM, HMM and DNN Based Approaches for Acoustic Event Detection Within Task 3 of The DCASE 2016 Challenge
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       This contribution reports on the performance of systems for polyphonic acoustic event detection (AED) compared within the framework of the Detection and classification of acoustic scenes and events 2016 (DCASE'16) challenge. State-of-the-art Gaussian mixture model (GMM) and GMM-hidden Markov model (HMM) approaches are applied using Mel-frequency cepstral coefficients (MFCCs) and Gabor filterbank (GFB) features and a non-negative matrix factorization (NMF) based system. Furthermore, tandem and hybrid deep neural network (DNN)-HMMsystems are adopted. All HMM systems that usually are of multiclass type, i.e., systems that just output one label per time segment from a set of possible classes, are extended to binary classification systems that are compound of single binary classifiers classifying between target and non-target classes and, thus, are capable of multi labeling. These systems are evaluated for the data of residential areas of Task 3 from the DCASE'16 challenge. It is shown, that the DNN based system performs worse than the traditional systems for this task. Best results are achieved using GFB features in combination with a multiclass GMM-HMM approach.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         GFB
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         GMM-HMM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Schroeder2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Schroeder_3002.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Schroeder2016label" class="modal fade" id="bibtex-Schroeder2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSchroeder2016label">
        Performance Comparison of GMM, HMM and DNN Based Approaches for Acoustic Event Detection Within Task 3 of The DCASE 2016 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Schroeder2016,
    Author = "SchrÃ¶der, Jens and AnemÃ¼ller, JÃ¶rn and Goetze, Stefan",
    title = "Performance Comparison of {GMM}, {HMM} and {DNN} Based Approaches for Acoustic Event Detection Within Task 3 of The {DCASE} 2016 Challenge",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "This contribution reports on the performance of systems for polyphonic acoustic event detection (AED) compared within the framework of the Detection and classification of acoustic scenes and events 2016 (DCASE'16) challenge. State-of-the-art Gaussian mixture model (GMM) and GMM-hidden Markov model (HMM) approaches are applied using Mel-frequency cepstral coefficients (MFCCs) and Gabor filterbank (GFB) features and a non-negative matrix factorization (NMF) based system. Furthermore, tandem and hybrid deep neural network (DNN)-HMMsystems are adopted. All HMM systems that usually are of multiclass type, i.e., systems that just output one label per time segment from a set of possible classes, are extended to binary classification systems that are compound of single binary classifiers classifying between target and non-target classes and, thus, are capable of multi labeling. These systems are evaluated for the data of residential areas of Task 3 from the DCASE'16 challenge. It is shown, that the DNN based system performs worse than the traditional systems for this task. Best results are achieved using GFB features in combination with a multiclass GMM-HMM approach."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Ubskii2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Ubskii2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Sound Event Detection in Real-Life Audio
       </h4>
<p style="text-align:left">
        Dmitrii Ubskii and Alexei Pugachev
       </p>
<p style="text-align:left">
<em>
         Chair of Speech Information Systems, ITMO University, St. Petersburg, Russia
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Ubskii_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Ubskii2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Ubskii2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Ubskii2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Ubskii_3004.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Ubskii2016" class="panel-collapse collapse" id="collapse-Ubskii2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Sound Event Detection in Real-Life Audio
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       In this paper, an acoustic event detection system is proposed. This system uses fusion of several classifiers (GMM, DNN, LSTM) using another classifier (DNN) in attempt to achieve better results. The proposed system yields F1 score of up to 21% for indoors subset of the provided data and up to 44% for outdoors subset.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCC
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Fusion
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Ubskii2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Ubskii_3004.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Ubskii2016label" class="modal fade" id="bibtex-Ubskii2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexUbskii2016label">
        Sound Event Detection in Real-Life Audio
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Ubskii2016,
    Author = "Ubskii, Dmitrii and Pugachev, Alexei",
    title = "Sound Event Detection in Real-Life Audio",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "In this paper, an acoustic event detection system is proposed. This system uses fusion of several classifiers (GMM, DNN, LSTM) using another classifier (DNN) in attempt to achieve better results. The proposed system yields F1 score of up to 21\% for indoors subset of the provided data and up to 44\% for outdoors subset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Vu2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Vu2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene and Event Recognition Using Recurrent Neural Networks
       </h4>
<p style="text-align:left">
        Toan H. Vu and Jia-Ching Wang
       </p>
<p style="text-align:left">
<em>
         Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Vu_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Vu2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Vu2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Vu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Vu_3007.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Vu2016" class="panel-collapse collapse" id="collapse-Vu2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene and Event Recognition Using Recurrent Neural Networks
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       The DCASE2016 challenge is designed particularly for research in environmental sound analysis. It consists of four tasks that spread on various problems such as acoustic scene classification and sound event detection. This paper reports our results on all the tasks by using Recurrent Neural Networks (RNNs). Experiments show that our models achieved superior performances compared with the baselines.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         mel energy
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Vu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Vu_3007.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Vu2016label" class="modal fade" id="bibtex-Vu2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexVu2016label">
        Acoustic Scene and Event Recognition Using Recurrent Neural Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Vu2016,
    Author = "Vu, Toan H. and Wang, Jia-Ching",
    title = "Acoustic Scene and Event Recognition Using Recurrent Neural Networks",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "The DCASE2016 challenge is designed particularly for research in environmental sound analysis. It consists of four tasks that spread on various problems such as acoustic scene classification and sound event detection. This paper reports our results on all the tasks by using Recurrent Neural Networks (RNNs). Experiments show that our models achieved superior performances compared with the baselines."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zoehrer2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Zoehrer2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Gated Recurrent Networks Applied To Acoustic Scene Classification and Acoustic Event Detection
       </h4>
<p style="text-align:left">
        Matthias ZÃ¶hrer and Franz Pernkopf
       </p>
<p style="text-align:left">
<em>
         Signal Processing and Speech Communication Laboratory, Graz University of Technology, Graz, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Zoehrer_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zoehrer2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zoehrer2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zoehrer2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Zoehrer_3000.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zoehrer2016" class="panel-collapse collapse" id="collapse-Zoehrer2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Gated Recurrent Networks Applied To Acoustic Scene Classification and Acoustic Event Detection
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       We present two resource efficient frameworks for acoustic scene classification and acoustic event detection. In particular, we combine gated recurrent neural networks (GRNNs) and linear discriminant analysis (LDA) for efficiently classifying environmental sound scenes of the IEEE Detection and Classification of Acoustic Scenes and Events challenge (DCASE2016). Our system reaches an overall accuracy of 79.1% on DCASE 2016 task 1 development data, resulting in a relative improvement of 8.34% compared to the baseline GMM system. By applying GRNNs on DCASE2016 real event detection data using a MSE objective, we obtain a segment-based error rate (ER) score of 0.73 - which is a relative improvement of 19.8% compared to the baseline GMM system. We further investigate semi-supervised learning applied to acoustic scene analysis. In particular, we evaluate the effects of a hybrid, i.e. generative discriminative, objective function.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Input
        </td>
<td>
         monophonic
        </td>
</tr>
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         GRNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zoehrer2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Zoehrer_3000.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zoehrer2016label" class="modal fade" id="bibtex-Zoehrer2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZoehrer2016label">
        Gated Recurrent Networks Applied To Acoustic Scene Classification and Acoustic Event Detection
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zoehrer2016,
    Author = "ZÃ¶hrer, Matthias and Pernkopf, Franz",
    title = "Gated Recurrent Networks Applied To Acoustic Scene Classification and Acoustic Event Detection",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "We present two resource efficient frameworks for acoustic scene classification and acoustic event detection. In particular, we combine gated recurrent neural networks (GRNNs) and linear discriminant analysis (LDA) for efficiently classifying environmental sound scenes of the IEEE Detection and Classification of Acoustic Scenes and Events challenge (DCASE2016). Our system reaches an overall accuracy of 79.1\% on DCASE 2016 task 1 development data, resulting in a relative improvement of 8.34\% compared to the baseline GMM system. By applying GRNNs on DCASE2016 real event detection data using a MSE objective, we obtain a segment-based error rate (ER) score of 0.73 - which is a relative improvement of 19.8\% compared to the baseline GMM system. We further investigate semi-supervised learning applied to acoustic scene analysis. In particular, we evaluate the effects of a hybrid, i.e. generative discriminative, objective function."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>