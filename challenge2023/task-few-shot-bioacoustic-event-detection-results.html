<!DOCTYPE html><html lang="en">
<head>
    <title>Few-shot Bioacoustic Event Detection - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2023/task-few-shot-bioacoustic-event-detection-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description More detailed task description can be found in the task description page Systems ranking Rank Submission code Submission name Technical Report Event-based F-score with 95% confidence interval (Evaluation dataset) Event-based F-score (Validation dataset) Baseline_TempMatch_task5_1 Baseline Template Matching 14.9 (14.0 - 15.3) 3.4 …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2023</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2023/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-sound-event-detection-with-weak-and-soft-labels" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-and-soft-labels"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Introduction</a>
    </li>
            <li class=" dropdown-header ">
        <strong>A: Sound Event Detection with Weak Labels and Synthetic Soundscapes</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-labels-and-synthetic-soundscapes"><i class="fa fa-random fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-labels-and-synthetic-soundscapes-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
            <li class=" dropdown-header ">
        <strong>B: Sound Event Detection with Soft Labels</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-soft-labels"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-soft-labels-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Introduction</a>
    </li>
            <li class=" dropdown-header ">
        <strong>A: Automated Audio-Captioning</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning"><i class="fa dc-captioning fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
            <li class=" dropdown-header ">
        <strong>B: Language-Based Audio Retrieval</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-language-based-audio-retrieval"><i class="fa fa-file-text fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-language-based-audio-retrieval-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-foley-sound-synthesis" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthesis text-task2"></i>&nbsp;Task7&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-foley-sound-synthesis"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-foley-sound-synthesis-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2023/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2023/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/wood-08.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-danger"></i><i class="fa dc-bird fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text dcase-icon-top-text-sm">Bio</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 5</span></span><img src="../images/logos/dcase/dcase2023_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Few-shot Bioacoustic Event Detection</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a>
<ul>
<li><a href="#dataset-wise-metrics">Dataset wise metrics</a></li>
</ul>
</li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#general-characteristics">General characteristics</a></li>
<li><a href="#machine-learning-characteristics">Machine learning characteristics</a></li>
<li><a href="#complexity">Complexity</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2023/task-few-shot-bioacoustic-event-detection" style="">task description page</a></p>
<h1 id="systems-ranking">Systems ranking</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="false" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="results_evaluation_set_overall_F-score" data-scatter-y="results_validation_set_overall_F-score" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="results_evaluation_set_overall_F-score" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Submission <br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission <br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical <br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Event-based F-score (Evaluation dataset)" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based <br/>F-score <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="results_validation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage">
                Event-based <br/>F-score <br/>(Validation dataset)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td>Baseline Template Matching</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td>3.4</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td>Baseline Prototypical Network</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_3</td>
<td>BRAIn_LORIA_S3</td>
<td>Moummad2023</td>
<td>38.3 (37.9 - 38.7)</td>
<td>62.8</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_4</td>
<td>BRAIn_LORIA_S4</td>
<td>Moummad2023</td>
<td>34.4 (33.9 - 34.8)</td>
<td>58.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_1</td>
<td>BRAIn_LORIA_S1</td>
<td>Moummad2023</td>
<td>35.6 (35.3 - 36.0)</td>
<td>62.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>BRAIn_LORIA_S2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>63.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>36.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_1</td>
<td>FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS</td>
<td>Gelderblom2023</td>
<td>23.4 (22.9 - 23.8)</td>
<td>36.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu_DYXS_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>63.9</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_1</td>
<td>XuQianHu_DYXS_task5_1</td>
<td>XuQianHu2023</td>
<td>21.7 (21.1 - 22.1)</td>
<td>65.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_2</td>
<td>XuQianHu_DYXS_task5_2</td>
<td>XuQianHu2023</td>
<td>34.1 (33.6 - 34.4)</td>
<td>63.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_4</td>
<td>XuQianHu_DYXS_task5_4</td>
<td>XuQianHu2023</td>
<td>21.7 (21.2 - 22.1)</td>
<td>62.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>FKIE system 4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>62.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_1</td>
<td>FKIE system 1</td>
<td>Wilkinghoff2023</td>
<td>10.1 (9.6 - 10.5)</td>
<td>63.8</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_3</td>
<td>FKIE system 3</td>
<td>Wilkinghoff2023</td>
<td>9.4 (8.9 - 9.8)</td>
<td>65.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_2</td>
<td>FKIE system 2</td>
<td>Wilkinghoff2023</td>
<td>9.9 (9.3 - 10.2)</td>
<td>63.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_4</td>
<td>Jung_KT_task5_4</td>
<td>Jung2023</td>
<td>26.3 (25.8 - 26.8)</td>
<td>83.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_2</td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>15.7 (14.8 - 16.3)</td>
<td>81.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung_KT_task5_3</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td>81.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_1</td>
<td>Jung_KT_task5_1</td>
<td>Jung2023</td>
<td>14.1 (13.2 - 14.6)</td>
<td>79.8</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Multi-task Frame-level embedding learning 2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>75.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_1</td>
<td>Multi-task Frame-level embedding learning 1</td>
<td>Du2023</td>
<td>61.2 (60.7 - 61.6)</td>
<td>74.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_3</td>
<td>Multi-task Frame-level embedding learning 3</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>76.4</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_4</td>
<td>Multi-task Frame-level embedding learning 4</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>76.4</td>
</tr>
</tbody>
</table>
<h2 id="dataset-wise-metrics">Dataset wise metrics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="false" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="false" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="results_evaluation_set_dataset_wise_CHE_F-score" data-scatter-y="results_evaluation_set_dataset_wise_CT_Fscore" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="results_evaluation_set_overall_F-score" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Submission <br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission <br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Event-based F-score (Evaluation dataset)" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based<br/>F-score <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (CHE dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_CHE_F-score" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(CHE dataset)
            </th>
<th class="sep-left-cell text-center" data-axis-label="Event-based F-score (CT dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_CT_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(CT dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (MGE dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_MGE_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(MGE dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (MS dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_MS_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(MS dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (QU dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_QU_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(QU dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (DC dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_DC_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(DC dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (DC dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_CHE23_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(CHE23 dataset)
            </th>
<th class="text-center" data-axis-label="Event-based F-score (DC dataset)" data-chartable="true" data-field="results_evaluation_set_dataset_wise_CW_Fscore" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(CW dataset)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td>Baseline Template Matching</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td>21.1</td>
<td>7.2</td>
<td>44.1</td>
<td>8.0</td>
<td>9.7</td>
<td>34.9</td>
<td>36.1</td>
<td>44.2</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td>Baseline Prototypical Network</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td>31.5</td>
<td>14.0</td>
<td>8.1</td>
<td>27.1</td>
<td>0.4</td>
<td>37.8</td>
<td>36.1</td>
<td>44.2</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_3</td>
<td>BRAIn_LORIA_S3</td>
<td>Moummad2023</td>
<td>38.3 (37.9 - 38.7)</td>
<td>60.0</td>
<td>43.9</td>
<td>41.5</td>
<td>71.1</td>
<td>13.6</td>
<td>40.7</td>
<td>83.7</td>
<td>70.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_4</td>
<td>BRAIn_LORIA_S4</td>
<td>Moummad2023</td>
<td>34.4 (33.9 - 34.8)</td>
<td>61.4</td>
<td>37.6</td>
<td>42.0</td>
<td>63.6</td>
<td>10.9</td>
<td>41.4</td>
<td>80.9</td>
<td>70.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_1</td>
<td>BRAIn_LORIA_S1</td>
<td>Moummad2023</td>
<td>35.6 (35.3 - 36.0)</td>
<td>52.0</td>
<td>39.7</td>
<td>66.5</td>
<td>31.4</td>
<td>13.7</td>
<td>40.9</td>
<td>81.5</td>
<td>62.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>BRAIn_LORIA_S2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>60.3</td>
<td>36.2</td>
<td>61.3</td>
<td>67.8</td>
<td>17.7</td>
<td>41.5</td>
<td>83.2</td>
<td>72.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>58.3</td>
<td>15.4</td>
<td>70.9</td>
<td>58.0</td>
<td>12.5</td>
<td>39.8</td>
<td>58.4</td>
<td>66.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_1</td>
<td>FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS</td>
<td>Gelderblom2023</td>
<td>23.4 (22.9 - 23.8)</td>
<td>52.0</td>
<td>14.1</td>
<td>58.5</td>
<td>56.3</td>
<td>6.6</td>
<td>40.7</td>
<td>64.2</td>
<td>57.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu_DYXS_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>75.0</td>
<td>27.3</td>
<td>42.6</td>
<td>38.7</td>
<td>31.0</td>
<td>43.8</td>
<td>64.2</td>
<td>78.0</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_1</td>
<td>XuQianHu_DYXS_task5_1</td>
<td>XuQianHu2023</td>
<td>21.7 (21.1 - 22.1)</td>
<td>36.4</td>
<td>21.9</td>
<td>62.5</td>
<td>38.8</td>
<td>5.5</td>
<td>40.1</td>
<td>58.3</td>
<td>59.9</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_2</td>
<td>XuQianHu_DYXS_task5_2</td>
<td>XuQianHu2023</td>
<td>34.1 (33.6 - 34.4)</td>
<td>28.9</td>
<td>26.1</td>
<td>60.8</td>
<td>40.3</td>
<td>18.6</td>
<td>39.9</td>
<td>54.8</td>
<td>59.9</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_4</td>
<td>XuQianHu_DYXS_task5_4</td>
<td>XuQianHu2023</td>
<td>21.7 (21.2 - 22.1)</td>
<td>50.3</td>
<td>31.5</td>
<td>69.9</td>
<td>29.2</td>
<td>5.5</td>
<td>34.9</td>
<td>64.3</td>
<td>32.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>FKIE system 4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>30.9</td>
<td>43.2</td>
<td>41.9</td>
<td>15.1</td>
<td>3.9</td>
<td>34.9</td>
<td>31.5</td>
<td>59.4</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_1</td>
<td>FKIE system 1</td>
<td>Wilkinghoff2023</td>
<td>10.1 (9.6 - 10.5)</td>
<td>29.7</td>
<td>40.5</td>
<td>32.3</td>
<td>15.2</td>
<td>1.9</td>
<td>32.4</td>
<td>26.6</td>
<td>63.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_3</td>
<td>FKIE system 3</td>
<td>Wilkinghoff2023</td>
<td>9.4 (8.9 - 9.8)</td>
<td>31.2</td>
<td>39.2</td>
<td>25.4</td>
<td>9.9</td>
<td>1.9</td>
<td>29.9</td>
<td>29.4</td>
<td>73.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_2</td>
<td>FKIE system 2</td>
<td>Wilkinghoff2023</td>
<td>9.9 (9.3 - 10.2)</td>
<td>31.9</td>
<td>38.1</td>
<td>31.6</td>
<td>12.5</td>
<td>1.9</td>
<td>31.5</td>
<td>34.6</td>
<td>73.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_4</td>
<td>Jung_KT_task5_4</td>
<td>Jung2023</td>
<td>26.3 (25.8 - 26.8)</td>
<td>30.2</td>
<td>14.4</td>
<td>47.2</td>
<td>24.8</td>
<td>17.9</td>
<td>37.7</td>
<td>30.0</td>
<td>62.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_2</td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>15.7 (14.8 - 16.3)</td>
<td>46.3</td>
<td>10.9</td>
<td>4.1</td>
<td>25.7</td>
<td>29.6</td>
<td>38.1</td>
<td>48.9</td>
<td>77.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung_KT_task5_3</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td>32.2</td>
<td>14.3</td>
<td>20.8</td>
<td>26.7</td>
<td>25.8</td>
<td>47.7</td>
<td>41.2</td>
<td>58.8</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_1</td>
<td>Jung_KT_task5_1</td>
<td>Jung2023</td>
<td>14.1 (13.2 - 14.6)</td>
<td>47.5</td>
<td>10.4</td>
<td>3.2</td>
<td>29.4</td>
<td>31.1</td>
<td>44.1</td>
<td>47.3</td>
<td>78.1</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Multi-task Frame-level embedding learning 2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>85.7</td>
<td>53.8</td>
<td>93.1</td>
<td>72.7</td>
<td>42.7</td>
<td>62.4</td>
<td>69.5</td>
<td>44.2</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_1</td>
<td>Multi-task Frame-level embedding learning 1</td>
<td>Du2023</td>
<td>61.2 (60.7 - 61.6)</td>
<td>85.7</td>
<td>53.8</td>
<td>93.1</td>
<td>72.7</td>
<td>38.5</td>
<td>53.7</td>
<td>69.1</td>
<td>71.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_3</td>
<td>Multi-task Frame-level embedding learning 3</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>74.9</td>
<td>54.5</td>
<td>95.2</td>
<td>68.3</td>
<td>43.7</td>
<td>66.3</td>
<td>71.1</td>
<td>59.3</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_4</td>
<td>Multi-task Frame-level embedding learning 4</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>86.0</td>
<td>51.4</td>
<td>95.2</td>
<td>75.0</td>
<td>43.7</td>
<td>60.8</td>
<td>69.1</td>
<td>72.3</td>
</tr>
</tbody>
</table>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="false" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="results_evaluation_set_overall_F-score" data-scatter-y="results_validation_set_overall_F-score" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="results_evaluation_set_overall_F-score" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Submission <br/>code
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Submission <br/>name
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Event-based F-score (Evaluation dataset)" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based<br/>F-score <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="results_validation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage">
                Event-based<br/>F-score <br/>(Development dataset)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td>Baseline Template Matching</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td>3.4</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td>Baseline Prototypical Network</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>BRAIn_LORIA_S2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>63.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>36.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu_DYXS_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>63.9</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>FKIE system 4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>62.6</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td>81.5</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Multi-task Frame-level embedding learning 2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>75.6</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<h2 id="general-characteristics">General characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="false" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="results_evaluation_set_overall_F-score" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based<br/>F-score <br/><small class="text-muted">with 95% confidence interval</small> <br/>(Evaluation dataset)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data <br/>augmentation
            </th>
<th class="text-center narrow-col" data-field="system_acoustic_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Features
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td>any</td>
<td></td>
<td>spectrogram</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td>22.05 KHz</td>
<td></td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_3</td>
<td>Moummad2023</td>
<td>38.3 (37.9 - 38.7)</td>
<td>22.05 KHz</td>
<td>spectrogram mixing, random crop, resized crop, compression, additive white gaussian noise</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_4</td>
<td>Moummad2023</td>
<td>34.4 (33.9 - 34.8)</td>
<td>22.05 KHz</td>
<td>spectrogram mixing, random crop, resized crop, compression, additive white gaussian noise</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_1</td>
<td>Moummad2023</td>
<td>35.6 (35.3 - 36.0)</td>
<td>22.05 KHz</td>
<td>spectrogram mixing, random crop, resized crop, compression, additive white gaussian noise</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>22.05 KHz</td>
<td>spectrogram mixing, random crop, resized crop, compression, additive white gaussian noise</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>16 KHz</td>
<td>time stretching, denoising</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_1</td>
<td>Gelderblom2023</td>
<td>23.4 (22.9 - 23.8)</td>
<td>16 KHz</td>
<td>time stretching, denoising</td>
<td>mel spectrogram</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC and PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_1</td>
<td>XuQianHu2023</td>
<td>21.7 (21.1 - 22.1)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC and PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_2</td>
<td>XuQianHu2023</td>
<td>34.1 (33.6 - 34.4)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC and PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_4</td>
<td>XuQianHu2023</td>
<td>21.7 (21.2 - 22.1)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC and PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>22.05 KHz</td>
<td>SpecAugment, Mixup</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_1</td>
<td>Wilkinghoff2023</td>
<td>10.1 (9.6 - 10.5)</td>
<td>22.05 KHz</td>
<td>SpecAugment, Mixup</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_3</td>
<td>Wilkinghoff2023</td>
<td>9.4 (8.9 - 9.8)</td>
<td>22.05 KHz</td>
<td>SpecAugment, Mixup</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_2</td>
<td>Wilkinghoff2023</td>
<td>9.9 (9.3 - 10.2)</td>
<td>22.05 KHz</td>
<td>SpecAugment, Mixup</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_4</td>
<td>Jung2023</td>
<td>26.3 (25.8 - 26.8)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC, PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>15.7 (14.8 - 16.3)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC, PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC, PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_1</td>
<td>Jung2023</td>
<td>14.1 (13.2 - 14.6)</td>
<td>22.05 KHz</td>
<td></td>
<td>delta MFCC, PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>22.05 KHz</td>
<td>SpecAugment</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_1</td>
<td>Du2023</td>
<td>61.2 (60.7 - 61.6)</td>
<td>22.05 KHz</td>
<td>SpecAugment</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_3</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>22.05 KHz</td>
<td>SpecAugment, time stretching</td>
<td>PCEN</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_4</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>22.05 KHz</td>
<td>SpecAugment, time stretching</td>
<td>PCEN</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="machine-learning-characteristics">Machine learning characteristics</h2>
<table class="datatable table table-hover table-condensed" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-show-bar-chart-xaxis="false" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="results_evaluation_set_overall_F-score" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based<br/>F-score <br/>(Eval)
            </th>
<th class="text-center narrow-col" data-field="system_machine_learning_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Classifier
            </th>
<th class="text-center narrow-col" data-field="system_few_shot_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Few-shot approach
            </th>
<th class="text-center narrow-col" data-field="system_post-processing" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Post-processing
            </th>
</tr>
</thead>
<tbody>
<tr data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td>template matching</td>
<td>template matching</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td>ResNet</td>
<td>prototypical</td>
<td>threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_3</td>
<td>Moummad2023</td>
<td>38.3 (37.9 - 38.7)</td>
<td>CNN</td>
<td>softmax binary classifier + finetuning two last layers</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_4</td>
<td>Moummad2023</td>
<td>34.4 (33.9 - 34.8)</td>
<td>CNN</td>
<td>softmax binary classifier + finetuning whole model</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_1</td>
<td>Moummad2023</td>
<td>35.6 (35.3 - 36.0)</td>
<td>CNN</td>
<td>softmax binary classifier</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>CNN</td>
<td>softmax binary classifier + finetuning last layers</td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>transformer</td>
<td>prototypical</td>
<td>threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_1</td>
<td>Gelderblom2023</td>
<td>23.4 (22.9 - 23.8)</td>
<td>transformer</td>
<td>prototypical</td>
<td>threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>CNN</td>
<td>prototypical</td>
<td>threshold (0.3)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_1</td>
<td>XuQianHu2023</td>
<td>21.7 (21.1 - 22.1)</td>
<td>CNN</td>
<td>prototypical</td>
<td>threshold (0.1)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_2</td>
<td>XuQianHu2023</td>
<td>34.1 (33.6 - 34.4)</td>
<td>CNN</td>
<td>prototypical</td>
<td>threshold (0.05)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_4</td>
<td>XuQianHu2023</td>
<td>21.7 (21.2 - 22.1)</td>
<td>CNN</td>
<td>prototypical</td>
<td>threshold (0.15)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>CNN, K-Means, Logistic Regression</td>
<td>TempArcFace, DTW</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_1</td>
<td>Wilkinghoff2023</td>
<td>10.1 (9.6 - 10.5)</td>
<td>CNN, K-Means, Logistic Regression</td>
<td>TempArcFace, DTW</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_3</td>
<td>Wilkinghoff2023</td>
<td>9.4 (8.9 - 9.8)</td>
<td>CNN, K-Means, Logistic Regression</td>
<td>TempArcFace, DTW</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_2</td>
<td>Wilkinghoff2023</td>
<td>9.9 (9.3 - 10.2)</td>
<td>CNN, K-Means, Logistic Regression</td>
<td>TempArcFace, DTW</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_4</td>
<td>Jung2023</td>
<td>26.3 (25.8 - 26.8)</td>
<td>CNN</td>
<td>prototypical, contrastive, fine tuning, Transductive Inference</td>
<td>threshold, filter by length, remove long</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>15.7 (14.8 - 16.3)</td>
<td>CNN</td>
<td>prototypical, contrastive, fine tuning, Transductive Inference</td>
<td>threshold, filter by length, remove long</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td>CNN</td>
<td>prototypical, contrastive, fine tuning, Transductive Inference</td>
<td>threshold, filter by length, remove long</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_1</td>
<td>Jung2023</td>
<td>14.1 (13.2 - 14.6)</td>
<td>CNN</td>
<td>prototypical, contrastive, fine tuning, Transductive Inference</td>
<td>threshold, filter by length, remove long</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>CNN</td>
<td>finetuning</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_1</td>
<td>Du2023</td>
<td>61.2 (60.7 - 61.6)</td>
<td>CNN</td>
<td>finetuning</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_3</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>CNN</td>
<td>finetuning</td>
<td>peak picking, threshold</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_4</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>CNN</td>
<td>finetuning</td>
<td>peak picking, threshold</td>
</tr>
</tbody>
</table>
<h2 id="complexity">Complexity</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="false" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="label" data-filter-control="true" data-filter-show-clear="true" data-id-field="label" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="results_evaluation_set_overall_F-score" data-scatter-y="system_complexity_total_parameters" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_complexity_total_parameters" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="label" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="results_evaluation_set_overall_F-score" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Event-based<br/>F-score <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total_parameters" data-sortable="true" data-value-type="numeric-unit">
                Model <br/>complexity
            </th>
<th class="text-center narrow-col" data-field="system_complexity_trainining_time" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Training time
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_TempMatch_task5_1</td>
<td></td>
<td>14.9 (14.0 - 15.3)</td>
<td></td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>Baseline_PROTO_task5_1</td>
<td></td>
<td>2.92 ( 2.32 - 3.08 )</td>
<td></td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_3</td>
<td>Moummad2023</td>
<td>38.3 (37.9 - 38.7)</td>
<td>7.2 M</td>
<td>50 min</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_4</td>
<td>Moummad2023</td>
<td>34.4 (33.9 - 34.8)</td>
<td>7.2 M</td>
<td>60 min</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_1</td>
<td>Moummad2023</td>
<td>35.6 (35.3 - 36.0)</td>
<td>7.2 M</td>
<td>25 min</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Moummad_IMT_task5_2</td>
<td>Moummad2023</td>
<td>42.7 (42.2 - 43.1)</td>
<td>7.2 M</td>
<td>40 min</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_2</td>
<td>Gelderblom2023</td>
<td>31.1 (30.5 - 31.6)</td>
<td>90 M</td>
<td>2 hours</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Gelderblom_SINTEF_task5_1</td>
<td>Gelderblom2023</td>
<td>23.4 (22.9 - 23.8)</td>
<td>90 M</td>
<td>2 hours</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_3</td>
<td>XuQianHu2023</td>
<td>42.5 (41.8 - 43.0)</td>
<td>724 K</td>
<td>3 hours (GTX 1080ti)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_1</td>
<td>XuQianHu2023</td>
<td>21.7 (21.1 - 22.1)</td>
<td>724 K</td>
<td>3 hours (GTX 1080ti)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_2</td>
<td>XuQianHu2023</td>
<td>34.1 (33.6 - 34.4)</td>
<td>724 K</td>
<td>3 hours (GTX 1080ti)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>XuQianHu_NUDT_BIT_task5_4</td>
<td>XuQianHu2023</td>
<td>21.7 (21.2 - 22.1)</td>
<td>724 K</td>
<td>3 hours (GTX 1080ti)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_4</td>
<td>Wilkinghoff2023</td>
<td>16.0 (15.5 - 16.4)</td>
<td>3.1 M</td>
<td>12 hours (Quadro RTX 5000)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_1</td>
<td>Wilkinghoff2023</td>
<td>10.1 (9.6 - 10.5)</td>
<td>3.1 M</td>
<td>12 hours (Quadro RTX 5000)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_3</td>
<td>Wilkinghoff2023</td>
<td>9.4 (8.9 - 9.8)</td>
<td>3.1 M</td>
<td>12 hours (Quadro RTX 5000)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Wilkinghoff_FKIE_task5_2</td>
<td>Wilkinghoff2023</td>
<td>9.9 (9.3 - 10.2)</td>
<td>3.1 M</td>
<td>12 hours (Quadro RTX 5000)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_4</td>
<td>Jung2023</td>
<td>26.3 (25.8 - 26.8)</td>
<td></td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_2</td>
<td>Jung2023</td>
<td>15.7 (14.8 - 16.3)</td>
<td></td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_3</td>
<td>Jung2023</td>
<td>27.1 (26.5 - 27.6)</td>
<td></td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Jung_KT_task5_1</td>
<td>Jung2023</td>
<td>14.1 (13.2 - 14.6)</td>
<td></td>
<td></td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_2</td>
<td>Du2023</td>
<td>63.8 (63.3 - 64.2)</td>
<td>21460630</td>
<td>1 hour (TeslaV100-32GB)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_1</td>
<td>Du2023</td>
<td>61.2 (60.7 - 61.6)</td>
<td>21460630</td>
<td>1 hour (TeslaV100-32GB)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_3</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>21460630</td>
<td>3 hour (TeslaV100-32GB)</td>
</tr>
<tr data-hline="true">
<td></td>
<td>Du_NERCSLIP_task5_4</td>
<td>Du2023</td>
<td>63.6 (63.2 - 64.0)</td>
<td>21460630</td>
<td>3 hour (TeslaV100-32GB)</td>
</tr>
</tbody>
</table>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2023/technical_reports_task5.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Du2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Du2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        MULTI-TASK FRAME LEVEL SYSTEM FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION
       </h4>
<p style="text-align:left">
        Yan,Genwei and Wang,Ruoyu and Zou,Liang and Du,Jun and Wang,Qing and Gao,Tian and Fang,Xin
       </p>
<p style="text-align:left">
<em>
         China University of Mining and Technology and University of Science and Technology of China and iFLYTEK Research Institute
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary"> Du_NERCSLIP_task5_1</span> <span class="label label-primary"> Du_NERCSLIP_task5_2</span> <span class="label label-primary"> Du_NERCSLIP_task5_3</span> <span class="label label-primary"> Du_NERCSLIP_task5_4</span><span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Du2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Du2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Du2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Du_102_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Du2023" class="panel-collapse collapse" id="collapse-Du2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       MULTI-TASK FRAME LEVEL SYSTEM FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION
      </h4>
<p style="text-align:left">
<small>
        Yan,Genwei and Wang,Ruoyu and Zou,Liang and Du,Jun and Wang,Qing and Gao,Tian and Fang,Xin
       </small>
<br/>
<small>
<em>
         China University of Mining and Technology and University of Science and Technology of China and iFLYTEK Research Institute
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our new frame-level embedding learning system for DCASE2023 Task5: few-shot bioacoustic event detection. In the previous work, we proposed the frame-level embedding learning system and achieved the best performance of the DCASE 2022 Task5. In this work, we utilize several techniques to improve upon our previous work. Additionally, we introduce multi-task learning and Target Speaker Voice Activity Detection (TS-VAD) strategies to transform our previous system into a new multi-task frame-level embedding learning system. Compare to our previous work, our new system can achieve a better result (Fmeasure 75.74%, No ML) on the official validation set
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment, time stretching
        </td>
</tr>
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         External data usage
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Du2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Du_102_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Du2023label" class="modal fade" id="bibtex-Du2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexDu2023label">
        MULTI-TASK FRAME LEVEL SYSTEM FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Du2023,
    Author = "Yan, Genwei and Wang, Ruoyu and Zou, Liang and Du, Jun and Wang, Qing and Gao, Tian and Fang, Xin",
    title = "MULTI-TASK FRAME LEVEL SYSTEM FOR FEW-SHOT BIOACOUSTIC EVENT DETECTION",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "This technical report describes our new frame-level embedding learning system for DCASE2023 Task5: few-shot bioacoustic event detection. In the previous work, we proposed the frame-level embedding learning system and achieved the best performance of the DCASE 2022 Task5. In this work, we utilize several techniques to improve upon our previous work. Additionally, we introduce multi-task learning and Target Speaker Voice Activity Detection (TS-VAD) strategies to transform our previous system into a new multi-task frame-level embedding learning system. Compare to our previous work, our new system can achieve a better result (Fmeasure 75.74\%, No ML) on the official validation set"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Gelderblom2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Gelderblom2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS
       </h4>
<p style="text-align:left">
        Gelderblom, Femke and Cretois,Benjamin and Johnsen,Pal and Remonato,Filippo and Reinen,Tor Arne
       </p>
<p style="text-align:left">
<em>
</em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2023_Gelderblom_2</span><span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Gelderblom2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Gelderblom2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Gelderblom2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Gelderblom_SINTEF_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Gelderblom2023" class="panel-collapse collapse" id="collapse-Gelderblom2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS
      </h4>
<p style="text-align:left">
<small>
        Gelderblom, Femke and Cretois,Benjamin and Johnsen,Pal and Remonato,Filippo and Reinen,Tor Arne
       </small>
<br/>
<small>
<em>
</em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Our method for the DCASE Challenge 2023 combines BEATs with Prototypical Networks. BEATs, standing for Bidirectional Encoder representation from Audio Transformers, is a newly-released architecture by Microsoft for audio tokenisation and classification. BEATs combines a tokenizer and a semi-supervised audio classifier which learn from each other to improve the classification of audio samples. Prototypical Networks, instead, can be briefly described as a neural network-based clustering algorithm. Somewhat resembling a K-means clustering, Prototypical Networks classify samples based on their distance from the classes’ prototypes (what would be the centroids in a K-means setting). Since the prototypes are constructed from a small set of examples from each class, called the support set, Prototypical Networks are well suited to handle fewshot learning settings like the DCASE Challenge. In our method, we combine the two by using BEATs as a feature extractor, constructing informative features which are used by the Prototypical Network to perform the prototypes’ construction and subsequent classification of test audio samples. We obtain a F1 score of 0.36 on the validation dataset.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time stretching, denoising
        </td>
</tr>
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         BEATS
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Gelderblom2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Gelderblom_SINTEF_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Gelderblom2023label" class="modal fade" id="bibtex-Gelderblom2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGelderblom2023label">
        FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Gelderblom2023,
    Author = "Gelderblom, Femke and Cretois, Benjamin and Johnsen, Pal and Remonato, Filippo and Reinen, Tor Arne",
    title = "FEW-SHOT BIOACOUSTIC EVENT DETECTION USING BEATS",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "Our method for the DCASE Challenge 2023 combines BEATs with Prototypical Networks. BEATs, standing for Bidirectional Encoder representation from Audio Transformers, is a newly-released architecture by Microsoft for audio tokenisation and classification. BEATs combines a tokenizer and a semi-supervised audio classifier which learn from each other to improve the classification of audio samples. Prototypical Networks, instead, can be briefly described as a neural network-based clustering algorithm. Somewhat resembling a K-means clustering, Prototypical Networks classify samples based on their distance from the classes’ prototypes (what would be the centroids in a K-means setting). Since the prototypes are constructed from a small set of examples from each class, called the support set, Prototypical Networks are well suited to handle fewshot learning settings like the DCASE Challenge. In our method, we combine the two by using BEATs as a feature extractor, constructing informative features which are used by the Prototypical Network to perform the prototypes’ construction and subsequent classification of test audio samples. We obtain a F1 score of 0.36 on the validation dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Jung2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Jung2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        FEW-SHOT BIOACOUSTIC DETECTION BOOSTING WITH FINE TUNING STRATEGY USING NEGATIVE BASED PROTOTYPICAL LEARNING
       </h4>
<p style="text-align:left">
        Lee, Yuna and Chung, HaeChun, and Jung, JaeHoon
       </p>
<p style="text-align:left">
<em>
         KT Corporation, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Jung_KT_task5_1</span> <span class="label label-primary">Jung_KT_task5_2</span> <span class="label label-primary">Jung_KT_task5_3</span> <span class="label label-primary">Jung_KT_task5_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Jung2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Jung2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Jung2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Jung_108_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Jung2023" class="panel-collapse collapse" id="collapse-Jung2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       FEW-SHOT BIOACOUSTIC DETECTION BOOSTING WITH FINE TUNING STRATEGY USING NEGATIVE BASED PROTOTYPICAL LEARNING
      </h4>
<p style="text-align:left">
<small>
        Lee, Yuna and Chung, HaeChun, and Jung, JaeHoon
       </small>
<br/>
<small>
<em>
         KT Corporation, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Few-shot sound event detection has always faced the challenge of detecting bioacoustic sound events with only a few labelled instances of the class of interest. In this technical report, we describe our submission system for DCASE2023 Task5: few-shot bioacoustic event detection. We propose a novel framework of training audio segments via contrastive learning and prototypical learning, building the network more robust to the variety of acoustic environments, even in unseen domains. In addition, a finetuning strategy based on the novel loss functions is introduced. Our final systems achieves an f-measure of 83.08 on the DCASE task 5 validation set, outperforming the baseline performance and last year’s first place by a large margin.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         External data usage
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Jung2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Jung_108_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Jung2023label" class="modal fade" id="bibtex-Jung2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJung2023label">
        FEW-SHOT BIOACOUSTIC DETECTION BOOSTING WITH FINE TUNING STRATEGY USING NEGATIVE BASED PROTOTYPICAL LEARNING
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Jung2023,
    Author = "Lee, Yuna and Chung, HaeChun and Jung, JaeHoon",
    title = "FEW-SHOT BIOACOUSTIC DETECTION BOOSTING WITH FINE TUNING STRATEGY USING NEGATIVE BASED PROTOTYPICAL LEARNING",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "Few-shot sound event detection has always faced the challenge of detecting bioacoustic sound events with only a few labelled instances of the class of interest. In this technical report, we describe our submission system for DCASE2023 Task5: few-shot bioacoustic event detection. We propose a novel framework of training audio segments via contrastive learning and prototypical learning, building the network more robust to the variety of acoustic environments, even in unseen domains. In addition, a finetuning strategy based on the novel loss functions is introduced. Our final systems achieves an f-measure of 83.08 on the DCASE task 5 validation set, outperforming the baseline performance and last year’s first place by a large margin."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Moummad2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Moummad2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SUPERVISED CONTRASTIVE LEARNING FOR PRE-TRAINING BIOACOUSTIC FEW SHOT SYSTEMS
       </h4>
<p style="text-align:left">
        Moummad, Ilyass and Serizel, Romain and Farrugia, Nicolas
       </p>
<p style="text-align:left">
<em>
         IMT Atlantique, UMR CNRS, University of Lorraine,CNRS, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2023_Moummad_1</span> <span class="label label-primary">DCASE2023_Moummad_2</span> <span class="label label-primary">DCASE2023_Moummad_3</span> <span class="label label-primary">DCASE2023_Moummad_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Moummad2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Moummad2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Moummad2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Moummad_IMT_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Moummad2023').collapse('show');window.location.hash='#Moummad2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Moummad2023" class="panel-collapse collapse" id="collapse-Moummad2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SUPERVISED CONTRASTIVE LEARNING FOR PRE-TRAINING BIOACOUSTIC FEW SHOT SYSTEMS
      </h4>
<p style="text-align:left">
<small>
        Moummad, Ilyass and Serizel, Romain and Farrugia, Nicolas
       </small>
<br/>
<small>
<em>
         IMT Atlantique, UMR CNRS, University of Lorraine,CNRS, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We show in this work that learning a rich feature extractor from scratch using only official training data is feasible. We achieve this by learning representations using a supervised contrastive learning framework. We then transfer the learned feature extractor to the sets of validation and test for few-shot evaluation. For fewshot validation, we simply train a linear classifier on the negative and positive shots and obtain a F-score of 63.46% outperforming the baseline by a large margin. We don’t use any external data or pretrained model. Our approach doesn’t require choosing a threshold for prediction or any post-processing technique
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         spectrogram mixing, random crop, resized crop, compression, additive white gaussian noise
        </td>
</tr>
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         External data usage
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Moummad2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Moummad_IMT_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/ilyassmoummad/dcase23_task5_scl" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Moummad2023label" class="modal fade" id="bibtex-Moummad2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexMoummad2023label">
        SUPERVISED CONTRASTIVE LEARNING FOR PRE-TRAINING BIOACOUSTIC FEW SHOT SYSTEMS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Moummad2023,
    Author = "Moummad, Ilyass and Serizel, Romain and Farrugia, Nicolas",
    title = "SUPERVISED CONTRASTIVE LEARNING FOR PRE-TRAINING BIOACOUSTIC FEW SHOT SYSTEMS",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "We show in this work that learning a rich feature extractor from scratch using only official training data is feasible. We achieve this by learning representations using a supervised contrastive learning framework. We then transfer the learned feature extractor to the sets of validation and test for few-shot evaluation. For fewshot validation, we simply train a linear classifier on the negative and positive shots and obtain a F-score of 63.46\% outperforming the baseline by a large margin. We don’t use any external data or pretrained model. Our approach doesn’t require choosing a threshold for prediction or any post-processing technique"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Wilkinghoff2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Wilkinghoff2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        FEW-SHOT BIOACOUSTIC EVENT DETECTION
       </h4>
<p style="text-align:left">
        Wilkinghoff, Kevin and Cornaggia-Urrigshardt, Alessia
       </p>
<p style="text-align:left">
<em>
         Fraunhofer FKIE, Wachtberg, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Wilkinghoff_FKIE_task5_4</span> <span class="label&lt;span class=" clearfix"=""></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Wilkinghoff2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Wilkinghoff2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Wilkinghoff2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Wilkinghoff_FKIE_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Wilkinghoff2023" class="panel-collapse collapse" id="collapse-Wilkinghoff2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       FEW-SHOT BIOACOUSTIC EVENT DETECTION
      </h4>
<p style="text-align:left">
<small>
        Wilkinghoff, Kevin and Cornaggia-Urrigshardt, Alessia
       </small>
<br/>
<small>
<em>
         Fraunhofer FKIE, Wachtberg, Germany
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes the Fraunhofer FKIE submission for task 5 “Few-shot Bioacoustic Event Detection” of the DCASE challenge 2023. The submitted system is an adaptation of a few-shot keyword spotting system that uses embeddings with a temporal resolution suitable for template matching with dynamic time warping. The embedding model is trained to not only predict the sound event class but also the temporal position of a segment in a sound event using the angular margin loss TempAdaCos. At inference, embeddings are extracted and segment-wise cosine distances between the recording to be searched in and the provided templates are calculated. The resulting cost matrices are processed by applying a logistic regression model that is trained to discriminate between positive and negative frames. Lastly, dynamic time warping in combination with peak-picking and using a decision threshold is applied to detect on- and offsets of bioacoustic events. As a result, the presented system significantly outperforms both baseline systems.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment, Mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         External data usage
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Wilkinghoff2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Wilkinghoff_FKIE_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Wilkinghoff2023label" class="modal fade" id="bibtex-Wilkinghoff2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWilkinghoff2023label">
        FEW-SHOT BIOACOUSTIC EVENT DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Wilkinghoff2023,
    Author = "Wilkinghoff, Kevin and Cornaggia-Urrigshardt, Alessia",
    title = "FEW-SHOT BIOACOUSTIC EVENT DETECTION",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "This report describes the Fraunhofer FKIE submission for task 5 “Few-shot Bioacoustic Event Detection” of the DCASE challenge 2023. The submitted system is an adaptation of a few-shot keyword spotting system that uses embeddings with a temporal resolution suitable for template matching with dynamic time warping. The embedding model is trained to not only predict the sound event class but also the temporal position of a segment in a sound event using the angular margin loss TempAdaCos. At inference, embeddings are extracted and segment-wise cosine distances between the recording to be searched in and the provided templates are calculated. The resulting cost matrices are processed by applying a logistic regression model that is trained to discriminate between positive and negative frames. Lastly, dynamic time warping in combination with peak-picking and using a decision threshold is applied to detect on- and offsets of bioacoustic events. As a result, the presented system significantly outperforms both baseline systems."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="XuQianHu2023" style="box-shadow: none">
<div class="panel-heading" id="heading-XuQianHu2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SE-PROTONET: PROTOTYPICAL NETWORK WITH SQUEEZE-AND-EXCITATION BLOCKS FOR BIOACOUSTIC EVENT DETECTION
       </h4>
<p style="text-align:left">
        Liu, Junyan and Zhou,Zikai and Sun,Mengkai and Xu,Kele and Qian,Kun and Hu,Bian
       </p>
<p style="text-align:left">
<em>
         National University of Defence Technology and Key Laboratory of Brain Health Intelligent Evaluation and Intervention,Beijing Institute of Technology and School of Medical Technology,Beijing Institute of Technology, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">XuQianHu_NUDT_BIT_task5_3</span> <span class="label&lt;span class=" clearfix"=""></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-XuQianHu2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-XuQianHu2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-XuQianHu2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_XuQianHu_NUDT&amp;BIT_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-XuQianHu2023" class="panel-collapse collapse" id="collapse-XuQianHu2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SE-PROTONET: PROTOTYPICAL NETWORK WITH SQUEEZE-AND-EXCITATION BLOCKS FOR BIOACOUSTIC EVENT DETECTION
      </h4>
<p style="text-align:left">
<small>
        Liu, Junyan and Zhou,Zikai and Sun,Mengkai and Xu,Kele and Qian,Kun and Hu,Bian
       </small>
<br/>
<small>
<em>
         National University of Defence Technology and Key Laboratory of Brain Health Intelligent Evaluation and Intervention,Beijing Institute of Technology and School of Medical Technology,Beijing Institute of Technology, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical reprot, we describe our submission system for DCASE2023 Task5: Few-shot Bioacoustic Event Detection. We propose a metric learning method to construct a novel prototypical network, based on adaptive segment-level learning and Squeezeand-Excitation (SE) blocks. We make better utilization of the negative data, which can be used to construct the loss function and provide much more semantic information. Most importantly, we propose to use SE blocks to adaptively recalibrate channel-wise feature response, by explicitly modeling interdependencies between channels, which improves f-measure to 63.94 %. For the input feature, we use combination of per-channel energy normalization (PCEN) and delta mel-frequency cepstral coefficients (∆MFCC). Our system performs better than the baseline given by the officials, on the DCASE task 5 validation set. Our final score reaches an f-measure of 65.49 %, outperforming the baseline performance by 30.18 %.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System embeddings
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         False
        </td>
</tr>
<tr>
<td class="col-md-3">
         External data usage
        </td>
<td>
         False
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-XuQianHu2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_XuQianHu_NUDT&amp;BIT_t5.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-XuQianHu2023label" class="modal fade" id="bibtex-XuQianHu2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexXuQianHu2023label">
        SE-PROTONET: PROTOTYPICAL NETWORK WITH SQUEEZE-AND-EXCITATION BLOCKS FOR BIOACOUSTIC EVENT DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{XuQianHu2023,
    Author = "Liu, Junyan and Zhou, Zikai and Sun, Mengkai and Xu, Kele and Qian, Kun and Hu, Bian",
    title = "SE-PROTONET: PROTOTYPICAL NETWORK WITH SQUEEZE-AND-EXCITATION BLOCKS FOR BIOACOUSTIC EVENT DETECTION",
    institution = "DCASE2023 Challenge",
    year = "2023",
    month = "June",
    abstract = "In this technical reprot, we describe our submission system for DCASE2023 Task5: Few-shot Bioacoustic Event Detection. We propose a metric learning method to construct a novel prototypical network, based on adaptive segment-level learning and Squeezeand-Excitation (SE) blocks. We make better utilization of the negative data, which can be used to construct the loss function and provide much more semantic information. Most importantly, we propose to use SE blocks to adaptively recalibrate channel-wise feature response, by explicitly modeling interdependencies between channels, which improves f-measure to 63.94 \%. For the input feature, we use combination of per-channel energy normalization (PCEN) and delta mel-frequency cepstral coefficients (∆MFCC). Our system performs better than the baseline given by the officials, on the DCASE task 5 validation set. Our final score reaches an f-measure of 65.49 \%, outperforming the baseline performance by 30.18 \%."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>