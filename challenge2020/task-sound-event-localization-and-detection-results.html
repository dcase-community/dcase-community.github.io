<!DOCTYPE html><html lang="en">
<head>
    <title>Sound Event Localization and Detection - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2020/task-sound-event-localization-and-detection-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description The Sound Event Localization and Detection (SELD) task deals with methods that detect the temporal onset and offset of sound events when active, classify the type of the event from a known set of sound classes, and further localize the events in space when active. The focus of â€¦" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2020</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2020/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2020/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2020/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-urban text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-urban-sound-tagging-with-spatiotemporal-context-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2020/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2020/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2020/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2020/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge awards">
        <a href="/challenge2020/awards"><i class="fa fa-trophy"></i>&nbsp;Awards</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/stones-02.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-warning"></i><i class="fa dc-localization fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text dcase-icon-top-text-sm">Localization</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 3</span></span><img src="../images/logos/dcase/dcase2020_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Sound Event Localization and Detection</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#acoustic-environment-wise-performance">Acoustic environment-wise performance</a></li>
<li><a href="#event-polyphony-wise-performance">Event polyphony-wise performance</a></li>
<li><a href="#system-characteristics">System characteristics</a></li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>The Sound Event Localization and Detection (SELD) task deals with methods that detect the temporal onset and offset of sound events when active, classify the type of the event from a known set of sound classes, and further localize the events in space when active. </p>
<p>The focus of the current SELD task is to build systems that are able to handle event polyphony while being robust to ambient noise and reverberation in different acoustic environments/rooms, under static and dynamic spatial conditions (i.e. with moving sources). The task provides two datasets, development and evaluation, recorded in a total of 13 different acoustics environments. 
Among the two datasets, only the development dataset provides the reference labels. The participants are expected to build and validate systems using the development dataset, report results on a predefined development set split, and finally test their system on the unseen evaluation dataset.</p>
<p>More details on the task setup and evaluation can be found in the <a class="btn btn-primary" href="/challenge2020/task-sound-event-localization-and-detection" style="">task description page.</a></p>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="anchor" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eval_er20" data-scatter-y="eval_le" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="anchor_rank" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="2">Submission Information</th>
<th class="sep-left-cell" colspan="5">Evaluation dataset</th>
<th class="sep-left-cell" colspan="4">Development dataset</th>
</tr>
<tr>
<th data-field="anchor" data-sortable="true">
Submission name
</th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
Technical<br/>Report
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="anchor_sys_rank" data-sortable="true" data-value-type="int">
Best official <br/>system rank
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error Rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_f20" data-sortable="true" data-value-type="float1-percentage">
F-score <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="dev_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error Rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="dev_f20" data-sortable="true" data-value-type="float1-percentage">
F-score <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="dev_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="dev_lr" data-sortable="true" data-value-type="float1-percentage">
Loalization <br/>recall
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Du_USTC_task3_4</td>
<td>Du2020_task3_report</td>
<td>1</td>
<td>0.20</td>
<td>84.9</td>
<td>6.0</td>
<td>88.5</td>
<td>0.26</td>
<td>80.0</td>
<td>7.4</td>
<td>84.7</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_2</td>
<td>Nguyen2020_task3_report</td>
<td>4</td>
<td>0.23</td>
<td>82.0</td>
<td>9.3</td>
<td>90.0</td>
<td>0.36</td>
<td>71.4</td>
<td>12.1</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_4</td>
<td>Shimada2020_task3_report</td>
<td>5</td>
<td>0.25</td>
<td>83.2</td>
<td>7.0</td>
<td>86.2</td>
<td>0.29</td>
<td>80.0</td>
<td>7.5</td>
<td>83.5</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_4</td>
<td>Cao2020_task3_report</td>
<td>11</td>
<td>0.36</td>
<td>71.2</td>
<td>13.3</td>
<td>81.1</td>
<td>0.47</td>
<td>61.5</td>
<td>16.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_4</td>
<td>Park2020_task3_report</td>
<td>13</td>
<td>0.43</td>
<td>65.2</td>
<td>16.8</td>
<td>81.9</td>
<td>0.54</td>
<td>55.5</td>
<td>20.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_3</td>
<td>Phan2020_task3_report</td>
<td>15</td>
<td>0.49</td>
<td>61.7</td>
<td>15.2</td>
<td>72.4</td>
<td>0.60</td>
<td>49.2</td>
<td>19.0</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_2</td>
<td>PerezLopez2020_task3_report</td>
<td>16</td>
<td>0.51</td>
<td>60.1</td>
<td>12.4</td>
<td>65.1</td>
<td>0.44</td>
<td>68.0</td>
<td>13.3</td>
<td>79.6</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_1</td>
<td>Sampathkumar2020_task3_report</td>
<td>20</td>
<td>0.53</td>
<td>56.6</td>
<td>14.8</td>
<td>66.5</td>
<td>0.57</td>
<td>51.8</td>
<td>16.9</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_4</td>
<td>Patel2020_task3_report</td>
<td>22</td>
<td>0.55</td>
<td>55.5</td>
<td>14.4</td>
<td>65.5</td>
<td>0.54</td>
<td>55.6</td>
<td>15.2</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_2</td>
<td>Ronchini2020_task3_report</td>
<td>28</td>
<td>0.58</td>
<td>50.8</td>
<td>16.9</td>
<td>65.5</td>
<td>0.60</td>
<td>49.9</td>
<td>17.9</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_2</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>30</td>
<td>0.61</td>
<td>49.1</td>
<td>19.5</td>
<td>67.1</td>
<td>0.70</td>
<td>39.5</td>
<td>24.8</td>
<td>63.0</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_3</td>
<td>Song2020_task3_report</td>
<td>31</td>
<td>0.57</td>
<td>50.4</td>
<td>20.0</td>
<td>64.3</td>
<td>0.57</td>
<td>50.6</td>
<td>20.2</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Tian_PKU_task3_1</td>
<td>Tian2020_task3_report</td>
<td>36</td>
<td>0.64</td>
<td>47.6</td>
<td>24.5</td>
<td>67.5</td>
<td>0.72</td>
<td>40.1</td>
<td>25.9</td>
<td>64.0</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_2</td>
<td>Singla2020_task3_report</td>
<td>38</td>
<td>0.88</td>
<td>18.0</td>
<td>53.4</td>
<td>66.2</td>
<td>0.72</td>
<td>36.2</td>
<td>23.4</td>
<td>67.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_MIC_baseline</td>
<td>Politis2020_task3_report</td>
<td>39</td>
<td>0.69</td>
<td>41.3</td>
<td>23.1</td>
<td>62.4</td>
<td>0.78</td>
<td>31.4</td>
<td>27.3</td>
<td>59.0</td>
</tr>
</tbody>
</table>
<h1 id="systems-ranking">Systems ranking</h1>
<p>Performance of all the submitted systems on the evaluation and the development datasets</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="anchor" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eval_er20" data-scatter-y="eval_le" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_rank" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="2">Submission Information</th>
<th class="sep-left-cell" colspan="5">Evaluation dataset</th>
<th class="sep-left-cell" colspan="4">Development dataset</th>
</tr>
<tr>
<th data-field="anchor" data-sortable="true">
Submission name
</th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
Technical<br/>Report
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="anchor_rank" data-sortable="true" data-value-type="int">
Official <br/>rank
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error Rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_f20" data-sortable="true" data-value-type="float1-percentage">
F-score  <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="dev_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error Rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="dev_f20" data-sortable="true" data-value-type="float1-percentage">
F-score <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="dev_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="dev_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Du_USTC_task3_4</td>
<td>Du2020_task3_report</td>
<td>1</td>
<td>0.20</td>
<td>84.9</td>
<td>6.0</td>
<td>88.5</td>
<td>0.26</td>
<td>80.0</td>
<td>7.4</td>
<td>84.7</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_2</td>
<td>Du2020_task3_report</td>
<td>2</td>
<td>0.20</td>
<td>84.7</td>
<td>6.1</td>
<td>88.1</td>
<td>0.27</td>
<td>79.4</td>
<td>7.5</td>
<td>84.4</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_1</td>
<td>Du2020_task3_report</td>
<td>3</td>
<td>0.23</td>
<td>83.0</td>
<td>6.1</td>
<td>86.2</td>
<td>0.27</td>
<td>78.9</td>
<td>7.5</td>
<td>83.6</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_2</td>
<td>Nguyen2020_task3_report</td>
<td>4</td>
<td>0.23</td>
<td>82.0</td>
<td>9.3</td>
<td>90.0</td>
<td>0.36</td>
<td>71.4</td>
<td>12.1</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_3</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.23</td>
<td>81.7</td>
<td>9.3</td>
<td>90.1</td>
<td>0.36</td>
<td>71.2</td>
<td>12.1</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_4</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.23</td>
<td>81.8</td>
<td>9.3</td>
<td>90.0</td>
<td>0.35</td>
<td>71.9</td>
<td>12.1</td>
<td>82.7</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_4</td>
<td>Shimada2020_task3_report</td>
<td>5</td>
<td>0.25</td>
<td>83.2</td>
<td>7.0</td>
<td>86.2</td>
<td>0.29</td>
<td>80.0</td>
<td>7.5</td>
<td>83.5</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_3</td>
<td>Du2020_task3_report</td>
<td>6</td>
<td>0.23</td>
<td>82.6</td>
<td>8.3</td>
<td>88.0</td>
<td>0.27</td>
<td>79.8</td>
<td>7.4</td>
<td>84.6</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_3</td>
<td>Shimada2020_task3_report</td>
<td>7</td>
<td>0.25</td>
<td>82.6</td>
<td>7.0</td>
<td>85.5</td>
<td>0.28</td>
<td>79.9</td>
<td>7.6</td>
<td>83.7</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_1</td>
<td>Nguyen2020_task3_report</td>
<td>8</td>
<td>0.24</td>
<td>81.6</td>
<td>9.4</td>
<td>89.7</td>
<td>0.36</td>
<td>71.5</td>
<td>12.0</td>
<td>82.0</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_2</td>
<td>Shimada2020_task3_report</td>
<td>9</td>
<td>0.26</td>
<td>81.7</td>
<td>7.0</td>
<td>84.6</td>
<td>0.29</td>
<td>79.4</td>
<td>7.5</td>
<td>82.9</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_1</td>
<td>Shimada2020_task3_report</td>
<td>10</td>
<td>0.31</td>
<td>77.9</td>
<td>7.6</td>
<td>81.2</td>
<td>0.32</td>
<td>76.8</td>
<td>7.9</td>
<td>80.5</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_4</td>
<td>Cao2020_task3_report</td>
<td>11</td>
<td>0.36</td>
<td>71.2</td>
<td>13.3</td>
<td>81.1</td>
<td>0.47</td>
<td>61.5</td>
<td>16.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_3</td>
<td>Cao2020_task3_report</td>
<td>12</td>
<td>0.39</td>
<td>69.6</td>
<td>10.1</td>
<td>76.1</td>
<td>0.47</td>
<td>61.5</td>
<td>16.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_4</td>
<td>Park2020_task3_report</td>
<td>13</td>
<td>0.43</td>
<td>65.2</td>
<td>16.8</td>
<td>81.9</td>
<td>0.54</td>
<td>55.5</td>
<td>20.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_3</td>
<td>Park2020_task3_report</td>
<td>14</td>
<td>0.43</td>
<td>64.5</td>
<td>17.2</td>
<td>81.6</td>
<td>0.54</td>
<td>55.5</td>
<td>20.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_2</td>
<td>Cao2020_task3_report</td>
<td>14</td>
<td>0.39</td>
<td>66.5</td>
<td>20.6</td>
<td>83.0</td>
<td>0.47</td>
<td>61.5</td>
<td>16.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_3</td>
<td>Phan2020_task3_report</td>
<td>15</td>
<td>0.49</td>
<td>61.7</td>
<td>15.2</td>
<td>72.4</td>
<td>0.60</td>
<td>49.2</td>
<td>19.0</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_2</td>
<td>Park2020_task3_report</td>
<td>15</td>
<td>0.43</td>
<td>63.9</td>
<td>17.4</td>
<td>81.5</td>
<td>0.54</td>
<td>55.5</td>
<td>20.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_2</td>
<td>PerezLopez2020_task3_report</td>
<td>16</td>
<td>0.51</td>
<td>60.1</td>
<td>12.4</td>
<td>65.1</td>
<td>0.44</td>
<td>68.0</td>
<td>13.3</td>
<td>79.6</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_4</td>
<td>Phan2020_task3_report</td>
<td>17</td>
<td>0.53</td>
<td>59.2</td>
<td>14.6</td>
<td>68.2</td>
<td>0.59</td>
<td>50.8</td>
<td>18.2</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_1</td>
<td>Park2020_task3_report</td>
<td>18</td>
<td>0.50</td>
<td>59.0</td>
<td>19.2</td>
<td>79.0</td>
<td>0.54</td>
<td>55.5</td>
<td>20.0</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_2</td>
<td>Phan2020_task3_report</td>
<td>18</td>
<td>0.55</td>
<td>58.8</td>
<td>14.6</td>
<td>68.2</td>
<td>0.59</td>
<td>50.8</td>
<td>18.2</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_1</td>
<td>Phan2020_task3_report</td>
<td>19</td>
<td>0.52</td>
<td>57.8</td>
<td>16.8</td>
<td>69.8</td>
<td>0.60</td>
<td>49.2</td>
<td>19.0</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_1</td>
<td>Sampathkumar2020_task3_report</td>
<td>20</td>
<td>0.53</td>
<td>56.6</td>
<td>14.8</td>
<td>66.5</td>
<td>0.57</td>
<td>51.8</td>
<td>16.9</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_2</td>
<td>Sampathkumar2020_task3_report</td>
<td>21</td>
<td>0.54</td>
<td>56.3</td>
<td>15.6</td>
<td>66.8</td>
<td>0.57</td>
<td>51.6</td>
<td>17.5</td>
<td>66.1</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_4</td>
<td>Patel2020_task3_report</td>
<td>22</td>
<td>0.55</td>
<td>55.5</td>
<td>14.4</td>
<td>65.5</td>
<td>0.54</td>
<td>55.6</td>
<td>15.2</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_3</td>
<td>Patel2020_task3_report</td>
<td>23</td>
<td>0.56</td>
<td>54.5</td>
<td>15.0</td>
<td>65.1</td>
<td>0.55</td>
<td>55.4</td>
<td>14.9</td>
<td>66.5</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_1</td>
<td>PerezLopez2020_task3_report</td>
<td>24</td>
<td>0.55</td>
<td>56.0</td>
<td>12.8</td>
<td>61.1</td>
<td>0.57</td>
<td>55.6</td>
<td>15.6</td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_1</td>
<td>Patel2020_task3_report</td>
<td>25</td>
<td>0.56</td>
<td>54.3</td>
<td>13.4</td>
<td>63.0</td>
<td>0.55</td>
<td>54.2</td>
<td>13.6</td>
<td>63.6</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_2</td>
<td>Patel2020_task3_report</td>
<td>26</td>
<td>0.56</td>
<td>54.3</td>
<td>13.8</td>
<td>62.8</td>
<td>0.56</td>
<td>53.7</td>
<td>14.0</td>
<td>62.6</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_1</td>
<td>Cao2020_task3_report</td>
<td>27</td>
<td>0.54</td>
<td>55.5</td>
<td>23.9</td>
<td>71.8</td>
<td>0.47</td>
<td>61.5</td>
<td>16.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_2</td>
<td>Ronchini2020_task3_report</td>
<td>28</td>
<td>0.58</td>
<td>50.8</td>
<td>16.9</td>
<td>65.5</td>
<td>0.60</td>
<td>49.9</td>
<td>17.9</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_3</td>
<td>Ronchini2020_task3_report</td>
<td>29</td>
<td>0.59</td>
<td>50.3</td>
<td>16.8</td>
<td>65.5</td>
<td>0.61</td>
<td>48.7</td>
<td>18.7</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_2</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>30</td>
<td>0.61</td>
<td>49.1</td>
<td>19.5</td>
<td>67.1</td>
<td>0.70</td>
<td>39.5</td>
<td>24.8</td>
<td>63.0</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_3</td>
<td>Song2020_task3_report</td>
<td>31</td>
<td>0.57</td>
<td>50.4</td>
<td>20.0</td>
<td>64.3</td>
<td>0.57</td>
<td>50.6</td>
<td>20.2</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_1</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>32</td>
<td>0.61</td>
<td>48.3</td>
<td>19.2</td>
<td>65.9</td>
<td>0.69</td>
<td>40.3</td>
<td>22.1</td>
<td>63.8</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_1</td>
<td>Ronchini2020_task3_report</td>
<td>32</td>
<td>0.61</td>
<td>49.1</td>
<td>16.7</td>
<td>63.3</td>
<td>0.59</td>
<td>50.6</td>
<td>17.6</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_4</td>
<td>Ronchini2020_task3_report</td>
<td>33</td>
<td>0.60</td>
<td>49.1</td>
<td>17.1</td>
<td>63.7</td>
<td>0.61</td>
<td>48.4</td>
<td>18.6</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_4</td>
<td>Song2020_task3_report</td>
<td>34</td>
<td>0.58</td>
<td>49.3</td>
<td>21.6</td>
<td>64.3</td>
<td>0.57</td>
<td>50.4</td>
<td>20.2</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_1</td>
<td>Song2020_task3_report</td>
<td>35</td>
<td>0.58</td>
<td>49.1</td>
<td>21.8</td>
<td>64.3</td>
<td>0.57</td>
<td>50.6</td>
<td>20.1</td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_4</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>35</td>
<td>0.63</td>
<td>47.3</td>
<td>19.5</td>
<td>65.5</td>
<td>0.69</td>
<td>39.9</td>
<td>22.8</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Tian_PKU_task3_1</td>
<td>Tian2020_task3_report</td>
<td>36</td>
<td>0.64</td>
<td>47.6</td>
<td>24.5</td>
<td>67.5</td>
<td>0.72</td>
<td>40.1</td>
<td>25.9</td>
<td>64.0</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_3</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>37</td>
<td>0.64</td>
<td>46.7</td>
<td>20.0</td>
<td>64.5</td>
<td>0.70</td>
<td>39.6</td>
<td>22.7</td>
<td>63.1</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_2</td>
<td>Song2020_task3_report</td>
<td>37</td>
<td>0.59</td>
<td>48.0</td>
<td>23.5</td>
<td>64.3</td>
<td>0.58</td>
<td>49.5</td>
<td>21.2</td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_2</td>
<td>Singla2020_task3_report</td>
<td>38</td>
<td>0.88</td>
<td>18.0</td>
<td>53.4</td>
<td>66.2</td>
<td>0.72</td>
<td>36.2</td>
<td>23.4</td>
<td>67.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_MIC_baseline</td>
<td>Politis2020_task3_report</td>
<td>39</td>
<td>0.69</td>
<td>41.3</td>
<td>23.1</td>
<td>62.4</td>
<td>0.78</td>
<td>31.4</td>
<td>27.3</td>
<td>59.0</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_3</td>
<td>Singla2020_task3_report</td>
<td>40</td>
<td>0.89</td>
<td>13.3</td>
<td>59.9</td>
<td>66.8</td>
<td>0.78</td>
<td>27.1</td>
<td>25.6</td>
<td>62.3</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_1</td>
<td>Singla2020_task3_report</td>
<td>41</td>
<td>0.88</td>
<td>17.4</td>
<td>55.6</td>
<td>64.6</td>
<td>0.73</td>
<td>34.2</td>
<td>24.3</td>
<td>65.8</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_FOA_baseline</td>
<td>Politis2020_task3_report</td>
<td>42</td>
<td>0.70</td>
<td>39.5</td>
<td>23.2</td>
<td>62.1</td>
<td>0.72</td>
<td>37.4</td>
<td>22.8</td>
<td>60.7</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_4</td>
<td>Singla2020_task3_report</td>
<td>43</td>
<td>0.92</td>
<td>15.9</td>
<td>57.0</td>
<td>62.5</td>
<td>0.83</td>
<td>25.5</td>
<td>26.9</td>
<td>56.9</td>
</tr>
</tbody>
</table>
<h1 id="acoustic-environment-wise-performance">Acoustic environment-wise performance</h1>
<p>Performance of submitted systems on the two unseen acoustic environments of the evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="false" data-id-field="anchor" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eval_ir1_lr" data-scatter-y="eval_ir1_le" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="anchor_rank" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="3">Submission Information</th>
<th class="sep-left-cell" colspan="4">Location 1</th>
<th class="sep-left-cell" colspan="4">Location 2</th>
</tr>
<tr>
<th class="sm-cell" data-field="anchor" data-sortable="true">
Submission<br/>name
</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
Technical<br/>Report
</th>
<th class="text-center" data-field="anchor_rank" data-sortable="true" data-value-type="int">
Official rank
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ir1_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ir1_f20" data-sortable="true" data-value-type="float1-percentage">
F-score  <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ir1_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ir1_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ir2_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ir2_f20" data-sortable="true" data-value-type="float1-percentage">
F-score <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ir2_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ir2_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Du_USTC_task3_4</td>
<td>Du2020_task3_report</td>
<td>1</td>
<td>0.18</td>
<td>86.4</td>
<td>6.0</td>
<td>90.7</td>
<td>0.22</td>
<td>83.4</td>
<td>6.0</td>
<td>86.2</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_2</td>
<td>Du2020_task3_report</td>
<td>2</td>
<td>0.18</td>
<td>86.3</td>
<td>5.9</td>
<td>90.4</td>
<td>0.22</td>
<td>82.9</td>
<td>6.3</td>
<td>85.8</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_1</td>
<td>Du2020_task3_report</td>
<td>3</td>
<td>0.22</td>
<td>83.9</td>
<td>6.0</td>
<td>87.7</td>
<td>0.24</td>
<td>82.1</td>
<td>6.1</td>
<td>84.6</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_2</td>
<td>Nguyen2020_task3_report</td>
<td>4</td>
<td>0.22</td>
<td>83.5</td>
<td>7.9</td>
<td>90.4</td>
<td>0.25</td>
<td>80.4</td>
<td>10.8</td>
<td>89.6</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_3</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.22</td>
<td>83.4</td>
<td>7.9</td>
<td>90.5</td>
<td>0.25</td>
<td>80.1</td>
<td>10.8</td>
<td>89.6</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_4</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.22</td>
<td>83.4</td>
<td>7.8</td>
<td>90.3</td>
<td>0.25</td>
<td>80.1</td>
<td>10.9</td>
<td>89.7</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_4</td>
<td>Shimada2020_task3_report</td>
<td>5</td>
<td>0.24</td>
<td>84.5</td>
<td>6.7</td>
<td>87.7</td>
<td>0.26</td>
<td>81.9</td>
<td>7.3</td>
<td>84.7</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_3</td>
<td>Du2020_task3_report</td>
<td>6</td>
<td>0.21</td>
<td>83.5</td>
<td>8.4</td>
<td>89.5</td>
<td>0.24</td>
<td>81.6</td>
<td>8.2</td>
<td>86.5</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_3</td>
<td>Shimada2020_task3_report</td>
<td>7</td>
<td>0.24</td>
<td>83.8</td>
<td>6.7</td>
<td>87.0</td>
<td>0.26</td>
<td>81.4</td>
<td>7.4</td>
<td>84.1</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_1</td>
<td>Nguyen2020_task3_report</td>
<td>8</td>
<td>0.22</td>
<td>83.5</td>
<td>7.8</td>
<td>90.0</td>
<td>0.26</td>
<td>79.6</td>
<td>11.1</td>
<td>89.3</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_2</td>
<td>Shimada2020_task3_report</td>
<td>9</td>
<td>0.25</td>
<td>83.1</td>
<td>6.6</td>
<td>86.1</td>
<td>0.28</td>
<td>80.2</td>
<td>7.3</td>
<td>83.0</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_1</td>
<td>Shimada2020_task3_report</td>
<td>10</td>
<td>0.31</td>
<td>78.3</td>
<td>7.1</td>
<td>81.2</td>
<td>0.31</td>
<td>77.5</td>
<td>8.0</td>
<td>81.1</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_4</td>
<td>Cao2020_task3_report</td>
<td>11</td>
<td>0.35</td>
<td>72.7</td>
<td>10.9</td>
<td>81.0</td>
<td>0.37</td>
<td>69.6</td>
<td>15.8</td>
<td>81.3</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_3</td>
<td>Cao2020_task3_report</td>
<td>12</td>
<td>0.37</td>
<td>71.6</td>
<td>8.7</td>
<td>77.9</td>
<td>0.41</td>
<td>67.6</td>
<td>11.6</td>
<td>74.4</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_4</td>
<td>Park2020_task3_report</td>
<td>13</td>
<td>0.40</td>
<td>67.2</td>
<td>16.4</td>
<td>83.4</td>
<td>0.45</td>
<td>63.1</td>
<td>17.3</td>
<td>80.4</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_3</td>
<td>Park2020_task3_report</td>
<td>14</td>
<td>0.41</td>
<td>66.4</td>
<td>16.6</td>
<td>83.1</td>
<td>0.45</td>
<td>62.6</td>
<td>17.9</td>
<td>80.1</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_2</td>
<td>Cao2020_task3_report</td>
<td>14</td>
<td>0.40</td>
<td>65.9</td>
<td>21.0</td>
<td>83.2</td>
<td>0.39</td>
<td>67.1</td>
<td>20.3</td>
<td>82.7</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_3</td>
<td>Phan2020_task3_report</td>
<td>15</td>
<td>0.43</td>
<td>66.2</td>
<td>12.9</td>
<td>75.8</td>
<td>0.54</td>
<td>57.2</td>
<td>17.7</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_2</td>
<td>Park2020_task3_report</td>
<td>15</td>
<td>0.42</td>
<td>65.4</td>
<td>16.8</td>
<td>82.5</td>
<td>0.45</td>
<td>62.4</td>
<td>17.9</td>
<td>80.4</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_2</td>
<td>PerezLopez2020_task3_report</td>
<td>16</td>
<td>0.49</td>
<td>62.1</td>
<td>12.3</td>
<td>67.0</td>
<td>0.53</td>
<td>58.1</td>
<td>12.5</td>
<td>63.1</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_4</td>
<td>Phan2020_task3_report</td>
<td>17</td>
<td>0.47</td>
<td>62.2</td>
<td>13.1</td>
<td>71.0</td>
<td>0.60</td>
<td>56.3</td>
<td>16.2</td>
<td>65.6</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_1</td>
<td>Park2020_task3_report</td>
<td>18</td>
<td>0.50</td>
<td>58.2</td>
<td>18.6</td>
<td>76.8</td>
<td>0.49</td>
<td>59.7</td>
<td>19.7</td>
<td>81.2</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_2</td>
<td>Phan2020_task3_report</td>
<td>18</td>
<td>0.48</td>
<td>62.2</td>
<td>13.8</td>
<td>71.6</td>
<td>0.62</td>
<td>55.6</td>
<td>15.4</td>
<td>64.8</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_1</td>
<td>Phan2020_task3_report</td>
<td>19</td>
<td>0.47</td>
<td>62.9</td>
<td>14.4</td>
<td>72.9</td>
<td>0.57</td>
<td>52.7</td>
<td>19.5</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_1</td>
<td>Sampathkumar2020_task3_report</td>
<td>20</td>
<td>0.52</td>
<td>57.7</td>
<td>13.1</td>
<td>66.5</td>
<td>0.54</td>
<td>55.4</td>
<td>16.6</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_2</td>
<td>Sampathkumar2020_task3_report</td>
<td>21</td>
<td>0.53</td>
<td>57.8</td>
<td>13.0</td>
<td>66.1</td>
<td>0.56</td>
<td>54.9</td>
<td>18.0</td>
<td>67.5</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_4</td>
<td>Patel2020_task3_report</td>
<td>22</td>
<td>0.54</td>
<td>56.3</td>
<td>12.4</td>
<td>65.2</td>
<td>0.56</td>
<td>54.7</td>
<td>16.4</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_3</td>
<td>Patel2020_task3_report</td>
<td>23</td>
<td>0.56</td>
<td>54.1</td>
<td>13.5</td>
<td>63.5</td>
<td>0.55</td>
<td>54.9</td>
<td>16.4</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_1</td>
<td>PerezLopez2020_task3_report</td>
<td>24</td>
<td>0.53</td>
<td>57.3</td>
<td>13.1</td>
<td>62.5</td>
<td>0.58</td>
<td>54.7</td>
<td>12.6</td>
<td>59.6</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_1</td>
<td>Patel2020_task3_report</td>
<td>25</td>
<td>0.55</td>
<td>55.1</td>
<td>11.7</td>
<td>62.7</td>
<td>0.57</td>
<td>53.5</td>
<td>15.1</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_2</td>
<td>Patel2020_task3_report</td>
<td>26</td>
<td>0.55</td>
<td>55.1</td>
<td>12.4</td>
<td>62.0</td>
<td>0.57</td>
<td>53.5</td>
<td>15.1</td>
<td>63.7</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_1</td>
<td>Cao2020_task3_report</td>
<td>27</td>
<td>0.54</td>
<td>54.7</td>
<td>24.3</td>
<td>72.2</td>
<td>0.53</td>
<td>56.3</td>
<td>23.5</td>
<td>71.4</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_2</td>
<td>Ronchini2020_task3_report</td>
<td>28</td>
<td>0.56</td>
<td>52.8</td>
<td>15.4</td>
<td>65.0</td>
<td>0.60</td>
<td>48.9</td>
<td>18.3</td>
<td>66.1</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_3</td>
<td>Ronchini2020_task3_report</td>
<td>29</td>
<td>0.59</td>
<td>50.4</td>
<td>16.7</td>
<td>64.7</td>
<td>0.60</td>
<td>50.2</td>
<td>17.0</td>
<td>66.3</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_2</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>30</td>
<td>0.57</td>
<td>52.0</td>
<td>17.2</td>
<td>68.8</td>
<td>0.66</td>
<td>46.2</td>
<td>21.8</td>
<td>65.4</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_3</td>
<td>Song2020_task3_report</td>
<td>31</td>
<td>0.57</td>
<td>50.1</td>
<td>20.8</td>
<td>65.3</td>
<td>0.58</td>
<td>50.7</td>
<td>19.1</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_1</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>32</td>
<td>0.59</td>
<td>50.1</td>
<td>17.7</td>
<td>65.9</td>
<td>0.63</td>
<td>46.6</td>
<td>20.7</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_1</td>
<td>Ronchini2020_task3_report</td>
<td>32</td>
<td>0.62</td>
<td>48.5</td>
<td>16.3</td>
<td>61.1</td>
<td>0.60</td>
<td>49.7</td>
<td>17.0</td>
<td>65.4</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_4</td>
<td>Ronchini2020_task3_report</td>
<td>33</td>
<td>0.57</td>
<td>52.4</td>
<td>16.0</td>
<td>65.0</td>
<td>0.64</td>
<td>45.9</td>
<td>18.4</td>
<td>62.5</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_4</td>
<td>Song2020_task3_report</td>
<td>34</td>
<td>0.57</td>
<td>49.7</td>
<td>21.8</td>
<td>65.3</td>
<td>0.59</td>
<td>48.8</td>
<td>21.4</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_1</td>
<td>Song2020_task3_report</td>
<td>35</td>
<td>0.58</td>
<td>49.3</td>
<td>22.1</td>
<td>65.3</td>
<td>0.59</td>
<td>48.9</td>
<td>21.6</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_4</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>35</td>
<td>0.63</td>
<td>48.7</td>
<td>18.0</td>
<td>66.1</td>
<td>0.64</td>
<td>45.9</td>
<td>21.0</td>
<td>64.9</td>
</tr>
<tr>
<td></td>
<td>Tian_PKU_task3_1</td>
<td>Tian2020_task3_report</td>
<td>36</td>
<td>0.60</td>
<td>50.9</td>
<td>21.8</td>
<td>69.1</td>
<td>0.68</td>
<td>44.3</td>
<td>27.2</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_3</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>37</td>
<td>0.61</td>
<td>49.3</td>
<td>18.5</td>
<td>65.3</td>
<td>0.67</td>
<td>44.1</td>
<td>21.5</td>
<td>63.6</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_2</td>
<td>Song2020_task3_report</td>
<td>37</td>
<td>0.58</td>
<td>48.9</td>
<td>23.1</td>
<td>65.3</td>
<td>0.61</td>
<td>47.0</td>
<td>23.8</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_2</td>
<td>Singla2020_task3_report</td>
<td>38</td>
<td>0.85</td>
<td>21.6</td>
<td>57.6</td>
<td>66.3</td>
<td>0.91</td>
<td>14.2</td>
<td>49.1</td>
<td>66.0</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_MIC_baseline</td>
<td>Politis2020_task3_report</td>
<td>39</td>
<td>0.66</td>
<td>44.0</td>
<td>21.8</td>
<td>65.9</td>
<td>0.72</td>
<td>38.6</td>
<td>24.7</td>
<td>58.9</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_3</td>
<td>Singla2020_task3_report</td>
<td>40</td>
<td>0.84</td>
<td>19.7</td>
<td>61.5</td>
<td>68.3</td>
<td>0.95</td>
<td>6.9</td>
<td>58.2</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_1</td>
<td>Singla2020_task3_report</td>
<td>41</td>
<td>0.82</td>
<td>22.5</td>
<td>58.8</td>
<td>69.5</td>
<td>0.93</td>
<td>12.3</td>
<td>51.9</td>
<td>59.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_FOA_baseline</td>
<td>Politis2020_task3_report</td>
<td>42</td>
<td>0.66</td>
<td>43.3</td>
<td>20.5</td>
<td>65.0</td>
<td>0.74</td>
<td>35.5</td>
<td>26.2</td>
<td>59.1</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_4</td>
<td>Singla2020_task3_report</td>
<td>43</td>
<td>0.87</td>
<td>20.2</td>
<td>60.2</td>
<td>63.7</td>
<td>0.96</td>
<td>11.4</td>
<td>53.6</td>
<td>61.4</td>
</tr>
</tbody>
</table>
<h1 id="event-polyphony-wise-performance">Event polyphony-wise performance</h1>
<p>Performance of submitted systems on different numbers of overlapping events of the evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="false" data-id-field="anchor" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eval_ov2_lr" data-scatter-y="eval_ov2_le" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="anchor_rank" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="3">Submission Information</th>
<th class="sep-left-cell" colspan="4">No overlapping</th>
<th class="sep-left-cell" colspan="4">2 overlapping</th>
</tr>
<tr>
<th class="sm-cell" data-field="anchor" data-sortable="true">
Submission<br/>name
</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
Technical<br/>Report
</th>
<th class="text-center" data-field="anchor_rank" data-sortable="true" data-value-type="int">
Official rank
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ov1_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error rate <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ov1_f20" data-sortable="true" data-value-type="float1-percentage">
F-score  <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ov1_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ov1_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ov2_er20" data-reversed="true" data-sortable="true" data-value-type="float2">
Error rate  <br/>(20Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ov2_f20" data-sortable="true" data-value-type="float1-percentage">
F-score  <br/>(20Â°)
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="eval_ov2_le" data-reversed="true" data-sortable="true" data-value-type="float1">
Localization <br/>error (Â°)
</th>
<th class="text-center" data-chartable="true" data-field="eval_ov2_lr" data-sortable="true" data-value-type="float1-percentage">
Localization <br/>recall
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Du_USTC_task3_4</td>
<td>Du2020_task3_report</td>
<td>1</td>
<td>0.12</td>
<td>90.8</td>
<td>3.4</td>
<td>91.1</td>
<td>0.24</td>
<td>81.8</td>
<td>7.5</td>
<td>87.1</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_2</td>
<td>Du2020_task3_report</td>
<td>2</td>
<td>0.12</td>
<td>90.9</td>
<td>3.6</td>
<td>91.3</td>
<td>0.25</td>
<td>81.3</td>
<td>7.5</td>
<td>86.4</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_1</td>
<td>Du2020_task3_report</td>
<td>3</td>
<td>0.14</td>
<td>89.1</td>
<td>3.6</td>
<td>89.5</td>
<td>0.27</td>
<td>79.7</td>
<td>7.5</td>
<td>84.4</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_2</td>
<td>Nguyen2020_task3_report</td>
<td>4</td>
<td>0.10</td>
<td>92.8</td>
<td>5.1</td>
<td>94.0</td>
<td>0.30</td>
<td>76.1</td>
<td>11.7</td>
<td>87.8</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_3</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.10</td>
<td>92.5</td>
<td>5.2</td>
<td>93.9</td>
<td>0.30</td>
<td>75.9</td>
<td>11.7</td>
<td>88.0</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_4</td>
<td>Nguyen2020_task3_report</td>
<td>5</td>
<td>0.11</td>
<td>92.4</td>
<td>5.1</td>
<td>93.8</td>
<td>0.30</td>
<td>76.1</td>
<td>11.7</td>
<td>88.0</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_4</td>
<td>Shimada2020_task3_report</td>
<td>5</td>
<td>0.18</td>
<td>88.4</td>
<td>5.2</td>
<td>89.3</td>
<td>0.28</td>
<td>80.3</td>
<td>8.0</td>
<td>84.5</td>
</tr>
<tr>
<td></td>
<td>Du_USTC_task3_3</td>
<td>Du2020_task3_report</td>
<td>6</td>
<td>0.13</td>
<td>90.1</td>
<td>5.2</td>
<td>90.8</td>
<td>0.27</td>
<td>78.6</td>
<td>10.0</td>
<td>86.6</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_3</td>
<td>Shimada2020_task3_report</td>
<td>7</td>
<td>0.18</td>
<td>87.9</td>
<td>5.2</td>
<td>88.7</td>
<td>0.28</td>
<td>79.7</td>
<td>8.1</td>
<td>83.8</td>
</tr>
<tr>
<td></td>
<td>Nguyen_NTU_task3_1</td>
<td>Nguyen2020_task3_report</td>
<td>8</td>
<td>0.11</td>
<td>92.2</td>
<td>5.1</td>
<td>93.5</td>
<td>0.30</td>
<td>75.8</td>
<td>11.9</td>
<td>87.6</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_2</td>
<td>Shimada2020_task3_report</td>
<td>9</td>
<td>0.20</td>
<td>86.7</td>
<td>5.3</td>
<td>87.6</td>
<td>0.30</td>
<td>78.9</td>
<td>7.9</td>
<td>82.9</td>
</tr>
<tr>
<td></td>
<td>Shimada_SONY_task3_1</td>
<td>Shimada2020_task3_report</td>
<td>10</td>
<td>0.25</td>
<td>83.2</td>
<td>5.9</td>
<td>84.6</td>
<td>0.34</td>
<td>75.1</td>
<td>8.5</td>
<td>79.3</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_4</td>
<td>Cao2020_task3_report</td>
<td>11</td>
<td>0.20</td>
<td>84.4</td>
<td>6.6</td>
<td>87.0</td>
<td>0.44</td>
<td>63.9</td>
<td>17.5</td>
<td>77.9</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_3</td>
<td>Cao2020_task3_report</td>
<td>12</td>
<td>0.24</td>
<td>82.3</td>
<td>4.6</td>
<td>83.6</td>
<td>0.46</td>
<td>62.7</td>
<td>13.5</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_4</td>
<td>Park2020_task3_report</td>
<td>13</td>
<td>0.25</td>
<td>81.5</td>
<td>9.9</td>
<td>88.0</td>
<td>0.52</td>
<td>56.0</td>
<td>21.2</td>
<td>78.5</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_3</td>
<td>Park2020_task3_report</td>
<td>14</td>
<td>0.26</td>
<td>80.2</td>
<td>10.4</td>
<td>87.2</td>
<td>0.52</td>
<td>55.7</td>
<td>21.5</td>
<td>78.5</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_2</td>
<td>Cao2020_task3_report</td>
<td>14</td>
<td>0.15</td>
<td>88.7</td>
<td>4.9</td>
<td>90.2</td>
<td>0.52</td>
<td>54.4</td>
<td>30.4</td>
<td>79.0</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_3</td>
<td>Phan2020_task3_report</td>
<td>15</td>
<td>0.33</td>
<td>76.8</td>
<td>9.1</td>
<td>80.5</td>
<td>0.57</td>
<td>52.9</td>
<td>19.4</td>
<td>67.7</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_2</td>
<td>Park2020_task3_report</td>
<td>15</td>
<td>0.27</td>
<td>79.9</td>
<td>10.1</td>
<td>86.9</td>
<td>0.52</td>
<td>55.0</td>
<td>21.9</td>
<td>78.5</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_2</td>
<td>PerezLopez2020_task3_report</td>
<td>16</td>
<td>0.34</td>
<td>76.3</td>
<td>7.7</td>
<td>77.1</td>
<td>0.60</td>
<td>50.6</td>
<td>16.1</td>
<td>57.9</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_4</td>
<td>Phan2020_task3_report</td>
<td>17</td>
<td>0.41</td>
<td>73.5</td>
<td>6.8</td>
<td>75.0</td>
<td>0.60</td>
<td>50.8</td>
<td>20.0</td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Park_ETRI_task3_1</td>
<td>Park2020_task3_report</td>
<td>18</td>
<td>0.36</td>
<td>73.7</td>
<td>11.4</td>
<td>82.6</td>
<td>0.57</td>
<td>50.6</td>
<td>23.9</td>
<td>76.9</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_2</td>
<td>Phan2020_task3_report</td>
<td>18</td>
<td>0.43</td>
<td>73.0</td>
<td>7.5</td>
<td>74.8</td>
<td>0.60</td>
<td>50.4</td>
<td>19.6</td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Phan_QMUL_task3_1</td>
<td>Phan2020_task3_report</td>
<td>19</td>
<td>0.36</td>
<td>73.1</td>
<td>10.1</td>
<td>77.2</td>
<td>0.60</td>
<td>49.0</td>
<td>21.4</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_1</td>
<td>Sampathkumar2020_task3_report</td>
<td>20</td>
<td>0.40</td>
<td>69.4</td>
<td>9.9</td>
<td>74.0</td>
<td>0.60</td>
<td>49.0</td>
<td>18.3</td>
<td>62.2</td>
</tr>
<tr>
<td></td>
<td>Sampathkumar_TUC_task3_2</td>
<td>Sampathkumar2020_task3_report</td>
<td>21</td>
<td>0.43</td>
<td>68.4</td>
<td>8.9</td>
<td>71.8</td>
<td>0.60</td>
<td>49.3</td>
<td>20.0</td>
<td>63.9</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_4</td>
<td>Patel2020_task3_report</td>
<td>22</td>
<td>0.43</td>
<td>66.7</td>
<td>9.8</td>
<td>71.6</td>
<td>0.61</td>
<td>48.8</td>
<td>17.6</td>
<td>61.8</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_3</td>
<td>Patel2020_task3_report</td>
<td>23</td>
<td>0.42</td>
<td>67.5</td>
<td>10.7</td>
<td>73.4</td>
<td>0.63</td>
<td>46.7</td>
<td>18.1</td>
<td>60.1</td>
</tr>
<tr>
<td></td>
<td>PerezLopez_UPF_task3_1</td>
<td>PerezLopez2020_task3_report</td>
<td>24</td>
<td>0.38</td>
<td>72.3</td>
<td>8.1</td>
<td>73.5</td>
<td>0.64</td>
<td>46.3</td>
<td>16.7</td>
<td>53.7</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_1</td>
<td>Patel2020_task3_report</td>
<td>25</td>
<td>0.45</td>
<td>64.9</td>
<td>9.8</td>
<td>69.9</td>
<td>0.61</td>
<td>48.0</td>
<td>16.0</td>
<td>58.8</td>
</tr>
<tr>
<td></td>
<td>Patel_MST_task3_2</td>
<td>Patel2020_task3_report</td>
<td>26</td>
<td>0.45</td>
<td>64.9</td>
<td>9.6</td>
<td>69.6</td>
<td>0.62</td>
<td>48.0</td>
<td>16.8</td>
<td>58.8</td>
</tr>
<tr>
<td></td>
<td>Cao_Surrey_task3_1</td>
<td>Cao2020_task3_report</td>
<td>27</td>
<td>0.42</td>
<td>71.4</td>
<td>6.8</td>
<td>74.2</td>
<td>0.60</td>
<td>47.6</td>
<td>32.8</td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_2</td>
<td>Ronchini2020_task3_report</td>
<td>28</td>
<td>0.45</td>
<td>64.1</td>
<td>12.2</td>
<td>72.8</td>
<td>0.65</td>
<td>43.1</td>
<td>20.2</td>
<td>61.3</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_3</td>
<td>Ronchini2020_task3_report</td>
<td>29</td>
<td>0.47</td>
<td>63.7</td>
<td>11.8</td>
<td>72.0</td>
<td>0.66</td>
<td>42.5</td>
<td>20.2</td>
<td>61.7</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_2</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>30</td>
<td>0.50</td>
<td>62.4</td>
<td>14.1</td>
<td>74.8</td>
<td>0.67</td>
<td>41.2</td>
<td>23.3</td>
<td>62.5</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_3</td>
<td>Song2020_task3_report</td>
<td>31</td>
<td>0.41</td>
<td>64.4</td>
<td>12.6</td>
<td>73.0</td>
<td>0.66</td>
<td>42.2</td>
<td>25.3</td>
<td>59.2</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_1</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>32</td>
<td>0.48</td>
<td>61.7</td>
<td>13.9</td>
<td>73.5</td>
<td>0.68</td>
<td>40.6</td>
<td>22.9</td>
<td>61.5</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_1</td>
<td>Ronchini2020_task3_report</td>
<td>32</td>
<td>0.52</td>
<td>59.8</td>
<td>12.5</td>
<td>68.9</td>
<td>0.66</td>
<td>42.7</td>
<td>19.5</td>
<td>59.9</td>
</tr>
<tr>
<td></td>
<td>Ronchini_UPF_task3_4</td>
<td>Ronchini2020_task3_report</td>
<td>33</td>
<td>0.49</td>
<td>61.6</td>
<td>11.9</td>
<td>69.3</td>
<td>0.67</td>
<td>41.9</td>
<td>20.7</td>
<td>60.5</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_4</td>
<td>Song2020_task3_report</td>
<td>34</td>
<td>0.42</td>
<td>63.3</td>
<td>14.4</td>
<td>73.0</td>
<td>0.67</td>
<td>41.1</td>
<td>26.8</td>
<td>59.2</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_1</td>
<td>Song2020_task3_report</td>
<td>35</td>
<td>0.42</td>
<td>63.1</td>
<td>13.3</td>
<td>73.0</td>
<td>0.67</td>
<td>40.8</td>
<td>28.1</td>
<td>59.2</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_4</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>35</td>
<td>0.52</td>
<td>60.2</td>
<td>13.7</td>
<td>72.6</td>
<td>0.69</td>
<td>39.7</td>
<td>23.5</td>
<td>61.4</td>
</tr>
<tr>
<td></td>
<td>Tian_PKU_task3_1</td>
<td>Tian2020_task3_report</td>
<td>36</td>
<td>0.47</td>
<td>66.7</td>
<td>10.4</td>
<td>72.4</td>
<td>0.73</td>
<td>37.1</td>
<td>33.1</td>
<td>64.7</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_VFY_task3_3</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>37</td>
<td>0.52</td>
<td>59.9</td>
<td>13.7</td>
<td>71.4</td>
<td>0.70</td>
<td>39.2</td>
<td>24.3</td>
<td>60.5</td>
</tr>
<tr>
<td></td>
<td>Song_LGE_task3_2</td>
<td>Song2020_task3_report</td>
<td>37</td>
<td>0.43</td>
<td>62.0</td>
<td>15.1</td>
<td>73.0</td>
<td>0.68</td>
<td>39.7</td>
<td>29.5</td>
<td>59.2</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_2</td>
<td>Singla2020_task3_report</td>
<td>38</td>
<td>0.85</td>
<td>23.3</td>
<td>49.9</td>
<td>73.3</td>
<td>0.90</td>
<td>14.8</td>
<td>55.8</td>
<td>62.0</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_MIC_baseline</td>
<td>Politis2020_task3_report</td>
<td>39</td>
<td>0.75</td>
<td>33.7</td>
<td>16.0</td>
<td>69.4</td>
<td>0.75</td>
<td>33.7</td>
<td>28.1</td>
<td>58.3</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_3</td>
<td>Singla2020_task3_report</td>
<td>40</td>
<td>0.86</td>
<td>17.5</td>
<td>58.0</td>
<td>74.2</td>
<td>0.91</td>
<td>10.8</td>
<td>61.2</td>
<td>62.4</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_1</td>
<td>Singla2020_task3_report</td>
<td>41</td>
<td>0.85</td>
<td>22.0</td>
<td>53.6</td>
<td>71.0</td>
<td>0.89</td>
<td>14.7</td>
<td>57.0</td>
<td>60.7</td>
</tr>
<tr data-hline="true">
<td></td>
<td>DCASE2020_FOA_baseline</td>
<td>Politis2020_task3_report</td>
<td>42</td>
<td>0.75</td>
<td>32.5</td>
<td>26.7</td>
<td>57.4</td>
<td>0.58</td>
<td>51.3</td>
<td>18.3</td>
<td>69.9</td>
</tr>
<tr>
<td></td>
<td>Singla_SRIB_task3_4</td>
<td>Singla2020_task3_report</td>
<td>43</td>
<td>0.92</td>
<td>19.7</td>
<td>54.7</td>
<td>68.9</td>
<td>0.91</td>
<td>13.6</td>
<td>58.6</td>
<td>58.7</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<p>Summary of the submitted systems characteristics.</p>
<table class="datatable table table-hover table-condensed" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="anchor" data-pagination="true" data-rank-mode="grouped_muted" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="anchor_rank" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="anchor_rank" data-sortable="true" data-value-type="int">
Rank
</th>
<th class="sm-cell" data-field="anchor" data-sortable="true">
Submission<br/>name
</th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
Technical<br/>Report
</th>
<th class="sep-left-cell text-center narrow-col" data-field="system_architecture" data-filter-control="select" data-filter-strict-search="true" data-sortable="false" data-tag="true">
Classifier
</th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-field="system_params" data-sortable="true" data-value-type="numeric-unit">
Classifier<br/>params
</th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input_format" data-filter-control="select" data-filter-strict-search="true" data-sortable="false" data-tag="true">
Audio<br/>format
</th>
<th class="sep-left-cell text-center narrow-col" data-field="system_acoustic_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="false" data-tag="true">
Acoustic<br/>feature
</th>
<th class="sep-left-cell text-center narrow-col" data-field="system_aug" data-filter-control="select" data-filter-strict-search="true" data-sortable="false" data-tag="true">
Data <br/>augmentation
</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Du_USTC_task3_4</td>
<td>Du2020_task3_report</td>
<td>CRNN, CNN, ensemble</td>
<td>123942947</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td>time mixing, time and frequency masking, multichannel data simulation, voice channel switching</td>
</tr>
<tr>
<td>2</td>
<td>Du_USTC_task3_2</td>
<td>Du2020_task3_report</td>
<td>CRNN, CNN, ensemble</td>
<td>32725833</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td>time mixing, time and frequency masking, multichannel data simulation, voice channel switching</td>
</tr>
<tr>
<td>3</td>
<td>Du_USTC_task3_1</td>
<td>Du2020_task3_report</td>
<td>CRNN, CNN, ensemble</td>
<td>66238098</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td>time mixing, time and frequency masking, multichannel data simulation, voice channel switching</td>
</tr>
<tr>
<td>4</td>
<td>Nguyen_NTU_task3_2</td>
<td>Nguyen2020_task3_report</td>
<td>CRNN, ensemble</td>
<td>11589297</td>
<td>Ambisonic</td>
<td>mel spectra, complex spectra</td>
<td>mixup, frequency-shift, random-cutout, specaugment,</td>
</tr>
<tr>
<td>5</td>
<td>Nguyen_NTU_task3_3</td>
<td>Nguyen2020_task3_report</td>
<td>CRNN, ensemble</td>
<td>12418724</td>
<td>Ambisonic</td>
<td>mel spectra, complex spectra</td>
<td>mixup, frequency-shift, random-cutout, specaugment,</td>
</tr>
<tr>
<td>5</td>
<td>Nguyen_NTU_task3_4</td>
<td>Nguyen2020_task3_report</td>
<td>CRNN, ensemble</td>
<td>12418724</td>
<td>Ambisonic</td>
<td>mel spectra, complex spectra</td>
<td>mixup, frequency-shift, random-cutout, specaugment,</td>
</tr>
<tr>
<td>5</td>
<td>Shimada_SONY_task3_4</td>
<td>Shimada2020_task3_report</td>
<td>RD3Net, ensemble</td>
<td>11715040</td>
<td>Ambisonic</td>
<td>magnitude spectra, PCEN spectra, IPD, cosIPD, sinIPD</td>
<td>EMDA, rotation, Multichannel SpecAugment</td>
</tr>
<tr>
<td>6</td>
<td>Du_USTC_task3_3</td>
<td>Du2020_task3_report</td>
<td>CRNN, CNN, ensemble</td>
<td>24979016</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td>time mixing, time and frequency masking, multichannel data simulation, voice channel switching</td>
</tr>
<tr>
<td>7</td>
<td>Shimada_SONY_task3_3</td>
<td>Shimada2020_task3_report</td>
<td>RD3Net, CRNN, ensemble</td>
<td>14739274</td>
<td>Ambisonic</td>
<td>magnitude spectra, PCEN mel spectra, IPD, cosIPD, sinIPD</td>
<td>EMDA, rotation, Multichannel SpecAugment</td>
</tr>
<tr>
<td>8</td>
<td>Nguyen_NTU_task3_1</td>
<td>Nguyen2020_task3_report</td>
<td>CRNN, ensemble</td>
<td>10759870</td>
<td>Ambisonic</td>
<td>mel spectra, complex spectra</td>
<td>mixup, frequency-shift, random-cutout, specaugment,</td>
</tr>
<tr>
<td>9</td>
<td>Shimada_SONY_task3_2</td>
<td>Shimada2020_task3_report</td>
<td>RD3Net, ensemble</td>
<td>8369540</td>
<td>Ambisonic</td>
<td>magnitude spectra, IPD, cosIPD, sinIPD</td>
<td>EMDA, rotation, Multichannel SpecAugment</td>
</tr>
<tr>
<td>10</td>
<td>Shimada_SONY_task3_1</td>
<td>Shimada2020_task3_report</td>
<td>RD3Net</td>
<td>1674680</td>
<td>Ambisonic</td>
<td>magnitude spectra, IPD</td>
<td>EMDA, rotation, Multichannel SpecAugment</td>
</tr>
<tr>
<td>11</td>
<td>Cao_Surrey_task3_4</td>
<td>Cao2020_task3_report</td>
<td>CRNN</td>
<td>23799012</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Cao_Surrey_task3_3</td>
<td>Cao2020_task3_report</td>
<td>CRNN</td>
<td>23799012</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>Park_ETRI_task3_4</td>
<td>Park2020_task3_report</td>
<td>FPN, RNN, TrellisNet, ensemble</td>
<td>19510056</td>
<td>both</td>
<td>mel spectra, intensity vector, HPSS</td>
<td>time stretching</td>
</tr>
<tr>
<td>14</td>
<td>Park_ETRI_task3_3</td>
<td>Park2020_task3_report</td>
<td>FPN, RNN, TrellisNet, ensemble</td>
<td>13078986</td>
<td>both</td>
<td>mel spectra, intensity vector, HPSS</td>
<td></td>
</tr>
<tr>
<td>14</td>
<td>Cao_Surrey_task3_2</td>
<td>Cao2020_task3_report</td>
<td>CRNN</td>
<td>23799012</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>Phan_QMUL_task3_3</td>
<td>Phan2020_task3_report</td>
<td>self-attention CRNN</td>
<td>116118</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>15</td>
<td>Park_ETRI_task3_2</td>
<td>Park2020_task3_report</td>
<td>FPN, RNN, TrellisNet</td>
<td>6647916</td>
<td>both</td>
<td>mel spectra, intensity vector, HPSS</td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>PerezLopez_UPF_task3_2</td>
<td>PerezLopez2020_task3_report</td>
<td>GBM</td>
<td>20800</td>
<td>Ambisonic</td>
<td>diffuseness</td>
<td></td>
</tr>
<tr>
<td>17</td>
<td>Phan_QMUL_task3_4</td>
<td>Phan2020_task3_report</td>
<td>self-attention CRNN</td>
<td>116118</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>18</td>
<td>Park_ETRI_task3_1</td>
<td>Park2020_task3_report</td>
<td>FPN, RNN, TrellisNet</td>
<td>6647916</td>
<td>both</td>
<td>mel spectra, intensity vector, HPSS</td>
<td></td>
</tr>
<tr>
<td>18</td>
<td>Phan_QMUL_task3_2</td>
<td>Phan2020_task3_report</td>
<td>self-attention CRNN</td>
<td>116118</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>19</td>
<td>Phan_QMUL_task3_1</td>
<td>Phan2020_task3_report</td>
<td>self-attention CRNN</td>
<td>116118</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>SpecAugment</td>
</tr>
<tr>
<td>20</td>
<td>Sampathkumar_TUC_task3_1</td>
<td>Sampathkumar2020_task3_report</td>
<td>CRNN</td>
<td>8010648</td>
<td>Ambisonic</td>
<td>Intensity vector</td>
<td></td>
</tr>
<tr>
<td>21</td>
<td>Sampathkumar_TUC_task3_2</td>
<td>Sampathkumar2020_task3_report</td>
<td>CRNN</td>
<td>8010648</td>
<td>Microphone Array</td>
<td>Intensity vector and GCC</td>
<td></td>
</tr>
<tr>
<td>22</td>
<td>Patel_MST_task3_4</td>
<td>Patel2020_task3_report</td>
<td>FC-CRNN</td>
<td>14463224</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td></td>
</tr>
<tr>
<td>23</td>
<td>Patel_MST_task3_3</td>
<td>Patel2020_task3_report</td>
<td>CRNN</td>
<td>14463224</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td></td>
</tr>
<tr>
<td>24</td>
<td>PerezLopez_UPF_task3_1</td>
<td>PerezLopez2020_task3_report</td>
<td>GBM</td>
<td>20800</td>
<td>Ambisonic</td>
<td>diffuseness</td>
<td>time shifting, time strecthing, pitch shifting, white noise addition, reverberation</td>
</tr>
<tr>
<td>25</td>
<td>Patel_MST_task3_1</td>
<td>Patel2020_task3_report</td>
<td>FC-CRNN</td>
<td>107143683</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td></td>
</tr>
<tr>
<td>26</td>
<td>Patel_MST_task3_2</td>
<td>Patel2020_task3_report</td>
<td>FC-CRNN</td>
<td>107143683</td>
<td>both</td>
<td>mel spectra, intensity vector, GCC</td>
<td></td>
</tr>
<tr>
<td>27</td>
<td>Cao_Surrey_task3_1</td>
<td>Cao2020_task3_report</td>
<td>CRNN</td>
<td>23799012</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>28</td>
<td>Ronchini_UPF_task3_2</td>
<td>Ronchini2020_task3_report</td>
<td>CRNN</td>
<td>1244536</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>channel rotations</td>
</tr>
<tr>
<td>29</td>
<td>Ronchini_UPF_task3_3</td>
<td>Ronchini2020_task3_report</td>
<td>CRNN</td>
<td>1278200</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>channel rotations</td>
</tr>
<tr>
<td>30</td>
<td>Naranjo-Alcazar_VFY_task3_2</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>CRNN</td>
<td>660264</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>31</td>
<td>Song_LGE_task3_3</td>
<td>Song2020_task3_report</td>
<td>CRNN</td>
<td>2586601</td>
<td>Both</td>
<td>mel spectra, GCC, intensity vector, angle mask</td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>Naranjo-Alcazar_VFY_task3_1</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>CRNN</td>
<td>635496</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>Ronchini_UPF_task3_1</td>
<td>Ronchini2020_task3_report</td>
<td>CRNN</td>
<td>1244536</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>channel rotations</td>
</tr>
<tr>
<td>33</td>
<td>Ronchini_UPF_task3_4</td>
<td>Ronchini2020_task3_report</td>
<td>CRNN</td>
<td>850680</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td>channel rotations</td>
</tr>
<tr>
<td>34</td>
<td>Song_LGE_task3_4</td>
<td>Song2020_task3_report</td>
<td>CRNN</td>
<td>2717033</td>
<td>Both</td>
<td>mel spectra, GCC, intensity vector, angle mask</td>
<td></td>
</tr>
<tr>
<td>35</td>
<td>Song_LGE_task3_1</td>
<td>Song2020_task3_report</td>
<td>CRNN</td>
<td>2587753</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>35</td>
<td>Naranjo-Alcazar_VFY_task3_4</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>CRNN</td>
<td>637224</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>36</td>
<td>Tian_PKU_task3_1</td>
<td>Tian2020_task3_report</td>
<td>CRNN</td>
<td>2000082</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>37</td>
<td>Naranjo-Alcazar_VFY_task3_3</td>
<td>Naranjo-Alcazar2020_task3_report</td>
<td>CRNN</td>
<td>638760</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>37</td>
<td>Song_LGE_task3_2</td>
<td>Song2020_task3_report</td>
<td>CRNN</td>
<td>2717033</td>
<td>Both</td>
<td>mel spectra, GCC, intensity vector, angle mask</td>
<td></td>
</tr>
<tr>
<td>38</td>
<td>Singla_SRIB_task3_2</td>
<td>Singla2020_task3_report</td>
<td>CRNN</td>
<td>517670</td>
<td>Ambisonic</td>
<td>phase and magnitude spectra, mel spectra, intensity vector</td>
<td></td>
</tr>
<tr data-hline="true">
<td>39</td>
<td>DCASE2020_MIC_baseline</td>
<td>Politis2020_task3_report</td>
<td>CRNN</td>
<td>513000</td>
<td>Microphone Array</td>
<td>mel spectra, GCC</td>
<td></td>
</tr>
<tr>
<td>40</td>
<td>Singla_SRIB_task3_3</td>
<td>Singla2020_task3_report</td>
<td>CRNN</td>
<td>517670</td>
<td>Ambisonic</td>
<td>phase and magnitude spectra, mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>41</td>
<td>Singla_SRIB_task3_1</td>
<td>Singla2020_task3_report</td>
<td>CRNN</td>
<td>513288</td>
<td>Ambisonic</td>
<td>phase and magnitude spectra, mel spectra, intensity vector</td>
<td></td>
</tr>
<tr data-hline="true">
<td>42</td>
<td>DCASE2020_FOA_baseline</td>
<td>Politis2020_task3_report</td>
<td>CRNN</td>
<td>513000</td>
<td>Ambisonic</td>
<td>mel spectra, intensity vector</td>
<td></td>
</tr>
<tr>
<td>43</td>
<td>Singla_SRIB_task3_4</td>
<td>Singla2020_task3_report</td>
<td>CRNN</td>
<td>513288</td>
<td>Ambisonic</td>
<td>phase and magnitude spectra, mel spectra, intensity vector</td>
<td>time stretching, block mixing</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2020/technical_reports_task3.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Cao2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Cao2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        EVENT-INDEPENDENT NETWORK FOR POLYPHONIC SOUND EVENT LOCALIZATION AND DETECTION
       </h4>
<p style="text-align:left">
        Yin Cao<sup>1</sup>, Turab Iqbal<sup>1</sup>, Qiuqiang Kong<sup>2</sup>, Zhong Yue<sup>1</sup>, Wenwu Wang<sup>1</sup>, Mark D. Plumbley<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>University of Surrey, <sup>2</sup>ByteDance Ltd.
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Cao_Surrey_task3_1</span>, <span class="label label-primary">Cao_Surrey_task3_3</span>, <span class="label label-primary">Cao_Surrey_task3_4</span>, <span class="label label-primary">Cao_Surrey_task3_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Cao2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Cao2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Cao2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Cao_37.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Cao2020_task3_report').collapse('show');window.location.hash='#Cao2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Cao2020_task3_report" class="panel-collapse collapse" id="collapse-Cao2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       EVENT-INDEPENDENT NETWORK FOR POLYPHONIC SOUND EVENT LOCALIZATION AND DETECTION
      </h4>
<p style="text-align:left">
<small>
        Yin Cao<sup>1</sup>, Turab Iqbal<sup>1</sup>, Qiuqiang Kong<sup>2</sup>, Zhong Yue<sup>1</sup>, Wenwu Wang<sup>1</sup>, Mark D. Plumbley<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>University of Surrey, <sup>2</sup>ByteDance Ltd.
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Polyphonic sound event localization and detection is to not only detect what sound events are happening but to localize corresponding sound sources. This series of tasks was firstly introduced in DCASE 2019 Task 3. This year, the sound event localization and detection task brings additional challenges in moving sources and up to two overlapping sound events, which include cases of two same type of events with two different direction-of-arrival (DoA) angles. In this report, a novel event-independent network for polyphonic sound event localization and detection is proposed. Unlike the two-stage method that was proposed by us last year [1], this new network is fully end-to-end. Inputs to the network are first-order Ambisonics (FOA) time-domain signals, which are then fed into a 1-D convolutional layer to extract logmel spectrograms and intensity vectors. The network is then split into two parallel branches. The first branch is for the sound event detection (SED), and the second branch is for the DoA estimation. There are three types of predictions from the network, which are SED predictions, event activity detection (EAD) predictions that are used to combine the SED and DOA features for the on-set and off-set estimation, and DoA predictions. All of these predictions have the format of two tracks indicating that there are at most two overlapping events. Within each track, there could be at most one event happening. This architecture brings a problem of track permutation. To address this problem, a frame-level permutation invariant training method is used. Experimental results show that the proposed method can detect polyphonic sound events and their corresponding DoAs. The performance of Task 3 dataset is greatly increased compared with the baseline method.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Cao2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Cao_37.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/yinkalario/Track-Independent-Network-for-Polyphonic-Sound-Event-Localization-and-Detection" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Cao2020_task3_reportlabel" class="modal fade" id="bibtex-Cao2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexCao2020_task3_reportlabel">
        EVENT-INDEPENDENT NETWORK FOR POLYPHONIC SOUND EVENT LOCALIZATION AND DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Cao2020_task3_report,
    Author = "Cao, Yin and Iqbal, Turab and Kong, Qiuqiang and Yue, Zhong and Wang, Wenwu and Plumbley, Mark D.",
    title = "EVENT-INDEPENDENT NETWORK FOR POLYPHONIC SOUND EVENT LOCALIZATION AND DETECTION",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "Polyphonic sound event localization and detection is to not only detect what sound events are happening but to localize corresponding sound sources. This series of tasks was firstly introduced in DCASE 2019 Task 3. This year, the sound event localization and detection task brings additional challenges in moving sources and up to two overlapping sound events, which include cases of two same type of events with two different direction-of-arrival (DoA) angles. In this report, a novel event-independent network for polyphonic sound event localization and detection is proposed. Unlike the two-stage method that was proposed by us last year [1], this new network is fully end-to-end. Inputs to the network are first-order Ambisonics (FOA) time-domain signals, which are then fed into a 1-D convolutional layer to extract logmel spectrograms and intensity vectors. The network is then split into two parallel branches. The first branch is for the sound event detection (SED), and the second branch is for the DoA estimation. There are three types of predictions from the network, which are SED predictions, event activity detection (EAD) predictions that are used to combine the SED and DOA features for the on-set and off-set estimation, and DoA predictions. All of these predictions have the format of two tracks indicating that there are at most two overlapping events. Within each track, there could be at most one event happening. This architecture brings a problem of track permutation. To address this problem, a frame-level permutation invariant training method is used. Experimental results show that the proposed method can detect polyphonic sound events and their corresponding DoAs. The performance of Task 3 dataset is greatly increased compared with the baseline method."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Du2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Du2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        THE USTC-IFLYTEK SYSTEM FOR SOUND EVENT LOCALIZATION AND DETECTION OF DCASE2020 CHALLENGE
       </h4>
<p style="text-align:left">
        Qing Wang<sup>1</sup>, Huaxin Wu<sup>2</sup>, Zijun Jing<sup>2</sup>, Feng Ma<sup>2</sup>, Yi Fang<sup>2</sup>, Yuxuan Wang<sup>1</sup>, Tairan Chen<sup>1</sup>, Jia Pan<sup>2</sup>, Jun Du<sup>1</sup>, Chin-Hui Lee<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>University of Science and Technology of China, <sup>2</sup>IFLYTEK CO. LTD., <sup>3</sup>Georgia Institute of Technology
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Du_USTC_task3_3</span>, <span class="label label-primary">Du_USTC_task3_4</span>, <span class="label label-primary">Du_USTC_task3_2</span>, <span class="label label-primary">Du_USTC_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Du2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Du2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Du2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Du_110.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Du2020_task3_report" class="panel-collapse collapse" id="collapse-Du2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       THE USTC-IFLYTEK SYSTEM FOR SOUND EVENT LOCALIZATION AND DETECTION OF DCASE2020 CHALLENGE
      </h4>
<p style="text-align:left">
<small>
        Qing Wang<sup>1</sup>, Huaxin Wu<sup>2</sup>, Zijun Jing<sup>2</sup>, Feng Ma<sup>2</sup>, Yi Fang<sup>2</sup>, Yuxuan Wang<sup>1</sup>, Tairan Chen<sup>1</sup>, Jia Pan<sup>2</sup>, Jun Du<sup>1</sup>, Chin-Hui Lee<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>University of Science and Technology of China, <sup>2</sup>IFLYTEK CO. LTD., <sup>3</sup>Georgia Institute of Technology
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we present our method for DCASE 2020 challenge: Sound Event Localization and Detection (SELD). We propose an entire technical solution, which consists of data augmentation, network training, model ensemble, and post-processing. First, more training data is generated by applying transformation to both Ambisonic and microphone array signals, and by mixing the non- overlapping samples in the development dataset. And SpecAugment is also used as an augmentation technique to expand the training dataset. Then we train several deep neural network (DNN) architectures to jointly predict the spatial and temporal location of sound events in addition to its type. Besides, for SED estimation, we also use softmax activation function to handle the classification of both non-overlapping and overlapping sound events. With several network architectures, a more robust prediction of SED and directions-of-arrival (DOA) is obtained by model ensemble. At last, we use post-processing to apply different thresholds to different sound events. The proposed system is evaluated on the development set of TAU-NIGENS Spatial Sound Events 2020.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Du2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Du_110.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Du2020_task3_reportlabel" class="modal fade" id="bibtex-Du2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexDu2020_task3_reportlabel">
        THE USTC-IFLYTEK SYSTEM FOR SOUND EVENT LOCALIZATION AND DETECTION OF DCASE2020 CHALLENGE
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Du2020_task3_report,
    Author = "Wang, Qing and Wu, Huaxin and Jing, Zijun and Ma, Feng and Fang, Yi and Wang, Yuxuan and Chen, Tairan and Pan, Jia and Du, Jun and Lee, Chin-Hui",
    title = "THE USTC-IFLYTEK SYSTEM FOR SOUND EVENT LOCALIZATION AND DETECTION OF DCASE2020 CHALLENGE",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "In this report, we present our method for DCASE 2020 challenge: Sound Event Localization and Detection (SELD). We propose an entire technical solution, which consists of data augmentation, network training, model ensemble, and post-processing. First, more training data is generated by applying transformation to both Ambisonic and microphone array signals, and by mixing the non- overlapping samples in the development dataset. And SpecAugment is also used as an augmentation technique to expand the training dataset. Then we train several deep neural network (DNN) architectures to jointly predict the spatial and temporal location of sound events in addition to its type. Besides, for SED estimation, we also use softmax activation function to handle the classification of both non-overlapping and overlapping sound events. With several network architectures, a more robust prediction of SED and directions-of-arrival (DOA) is obtained by model ensemble. At last, we use post-processing to apply different thresholds to different sound events. The proposed system is evaluated on the development set of TAU-NIGENS Spatial Sound Events 2020."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Naranjo-Alcazar2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Naranjo-Alcazar2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        TASK 3 DCASE 2020: SOUND EVENT LOCALIZATION AND DETECTION USING RESIDUAL SQUEEZE-EXCITATION CNNS
       </h4>
<p style="text-align:left">
        Javier Naranjo-Alcazar<sup>1</sup>, Sergi Perez-Castanos<sup>2</sup>, Jose Ferrandis<sup>2</sup>, Pedro Zuccarello<sup>2</sup>, Maximo Cobos<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Universitat de Valencia, <sup>2</sup>Visualfy
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Naranjo-Alcazar_VFY_task3_3</span>, <span class="label label-primary">Naranjo-Alcazar_VFY_task3_2</span>, <span class="label label-primary">Naranjo-Alcazar_VFY_task3_1</span>, <span class="label label-primary">Naranjo-Alcazar_VFY_task3_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Naranjo-Alcazar2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Naranjo-Alcazar2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Naranjo-Alcazar2020_task3_report').collapse('show');window.location.hash='#Naranjo-Alcazar2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Naranjo-Alcazar2020_task3_report" class="panel-collapse collapse" id="collapse-Naranjo-Alcazar2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       TASK 3 DCASE 2020: SOUND EVENT LOCALIZATION AND DETECTION USING RESIDUAL SQUEEZE-EXCITATION CNNS
      </h4>
<p style="text-align:left">
<small>
        Javier Naranjo-Alcazar<sup>1</sup>, Sergi Perez-Castanos<sup>2</sup>, Jose Ferrandis<sup>2</sup>, Pedro Zuccarello<sup>2</sup>, Maximo Cobos<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Universitat de Valencia, <sup>2</sup>Visualfy
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Sound Event Localization and Detection (SELD) is a problem related to the field of machine listening whose objective is to recognize individual sound events, detect their temporal activity, and estimate their spatial location. Thanks to the emergence of more hard-labeled audio datasets, Deep Learning techniques have become state-of-the-art solutions. The most common ones are those that implement a convolutional recurrent network (CRNN) having previously transformed the audio signal into multichannel 2D representation. In the context of this problem, the input to the network, usually, has many more channels than in other problems related to machine listening. This is because the audio is recorded by an array of microphones.Some frequency representation is obtained for each of them together with some additional representations, such as the generalized cross-correlation (GCC), whose objective is the assessment of the relationship between channels. This work aims to improve the accuracy results of the baseline CRNN by adding residual squeeze-excitation (SE) blocks in the convolutional part of the CRNN. The followed procedure involves a grid search of the parameter ratio of the residual SE block, whereas the hyperparameters of the network remain the same as in the baseline. Experiments show that by simply introducing the residual SE blocks, the results obtained in the development phase clearly exceed the baseline.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Naranjo-Alcazar2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Naranjo-Alcazar_34.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/Joferesp/DCASE2020-Task3" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Naranjo-Alcazar2020_task3_reportlabel" class="modal fade" id="bibtex-Naranjo-Alcazar2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNaranjo-Alcazar2020_task3_reportlabel">
        TASK 3 DCASE 2020: SOUND EVENT LOCALIZATION AND DETECTION USING RESIDUAL SQUEEZE-EXCITATION CNNS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Naranjo-Alcazar2020_task3_report,
    Author = "Naranjo-Alcazar, Javier and Perez-Castanos, Sergi and Ferrandis, Jose and Zuccarello, Pedro and Cobos, Maximo",
    title = "TASK 3 DCASE 2020: SOUND EVENT LOCALIZATION AND DETECTION USING RESIDUAL SQUEEZE-EXCITATION CNNS",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "Sound Event Localization and Detection (SELD) is a problem related to the field of machine listening whose objective is to recognize individual sound events, detect their temporal activity, and estimate their spatial location. Thanks to the emergence of more hard-labeled audio datasets, Deep Learning techniques have become state-of-the-art solutions. The most common ones are those that implement a convolutional recurrent network (CRNN) having previously transformed the audio signal into multichannel 2D representation. In the context of this problem, the input to the network, usually, has many more channels than in other problems related to machine listening. This is because the audio is recorded by an array of microphones.Some frequency representation is obtained for each of them together with some additional representations, such as the generalized cross-correlation (GCC), whose objective is the assessment of the relationship between channels. This work aims to improve the accuracy results of the baseline CRNN by adding residual squeeze-excitation (SE) blocks in the convolutional part of the CRNN. The followed procedure involves a grid search of the parameter ratio of the residual SE block, whereas the hyperparameters of the network remain the same as in the baseline. Experiments show that by simply introducing the residual SE blocks, the results obtained in the development phase clearly exceed the baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Nguyen2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Nguyen2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2020 TASK 3: ENSEMBLE OF SEQUENCE MATCHING NETWORKS FOR DYNAMIC SOUND EVENT LOCALIZATION, DETECTION, AND TRACKING
       </h4>
<p style="text-align:left">
        Thi Ngoc Tho Nguyen<sup>1</sup>, Douglas L. Jones<sup>2</sup>, Woon Seng Gan<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Nanyang Technological University, <sup>2</sup>University of Illinois Urbana-Champaign
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Nguyen_NTU_task3_4</span>, <span class="label label-primary">Nguyen_NTU_task3_2</span>, <span class="label label-primary">Nguyen_NTU_task3_3</span>, <span class="label label-primary">Nguyen_NTU_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Nguyen2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Nguyen2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Nguyen2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Nguyen_119.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Nguyen2020_task3_report" class="panel-collapse collapse" id="collapse-Nguyen2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2020 TASK 3: ENSEMBLE OF SEQUENCE MATCHING NETWORKS FOR DYNAMIC SOUND EVENT LOCALIZATION, DETECTION, AND TRACKING
      </h4>
<p style="text-align:left">
<small>
        Thi Ngoc Tho Nguyen<sup>1</sup>, Douglas L. Jones<sup>2</sup>, Woon Seng Gan<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Nanyang Technological University, <sup>2</sup>University of Illinois Urbana-Champaign
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Sound event localization and detection consisted two subtasks which are sound event detection and direction-of-arrival estimation. While sound event detection mainly relies on time-frequency patterns to distinguish different event classes, direction-of-arrival estimation uses magnitude or phase differences between microphones to estimate source directions. Therefore, it is often difficult to jointly train two subtasks simultaneously. Our previous sequence matching approach that solves sound event detection and direction-of-arrival separately and trains a convolutional recurrent neural network to associate the sound classes with the directions-of-arrival using onsets and offsets of the sound events shows improved performance for multiple-static-sound-source scenarios compared to other state-of-the-art networks such as the SELDnet, and the two-stage networks. Experimental results on the new DCASE dataset for sound event localization, detection, and tracking of multiple moving sound sources showed that the sequence matching network also outperformed the jointly trained SELDnet model. In order to estimate directions-of-arrival of moving sound sources with high spatial resolution, we proposed to separate the directional estimations into azimuth and elevation before feeding them into the sequence matching network. We combined several sequence matching networks into ensembles and achieved a sound event detection and localization error of 0.217 compared to 0.466 of the baseline.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Nguyen2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Nguyen_119.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Nguyen2020_task3_reportlabel" class="modal fade" id="bibtex-Nguyen2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNguyen2020_task3_reportlabel">
        DCASE 2020 TASK 3: ENSEMBLE OF SEQUENCE MATCHING NETWORKS FOR DYNAMIC SOUND EVENT LOCALIZATION, DETECTION, AND TRACKING
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Nguyen2020_task3_report,
    Author = "Nguyen, Thi Ngoc Tho and Jones, Douglas L. and Gan, Woon Seng",
    title = "DCASE 2020 TASK 3: ENSEMBLE OF SEQUENCE MATCHING NETWORKS FOR DYNAMIC SOUND EVENT LOCALIZATION, DETECTION, AND TRACKING",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "Sound event localization and detection consisted two subtasks which are sound event detection and direction-of-arrival estimation. While sound event detection mainly relies on time-frequency patterns to distinguish different event classes, direction-of-arrival estimation uses magnitude or phase differences between microphones to estimate source directions. Therefore, it is often difficult to jointly train two subtasks simultaneously. Our previous sequence matching approach that solves sound event detection and direction-of-arrival separately and trains a convolutional recurrent neural network to associate the sound classes with the directions-of-arrival using onsets and offsets of the sound events shows improved performance for multiple-static-sound-source scenarios compared to other state-of-the-art networks such as the SELDnet, and the two-stage networks. Experimental results on the new DCASE dataset for sound event localization, detection, and tracking of multiple moving sound sources showed that the sequence matching network also outperformed the jointly trained SELDnet model. In order to estimate directions-of-arrival of moving sound sources with high spatial resolution, we proposed to separate the directional estimations into azimuth and elevation before feeding them into the sequence matching network. We combined several sequence matching networks into ensembles and achieved a sound event detection and localization error of 0.217 compared to 0.466 of the baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Park2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Park2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SOUND EVENT LOCALIZATION AND DETECTION WITH VARIOUS LOSS FUNCTIONS
       </h4>
<p style="text-align:left">
        Sooyoung Park<sup>1</sup>, Sangwon Suh<sup>1</sup>, Youngho Jeong<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Electronics and Telecommunications Research Institute
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Park_ETRI_task3_1</span>, <span class="label label-primary">Park_ETRI_task3_3</span>, <span class="label label-primary">Park_ETRI_task3_2</span>, <span class="label label-primary">Park_ETRI_task3_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Park2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Park2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Park2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Park_89.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Park2020_task3_report" class="panel-collapse collapse" id="collapse-Park2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SOUND EVENT LOCALIZATION AND DETECTION WITH VARIOUS LOSS FUNCTIONS
      </h4>
<p style="text-align:left">
<small>
        Sooyoung Park<sup>1</sup>, Sangwon Suh<sup>1</sup>, Youngho Jeong<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Electronics and Telecommunications Research Institute
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report presents our system submitted to DCASE 2020 task 3. The goal of DCASE Task 3 is to detect a sound event and its location when a polyphonic sound event moves dynamically. We focus on designing loss functions to overcome the characteristics of the sub-task and imbalanced dataset. Temporal masking loss is used to overcome imbalance from zero labels of the silence frame. Soft floss is used for overcoming imbalance instances between class labels. A periodic loss function is proposed for regression that infers the periodic label in the direction of arrival estimation. Also, we take a feature pyramid network based network to overcome the information leakage occurred by the pooling layer in the CRNN.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Park2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Park_89.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Park2020_task3_reportlabel" class="modal fade" id="bibtex-Park2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPark2020_task3_reportlabel">
        SOUND EVENT LOCALIZATION AND DETECTION WITH VARIOUS LOSS FUNCTIONS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Park2020_task3_report,
    Author = "Park, Sooyoung and Suh, Sangwon and Jeong, Youngho",
    title = "SOUND EVENT LOCALIZATION AND DETECTION WITH VARIOUS LOSS FUNCTIONS",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "This technical report presents our system submitted to DCASE 2020 task 3. The goal of DCASE Task 3 is to detect a sound event and its location when a polyphonic sound event moves dynamically. We focus on designing loss functions to overcome the characteristics of the sub-task and imbalanced dataset. Temporal masking loss is used to overcome imbalance from zero labels of the silence frame. Soft floss is used for overcoming imbalance instances between class labels. A periodic loss function is proposed for regression that infers the periodic label in the direction of arrival estimation. Also, we take a feature pyramid network based network to overcome the information leakage occurred by the pooling layer in the CRNN."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Patel2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Patel2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2020 TASK 3: A SINGLE STAGE FULLY CONVOLUTIONAL NEURAL NETWORK FOR SOUND SOURCE LOCALIZATION AND DETECTION
       </h4>
<p style="text-align:left">
        Sohel Patel<sup>1</sup>, Maciej Zawodniok<sup>1</sup>, Jacob Benesty<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Missouri University of Science and Technology, <sup>2</sup>University of Quebec
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Patel_MST_task3_1</span>, <span class="label label-primary">Patel_MST_task3_3</span>, <span class="label label-primary">Patel_MST_task3_4</span>, <span class="label label-primary">Patel_MST_task3_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Patel2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Patel2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Patel2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Patel_112.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Patel2020_task3_report" class="panel-collapse collapse" id="collapse-Patel2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2020 TASK 3: A SINGLE STAGE FULLY CONVOLUTIONAL NEURAL NETWORK FOR SOUND SOURCE LOCALIZATION AND DETECTION
      </h4>
<p style="text-align:left">
<small>
        Sohel Patel<sup>1</sup>, Maciej Zawodniok<sup>1</sup>, Jacob Benesty<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Missouri University of Science and Technology, <sup>2</sup>University of Quebec
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we present our approach for DCASE 2020 Challenge Task3: Sound event localization and detection. We use a single step training method using SELDNet like models but using fully convolutional architectures. We consider the joint optimization of both event detection and DoA estimation. For the metrics that evaluate the performance of the model consider interdependence of both parameters performance unlike independent performance like DCASE 2019 challenge. We use all the sound event classes and corresponding cartesian co-ordinates for each class to create an image like label for reference and make this an image to image mapping problem. The best model could get DOA error of around 13.5Â° and error rate of 0.55.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Patel2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Patel_112.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Patel2020_task3_reportlabel" class="modal fade" id="bibtex-Patel2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPatel2020_task3_reportlabel">
        DCASE 2020 TASK 3: A SINGLE STAGE FULLY CONVOLUTIONAL NEURAL NETWORK FOR SOUND SOURCE LOCALIZATION AND DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Patel2020_task3_report,
    Author = "Patel, Sohel and Zawodniok, Maciej and Benesty, Jacob",
    title = "DCASE 2020 TASK 3: A SINGLE STAGE FULLY CONVOLUTIONAL NEURAL NETWORK FOR SOUND SOURCE LOCALIZATION AND DETECTION",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "In this report, we present our approach for DCASE 2020 Challenge Task3: Sound event localization and detection. We use a single step training method using SELDNet like models but using fully convolutional architectures. We consider the joint optimization of both event detection and DoA estimation. For the metrics that evaluate the performance of the model consider interdependence of both parameters performance unlike independent performance like DCASE 2019 challenge. We use all the sound event classes and corresponding cartesian co-ordinates for each class to create an image like label for reference and make this an image to image mapping problem. The best model could get DOA error of around 13.5Â° and error rate of 0.55."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="PerezLopez2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-PerezLopez2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        PAPAFIL: A LOW COMPLEXITY SOUND EVENT LOCALIZATION AND DETECTION METHOD WITH PARAMETRIC PARTICLE FILTERING AND GRADIENT BOOSTING
       </h4>
<p style="text-align:left">
        Andres Perez-Lopez<sup>1</sup>, Rafael Ibanez-Usach<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Pompeu Fabra University, <sup>2</sup>STRATIO
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">PerezLopez_UPF_task3_1</span>, <span class="label label-primary">PerezLopez_UPF_task3_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-PerezLopez2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-PerezLopez2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-PerezLopez2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_PerezLopez_123.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-PerezLopez2020_task3_report').collapse('show');window.location.hash='#PerezLopez2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-PerezLopez2020_task3_report" class="panel-collapse collapse" id="collapse-PerezLopez2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       PAPAFIL: A LOW COMPLEXITY SOUND EVENT LOCALIZATION AND DETECTION METHOD WITH PARAMETRIC PARTICLE FILTERING AND GRADIENT BOOSTING
      </h4>
<p style="text-align:left">
<small>
        Andres Perez-Lopez<sup>1</sup>, Rafael Ibanez-Usach<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Pompeu Fabra University, <sup>2</sup>STRATIO
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The present technical report describes the architecture of the system submitted to the DCASE 2020 Challenge - Task 3: Sound Event Localization and Detection. The proposed method conforms a low complexity solution for the task. It is based on four building blocks: a spatial parametric analysis to find single-source spectrogram bins, a particle tracker to estimate trajectories and temporal activities, a spatial filter, and a gradient boosting machine single-class classifier. Provisional results, computed from the development dataset, show that the proposed method outperforms a CRNN baseline in three out of the four evaluation metrics considered in the challenge, and obtains an overall score almost ten points above the baseline.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-PerezLopez2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_PerezLopez_123.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/andresperezlopez/DCASE2020" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-PerezLopez2020_task3_reportlabel" class="modal fade" id="bibtex-PerezLopez2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPerezLopez2020_task3_reportlabel">
        PAPAFIL: A LOW COMPLEXITY SOUND EVENT LOCALIZATION AND DETECTION METHOD WITH PARAMETRIC PARTICLE FILTERING AND GRADIENT BOOSTING
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{PerezLopez2020_task3_report,
    Author = "Perez-Lopez, Andres and Ibanez-Usach, Rafael",
    title = "PAPAFIL: A LOW COMPLEXITY SOUND EVENT LOCALIZATION AND DETECTION METHOD WITH PARAMETRIC PARTICLE FILTERING AND GRADIENT BOOSTING",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "The present technical report describes the architecture of the system submitted to the DCASE 2020 Challenge - Task 3: Sound Event Localization and Detection. The proposed method conforms a low complexity solution for the task. It is based on four building blocks: a spatial parametric analysis to find single-source spectrogram bins, a particle tracker to estimate trajectories and temporal activities, a spatial filter, and a gradient boosting machine single-class classifier. Provisional results, computed from the development dataset, show that the proposed method outperforms a CRNN baseline in three out of the four evaluation metrics considered in the challenge, and obtains an overall score almost ten points above the baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Phan2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Phan2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        AUDIO EVENT DETECTION AND LOCALIZATION WITH MULTITASK REGRESSION NETWORK
       </h4>
<p style="text-align:left">
        Huy Phan<sup>1</sup>, Lam Pham<sup>2</sup>, Philipp Koch<sup>3</sup>, Ngoc Duong<sup>4</sup>, Ian McLoughlin<sup>5</sup>, Alfred Mertins<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Queen Mary University of London, <sup>2</sup>University of Kent, <sup>3</sup>University of Luebeck, <sup>4</sup>InterDigital R&amp;D France, <sup>5</sup>Singapore Institute of Technology
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Phan_QMUL_task3_4</span>, <span class="label label-primary">Phan_QMUL_task3_2</span>, <span class="label label-primary">Phan_QMUL_task3_3</span>, <span class="label label-primary">Phan_QMUL_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Phan2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Phan2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Phan2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Phan_117.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Phan2020_task3_report').collapse('show');window.location.hash='#Phan2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Phan2020_task3_report" class="panel-collapse collapse" id="collapse-Phan2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       AUDIO EVENT DETECTION AND LOCALIZATION WITH MULTITASK REGRESSION NETWORK
      </h4>
<p style="text-align:left">
<small>
        Huy Phan<sup>1</sup>, Lam Pham<sup>2</sup>, Philipp Koch<sup>3</sup>, Ngoc Duong<sup>4</sup>, Ian McLoughlin<sup>5</sup>, Alfred Mertins<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Queen Mary University of London, <sup>2</sup>University of Kent, <sup>3</sup>University of Luebeck, <sup>4</sup>InterDigital R&amp;D France, <sup>5</sup>Singapore Institute of Technology
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission to the DCASE 2020 Task 3 (Sound Event Localization and Detection (SELD)). In the submission, we propose a multitask regression model, in which both (multi-label) event detection and localization are formulated as regression problems to use the mean squared error loss homogeneously for model training. The deep learning model features a recurrent convolutional neural network (CRNN) architecture coupled with self-attention mechanism. Experiments on the development set of the challengeâ€™s SELD task demonstrate that the proposed system outperforms the DCASE 2020 SELD baseline across all the detection and localization metrics, reducing the overall SELD error (the combined metric) approximately 10% absolute.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Phan2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Phan_117.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/pquochuy/dcase2020-seld" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Phan2020_task3_reportlabel" class="modal fade" id="bibtex-Phan2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPhan2020_task3_reportlabel">
        AUDIO EVENT DETECTION AND LOCALIZATION WITH MULTITASK REGRESSION NETWORK
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Phan2020_task3_report,
    Author = "Phan, Huy and Pham, Lam and Koch, Philipp and Duong, Ngoc and McLoughlin, Ian and Mertins, Alfred",
    title = "AUDIO EVENT DETECTION AND LOCALIZATION WITH MULTITASK REGRESSION NETWORK",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "This technical report describes our submission to the DCASE 2020 Task 3 (Sound Event Localization and Detection (SELD)). In the submission, we propose a multitask regression model, in which both (multi-label) event detection and localization are formulated as regression problems to use the mean squared error loss homogeneously for model training. The deep learning model features a recurrent convolutional neural network (CRNN) architecture coupled with self-attention mechanism. Experiments on the development set of the challengeâ€™s SELD task demonstrate that the proposed system outperforms the DCASE 2020 SELD baseline across all the detection and localization metrics, reducing the overall SELD error (the combined metric) approximately 10\% absolute."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Politis2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Politis2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        A DATASET OF REVERBERANT SPATIAL SOUND SCENES WITH MOVING SOURCES FOR SOUND EVENT LOCALIZATION AND DETECTION
       </h4>
<p style="text-align:left">
        Archontis Politis<sup>1</sup>, Sharath Adavanne<sup>1</sup>, Tuomas Virtanen<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Tampere University
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2020_MIC_baseline</span>,<span class="label label-primary">DCASE2020_FOA_baseline</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Politis2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Politis2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Politis2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Politis_base.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Politis2020_task3_report').collapse('show');window.location.hash='#Politis2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Politis2020_task3_report" class="panel-collapse collapse" id="collapse-Politis2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       A DATASET OF REVERBERANT SPATIAL SOUND SCENES WITH MOVING SOURCES FOR SOUND EVENT LOCALIZATION AND DETECTION
      </h4>
<p style="text-align:left">
<small>
        Archontis Politis<sup>1</sup>, Sharath Adavanne<sup>1</sup>, Tuomas Virtanen<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Tampere University
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report presents the dataset and the evaluation setup of the Sound Event Localization &amp; Detection (SELD) task for the DCASE 2020 Challenge. The SELD task refers to the problem of trying to simultaneously classify a known set of sound event classes, detect their temporal activations, and estimate their spatial directions or locations while they are active. To train and test SELD systems, datasets of diverse sound events occurring under realistic acoustic conditions are needed. Compared to the previous challenge, a significantly more complex dataset was created for DCASE 2020. The two key differences are a more diverse range of acoustical conditions, and dynamic conditions, i.e. moving sources. The spatial sound scenes are created using real room impulse responses captured in a continuous manner with a slowly moving excitation source. Both static and moving sound events are synthesized from them. Ambient noise recorded on location is added to complete the generation of scene recordings. A baseline SELD method accompanies the dataset, based on a convolutional recurrent neural network, to provide benchmark scores for the task. The baseline is an updated version of the one used in the previous challenge, with input features and training modifications to improve its performance.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Politis2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Politis_base.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/sharathadavanne/seld-dcase2020" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Politis2020_task3_reportlabel" class="modal fade" id="bibtex-Politis2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPolitis2020_task3_reportlabel">
        A DATASET OF REVERBERANT SPATIAL SOUND SCENES WITH MOVING SOURCES FOR SOUND EVENT LOCALIZATION AND DETECTION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Politis2020_task3_report,
    Author = "Politis, Archontis and Adavanne, Sharath and Virtanen, Tuomas",
    title = "A DATASET OF REVERBERANT SPATIAL SOUND SCENES WITH MOVING SOURCES FOR SOUND EVENT LOCALIZATION AND DETECTION",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "This report presents the dataset and the evaluation setup of the Sound Event Localization \&amp; Detection (SELD) task for the DCASE 2020 Challenge. The SELD task refers to the problem of trying to simultaneously classify a known set of sound event classes, detect their temporal activations, and estimate their spatial directions or locations while they are active. To train and test SELD systems, datasets of diverse sound events occurring under realistic acoustic conditions are needed. Compared to the previous challenge, a significantly more complex dataset was created for DCASE 2020. The two key differences are a more diverse range of acoustical conditions, and dynamic conditions, i.e. moving sources. The spatial sound scenes are created using real room impulse responses captured in a continuous manner with a slowly moving excitation source. Both static and moving sound events are synthesized from them. Ambient noise recorded on location is added to complete the generation of scene recordings. A baseline SELD method accompanies the dataset, based on a convolutional recurrent neural network, to provide benchmark scores for the task. The baseline is an updated version of the one used in the previous challenge, with input features and training modifications to improve its performance."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Ronchini2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Ronchini2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SOUND EVENT LOCALIZATION AND DETECTION BASED ON CRNN USING DENSE RECTANGULAR FILTERS AND CHANNEL ROTATION DATA AUGMENTATION
       </h4>
<p style="text-align:left">
        Francesca Ronchini<sup>1</sup>, AndrÃ©s PÃ©rez LÃ³pez<sup>1</sup>, Daniel Arteaga<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Pompeu Fabra University
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Ronchini_UPF_task3_3</span>, <span class="label label-primary">Ronchini_UPF_task3_4</span>, <span class="label label-primary">Ronchini_UPF_task3_2</span>, <span class="label label-primary">Ronchini_UPF_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Ronchini2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Ronchini2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Ronchini2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Ronchini_82.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Ronchini2020_task3_report').collapse('show');window.location.hash='#Ronchini2020_task3_report';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Ronchini2020_task3_report" class="panel-collapse collapse" id="collapse-Ronchini2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SOUND EVENT LOCALIZATION AND DETECTION BASED ON CRNN USING DENSE RECTANGULAR FILTERS AND CHANNEL ROTATION DATA AUGMENTATION
      </h4>
<p style="text-align:left">
<small>
        Francesca Ronchini<sup>1</sup>, AndrÃ©s PÃ©rez LÃ³pez<sup>1</sup>, Daniel Arteaga<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Pompeu Fabra University
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report illustrates the system submitted to the DCASE 2020 Challenge Task 3: Sound Event Localization and Detection. The algorithm consists of a CRNN using dense rectangular filters specialized to recognize significant frequency features related to the task. In order to further improve the score and to generalize the system performance to unseen data, the training dataset size has been increased using data augmentation based on channel rotations and reflection on the xy plane in the First Order Ambisonic domain, which allow to improve Direction of Arrival labels keeping the physical relationships between channels. Evaluation results on the cross-validation development dataset show that the proposed system outperforms the baseline results, considerably improving Error Rate and F-score for location-aware detection.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Ronchini2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Ronchini_82.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/RonFrancesca/dcase2020-fp" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="">
<i class="fa fa-file-code-o">
</i>
</a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Ronchini2020_task3_reportlabel" class="modal fade" id="bibtex-Ronchini2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexRonchini2020_task3_reportlabel">
        SOUND EVENT LOCALIZATION AND DETECTION BASED ON CRNN USING DENSE RECTANGULAR FILTERS AND CHANNEL ROTATION DATA AUGMENTATION
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Ronchini2020_task3_report,
    Author = "Ronchini, Francesca and LÃ³pez, AndrÃ©s PÃ©rez and Arteaga, Daniel",
    title = "SOUND EVENT LOCALIZATION AND DETECTION BASED ON CRNN USING DENSE RECTANGULAR FILTERS AND CHANNEL ROTATION DATA AUGMENTATION",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "This technical report illustrates the system submitted to the DCASE 2020 Challenge Task 3: Sound Event Localization and Detection. The algorithm consists of a CRNN using dense rectangular filters specialized to recognize significant frequency features related to the task. In order to further improve the score and to generalize the system performance to unseen data, the training dataset size has been increased using data augmentation based on channel rotations and reflection on the xy plane in the First Order Ambisonic domain, which allow to improve Direction of Arrival labels keeping the physical relationships between channels. Evaluation results on the cross-validation development dataset show that the proposed system outperforms the baseline results, considerably improving Error Rate and F-score for location-aware detection."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Sampathkumar2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Sampathkumar2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SOUND EVENT DETECTION AND LOCALIZATION USING CRNN MODELS
       </h4>
<p style="text-align:left">
        Arunodhayan Sampathkumar<sup>1</sup>, Danny Kowerko<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Techniche UniversitÃ¤t Chemnitz
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Sampathkumar_TUC_task3_1</span>, <span class="label label-primary">Sampathkumar_TUC_task3_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Sampathkumar2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Sampathkumar2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Sampathkumar2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Sampathkumar_41.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Sampathkumar2020_task3_report" class="panel-collapse collapse" id="collapse-Sampathkumar2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SOUND EVENT DETECTION AND LOCALIZATION USING CRNN MODELS
      </h4>
<p style="text-align:left">
<small>
        Arunodhayan Sampathkumar<sup>1</sup>, Danny Kowerko<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Techniche UniversitÃ¤t Chemnitz
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Sound Event Localization and Detection (SELD) requires both spatial and temporal information of sound events that appears in an acoustic event. The sound event localization and detection DCASE2020 task3 developed a strongly labelled dataset consisting of 14 classes. In this research work the existing method from DCASE2019 is used with significant modifications, where this method utilizes logmel features for sound event detection, and uses intensity vector and generalized cross-correlation (GCC) GCC-PHAT features for sound source localization. The Convolutional Recurrent Neural Network (CRNN) is developed that jointly predicts the Sound Event Detection (SED) and Degree of Arrival (DOA) hence minimizing the overlapping problems. The developed model significantly outperformed the baseline system.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Sampathkumar2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Sampathkumar_41.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Sampathkumar2020_task3_reportlabel" class="modal fade" id="bibtex-Sampathkumar2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSampathkumar2020_task3_reportlabel">
        SOUND EVENT DETECTION AND LOCALIZATION USING CRNN MODELS
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Sampathkumar2020_task3_report,
    Author = "Sampathkumar, Arunodhayan and Kowerko, Danny",
    title = "SOUND EVENT DETECTION AND LOCALIZATION USING CRNN MODELS",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "Sound Event Localization and Detection (SELD) requires both spatial and temporal information of sound events that appears in an acoustic event. The sound event localization and detection DCASE2020 task3 developed a strongly labelled dataset consisting of 14 classes. In this research work the existing method from DCASE2019 is used with significant modifications, where this method utilizes logmel features for sound event detection, and uses intensity vector and generalized cross-correlation (GCC) GCC-PHAT features for sound source localization. The Convolutional Recurrent Neural Network (CRNN) is developed that jointly predicts the Sound Event Detection (SED) and Degree of Arrival (DOA) hence minimizing the overlapping problems. The developed model significantly outperformed the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Shimada2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Shimada2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        SOUND EVENT LOCALIZATION AND DETECTION USING ACTIVITY-COUPLED CARTESIAN DOA VECTOR AND RD3NET
       </h4>
<p style="text-align:left">
        Kazuki Shimada<sup>1</sup>, Naoya Takahashi<sup>1</sup>, Shusuke Takahashi<sup>1</sup>, Yuki Mitsufuji<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>SONY Corporation
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Shimada_SONY_task3_1</span>, <span class="label label-primary">Shimada_SONY_task3_2</span>, <span class="label label-primary">Shimada_SONY_task3_3</span>, <span class="label label-primary">Shimada_SONY_task3_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Shimada2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Shimada2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Shimada2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Shimada_139.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Shimada2020_task3_report" class="panel-collapse collapse" id="collapse-Shimada2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       SOUND EVENT LOCALIZATION AND DETECTION USING ACTIVITY-COUPLED CARTESIAN DOA VECTOR AND RD3NET
      </h4>
<p style="text-align:left">
<small>
        Kazuki Shimada<sup>1</sup>, Naoya Takahashi<sup>1</sup>, Shusuke Takahashi<sup>1</sup>, Yuki Mitsufuji<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>SONY Corporation
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Our systems submitted to the DCASE2020 task 3: Sound Event Localization and Detection (SELD) are described in this report. We consider two systems: a single-stage system that solve sound event localization (SEL) and sound event detection (SED) simultaneously, and a two-stage system that first handles the SED and SEL tasks individually and later combines those results. As the single-stage system, we propose a unified training framework that uses an activity-coupled Cartesian DOA vector (ACCDOA) representation as a single target for both the SED and SEL tasks. To efficiently estimate sound event locations and activities, we further propose RD3Net, which incorporates recurrent and convolution layers with dense skip connections and dilation. To generalize the models, we apply three data augmentation techniques: equalized mixture data augmentation (EMDA), rotation of first-order Ambisonic (FOA) singals, and multichannel extension of SpecAugment. Our systems demonstrate a significant improvement over the baseline system.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Shimada2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Shimada_139.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Shimada2020_task3_reportlabel" class="modal fade" id="bibtex-Shimada2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexShimada2020_task3_reportlabel">
        SOUND EVENT LOCALIZATION AND DETECTION USING ACTIVITY-COUPLED CARTESIAN DOA VECTOR AND RD3NET
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Shimada2020_task3_report,
    Author = "Shimada, Kazuki and Takahashi, Naoya and Takahashi, Shusuke and Mitsufuji, Yuki",
    title = "SOUND EVENT LOCALIZATION AND DETECTION USING ACTIVITY-COUPLED CARTESIAN DOA VECTOR AND RD3NET",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "Our systems submitted to the DCASE2020 task 3: Sound Event Localization and Detection (SELD) are described in this report. We consider two systems: a single-stage system that solve sound event localization (SEL) and sound event detection (SED) simultaneously, and a two-stage system that first handles the SED and SEL tasks individually and later combines those results. As the single-stage system, we propose a unified training framework that uses an activity-coupled Cartesian DOA vector (ACCDOA) representation as a single target for both the SED and SEL tasks. To efficiently estimate sound event locations and activities, we further propose RD3Net, which incorporates recurrent and convolution layers with dense skip connections and dilation. To generalize the models, we apply three data augmentation techniques: equalized mixture data augmentation (EMDA), rotation of first-order Ambisonic (FOA) singals, and multichannel extension of SpecAugment. Our systems demonstrate a significant improvement over the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Singla2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Singla2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        A SEQUENTIAL SYSTEM FOR SOUND EVENT DETECTION AND LOCALIZATION USING CRNN
       </h4>
<p style="text-align:left">
        Rohit Singla<sup>1</sup>, Sourabh Tiwari<sup>1</sup>, Rajat Sharma<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Samsung Research Institute Bangalore
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Singla_SRIB_task3_3</span>, <span class="label label-primary">Singla_SRIB_task3_2</span>, <span class="label label-primary">Singla_SRIB_task3_1</span>, <span class="label label-primary">Singla_SRIB_task3_4</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Singla2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Singla2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Singla2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Singla_56.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Singla2020_task3_report" class="panel-collapse collapse" id="collapse-Singla2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       A SEQUENTIAL SYSTEM FOR SOUND EVENT DETECTION AND LOCALIZATION USING CRNN
      </h4>
<p style="text-align:left">
<small>
        Rohit Singla<sup>1</sup>, Sourabh Tiwari<sup>1</sup>, Rajat Sharma<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Samsung Research Institute Bangalore
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our method for DCASE2020 task 3: Sound Event Localization and Detection. We use a CRNN SELDnet-like single output models which run on the features extracted from audio files using log-mel spectrogram. Our model uses CNN layers followed by RNN layers followed by predicting sound event classes: Sound Event Detection (SED) and then giving the output of SED to estimate Direction Of Arrival (DOA) for those sound events and then the final output is given as a concatenation of SED and DOA. The proposed approach is evaluated on the development set of TAU Spatial Sound Events 2020 â€“ First-Order Ambisonics (FOA).
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Singla2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Singla_56.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Singla2020_task3_reportlabel" class="modal fade" id="bibtex-Singla2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSingla2020_task3_reportlabel">
        A SEQUENTIAL SYSTEM FOR SOUND EVENT DETECTION AND LOCALIZATION USING CRNN
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Singla2020_task3_report,
    Author = "Singla, Rohit and Tiwari, Sourabh and Sharma, Rajat",
    title = "A SEQUENTIAL SYSTEM FOR SOUND EVENT DETECTION AND LOCALIZATION USING CRNN",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "In this technical report, we describe our method for DCASE2020 task 3: Sound Event Localization and Detection. We use a CRNN SELDnet-like single output models which run on the features extracted from audio files using log-mel spectrogram. Our model uses CNN layers followed by RNN layers followed by predicting sound event classes: Sound Event Detection (SED) and then giving the output of SED to estimate Direction Of Arrival (DOA) for those sound events and then the final output is given as a concatenation of SED and DOA. The proposed approach is evaluated on the development set of TAU Spatial Sound Events 2020 â€“ First-Order Ambisonics (FOA)."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Song2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Song2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        LOCALIZATION AND DETECTION FOR MOVING SOUND SOURCES USING CONSECUTIVE ENSEMBLE OF 2D-CRNN
       </h4>
<p style="text-align:left">
        Ju-man Song<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>LG Electronics
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Song_LGE_task3_4</span>, <span class="label label-primary">Song_LGE_task3_2</span>, <span class="label label-primary">Song_LGE_task3_1</span>, <span class="label label-primary">Song_LGE_task3_3</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Song2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Song2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Song2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Song_61.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Song2020_task3_report" class="panel-collapse collapse" id="collapse-Song2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       LOCALIZATION AND DETECTION FOR MOVING SOUND SOURCES USING CONSECUTIVE ENSEMBLE OF 2D-CRNN
      </h4>
<p style="text-align:left">
<small>
        Ju-man Song<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>LG Electronics
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report introduces a deep learning strategy for sound event localization and detection in DCASE 2020 Task 3. This strategy is designed to get accurate estimation of both detecting and localizing moving sound events by splitting a task into five sub-tasks. Each subtask estimates the number of existing sound sources, the number of sound directions, single sound direction, multiple sound directions, and category of events. Thus, each two dimensional convolutional recurrent neural network (2D-CRNN) is focused on each sub-task. In this way, we could improve its robustness to complex conditions. Finally, the consecutive ensemble strategy is performed to achieve high performance with some decision logic. With the proposed strategy, we could get optimal network models for each sub-task. The proposed strategy is evaluated on the development set of TAU-NIGENS Spatial Sound Events 2020, and shows notable improvements.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Song2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Song_61.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Song2020_task3_reportlabel" class="modal fade" id="bibtex-Song2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSong2020_task3_reportlabel">
        LOCALIZATION AND DETECTION FOR MOVING SOUND SOURCES USING CONSECUTIVE ENSEMBLE OF 2D-CRNN
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Song2020_task3_report,
    Author = "Song, Ju-man",
    title = "LOCALIZATION AND DETECTION FOR MOVING SOUND SOURCES USING CONSECUTIVE ENSEMBLE OF 2D-CRNN",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "July",
    abstract = "This technical report introduces a deep learning strategy for sound event localization and detection in DCASE 2020 Task 3. This strategy is designed to get accurate estimation of both detecting and localizing moving sound events by splitting a task into five sub-tasks. Each subtask estimates the number of existing sound sources, the number of sound directions, single sound direction, multiple sound directions, and category of events. Thus, each two dimensional convolutional recurrent neural network (2D-CRNN) is focused on each sub-task. In this way, we could improve its robustness to complex conditions. Finally, the consecutive ensemble strategy is performed to achieve high performance with some decision logic. With the proposed strategy, we could get optimal network models for each sub-task. The proposed strategy is evaluated on the development set of TAU-NIGENS Spatial Sound Events 2020, and shows notable improvements."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Tian2020_task3_report" style="box-shadow: none">
<div class="panel-heading" id="heading-Tian2020_task3_report" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        MULTIPLE CRNN FOR SELD
       </h4>
<p style="text-align:left">
        Congzhou Tian<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Peking University
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Tian_PKU_task3_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Tian2020_task3_report" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Tian2020_task3_report" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Tian2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Tian_72.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Tian2020_task3_report" class="panel-collapse collapse" id="collapse-Tian2020_task3_report" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       MULTIPLE CRNN FOR SELD
      </h4>
<p style="text-align:left">
<small>
        Congzhou Tian<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Peking University
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this task, we use multiple CRNN for SELD. Firstly, there is a CRNN to predict the number of sound events at the same time. A SED CRNN is used to predict the current sound events given the activated number result. After that, we train a DOA1 CRNN specifically for frames with single active event and a total DOA CRNN for frames with more active events. We think training with separate network is helpful for both SED and DOA tasks and our results are proved better than the baseline method on the development dataset.
      </p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Tian2020_task3_report" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2020/technical_reports/DCASE2020_Tian_72.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Tian2020_task3_reportlabel" class="modal fade" id="bibtex-Tian2020_task3_report" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         Ã—
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexTian2020_task3_reportlabel">
        MULTIPLE CRNN FOR SELD
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Tian2020_task3_report,
    Author = "Tian, Congzhou",
    title = "MULTIPLE CRNN FOR SELD",
    institution = "DCASE2020 Challenge",
    year = "2020",
    month = "June",
    abstract = "In this task, we use multiple CRNN for SELD. Firstly, there is a CRNN to predict the number of sound events at the same time. A SED CRNN is used to predict the current sound events given the activated number result. After that, we train a DOA1 CRNN specifically for frames with single active event and a total DOA CRNN for frames with more active events. We think training with separate network is helpful for both SED and DOA tasks and our results are proved better than the baseline method on the development dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
$(document).ready(function() {
var hash = window.location.hash.substr(1);
var anchor = window.location.hash;

var shiftWindow = function() {
var hash = window.location.hash.substr(1);
if($('#collapse-'+hash).length){
scrollBy(0, -100);
}
};
window.addEventListener("hashchange", shiftWindow);

if (window.location.hash){
window.scrollTo(0, 0);
history.replaceState(null, document.title, "#");
$('#collapse-'+hash).collapse('show');
setTimeout(function(){
window.location.hash = anchor;
shiftWindow();
}, 2000);
}
});
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>