<!DOCTYPE html><html lang="en">
<head>
    <title>Foley Sound Synthesis - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2023/task-foley-sound-synthesis-results">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description This task aims to build a foley sound synthesis system that can generate plausible audio signals fitting into given categories of foley sound. The foley sound categories are composed of sound events and environmental background sounds. The challenge has two subproblems – the development of models with and without …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2023</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2023/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-low-complexity-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-localization-and-detection-evaluated-in-real-spatial-sound-scenes-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-sound-event-detection-with-weak-and-soft-labels" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-and-soft-labels"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Introduction</a>
    </li>
            <li class=" dropdown-header ">
        <strong>A: Sound Event Detection with Weak Labels and Synthetic Soundscapes</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-labels-and-synthetic-soundscapes"><i class="fa fa-random fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-weak-labels-and-synthetic-soundscapes-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
            <li class=" dropdown-header ">
        <strong>B: Sound Event Detection with Soft Labels</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-soft-labels"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-sound-event-detection-with-soft-labels-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval"><i class="fa fa-info-circle fa-fw"></i>&nbsp;Introduction</a>
    </li>
            <li class=" dropdown-header ">
        <strong>A: Automated Audio-Captioning</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning"><i class="fa dc-captioning fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-automated-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
            <li class=" dropdown-header ">
        <strong>B: Language-Based Audio Retrieval</strong>
    </li>
            <li class="">
        <a href="/challenge2023/task-language-based-audio-retrieval"><i class="fa fa-file-text fa-fw"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2023/task-language-based-audio-retrieval-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2023/task-foley-sound-synthesis" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthesis text-task2"></i>&nbsp;Task7&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2023/task-foley-sound-synthesis"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2023/task-foley-sound-synthesis-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2023/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2023/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/wave-02.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-task2"></i><i class="fa dc-synthesis fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Synthesis</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 7</span></span><img src="../images/logos/dcase/dcase2023_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Foley Sound Synthesis</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a>
<ul>
<li><a href="#track-a">Track A</a></li>
<li><a href="#track-b">Track B</a></li>
</ul>
</li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#track-a-1">Track A</a></li>
<li><a href="#track-b-1">Track B</a></li>
</ul>
</li>
<li><a href="#wav-files-used-for-evaluation-experiment">Wav files used for evaluation experiment</a></li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>This task aims to build a foley sound synthesis system that can generate plausible audio signals fitting into given categories of foley sound. The foley sound categories are composed of sound events and environmental background sounds. The challenge has two subproblems – the development of models with and without external resources. Participants are expected to submit a system for one of the two problems, and each problem is evaluated independently. Submissions will be evaluated by Frechet Audio Distance (FAD), followed by a subjective test.</p>
<h1 id="systems-ranking">Systems ranking</h1>
<h2 id="track-a">Track A</h2>
<p><strong>A big THANK YOU to the DCASE community members and the contestants who spent several hours rating other teams' anonymized sounds for the perceptual evaluation stage (see column '# Categories Rated by Team Members' in the FAD table). </strong></p>
<h3>Perceptual Evaluation Score</h3>
<p>The weighted average of the three ratings were based on a ratio of <strong>audio quality : category fit : diversity</strong> that was  <strong>2:2:1</strong>.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="scatter,comparison" data-comparison-a-row="DCASE2023_baseline_task7" data-comparison-active-set="Weighted Average Score" data-comparison-b-row="Yi_SURREY_task7_trackA_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
       {"title": "Weighted Average Score", "data_axis_title": "Score", "fields": ["weighted_average_DogBark", "weighted_average_Footstep", "weighted_average_GunShot", "weighted_average_Keyboard", "weighted_average_MovingMotorVehicle", "weighted_average_Rain", "weighted_average_Sneeze_Cough"]
       },
       {"title": "Audio Quality Score", "data_axis_title": "Score", "fields": ["audio_quality_DogBark", "audio_quality_Footstep", "audio_quality_GunShot", "audio_quality_Keyboard", "audio_quality_MovingMotorVehicle", "audio_quality_Rain", "audio_quality_Sneeze_Cough"]
       },
       {"title": "Category Fit Score", "data_axis_title": "Score", "fields": ["category_fit_DogBark", "category_fit_Footstep", "category_fit_GunShot", "category_fit_Keyboard", "category_fit_MovingMotorVehicle", "category_fit_Rain", "category_fit_Sneeze_Cough"]
       },
       {"title": "Diversity Score", "data_axis_title": "Score", "fields": ["diversity_DogBark", "diversity_Footstep", "diversity_GunShot", "diversity_Keyboard", "diversity_MovingMotorVehicle", "diversity_Rain", "diversity_Sneeze_Cough"]
       }]' data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="FAD_eval_DogBark" data-scatter-y="FAD_eval_Footstep" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackA" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="2">Submission Information</th>
<th class="sep-left-cell" colspan="9">Weighted Average Score of Audio Quality, Category Fit, and Diversity</th>
<th class="sep-left-cell" colspan="8">Audio Quality (MOS score w/ 10 steps)</th>
<th class="sep-left-cell" colspan="8">Category Fit (MOS score w/ 10 steps)</th>
<th class="sep-left-cell" colspan="8">Diversity (MOS score w/ 10 steps, weighted 0.5)</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Submission Code
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="system_rank_trackA" data-sortable="true" data-value-type="int">
                Official<br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="weighted_average_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="audio_quality_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="audio_quality_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="category_fit_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="category_fit_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="diversity_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="diversity_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td>6</td>
<td>3.810</td>
<td>2.688</td>
<td>4.160</td>
<td>3.237</td>
<td>5.150</td>
<td>3.862</td>
<td>4.175</td>
<td>3.400</td>
<td>3.831</td>
<td>2.930</td>
<td>4.158</td>
<td>3.504</td>
<td>5.137</td>
<td>3.543</td>
<td>4.115</td>
<td>3.432</td>
<td>3.789</td>
<td>2.447</td>
<td>4.162</td>
<td>2.969</td>
<td>5.163</td>
<td>4.182</td>
<td>4.235</td>
<td>3.368</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Chon_Gaudio_task7_trackA_1</td>
<td>ChonGLI2023</td>
<td>2</td>
<td>6.967</td>
<td>7.984</td>
<td>6.865</td>
<td>7.255</td>
<td>6.989</td>
<td>6.881</td>
<td>6.243</td>
<td>6.553</td>
<td>6.657</td>
<td>7.612</td>
<td>6.455</td>
<td>6.814</td>
<td>6.814</td>
<td>6.446</td>
<td>5.928</td>
<td>6.528</td>
<td>7.154</td>
<td>8.223</td>
<td>7.082</td>
<td>7.573</td>
<td>7.157</td>
<td>7.131</td>
<td>6.306</td>
<td>6.606</td>
<td>7.214</td>
<td>8.250</td>
<td>7.250</td>
<td>7.500</td>
<td>7.000</td>
<td>7.250</td>
<td>6.750</td>
<td>6.500</td>
</tr>
<tr>
<td></td>
<td>Yi_SURREY_task7_trackA_1</td>
<td>YiSURREY2023</td>
<td>1</td>
<td>7.056</td>
<td>7.742</td>
<td>6.466</td>
<td>6.189</td>
<td>7.433</td>
<td>7.448</td>
<td>6.441</td>
<td>7.675</td>
<td>6.723</td>
<td>7.309</td>
<td>6.143</td>
<td>5.532</td>
<td>7.243</td>
<td>7.315</td>
<td>6.067</td>
<td>7.454</td>
<td>7.578</td>
<td>8.297</td>
<td>6.646</td>
<td>6.689</td>
<td>8.089</td>
<td>8.181</td>
<td>6.911</td>
<td>8.233</td>
<td>6.679</td>
<td>7.500</td>
<td>6.750</td>
<td>6.500</td>
<td>6.500</td>
<td>6.250</td>
<td>6.250</td>
<td>7.000</td>
</tr>
<tr>
<td></td>
<td>Guan_HEU_task7_trackA_2</td>
<td>GuanHEU2023</td>
<td>4</td>
<td>5.157</td>
<td>4.877</td>
<td>4.450</td>
<td>6.413</td>
<td>5.479</td>
<td>5.822</td>
<td>5.201</td>
<td>3.856</td>
<td>4.670</td>
<td>3.800</td>
<td>4.164</td>
<td>5.800</td>
<td>5.339</td>
<td>5.365</td>
<td>4.972</td>
<td>3.250</td>
<td>5.293</td>
<td>5.142</td>
<td>3.836</td>
<td>7.482</td>
<td>5.232</td>
<td>6.315</td>
<td>5.656</td>
<td>3.389</td>
<td>5.857</td>
<td>6.500</td>
<td>6.250</td>
<td>5.500</td>
<td>6.250</td>
<td>5.750</td>
<td>4.750</td>
<td>6.000</td>
</tr>
<tr>
<td></td>
<td>Scheibler_LINE_task7_trackA_1</td>
<td>ScheiblerLINE2023</td>
<td>3</td>
<td>6.887</td>
<td>7.333</td>
<td>6.832</td>
<td>7.317</td>
<td>7.199</td>
<td>6.474</td>
<td>5.222</td>
<td>7.834</td>
<td>6.355</td>
<td>6.479</td>
<td>6.263</td>
<td>6.771</td>
<td>6.886</td>
<td>6.131</td>
<td>4.780</td>
<td>7.180</td>
<td>7.327</td>
<td>7.479</td>
<td>7.192</td>
<td>7.896</td>
<td>7.861</td>
<td>7.054</td>
<td>5.150</td>
<td>8.655</td>
<td>7.071</td>
<td>8.750</td>
<td>7.250</td>
<td>7.250</td>
<td>6.500</td>
<td>6.000</td>
<td>6.250</td>
<td>7.500</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h3>FAD Score</h3>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="scatter,comparison" data-comparison-a-row="DCASE2023_baseline_task7" data-comparison-active-set="FAD (eval)" data-comparison-b-row="Yi_SURREY_task7_trackA_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
       {"title": "FAD (eval)", "data_axis_title": "FAD", "fields": ["FAD_eval_DogBark", "FAD_eval_Footstep", "FAD_eval_GunShot", "FAD_eval_Keyboard", "FAD_eval_MovingMotorVehicle", "FAD_eval_Rain", "FAD_eval_Sneeze_Cough"]
       },
       {"title": "FAD (dev)", "data_axis_title": "FAD", "fields": ["FAD_dev_DogBark", "FAD_dev_Footstep", "FAD_dev_GunShot", "FAD_dev_Keyboard", "FAD_dev_MovingMotorVehicle", "FAD_dev_Rain", "FAD_dev_Sneeze_Cough"]
       }]' data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="FAD_eval_DogBark" data-scatter-y="FAD_eval_Footstep" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackA" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="3">Submission Information</th>
<th class="sep-left-cell" colspan="10">Evaluation Dataset</th>
<th class="sep-left-cell" colspan="8">Development Dataset</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Submission Code
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="text-center" data-field="evaluation_participant" data-sortable="false" data-value-type="int">
                # Categories Rated by <br/>Team Members
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="system_rank_trackA" data-sortable="true" data-value-type="int">
                Official<br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_rank_trackA" data-sortable="true" data-value-type="int">
                FAD<br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_average" data-sortable="true" data-value-type="float3">
                Average<br/>FAD
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_eval_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Footstep" data-sortable="true" data-value-type="float3">
                Footstep<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle (FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Rain" data-sortable="true" data-value-type="float3">
                Rain<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough<br/>(FAD)
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_dev_average" data-sortable="true" data-value-type="float3">
                Average<br/>FAD
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_dev_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Footstep" data-sortable="true" data-value-type="float3">
                Footstep<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle (FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Rain" data-sortable="true" data-value-type="float3">
                Rain<br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough<br/>(FAD)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td></td>
<td>6</td>
<td>6</td>
<td>9.702</td>
<td>13.412</td>
<td>8.108</td>
<td>7.952</td>
<td>5.230</td>
<td>16.107</td>
<td>13.338</td>
<td>3.771</td>
<td>8.701</td>
<td>13.614</td>
<td>6.826</td>
<td>6.152</td>
<td>5.065</td>
<td>11.239</td>
<td>14.449</td>
<td>3.563</td>
</tr>
<tr>
<td></td>
<td>Chon_Gaudio_task7_trackA_1</td>
<td>ChonGLI2023</td>
<td>7</td>
<td>2</td>
<td>3</td>
<td>5.540</td>
<td>11.456</td>
<td>5.959</td>
<td>3.021</td>
<td>4.090</td>
<td>6.173</td>
<td>5.738</td>
<td>2.340</td>
<td>5.522</td>
<td>11.464</td>
<td>4.575</td>
<td>3.782</td>
<td>6.190</td>
<td>5.814</td>
<td>4.746</td>
<td>2.083</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackA_1</td>
<td>Leemaum2023</td>
<td>4</td>
<td>9</td>
<td>9</td>
<td>12.937</td>
<td>9.265</td>
<td>6.924</td>
<td>10.451</td>
<td>6.488</td>
<td>37.748</td>
<td>7.778</td>
<td>11.903</td>
<td>11.331</td>
<td>9.716</td>
<td>4.858</td>
<td>8.672</td>
<td>5.227</td>
<td>29.206</td>
<td>10.450</td>
<td>11.187</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackA_2</td>
<td>Leemaum2023</td>
<td>4</td>
<td>10</td>
<td>10</td>
<td>12.946</td>
<td>10.549</td>
<td>7.747</td>
<td>7.643</td>
<td>9.922</td>
<td>38.558</td>
<td>6.585</td>
<td>9.620</td>
<td>10.900</td>
<td>10.854</td>
<td>5.751</td>
<td>5.588</td>
<td>7.413</td>
<td>29.562</td>
<td>8.140</td>
<td>8.992</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackA_3</td>
<td>Leemaum2023</td>
<td>4</td>
<td>8</td>
<td>8</td>
<td>12.429</td>
<td>11.719</td>
<td>6.903</td>
<td>7.287</td>
<td>9.292</td>
<td>35.209</td>
<td>6.787</td>
<td>9.804</td>
<td>10.586</td>
<td>12.056</td>
<td>5.742</td>
<td>5.420</td>
<td>7.242</td>
<td>26.474</td>
<td>8.043</td>
<td>9.126</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackA_4</td>
<td>Leemaum2023</td>
<td>4</td>
<td>7</td>
<td>7</td>
<td>9.883</td>
<td>9.287</td>
<td>6.910</td>
<td>7.881</td>
<td>6.603</td>
<td>22.310</td>
<td>6.750</td>
<td>9.436</td>
<td>8.964</td>
<td>9.700</td>
<td>5.566</td>
<td>6.037</td>
<td>5.370</td>
<td>19.305</td>
<td>7.946</td>
<td>8.827</td>
</tr>
<tr>
<td></td>
<td>Yi_SURREY_task7_trackA_1</td>
<td>YiSURREY2023</td>
<td>7</td>
<td>1</td>
<td>2</td>
<td>5.025</td>
<td>3.621</td>
<td>5.104</td>
<td>5.748</td>
<td>3.038</td>
<td>9.801</td>
<td>5.964</td>
<td>1.901</td>
<td>4.051</td>
<td>3.355</td>
<td>3.434</td>
<td>5.796</td>
<td>3.483</td>
<td>4.674</td>
<td>5.994</td>
<td>1.621</td>
</tr>
<tr>
<td></td>
<td>Guan_HEU_task7_trackA_1</td>
<td>GuanHEU2023</td>
<td>7</td>
<td>5</td>
<td>5</td>
<td>8.623</td>
<td>5.583</td>
<td>10.143</td>
<td>8.428</td>
<td>5.403</td>
<td>17.984</td>
<td>7.561</td>
<td>5.258</td>
<td>7.941</td>
<td>5.893</td>
<td>9.118</td>
<td>7.485</td>
<td>7.706</td>
<td>12.818</td>
<td>7.874</td>
<td>4.692</td>
</tr>
<tr>
<td></td>
<td>Guan_HEU_task7_trackA_2</td>
<td>GuanHEU2023</td>
<td>7</td>
<td>4</td>
<td>4</td>
<td>7.799</td>
<td>5.685</td>
<td>7.685</td>
<td>8.532</td>
<td>4.165</td>
<td>17.258</td>
<td>7.795</td>
<td>3.475</td>
<td>7.015</td>
<td>6.020</td>
<td>7.297</td>
<td>7.628</td>
<td>4.049</td>
<td>12.216</td>
<td>8.446</td>
<td>3.452</td>
</tr>
<tr>
<td></td>
<td>Scheibler_LINE_task7_trackA_1</td>
<td>ScheiblerLINE2023</td>
<td>6</td>
<td>3</td>
<td>1</td>
<td>4.777</td>
<td>3.679</td>
<td>8.073</td>
<td>3.655</td>
<td>2.775</td>
<td>7.422</td>
<td>5.225</td>
<td>2.609</td>
<td>4.156</td>
<td>3.726</td>
<td>5.713</td>
<td>3.226</td>
<td>3.415</td>
<td>5.453</td>
<td>5.308</td>
<td>2.253</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="track-b">Track B</h2>
<p><strong>A big THANK YOU to the DCASE community members and the contestants who spent several hours rating other teams' anonymized sounds for the perceptual evaluation stage (see column '# Categories Rated by Team Members' in the FAD table). </strong></p>
<h3>Perceptual Evaluation Score</h3>
<p>In the case that multiple systems were submitted by one team, only the system with the highest FAD score per team was perceptually evaluated. The weighted average of the three ratings were based on a ratio of <strong>audio quality : category fit : diversity</strong> that was  <strong>2:2:1</strong>.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="scatter,comparison" data-comparison-a-row="DCASE2023_baseline_task7" data-comparison-active-set="Weighted Average Score" data-comparison-b-row="Chang_HYU_task7_trackB_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
       {"title": "Weighted Average Score", "data_axis_title": "Score", "fields": ["weighted_average_DogBark", "weighted_average_Footstep", "weighted_average_GunShot", "weighted_average_Keyboard", "weighted_average_MovingMotorVehicle", "weighted_average_Rain", "weighted_average_Sneeze_Cough"]
       },
       {"title": "Audio Quality Score", "data_axis_title": "Score", "fields": ["audio_quality_DogBark", "audio_quality_Footstep", "audio_quality_GunShot", "audio_quality_Keyboard", "audio_quality_MovingMotorVehicle", "audio_quality_Rain", "audio_quality_Sneeze_Cough"]
       },
       {"title": "Category Fit Score", "data_axis_title": "Score", "fields": ["category_fit_DogBark", "category_fit_Footstep", "category_fit_GunShot", "category_fit_Keyboard", "category_fit_MovingMotorVehicle", "category_fit_Rain", "category_fit_Sneeze_Cough"]
       },
       {"title": "Diversity Score", "data_axis_title": "Score", "fields": ["diversity_DogBark", "diversity_Footstep", "diversity_GunShot", "diversity_Keyboard", "diversity_MovingMotorVehicle", "diversity_Rain", "diversity_Sneeze_Cough"]
       }]' data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="FAD_eval_DogBark" data-scatter-y="FAD_eval_Footstep" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackB" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="2">Submission Information</th>
<th class="sep-left-cell" colspan="9">Weighted Average Score of Audio Quality, Category Fit, and Diversity</th>
<th class="sep-left-cell" colspan="8">Audio Quality (MOS score w/ 10 steps)</th>
<th class="sep-left-cell" colspan="8">Category Fit (MOS score w/ 10 steps)</th>
<th class="sep-left-cell" colspan="8">Diversity (MOS score w/ 10 steps, weighted 0.5)</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Submission Code
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="system_rank_trackB" data-sortable="true" data-value-type="int">
                Official<br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="weighted_average_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="weighted_average_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="audio_quality_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="audio_quality_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="audio_quality_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="category_fit_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="category_fit_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="category_fit_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="diversity_average" data-sortable="true" data-value-type="float3">
                Average Score
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="diversity_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Footstep" data-sortable="true" data-value-type="float3">
                Footstep
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor<br/>Vehicle
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Rain" data-sortable="true" data-value-type="float3">
                Rain
            </th>
<th class="text-center" data-chartable="true" data-field="diversity_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td>18</td>
<td>3.810</td>
<td>2.688</td>
<td>4.160</td>
<td>3.237</td>
<td>5.150</td>
<td>3.862</td>
<td>4.175</td>
<td>3.400</td>
<td>3.831</td>
<td>2.930</td>
<td>4.158</td>
<td>3.504</td>
<td>5.137</td>
<td>3.543</td>
<td>4.115</td>
<td>3.432</td>
<td>3.789</td>
<td>2.447</td>
<td>4.162</td>
<td>2.969</td>
<td>5.163</td>
<td>4.182</td>
<td>4.235</td>
<td>3.368</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kamath_NUS_task7_trackB_2</td>
<td>KamathNUS2023</td>
<td>3</td>
<td>4.647</td>
<td>4.807</td>
<td>4.073</td>
<td>5.010</td>
<td>4.276</td>
<td>5.248</td>
<td>4.013</td>
<td>5.102</td>
<td>3.988</td>
<td>3.789</td>
<td>3.554</td>
<td>4.346</td>
<td>3.911</td>
<td>4.642</td>
<td>3.378</td>
<td>4.295</td>
<td>4.612</td>
<td>4.979</td>
<td>3.629</td>
<td>5.054</td>
<td>4.029</td>
<td>5.727</td>
<td>3.406</td>
<td>5.459</td>
<td>6.036</td>
<td>6.500</td>
<td>6.000</td>
<td>6.250</td>
<td>5.500</td>
<td>5.500</td>
<td>6.500</td>
<td>6.000</td>
</tr>
<tr>
<td></td>
<td>Chang_HYU_task7_trackB_1</td>
<td>ChangHYU2023</td>
<td>1</td>
<td>6.515</td>
<td>5.659</td>
<td>7.111</td>
<td>6.557</td>
<td>7.384</td>
<td>6.155</td>
<td>7.042</td>
<td>5.699</td>
<td>6.085</td>
<td>4.882</td>
<td>6.738</td>
<td>5.879</td>
<td>7.296</td>
<td>6.069</td>
<td>6.860</td>
<td>4.873</td>
<td>6.845</td>
<td>6.014</td>
<td>7.288</td>
<td>7.013</td>
<td>7.789</td>
<td>6.442</td>
<td>7.370</td>
<td>6.000</td>
<td>6.714</td>
<td>6.500</td>
<td>7.500</td>
<td>7.000</td>
<td>6.750</td>
<td>5.750</td>
<td>6.750</td>
<td>6.750</td>
</tr>
<tr>
<td></td>
<td>Jung_KT_task7_trackB_2</td>
<td>JungKT2023</td>
<td>2</td>
<td>5.534</td>
<td>5.321</td>
<td>5.033</td>
<td>6.022</td>
<td>5.614</td>
<td>6.021</td>
<td>5.902</td>
<td>4.826</td>
<td>5.082</td>
<td>4.432</td>
<td>4.933</td>
<td>5.579</td>
<td>5.139</td>
<td>5.623</td>
<td>5.600</td>
<td>4.270</td>
<td>5.610</td>
<td>5.371</td>
<td>4.775</td>
<td>6.100</td>
<td>5.646</td>
<td>6.554</td>
<td>5.906</td>
<td>4.920</td>
<td>6.286</td>
<td>7.000</td>
<td>5.750</td>
<td>6.750</td>
<td>6.500</td>
<td>5.750</td>
<td>6.500</td>
<td>5.750</td>
</tr>
<tr>
<td></td>
<td>Lee_MARG_task7_trackB_1</td>
<td>LeeMARG2023</td>
<td>4</td>
<td>4.427</td>
<td>3.273</td>
<td>4.843</td>
<td>3.941</td>
<td>5.409</td>
<td>4.942</td>
<td>4.210</td>
<td>4.374</td>
<td>3.929</td>
<td>2.530</td>
<td>4.204</td>
<td>3.531</td>
<td>5.311</td>
<td>4.542</td>
<td>3.735</td>
<td>3.650</td>
<td>4.443</td>
<td>3.153</td>
<td>4.654</td>
<td>3.696</td>
<td>5.336</td>
<td>5.312</td>
<td>4.040</td>
<td>4.910</td>
<td>5.393</td>
<td>5.000</td>
<td>6.500</td>
<td>5.250</td>
<td>5.750</td>
<td>5.000</td>
<td>5.500</td>
<td>4.750</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h3>FAD Score</h3>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="scatter,comparison" data-comparison-a-row="DCASE2023_baseline_task7" data-comparison-active-set="FAD (eval)" data-comparison-b-row="Chang_HYU_task7_trackB_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
       {"title": "FAD (eval)", "data_axis_title": "FAD", "fields": ["FAD_eval_DogBark", "FAD_eval_Footstep", "FAD_eval_GunShot", "FAD_eval_Keyboard", "FAD_eval_MovingMotorVehicle", "FAD_eval_Rain", "FAD_eval_Sneeze_Cough"]
       },
       {"title": "FAD (dev)", "data_axis_title": "FAD", "fields": ["FAD_dev_DogBark", "FAD_dev_Footstep", "FAD_dev_GunShot", "FAD_dev_Keyboard", "FAD_dev_MovingMotorVehicle", "FAD_dev_Rain", "FAD_dev_Sneeze_Cough"]
       }]' data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="FAD_eval_DogBark" data-scatter-y="FAD_eval_Footstep" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackB" data-sort-order="asc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="3">Submission Information</th>
<th class="sep-left-cell" colspan="10">Evaluation Dataset</th>
<th class="sep-left-cell" colspan="8">Development Dataset</th>
</tr>
<tr>
<th data-field="code" data-sortable="true">
                Submission Code
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="text-center" data-field="evaluation_participant" data-sortable="false" data-value-type="int">
                # Categories Rated by <br/>Team Members
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="system_rank_trackB" data-sortable="true" data-value-type="int">
                Official <br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_rank_trackB" data-sortable="true" data-value-type="int">
                FAD <br/>Rank
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_average" data-sortable="true" data-value-type="float3">
                Average <br/>FAD
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_eval_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Footstep" data-sortable="true" data-value-type="float3">
                Footstep <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor <br/>Vehicle (FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Rain" data-sortable="true" data-value-type="float3">
                Rain <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_eval_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough <br/>(FAD)
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_dev_average" data-sortable="true" data-value-type="float3">
                Average <br/>FAD
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="FAD_dev_DogBark" data-sortable="true" data-value-type="float3">
                Dog Bark&lt; br&gt;(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Footstep" data-sortable="true" data-value-type="float3">
                Footstep <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_GunShot" data-sortable="true" data-value-type="float3">
                Gun Shot <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Keyboard" data-sortable="true" data-value-type="float3">
                Keyboard <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_MovingMotorVehicle" data-sortable="true" data-value-type="float3">
                Moving Motor <br/>Vehicle (FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Rain" data-sortable="true" data-value-type="float3">
                Rain <br/>(FAD)
            </th>
<th class="text-center" data-chartable="true" data-field="FAD_dev_Sneeze_Cough" data-sortable="true" data-value-type="float3">
                Sneeze/Cough <br/>(FAD)
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td></td>
<td>18</td>
<td>18</td>
<td>9.702</td>
<td>13.412</td>
<td>8.108</td>
<td>7.952</td>
<td>5.230</td>
<td>16.107</td>
<td>13.338</td>
<td>3.771</td>
<td>8.701</td>
<td>13.614</td>
<td>6.826</td>
<td>6.152</td>
<td>5.065</td>
<td>11.239</td>
<td>14.449</td>
<td>3.563</td>
</tr>
<tr>
<td></td>
<td>Kamath_NUS_task7_trackB_1</td>
<td>KamathNUS2023</td>
<td>7</td>
<td>15</td>
<td>15</td>
<td>9.081</td>
<td>6.468</td>
<td>6.348</td>
<td>10.665</td>
<td>5.656</td>
<td>24.674</td>
<td>6.498</td>
<td>3.259</td>
<td>7.341</td>
<td>6.455</td>
<td>4.875</td>
<td>7.922</td>
<td>4.521</td>
<td>16.567</td>
<td>8.023</td>
<td>3.026</td>
</tr>
<tr>
<td></td>
<td>Kamath_NUS_task7_trackB_2</td>
<td>KamathNUS2023</td>
<td>7</td>
<td>3</td>
<td>6</td>
<td>6.754</td>
<td>3.870</td>
<td>7.223</td>
<td>7.561</td>
<td>3.884</td>
<td>13.564</td>
<td>7.045</td>
<td>4.129</td>
<td>5.348</td>
<td>3.438</td>
<td>5.906</td>
<td>5.648</td>
<td>4.192</td>
<td>7.234</td>
<td>7.383</td>
<td>3.632</td>
</tr>
<tr>
<td></td>
<td>Pillay_CMU_task7_trackB_1</td>
<td>PillayCMU2023</td>
<td>4</td>
<td>22</td>
<td>22</td>
<td>12.034</td>
<td>14.607</td>
<td>6.656</td>
<td>16.268</td>
<td>5.279</td>
<td>16.471</td>
<td>9.451</td>
<td>15.506</td>
<td>11.257</td>
<td>14.436</td>
<td>5.505</td>
<td>12.523</td>
<td>5.355</td>
<td>13.252</td>
<td>12.766</td>
<td>14.964</td>
</tr>
<tr>
<td></td>
<td>Qianbin_BIT_task7_trackB_1</td>
<td>QianbinBIT2023</td>
<td>4</td>
<td>10</td>
<td>10</td>
<td>7.154</td>
<td>10.681</td>
<td>5.679</td>
<td>6.960</td>
<td>4.283</td>
<td>11.485</td>
<td>9.502</td>
<td>1.489</td>
<td>6.280</td>
<td>10.729</td>
<td>3.106</td>
<td>5.613</td>
<td>3.269</td>
<td>8.837</td>
<td>10.854</td>
<td>1.555</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackB_1</td>
<td>Leemaum2023</td>
<td>4</td>
<td>26</td>
<td>26</td>
<td>12.862</td>
<td>9.692</td>
<td>6.948</td>
<td>9.263</td>
<td>6.341</td>
<td>37.965</td>
<td>8.098</td>
<td>11.729</td>
<td>11.267</td>
<td>10.197</td>
<td>4.868</td>
<td>7.472</td>
<td>5.289</td>
<td>29.329</td>
<td>10.744</td>
<td>10.973</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackB_2</td>
<td>Leemaum2023</td>
<td>4</td>
<td>25</td>
<td>25</td>
<td>12.858</td>
<td>9.754</td>
<td>7.411</td>
<td>7.458</td>
<td>9.687</td>
<td>38.361</td>
<td>6.905</td>
<td>10.429</td>
<td>10.849</td>
<td>10.057</td>
<td>5.335</td>
<td>5.516</td>
<td>7.141</td>
<td>29.502</td>
<td>8.564</td>
<td>9.829</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackB_3</td>
<td>Leemaum2023</td>
<td>4</td>
<td>23</td>
<td>23</td>
<td>12.276</td>
<td>11.651</td>
<td>7.373</td>
<td>7.606</td>
<td>9.407</td>
<td>34.061</td>
<td>6.267</td>
<td>9.566</td>
<td>10.366</td>
<td>11.890</td>
<td>6.002</td>
<td>5.418</td>
<td>7.333</td>
<td>25.451</td>
<td>7.558</td>
<td>8.913</td>
</tr>
<tr>
<td></td>
<td>Lee_maum_task7_trackB_4</td>
<td>Leemaum2023</td>
<td>4</td>
<td>20</td>
<td>20</td>
<td>9.964</td>
<td>9.701</td>
<td>6.837</td>
<td>7.789</td>
<td>6.591</td>
<td>22.998</td>
<td>6.825</td>
<td>9.008</td>
<td>9.143</td>
<td>10.218</td>
<td>5.634</td>
<td>5.868</td>
<td>5.353</td>
<td>20.414</td>
<td>8.190</td>
<td>8.323</td>
</tr>
<tr>
<td></td>
<td>Chang_HYU_task7_trackB_1</td>
<td>ChangHYU2023</td>
<td>4</td>
<td>1</td>
<td>7</td>
<td>6.898</td>
<td>4.677</td>
<td>5.736</td>
<td>6.407</td>
<td>4.753</td>
<td>18.859</td>
<td>5.892</td>
<td>1.965</td>
<td>4.422</td>
<td>4.317</td>
<td>3.597</td>
<td>5.311</td>
<td>2.432</td>
<td>10.177</td>
<td>3.398</td>
<td>1.722</td>
</tr>
<tr>
<td></td>
<td>Chang_HYU_task7_trackB_2</td>
<td>ChangHYU2023</td>
<td>4</td>
<td>12</td>
<td>12</td>
<td>7.356</td>
<td>5.098</td>
<td>5.877</td>
<td>8.000</td>
<td>4.623</td>
<td>19.926</td>
<td>5.796</td>
<td>2.169</td>
<td>4.871</td>
<td>4.948</td>
<td>3.448</td>
<td>6.538</td>
<td>2.457</td>
<td>11.320</td>
<td>3.502</td>
<td>1.885</td>
</tr>
<tr>
<td></td>
<td>Xie_SJTU_task7_trackB_1</td>
<td>XieSJTU2023</td>
<td>6</td>
<td>13</td>
<td>13</td>
<td>7.407</td>
<td>8.035</td>
<td>6.987</td>
<td>8.185</td>
<td>3.495</td>
<td>13.565</td>
<td>9.267</td>
<td>2.315</td>
<td>6.050</td>
<td>7.564</td>
<td>4.761</td>
<td>6.237</td>
<td>2.176</td>
<td>9.853</td>
<td>9.592</td>
<td>2.167</td>
</tr>
<tr>
<td></td>
<td>Xie_SJTU_task7_trackB_2</td>
<td>XieSJTU2023</td>
<td>6</td>
<td>9</td>
<td>9</td>
<td>6.998</td>
<td>6.817</td>
<td>6.894</td>
<td>7.815</td>
<td>3.495</td>
<td>12.536</td>
<td>9.265</td>
<td>2.164</td>
<td>6.232</td>
<td>6.809</td>
<td>5.236</td>
<td>6.877</td>
<td>2.176</td>
<td>9.587</td>
<td>10.983</td>
<td>1.958</td>
</tr>
<tr>
<td></td>
<td>Xie_SJTU_task7_trackB_3</td>
<td>XieSJTU2023</td>
<td>6</td>
<td>8</td>
<td>8</td>
<td>6.992</td>
<td>7.017</td>
<td>6.949</td>
<td>7.913</td>
<td>3.600</td>
<td>11.621</td>
<td>9.350</td>
<td>2.492</td>
<td>6.458</td>
<td>6.991</td>
<td>5.300</td>
<td>7.286</td>
<td>2.569</td>
<td>9.716</td>
<td>11.071</td>
<td>2.271</td>
</tr>
<tr>
<td></td>
<td>Xie_SJTU_task7_trackB_4</td>
<td>XieSJTU2023</td>
<td>6</td>
<td>11</td>
<td>11</td>
<td>7.177</td>
<td>6.660</td>
<td>7.763</td>
<td>8.199</td>
<td>3.703</td>
<td>11.443</td>
<td>9.817</td>
<td>2.654</td>
<td>6.904</td>
<td>6.598</td>
<td>6.079</td>
<td>7.992</td>
<td>3.718</td>
<td>9.456</td>
<td>11.941</td>
<td>2.546</td>
</tr>
<tr>
<td></td>
<td>QianXu_BIT_NUDT_task7_trackB_1</td>
<td>QianXuBIT2023</td>
<td>4</td>
<td>21</td>
<td>21</td>
<td>10.644</td>
<td>17.956</td>
<td>6.526</td>
<td>10.180</td>
<td>4.901</td>
<td>14.348</td>
<td>5.616</td>
<td>14.979</td>
<td>8.817</td>
<td>18.385</td>
<td>6.301</td>
<td>6.729</td>
<td>3.130</td>
<td>7.759</td>
<td>5.229</td>
<td>14.186</td>
</tr>
<tr>
<td></td>
<td>QianXu_BIT_NUDT_task7_trackB_2</td>
<td>QianXuBIT2023</td>
<td>4</td>
<td>17</td>
<td>17</td>
<td>9.645</td>
<td>12.148</td>
<td>5.899</td>
<td>10.771</td>
<td>5.380</td>
<td>14.004</td>
<td>5.534</td>
<td>13.777</td>
<td>7.705</td>
<td>12.672</td>
<td>5.735</td>
<td>6.473</td>
<td>3.083</td>
<td>7.751</td>
<td>5.205</td>
<td>13.018</td>
</tr>
<tr>
<td></td>
<td>QianXu_BIT_NUDT_task7_trackB_3</td>
<td>QianXuBIT2023</td>
<td>4</td>
<td>19</td>
<td>19</td>
<td>9.959</td>
<td>13.526</td>
<td>6.064</td>
<td>10.615</td>
<td>5.574</td>
<td>16.127</td>
<td>5.864</td>
<td>11.944</td>
<td>7.857</td>
<td>14.248</td>
<td>5.662</td>
<td>6.395</td>
<td>3.400</td>
<td>8.971</td>
<td>5.184</td>
<td>11.136</td>
</tr>
<tr>
<td></td>
<td>QianXu_BIT_NUDT_task7_trackB_4</td>
<td>QianXuBIT2023</td>
<td>4</td>
<td>24</td>
<td>24</td>
<td>12.319</td>
<td>12.883</td>
<td>12.139</td>
<td>8.442</td>
<td>8.173</td>
<td>22.671</td>
<td>14.680</td>
<td>7.243</td>
<td>12.601</td>
<td>13.295</td>
<td>12.775</td>
<td>7.077</td>
<td>10.839</td>
<td>18.117</td>
<td>19.511</td>
<td>6.595</td>
</tr>
<tr>
<td></td>
<td>Bai_JLESS_task7_trackB_1</td>
<td>BaiJLESS2023</td>
<td>0</td>
<td>27</td>
<td>27</td>
<td>13.583</td>
<td>15.958</td>
<td>8.663</td>
<td>18.485</td>
<td>6.728</td>
<td>24.094</td>
<td>15.193</td>
<td>5.958</td>
<td>12.437</td>
<td>17.510</td>
<td>8.497</td>
<td>16.824</td>
<td>6.956</td>
<td>18.737</td>
<td>12.874</td>
<td>5.662</td>
</tr>
<tr>
<td></td>
<td>Chun_Chosun_task7_trackB_2</td>
<td>ChunChosun2023</td>
<td>5</td>
<td>14</td>
<td>14</td>
<td>8.351</td>
<td>8.690</td>
<td>7.265</td>
<td>10.764</td>
<td>5.602</td>
<td>13.941</td>
<td>9.512</td>
<td>2.684</td>
<td>7.376</td>
<td>8.382</td>
<td>6.203</td>
<td>8.294</td>
<td>3.748</td>
<td>10.974</td>
<td>11.562</td>
<td>2.467</td>
</tr>
<tr>
<td></td>
<td>Wendner_JKU_task7_trackB_1</td>
<td>WendnerJKU2023</td>
<td>5</td>
<td>28</td>
<td>28</td>
<td>15.736</td>
<td>8.979</td>
<td>9.950</td>
<td>15.354</td>
<td>12.564</td>
<td>31.160</td>
<td>21.753</td>
<td>10.388</td>
<td>15.669</td>
<td>10.093</td>
<td>9.682</td>
<td>11.984</td>
<td>13.334</td>
<td>26.435</td>
<td>28.391</td>
<td>9.763</td>
</tr>
<tr>
<td></td>
<td>Jung_KT_task7_trackB_1</td>
<td>JungKT2023</td>
<td>7</td>
<td>7</td>
<td>4</td>
<td>5.480</td>
<td>2.784</td>
<td>4.370</td>
<td>4.667</td>
<td>3.555</td>
<td>17.511</td>
<td>3.899</td>
<td>1.577</td>
<td>3.373</td>
<td>2.771</td>
<td>2.514</td>
<td>2.960</td>
<td>2.246</td>
<td>8.776</td>
<td>2.947</td>
<td>1.397</td>
</tr>
<tr>
<td></td>
<td>Jung_KT_task7_trackB_2</td>
<td>JungKT2023</td>
<td>7</td>
<td>2</td>
<td>1</td>
<td>5.023</td>
<td>3.348</td>
<td>3.990</td>
<td>3.495</td>
<td>4.074</td>
<td>14.861</td>
<td>3.529</td>
<td>1.865</td>
<td>3.181</td>
<td>3.087</td>
<td>2.580</td>
<td>2.560</td>
<td>2.255</td>
<td>7.540</td>
<td>2.626</td>
<td>1.617</td>
</tr>
<tr>
<td></td>
<td>Jung_KT_task7_trackB_3</td>
<td>JungKT2023</td>
<td>7</td>
<td>6</td>
<td>3</td>
<td>5.230</td>
<td>2.616</td>
<td>3.739</td>
<td>6.322</td>
<td>4.089</td>
<td>14.172</td>
<td>4.304</td>
<td>1.371</td>
<td>3.088</td>
<td>2.477</td>
<td>2.588</td>
<td>3.722</td>
<td>2.220</td>
<td>6.867</td>
<td>2.349</td>
<td>1.395</td>
</tr>
<tr>
<td></td>
<td>Jung_KT_task7_trackB_4</td>
<td>JungKT2023</td>
<td>7</td>
<td>5</td>
<td>2</td>
<td>5.026</td>
<td>4.854</td>
<td>3.103</td>
<td>4.790</td>
<td>3.665</td>
<td>13.604</td>
<td>3.727</td>
<td>1.435</td>
<td>3.215</td>
<td>4.673</td>
<td>2.045</td>
<td>3.614</td>
<td>2.450</td>
<td>6.018</td>
<td>2.322</td>
<td>1.380</td>
</tr>
<tr>
<td></td>
<td>Lee_MARG_task7_trackB_1</td>
<td>LeeMARG2023</td>
<td>4</td>
<td>4</td>
<td>5</td>
<td>6.409</td>
<td>6.947</td>
<td>4.563</td>
<td>10.657</td>
<td>3.900</td>
<td>11.602</td>
<td>5.491</td>
<td>1.699</td>
<td>4.766</td>
<td>7.778</td>
<td>3.712</td>
<td>8.208</td>
<td>3.584</td>
<td>4.359</td>
<td>4.386</td>
<td>1.332</td>
</tr>
<tr>
<td></td>
<td>Chung_KAIST_task7_trackB_1</td>
<td>ChungKAIST2023</td>
<td>5</td>
<td>16</td>
<td>16</td>
<td>9.192</td>
<td>10.389</td>
<td>6.832</td>
<td>7.572</td>
<td>5.188</td>
<td>15.653</td>
<td>13.348</td>
<td>5.359</td>
<td>7.841</td>
<td>11.783</td>
<td>6.283</td>
<td>6.668</td>
<td>5.168</td>
<td>10.830</td>
<td>9.498</td>
<td>4.655</td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="system-characteristics">System characteristics</h1>
<p>Summary of the submitted system characteristics.</p>
<h2 id="track-a-1">Track A</h2>
<table class="datatable table table-hover table-condensed" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="false" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackA" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="system_rank_trackA" data-sortable="true" data-value-type="int">
                Rank
            </th>
<th class="sm-cell" data-field="code" data-sortable="true">
                Submission<br/>Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                System<br/>input
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_machine_learning_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                ML<br/>method
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_phase_reconstruction" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Phase<br/>reconstruction
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_acoustic_feature" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Acoustic<br/>feature
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-field="system_complexity" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-value-type="numeric-unit">
                System<br/>Complexity
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data<br/>Augmentation
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_ensemble_method_subsystem_count" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true" data-value-type="int">
                Subsystem<br/>Count
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td>6</td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>269992</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Chon_Gaudio_task7_trackA_1</td>
<td>ChonGLI2023</td>
<td>sound event label</td>
<td>diffusion model</td>
<td>modified HiFi-GAN</td>
<td>spectrogram</td>
<td>642000000</td>
<td>mixup, time stretching</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Lee_maum_task7_trackA_1</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Lee_maum_task7_trackA_2</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Lee_maum_task7_trackA_3</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Lee_maum_task7_trackA_4</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo, ensemble</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>369279688</td>
<td>PhaseAug</td>
<td>4</td>
</tr>
<tr>
<td>1</td>
<td>Yi_SURREY_task7_trackA_1</td>
<td>YiSURREY2023</td>
<td>sound event label</td>
<td>diffusion model, VQ-VAE</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>1173847474</td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>Guan_HEU_task7_trackA_1</td>
<td>GuanHEU2023</td>
<td>sound event label, caption</td>
<td>AudioLDM</td>
<td></td>
<td></td>
<td>421000000</td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Guan_HEU_task7_trackA_2</td>
<td>GuanHEU2023</td>
<td>sound event label, caption</td>
<td>AudioLDM, Baseline</td>
<td></td>
<td></td>
<td>421269992</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Scheibler_LINE_task7_trackA_1</td>
<td>ScheiblerLINE2023</td>
<td>sound event label</td>
<td>VQ-VAE, diffusion model</td>
<td>HiFi-GAN</td>
<td>log-mel spectrogram</td>
<td>977116210</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="track-b-1">Track B</h2>
<table class="datatable table table-hover table-condensed" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="false" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="system_rank_trackB" data-sort-order="asc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th data-field="system_rank_trackB" data-sortable="true" data-value-type="int">
                Rank
            </th>
<th class="sm-cell" data-field="code" data-sortable="true">
                Submission<br/>Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_input" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                System<br/>input
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_machine_learning_method" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                ML<br/>method
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_phase_reconstruction" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Phase<br/>reconstruction
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_acoustic_feature" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Acoustic<br/>feature
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-field="system_complexity" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-value-type="numeric-unit">
                System<br/>Complexity
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data<br/>Augmentation
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_ensemble_method_subsystem_count" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true" data-value-type="int">
                Subsystem<br/>Count
            </th>
</tr>
</thead>
<tbody>
<tr class="info" data-hline="true">
<td>18</td>
<td>DCASE2023_baseline_task7</td>
<td>DCASE2023baseline2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>269992</td>
<td></td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>Kamath_NUS_task7_trackB_1</td>
<td>KamathNUS2023</td>
<td>sound event label</td>
<td>StyleGAN2</td>
<td>phase gradient heap integration</td>
<td>log-magnitude spectrogram</td>
<td>62010138</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Kamath_NUS_task7_trackB_2</td>
<td>KamathNUS2023</td>
<td>sound event label</td>
<td>StyleGAN2</td>
<td>phase gradient heap integration</td>
<td>log-magnitude spectrogram</td>
<td>376959933</td>
<td>time shifting, sound wrapping</td>
<td>7</td>
</tr>
<tr>
<td>22</td>
<td>Pillay_CMU_task7_trackB_1</td>
<td>PillayCMU2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>103316216</td>
<td>time masking, frequency masking</td>
<td>3</td>
</tr>
<tr>
<td>10</td>
<td>Qianbin_BIT_task7_trackB_1</td>
<td>QianbinBIT2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL, Bit-diffusion</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>112857385</td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>26</td>
<td>Lee_maum_task7_trackB_1</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>25</td>
<td>Lee_maum_task7_trackB_2</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>23</td>
<td>Lee_maum_task7_trackB_3</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>92319922</td>
<td>PhaseAug</td>
<td></td>
</tr>
<tr>
<td>20</td>
<td>Lee_maum_task7_trackB_4</td>
<td>Leemaum2023</td>
<td>sound event label</td>
<td>VAE, GAN, flow, VITS, PhaseAug, Avocodo, ensemble</td>
<td>HiFi-GAN</td>
<td>Gaussian latent variables</td>
<td>369279688</td>
<td>PhaseAug</td>
<td>4</td>
</tr>
<tr>
<td>1</td>
<td>Chang_HYU_task7_trackB_1</td>
<td>ChangHYU2023</td>
<td>sound event label</td>
<td>diffusion model</td>
<td>HiFi-GAN</td>
<td>log-mel spectrogram</td>
<td>23374056</td>
<td></td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Chang_HYU_task7_trackB_2</td>
<td>ChangHYU2023</td>
<td>sound event label</td>
<td>diffusion model</td>
<td>HiFi-GAN</td>
<td>log-mel spectrogram</td>
<td>23374056</td>
<td></td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>Xie_SJTU_task7_trackB_1</td>
<td>XieSJTU2023</td>
<td>sound event label</td>
<td>VQ-VAE, Transformer</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>28224194</td>
<td></td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Xie_SJTU_task7_trackB_2</td>
<td>XieSJTU2023</td>
<td>sound event label</td>
<td>VQ-VAE, Transformer, TransformerDecoder</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>40843458</td>
<td>mixup</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>Xie_SJTU_task7_trackB_3</td>
<td>XieSJTU2023</td>
<td>sound event label</td>
<td>VQ-VAE, Transformer, TransformerDecoder, TrnsformerEncder Discriminator</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>44037827</td>
<td>mixup</td>
<td>3</td>
</tr>
<tr>
<td>11</td>
<td>Xie_SJTU_task7_trackB_4</td>
<td>XieSJTU2023</td>
<td>sound event label</td>
<td>VQ-VAE, Transformer, TransformerDecoder, TrnsformerEncder Discriminator</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>44037827</td>
<td>mixup</td>
<td>3</td>
</tr>
<tr>
<td>21</td>
<td>QianXu_BIT_NUDT_task7_trackB_1</td>
<td>QianXuBIT2023</td>
<td>sound</td>
<td>diffusion model</td>
<td></td>
<td>spectrogram</td>
<td>113668609</td>
<td></td>
<td></td>
</tr>
<tr>
<td>17</td>
<td>QianXu_BIT_NUDT_task7_trackB_2</td>
<td>QianXuBIT2023</td>
<td>sound</td>
<td>diffusion model</td>
<td></td>
<td>spectrogram</td>
<td>113668609</td>
<td></td>
<td></td>
</tr>
<tr>
<td>19</td>
<td>QianXu_BIT_NUDT_task7_trackB_3</td>
<td>QianXuBIT2023</td>
<td>sound</td>
<td>diffusion model</td>
<td></td>
<td>spectrogram</td>
<td>113668609</td>
<td></td>
<td></td>
</tr>
<tr>
<td>24</td>
<td>QianXu_BIT_NUDT_task7_trackB_4</td>
<td>QianXuBIT2023</td>
<td>sound</td>
<td>diffusion model</td>
<td></td>
<td>spectrogram</td>
<td>113668609</td>
<td>wavelet domain denoise</td>
<td></td>
</tr>
<tr>
<td>27</td>
<td>Bai_JLESS_task7_trackB_1</td>
<td>BaiJLESS2023</td>
<td>sound event label</td>
<td>CVAE-GAN</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>8760000</td>
<td>gain, pitch shifting, time shifting, peak normalization</td>
<td>7</td>
</tr>
<tr>
<td>14</td>
<td>Chun_Chosun_task7_trackB_2</td>
<td>ChunChosun2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL</td>
<td>HiFi-GAN</td>
<td>spectrogram</td>
<td>386598842</td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>28</td>
<td>Wendner_JKU_task7_trackB_1</td>
<td>WendnerJKU2023</td>
<td>sound event label</td>
<td>diffusion model, ensemble</td>
<td></td>
<td></td>
<td>7167405</td>
<td>gain reduction, time shifting</td>
<td>7</td>
</tr>
<tr>
<td>7</td>
<td>Jung_KT_task7_trackB_1</td>
<td>JungKT2023</td>
<td>sound event label, random noise</td>
<td>C-SupConGAN</td>
<td>HiFi-GAN</td>
<td>mel spectrogram</td>
<td>21398259</td>
<td>fade in/out, time masking</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Jung_KT_task7_trackB_2</td>
<td>JungKT2023</td>
<td>sound event label, random noise</td>
<td>C-SupConGAN</td>
<td>HiFi-GAN</td>
<td>mel spectrogram</td>
<td>21398259</td>
<td>fade in/out, time masking</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Jung_KT_task7_trackB_3</td>
<td>JungKT2023</td>
<td>sound event label, random noise</td>
<td>C-SupConGAN</td>
<td>HiFi-GAN</td>
<td>mel spectrogram</td>
<td>21398259</td>
<td>fade in/out, time masking</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Jung_KT_task7_trackB_4</td>
<td>JungKT2023</td>
<td>sound event label, random noise</td>
<td>C-SupConGAN</td>
<td>HiFi-GAN</td>
<td>mel spectrogram</td>
<td>21398259</td>
<td>fade in/out, time masking</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Lee_MARG_task7_trackB_1</td>
<td>LeeMARG2023</td>
<td>sound event label</td>
<td>VQ-VAE, PixelSNAIL, StyleGAN2-ADA</td>
<td>HiFi-GAN, Griffin-Lim</td>
<td>spectrogram</td>
<td>116202572</td>
<td>time stretching, time shifting, RoomSimulator, TanhDistortion, resample, time masking, pitch shift</td>
<td>6</td>
</tr>
<tr>
<td>16</td>
<td>Chung_KAIST_task7_trackB_1</td>
<td>ChungKAIST2023</td>
<td>sound event label</td>
<td>diffusion model</td>
<td></td>
<td></td>
<td>87330433</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h1 id="wav-files-used-for-evaluation-experiment">Wav files used for evaluation experiment</h1>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/8091972" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/8091972" target="_blank">
<span style="font-size:20px;">DCASE2023 Task 7 <strong>wav files used for evaluation</strong>, repository <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(4.0 GB)</span>
<br/>
<span class="text-muted">
                
                version 2.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2023/technical_reports_task7.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="BaiJLESS2023" style="box-shadow: none">
<div class="panel-heading" id="heading-BaiJLESS2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        JLESS Submission to DCASE2023 Task7: Foley Sound Synthesis Using Non-Autoagressive Generative Model
       </h4>
<p style="text-align:left">
        Siwei Huang, Jisheng Bai, Yafei Jia, Jianfeng Chen
       </p>
<p style="text-align:left">
<em>
         School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, LianFeng Acoustic Technologies Co., Ltd. Xi'an, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Bai_JLESS_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-BaiJLESS2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-BaiJLESS2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-BaiJLESS2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Bai_87_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-BaiJLESS2023" class="panel-collapse collapse" id="collapse-BaiJLESS2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       JLESS Submission to DCASE2023 Task7: Foley Sound Synthesis Using Non-Autoagressive Generative Model
      </h4>
<p style="text-align:left">
<small>
        Siwei Huang, Jisheng Bai, Yafei Jia, Jianfeng Chen
       </small>
<br/>
<small>
<em>
         School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, LianFeng Acoustic Technologies Co., Ltd. Xi'an, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our proposed system for DCASE2023 task7: Foley Sound Synthesis. In our approach, we propose a GAN-based mel-spectrogram synthesis system. we take a Conditional Variational auto-encoder (CVAE) as the generator, which consists of densely-connected dilated convolution blocks, and a simple CNN as the discriminator. The decoder of CVAE synthesizes fake mel-spectrogram resampling from prior noise and class, and the discriminator determines whether it is real or not. Furthermore, we also train a classifier to help CVAE keep class-wise distribution. Finally, the audio is wrapped using the HiFiGAN vocoder.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         CVAE-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         gain, pitch shifting, time shifting, peak normalization
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         7
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         8760000 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-BaiJLESS2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Bai_87_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-BaiJLESS2023label" class="modal fade" id="bibtex-BaiJLESS2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexBaiJLESS2023label">
        JLESS Submission to DCASE2023 Task7: Foley Sound Synthesis Using Non-Autoagressive Generative Model
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{BaiJLESS2023,
    Author = "Huang, Siwei and Bai, Jisheng and Jia, Yafei and Chen, Jianfeng",
    title = "JLESS Submission to DCASE2023 Task7: Foley Sound Synthesis Using Non-Autoagressive Generative Model",
    institution = "School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, LianFeng Acoustic Technologies Co., Ltd. Xi'an, China",
    year = "2023",
    month = "June",
    abstract = "This technical report describes our proposed system for DCASE2023 task7: Foley Sound Synthesis. In our approach, we propose a GAN-based mel-spectrogram synthesis system. we take a Conditional Variational auto-encoder (CVAE) as the generator, which consists of densely-connected dilated convolution blocks, and a simple CNN as the discriminator. The decoder of CVAE synthesizes fake mel-spectrogram resampling from prior noise and class, and the discriminator determines whether it is real or not. Furthermore, we also train a classifier to help CVAE keep class-wise distribution. Finally, the audio is wrapped using the HiFiGAN vocoder."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="ChangHYU2023" style="box-shadow: none">
<div class="panel-heading" id="heading-ChangHYU2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        HYU Submission For The DCASE 2023 Task 7: Diffusion Probabilistic Model With Adversarial Training For Foley Sound Synthesis
       </h4>
<p style="text-align:left">
        Won-Gook Choi, Joon-Hyuk Chang
       </p>
<p style="text-align:left">
<em>
         Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea, Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Chang_HYU_task7_trackB_1</span> <span class="label label-primary">Chang_HYU_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-ChangHYU2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-ChangHYU2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-ChangHYU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chang_58_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-ChangHYU2023" class="panel-collapse collapse" id="collapse-ChangHYU2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       HYU Submission For The DCASE 2023 Task 7: Diffusion Probabilistic Model With Adversarial Training For Foley Sound Synthesis
      </h4>
<p style="text-align:left">
<small>
        Won-Gook Choi, Joon-Hyuk Chang
       </small>
<br/>
<small>
<em>
         Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea, Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This paper is a technical report of the Hanyang University team submission for the DCASE 2023 challenge task 7, Foley Sound Synthesis. The goal of the task is to build a generative model that can synthesize high-quality and various foley sounds: the sounds of dog barking, footsteps, gunshots, keyboards, moving motor vehicles, rainy scenes, and sneezing. The core strategy of the submissions is a diffusion probabilistic model-based acoustic model. Also, we adopted adversarial training on the evidence lower bound (ELBO) of the diffusion model for the higher quality. The submissions did not use any external dataset and achieved lower Frechet audio distance (FAD) scores than the DCASE baseline, except for the sounds of moving motor vehicles.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         log-mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         23374056,23374056 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-ChangHYU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chang_58_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-ChangHYU2023label" class="modal fade" id="bibtex-ChangHYU2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChangHYU2023label">
        HYU Submission For The DCASE 2023 Task 7: Diffusion Probabilistic Model With Adversarial Training For Foley Sound Synthesis
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{ChangHYU2023,
    Author = "Choi, Won-Gook and Chang, Joon-Hyuk",
    title = "HYU Submission For The DCASE 2023 Task 7: Diffusion Probabilistic Model With Adversarial Training For Foley Sound Synthesis",
    institution = "Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea, Department of Electronic Engineering, Hanyang University, Seoul, Republic of Korea",
    year = "2023",
    month = "June",
    abstract = "This paper is a technical report of the Hanyang University team submission for the DCASE 2023 challenge task 7, Foley Sound Synthesis. The goal of the task is to build a generative model that can synthesize high-quality and various foley sounds: the sounds of dog barking, footsteps, gunshots, keyboards, moving motor vehicles, rainy scenes, and sneezing. The core strategy of the submissions is a diffusion probabilistic model-based acoustic model. Also, we adopted adversarial training on the evidence lower bound (ELBO) of the diffusion model for the higher quality. The submissions did not use any external dataset and achieved lower Frechet audio distance (FAD) scores than the DCASE baseline, except for the sounds of moving motor vehicles."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="ChonGLI2023" style="box-shadow: none">
<div class="panel-heading" id="heading-ChonGLI2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        FALL-E: Gaudio Foley Synthesis System
       </h4>
<p style="text-align:left">
        Minsung Kang, Sangshin Oh, Hyeongi Moon, Kyungyun Lee, Ben Sangbae Chon
       </p>
<p style="text-align:left">
<em>
         Gaudio Lab, Inc., Seoul, South Kore
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Chon_Gaudio_task7_trackA_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-ChonGLI2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-ChonGLI2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-ChonGLI2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chon_10_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-ChonGLI2023" class="panel-collapse collapse" id="collapse-ChonGLI2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       FALL-E: Gaudio Foley Synthesis System
      </h4>
<p style="text-align:left">
<small>
        Minsung Kang, Sangshin Oh, Hyeongi Moon, Kyungyun Lee, Ben Sangbae Chon
       </small>
<br/>
<small>
<em>
         Gaudio Lab, Inc., Seoul, South Kore
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This paper introduces FALL-E, Gaudio's Foley Synthesis System, which is submitted to the DCASE 2023 Task 7 Foley Synthesis Challenge (Track A). The system employs a cascaded approach comprising low-resolution spectrogram generation, spectrogram super-resolution, and a vocoder. We trained every sound-related model from scratch using our extensive datasets, and we utilized a pre-trained language model. We conditioned the model with dataset-specific texts, enabling it to learn sound quality and recording environment based on the text input. Moreover, we leveraged external language models to improve text descriptions of our datasets and performed prompt engineering for quality, coherence, and diversity. We report the objective measure with respect to the official evaluation set, although our focus is on developing generally working sound generation models beyond the challenge.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         modified HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time stretching
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         642000000 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-ChonGLI2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chon_10_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-ChonGLI2023label" class="modal fade" id="bibtex-ChonGLI2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChonGLI2023label">
        FALL-E: Gaudio Foley Synthesis System
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{ChonGLI2023,
    Author = "Kang, Minsung and Oh, Sangshin and Moon, Hyeongi and Lee, Kyungyun and Chon, Ben Sangbae",
    title = "FALL-E: Gaudio Foley Synthesis System",
    institution = "Gaudio Lab, Inc., Seoul, South Kore",
    year = "2023",
    month = "June",
    abstract = "This paper introduces FALL-E, Gaudio's Foley Synthesis System, which is submitted to the DCASE 2023 Task 7 Foley Synthesis Challenge (Track A). The system employs a cascaded approach comprising low-resolution spectrogram generation, spectrogram super-resolution, and a vocoder. We trained every sound-related model from scratch using our extensive datasets, and we utilized a pre-trained language model. We conditioned the model with dataset-specific texts, enabling it to learn sound quality and recording environment based on the text input. Moreover, we leveraged external language models to improve text descriptions of our datasets and performed prompt engineering for quality, coherence, and diversity. We report the objective measure with respect to the official evaluation set, although our focus is on developing generally working sound generation models beyond the challenge."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="ChunChosun2023" style="box-shadow: none">
<div class="panel-heading" id="heading-ChunChosun2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        High-Quality Foley Sound Synthesis Using Monte Carlo Dropout
       </h4>
<p style="text-align:left">
        Chae-Woon Bang, Nam Kyun Kim, Chanjun Chun
       </p>
<p style="text-align:left">
<em>
         Chosun University, Gwangju, South Korea, Korea Automotive Technology Institute, Gwanjgu, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Chun_Chosun_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-ChunChosun2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-ChunChosun2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-ChunChosun2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chun_93_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-ChunChosun2023" class="panel-collapse collapse" id="collapse-ChunChosun2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       High-Quality Foley Sound Synthesis Using Monte Carlo Dropout
      </h4>
<p style="text-align:left">
<small>
        Chae-Woon Bang, Nam Kyun Kim, Chanjun Chun
       </small>
<br/>
<small>
<em>
         Chosun University, Gwangju, South Korea, Korea Automotive Technology Institute, Gwanjgu, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the foley sound synthesis system for DCASE2022 Task7. Here, it aims to creates foley sound, which is widely utilized as various sound effects in multimedia contents. To accomplish this, it uses sound synthesis technique, generating a 4-second audio clip of one of seven classes. Specifically, we fine-tuned the baseline model such that improves the performance. After that, we ensemble the models using Monte Carlo Dropout. The performance of the proposed system was compared with the baseline using Frechet Audio Distance (FAD), which is referred as an audio evaluation metric. As a result, it was confirmed that both the single model and the ensemble model outperform the existing baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         PixelSNAIL,VQ-VAE
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         2
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         386598842 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-ChunChosun2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chun_93_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-ChunChosun2023label" class="modal fade" id="bibtex-ChunChosun2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChunChosun2023label">
        High-Quality Foley Sound Synthesis Using Monte Carlo Dropout
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{ChunChosun2023,
    Author = "Bang, Chae-Woon and Kim, Nam Kyun and Chun, Chanjun",
    title = "High-Quality Foley Sound Synthesis Using Monte Carlo Dropout",
    institution = "Chosun University, Gwangju, South Korea, Korea Automotive Technology Institute, Gwanjgu, South Korea",
    year = "2023",
    month = "June",
    abstract = "This technical report describes the foley sound synthesis system for DCASE2022 Task7. Here, it aims to creates foley sound, which is widely utilized as various sound effects in multimedia contents. To accomplish this, it uses sound synthesis technique, generating a 4-second audio clip of one of seven classes. Specifically, we fine-tuned the baseline model such that improves the performance. After that, we ensemble the models using Monte Carlo Dropout. The performance of the proposed system was compared with the baseline using Frechet Audio Distance (FAD), which is referred as an audio evaluation metric. As a result, it was confirmed that both the single model and the ensemble model outperform the existing baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="ChungKAIST2023" style="box-shadow: none">
<div class="panel-heading" id="heading-ChungKAIST2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Foley Sound Synthesis In Waveform Domain With Diffusion Model
       </h4>
<p style="text-align:left">
        Yoonjin Chung, Junwon Lee, Juhan Nam
       </p>
<p style="text-align:left">
<em>
         Graduate School of AI, KAIST, Graduate School of Culture Technology, KAIST
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Chung_KAIST_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-ChungKAIST2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-ChungKAIST2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-ChungKAIST2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chung_120_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-ChungKAIST2023" class="panel-collapse collapse" id="collapse-ChungKAIST2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Foley Sound Synthesis In Waveform Domain With Diffusion Model
      </h4>
<p style="text-align:left">
<small>
        Yoonjin Chung, Junwon Lee, Juhan Nam
       </small>
<br/>
<small>
<em>
         Graduate School of AI, KAIST, Graduate School of Culture Technology, KAIST
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Foley sound synthesis becomes an important task due to the growing popularity of multi-media content, which is an industrial usecase of general audio synthesis. We propose a diffusion-based model that generates class-conditioned general audio in a classifier-free guidance manner as a participant of DCASE 2023 challenge task 7[1]. Our model follows a UNet-like structure while incorporating LSTM[2] inside the encoder block. We demonstrate the FAD (Frechet Audio Distance) scores of generated results for each 7 sound class respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         87330433 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-ChungKAIST2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Chung_120_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-ChungKAIST2023label" class="modal fade" id="bibtex-ChungKAIST2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexChungKAIST2023label">
        Foley Sound Synthesis In Waveform Domain With Diffusion Model
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{ChungKAIST2023,
    Author = "Chung, Yoonjin and Lee, Junwon and Nam, Juhan",
    title = "Foley Sound Synthesis In Waveform Domain With Diffusion Model",
    institution = "Graduate School of AI, KAIST, Graduate School of Culture Technology, KAIST",
    year = "2023",
    month = "June",
    abstract = "Foley sound synthesis becomes an important task due to the growing popularity of multi-media content, which is an industrial usecase of general audio synthesis. We propose a diffusion-based model that generates class-conditioned general audio in a classifier-free guidance manner as a participant of DCASE 2023 challenge task 7[1]. Our model follows a UNet-like structure while incorporating LSTM[2] inside the encoder block. We demonstrate the FAD (Frechet Audio Distance) scores of generated results for each 7 sound class respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="GuanHEU2023" style="box-shadow: none">
<div class="panel-heading" id="heading-GuanHEU2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Foley Sound Synthesis With AudioLDM For DCASE2023 Task 7
       </h4>
<p style="text-align:left">
        Shitong Fan, Qiaoxi Zhu, Feiyang Xiao, Haiyan Lan, Wenwu Wang, Jian Guan1
       </p>
<p style="text-align:left">
<em>
         Group of Intelligent Signal Processing (GISP), College of Computer Science and Technology, Harbin Engineering University, Harbin, China, Centre for Audio, Acoustic and Vibration (CAAV), University of Technology Sydney, Ultimo, Australia, Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, Guildford, UK
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Guan_HEU_task7_trackA_1</span> <span class="label label-primary">Guan_HEU_task7_trackA_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-GuanHEU2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-GuanHEU2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-GuanHEU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Guan_84_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-GuanHEU2023" class="panel-collapse collapse" id="collapse-GuanHEU2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Foley Sound Synthesis With AudioLDM For DCASE2023 Task 7
      </h4>
<p style="text-align:left">
<small>
        Shitong Fan, Qiaoxi Zhu, Feiyang Xiao, Haiyan Lan, Wenwu Wang, Jian Guan1
       </small>
<br/>
<small>
<em>
         Group of Intelligent Signal Processing (GISP), College of Computer Science and Technology, Harbin Engineering University, Harbin, China, Centre for Audio, Acoustic and Vibration (CAAV), University of Technology Sydney, Ultimo, Australia, Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, Guildford, UK
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our submission for DCASE2023 Challenge Task 7, a system for foley sound synthesis. Our system is based on AudioLDM, which offers high generation quality and computational efficiency for the text-to-audio task. Experiments are conducted on the dataset of DCASE2023 Challenge Task 7. The Fr\'{e}chet audio distance (FAD) between the sound generated by our system and the actual sound sample is 5.120 in the category “DogBark” and 8.102 in the category “Rain”, better than the baseline with an FAD 7.256 and an FAD 4.901 distance closer to the actual samples, respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label, caption
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         AudioLDM,Baseline
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         421000000,421269992 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-GuanHEU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Guan_84_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-GuanHEU2023label" class="modal fade" id="bibtex-GuanHEU2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGuanHEU2023label">
        Foley Sound Synthesis With AudioLDM For DCASE2023 Task 7
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{GuanHEU2023,
    Author = "Fan, Shitong and Zhu, Qiaoxi and Xiao, Feiyang and Lan, Haiyan and Wang, Wenwu and Guan1, Jian",
    title = "Foley Sound Synthesis With AudioLDM For DCASE2023 Task 7",
    institution = "Group of Intelligent Signal Processing (GISP), College of Computer Science and Technology, Harbin Engineering University, Harbin, China, Centre for Audio, Acoustic and Vibration (CAAV), University of Technology Sydney, Ultimo, Australia, Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, Guildford, UK",
    year = "2023",
    month = "June",
    abstract = "This report describes our submission for DCASE2023 Challenge Task 7, a system for foley sound synthesis. Our system is based on AudioLDM, which offers high generation quality and computational efficiency for the text-to-audio task. Experiments are conducted on the dataset of DCASE2023 Challenge Task 7. The Fr\'{e}chet audio distance (FAD) between the sound generated by our system and the actual sound sample is 5.120 in the category “DogBark” and 8.102 in the category “Rain”, better than the baseline with an FAD 7.256 and an FAD 4.901 distance closer to the actual samples, respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="JungKT2023" style="box-shadow: none">
<div class="panel-heading" id="heading-JungKT2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Foley Sound Synthesis Based On GAN Using Contrastive Learning Without Label Information
       </h4>
<p style="text-align:left">
        Hae Chun Chung, Yuna Lee, Jae Hoon Jung
       </p>
<p style="text-align:left">
<em>
         KT Corporation, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Jung_KT_task7_trackB_1</span> <span class="label label-primary">Jung_KT_task7_trackB_2</span> <span class="label label-primary">Jung_KT_task7_trackB_3</span> <span class="label label-primary">Jung_KT_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-JungKT2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-JungKT2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-JungKT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Jung_112_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-JungKT2023" class="panel-collapse collapse" id="collapse-JungKT2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Foley Sound Synthesis Based On GAN Using Contrastive Learning Without Label Information
      </h4>
<p style="text-align:left">
<small>
        Hae Chun Chung, Yuna Lee, Jae Hoon Jung
       </small>
<br/>
<small>
<em>
         KT Corporation, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Sound effects used in radio or movies, such as foley sound, have been difficult to create without the help of experts. Furthermore, in the field of audio synthesis, the field of speech has been actively progressed, but there has been no research on audio sounds that can be obtained in real life. In this technical report, We present our submission system for DCASE2023 Task7: Foley-sound synthesis. We participate in track B, which forbids the usage of external resources. We propose a framework that employ the loss function of ContraGAN and C-SupConGAN based on structure of Self-Attention GAN (SAGAN). Our final system achieves outperforming the baseline performance by a large margin.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label, random noise
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         C-SupConGAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         fade in/out, time masking
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         21398259,21398259,21398259,21398259 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-JungKT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Jung_112_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-JungKT2023label" class="modal fade" id="bibtex-JungKT2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJungKT2023label">
        Foley Sound Synthesis Based On GAN Using Contrastive Learning Without Label Information
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{JungKT2023,
    Author = "Chung, Hae Chun and Lee, Yuna and Jung, Jae Hoon",
    title = "Foley Sound Synthesis Based On GAN Using Contrastive Learning Without Label Information",
    institution = "KT Corporation, Republic of Korea",
    year = "2023",
    month = "June",
    abstract = "Sound effects used in radio or movies, such as foley sound, have been difficult to create without the help of experts. Furthermore, in the field of audio synthesis, the field of speech has been actively progressed, but there has been no research on audio sounds that can be obtained in real life. In this technical report, We present our submission system for DCASE2023 Task7: Foley-sound synthesis. We participate in track B, which forbids the usage of external resources. We propose a framework that employ the loss function of ContraGAN and C-SupConGAN based on structure of Self-Attention GAN (SAGAN). Our final system achieves outperforming the baseline performance by a large margin."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="KamathNUS2023" style="box-shadow: none">
<div class="panel-heading" id="heading-KamathNUS2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE Task-7: StyleGAN2-Based Foley Sound Synthesis
       </h4>
<p style="text-align:left">
        Purnima Kamath, Tasnim Nishat Islam, Chitralekha Gupta, Lonce Wyse, Suranga Nanayakkara
       </p>
<p style="text-align:left">
<em>
         National University of Singapore, Singapore and Bangladesh University of Engineering and Technology, Bangladesh and Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kamath_NUS_task7_trackB_1</span> <span class="label label-primary">Kamath_NUS_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-KamathNUS2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-KamathNUS2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-KamathNUS2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Kamath_6_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-KamathNUS2023').collapse('show');window.location.hash='#KamathNUS2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-KamathNUS2023" class="panel-collapse collapse" id="collapse-KamathNUS2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE Task-7: StyleGAN2-Based Foley Sound Synthesis
      </h4>
<p style="text-align:left">
<small>
        Purnima Kamath, Tasnim Nishat Islam, Chitralekha Gupta, Lonce Wyse, Suranga Nanayakkara
       </small>
<br/>
<small>
<em>
         National University of Singapore, Singapore and Bangladesh University of Engineering and Technology, Bangladesh and Universitat Pompeu Fabra, Barcelona, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       For the DCASE 2023 Task 7 (Track B), Foley Sound Synthesis, we submit two systems, (1) a StyleGAN conditioned on the class ID, and (2) an ensemble of StyleGANs each trained unconditionally on each class separately. We quantitatively find that both systems out-perform the task 7 baseline models in terms of FAD Scores. Given the high inter-class and intra-class variance in the development datasets, the system conditioned on class ID is able to generate a smooth and a homogeneous latent space indicated by the subjective quality of its generated samples. The unconditionally trained ensemble generates more categorically recognizable samples than system 1, but tends to generate more instances of out-of-distribution or noisy samples.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         StyleGAN2
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         phase gradient heap integration
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         log-magnitude spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time shifting, sound wrapping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         7
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         62010138,376959933 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-KamathNUS2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Kamath_6_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/pkamath2/stylegan2-ada-pytorch" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-KamathNUS2023label" class="modal fade" id="bibtex-KamathNUS2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKamathNUS2023label">
        DCASE Task-7: StyleGAN2-Based Foley Sound Synthesis
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{KamathNUS2023,
    Author = "Kamath, Purnima and Islam, Tasnim Nishat and Gupta, Chitralekha and Wyse, Lonce and Nanayakkara, Suranga",
    title = "DCASE Task-7: StyleGAN2-Based Foley Sound Synthesis",
    institution = "National University of Singapore, Singapore and Bangladesh University of Engineering and Technology, Bangladesh and Universitat Pompeu Fabra, Barcelona, Spain",
    year = "2023",
    month = "June",
    abstract = "For the DCASE 2023 Task 7 (Track B), Foley Sound Synthesis, we submit two systems, (1) a StyleGAN conditioned on the class ID, and (2) an ensemble of StyleGANs each trained unconditionally on each class separately. We quantitatively find that both systems out-perform the task 7 baseline models in terms of FAD Scores. Given the high inter-class and intra-class variance in the development datasets, the system conditioned on class ID is able to generate a smooth and a homogeneous latent space indicated by the subjective quality of its generated samples. The unconditionally trained ensemble generates more categorically recognizable samples than system 1, but tends to generate more instances of out-of-distribution or noisy samples."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="KeunwooGLI2023" style="box-shadow: none">
<div class="panel-heading" id="heading-KeunwooGLI2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Foley Sound Synthesis at the DCASE 2023 Challenge
       </h4>
<p style="text-align:left">
        Keunwoo Choi, Jaekwon Im, Laurie Heller, Brian McFee, Keisuke Imoto, Yuki Okamoto, Mathieu Lagrange, and Shinnosuke Takamichi
       </p>
<p style="text-align:left">
<em>
         Gaudio Lab, Inc., Seoul, South Korea, KAIST and Daejeon, South Korea and Carnegie Mellon University, Pennsylvania, USA and New York University, New York, USA, and Doshisha University, Kyoto, Japan and Ritsumeikan University, Kyoto, Japan and CNRS, Ecole Centrale Nantes, Nantes Universite, Nantes, France and The University of Tokyo, Tokyo, Japan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2023_baseline_task7</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-KeunwooGLI2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-KeunwooGLI2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-KeunwooGLI2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="https://arxiv.org/pdf/2304.12521.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-KeunwooGLI2023').collapse('show');window.location.hash='#KeunwooGLI2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-KeunwooGLI2023" class="panel-collapse collapse" id="collapse-KeunwooGLI2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Foley Sound Synthesis at the DCASE 2023 Challenge
      </h4>
<p style="text-align:left">
<small>
        Keunwoo Choi, Jaekwon Im, Laurie Heller, Brian McFee, Keisuke Imoto, Yuki Okamoto, Mathieu Lagrange, and Shinnosuke Takamichi
       </small>
<br/>
<small>
<em>
         Gaudio Lab, Inc., Seoul, South Korea, KAIST and Daejeon, South Korea and Carnegie Mellon University, Pennsylvania, USA and New York University, New York, USA, and Doshisha University, Kyoto, Japan and Ritsumeikan University, Kyoto, Japan and CNRS, Ecole Centrale Nantes, Nantes Universite, Nantes, France and The University of Tokyo, Tokyo, Japan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       The addition of Foley sound effects during post-production is a common technique used to enhance the perceived acoustic properties of multimedia content. Traditionally, Foley sound has been produced by human Foley artists, which involves manual recording and mixing of sound. However, recent advances in sound synthesis and generative models have generated interest in machine-assisted or automatic Foley synthesis techniques. To promote further research in this area, we have organized a challenge in DCASE 2023: Task 7 - Foley Sound Synthesis. Our challenge aims to provide a standardized evaluation framework that is both rigorous and efficient, allowing for the evaluation of different Foley synthesis systems. Through this challenge, we hope to encourage active participation from the research community and advance the state-of-the-art in automatic Foley synthesis. In this technical report, we provide a detailed overview of the Foley sound synthesis challenge, including task definition, dataset, baseline, evaluation scheme and criteria, and discussion.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         VQ-VAE, PixelSNAIL
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         null
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         null
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         269992 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-KeunwooGLI2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="https://arxiv.org/pdf/2304.12521.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/DCASE2023-Task7-Foley-Sound-Synthesis/dcase2023_task7_baseline" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-KeunwooGLI2023label" class="modal fade" id="bibtex-KeunwooGLI2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKeunwooGLI2023label">
        Foley Sound Synthesis at the DCASE 2023 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{KeunwooGLI2023,
    Author = "Choi, Keunwoo and Im, Jaekwon and Heller, Laurie and McFee, Brian and Imoto, Keisuke and Okamoto, Yuki and Lagrange, Mathieu and Takamichi, Shinnosuke",
    title = "Foley Sound Synthesis at the DCASE 2023 Challenge",
    institution = "Gaudio Lab, Inc., Seoul, South Korea, KAIST and Daejeon, South Korea and Carnegie Mellon University, Pennsylvania, USA and New York University, New York, USA, and Doshisha University, Kyoto, Japan and Ritsumeikan University, Kyoto, Japan and CNRS, Ecole Centrale Nantes, Nantes Universite, Nantes, France and The University of Tokyo, Tokyo, Japan",
    year = "2023",
    month = "June",
    abstract = "The addition of Foley sound effects during post-production is a common technique used to enhance the perceived acoustic properties of multimedia content. Traditionally, Foley sound has been produced by human Foley artists, which involves manual recording and mixing of sound. However, recent advances in sound synthesis and generative models have generated interest in machine-assisted or automatic Foley synthesis techniques. To promote further research in this area, we have organized a challenge in DCASE 2023: Task 7 - Foley Sound Synthesis. Our challenge aims to provide a standardized evaluation framework that is both rigorous and efficient, allowing for the evaluation of different Foley synthesis systems. Through this challenge, we hope to encourage active participation from the research community and advance the state-of-the-art in automatic Foley synthesis. In this technical report, we provide a detailed overview of the Foley sound synthesis challenge, including task definition, dataset, baseline, evaluation scheme and criteria, and discussion."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="LeeMARG2023" style="box-shadow: none">
<div class="panel-heading" id="heading-LeeMARG2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Conditional Foley Sound Synthesis With Limited Data: Two-Stage Data Augmentation Approach With StyleGAN2-ADA
       </h4>
<p style="text-align:left">
        Kyungsu Kim, Jinwoo Lee, Hayoon Kim, Kyogu Lee
       </p>
<p style="text-align:left">
<em>
         Seoul National University Department of Intelligence and Information
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lee_MARG_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-LeeMARG2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-LeeMARG2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-LeeMARG2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Lee_115_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-LeeMARG2023" class="panel-collapse collapse" id="collapse-LeeMARG2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Conditional Foley Sound Synthesis With Limited Data: Two-Stage Data Augmentation Approach With StyleGAN2-ADA
      </h4>
<p style="text-align:left">
<small>
        Kyungsu Kim, Jinwoo Lee, Hayoon Kim, Kyogu Lee
       </small>
<br/>
<small>
<em>
         Seoul National University Department of Intelligence and Information
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report introduces an audio synthesis system designed to tackle the task of Foley Sound Synthesis in the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 challenge. Our proposed system comprises an ensemble of a baseline model and StyleGAN2-ADA. To optimize the system with the limited data without relying on external datasets and pretrained systems, we propose a two-stage data augmentation strategy. This approach involves augmenting input waveforms to expand the size of the training dataset, as well as employing adaptive discriminator augmentation (ADA) to alleviate overfitting of discriminator and ensure stable training. Experimental results demonstrate that our proposed ensemble system achieves an FAD (Fr\'{e}chet Audio Distance) of 5.84 on the evaluation dataset.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         PixelSNAIL,StyleGAN2-ADA,VQ-VAE
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN, Griffin-Lim
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time stretching, time shifting, RoomSimulator, TanhDistortion, resample, time masking, pitch shifting
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         6
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         116202572 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-LeeMARG2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Lee_115_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-LeeMARG2023label" class="modal fade" id="bibtex-LeeMARG2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLeeMARG2023label">
        Conditional Foley Sound Synthesis With Limited Data: Two-Stage Data Augmentation Approach With StyleGAN2-ADA
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{LeeMARG2023,
    Author = "Kim, Kyungsu and Lee, Jinwoo and Kim, Hayoon and Lee, Kyogu",
    title = "Conditional Foley Sound Synthesis With Limited Data: Two-Stage Data Augmentation Approach With StyleGAN2-ADA",
    institution = "Seoul National University Department of Intelligence and Information",
    year = "2023",
    month = "June",
    abstract = "This report introduces an audio synthesis system designed to tackle the task of Foley Sound Synthesis in the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 challenge. Our proposed system comprises an ensemble of a baseline model and StyleGAN2-ADA. To optimize the system with the limited data without relying on external datasets and pretrained systems, we propose a two-stage data augmentation strategy. This approach involves augmenting input waveforms to expand the size of the training dataset, as well as employing adaptive discriminator augmentation (ADA) to alleviate overfitting of discriminator and ensure stable training. Experimental results demonstrate that our proposed ensemble system achieves an FAD (Fr\'{e}chet Audio Distance) of 5.84 on the evaluation dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Leemaum2023" style="box-shadow: none">
<div class="panel-heading" id="heading-Leemaum2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        VIFS: An End-To-End Variational Inference For Foley Sound Synthesis
       </h4>
<p style="text-align:left">
        Junhyeok Lee1, Hyeonuk Nam, Yong-Hwa Park
       </p>
<p style="text-align:left">
<em>
         maum.ai Inc., Republic of Korea and Korea Advanced Institute of Science and Technology, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lee_maum_task7_trackA_1</span> <span class="label label-primary">Lee_maum_task7_trackA_2</span> <span class="label label-primary">Lee_maum_task7_trackA_3</span> <span class="label label-primary">Lee_maum_task7_trackA_4</span> <span class="label label-primary">Lee_maum_task7_trackB_1</span> <span class="label label-primary">Lee_maum_task7_trackB_2</span> <span class="label label-primary">Lee_maum_task7_trackB_3</span> <span class="label label-primary">Lee_maum_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Leemaum2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Leemaum2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Leemaum2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Lee_51_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Leemaum2023').collapse('show');window.location.hash='#Leemaum2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Leemaum2023" class="panel-collapse collapse" id="collapse-Leemaum2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       VIFS: An End-To-End Variational Inference For Foley Sound Synthesis
      </h4>
<p style="text-align:left">
<small>
        Junhyeok Lee1, Hyeonuk Nam, Yong-Hwa Park
       </small>
<br/>
<small>
<em>
         maum.ai Inc., Republic of Korea and Korea Advanced Institute of Science and Technology, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Foley sound synthesis (FSS) is a task to generate a sound for specific conditions. In this work, FSS is defined as a ”category-to-sound” problem, which is generating various sounds for a given category. To solve this diversity problem, we adopt VITS, a text-to-speech (TTS) model with variational inference. In addition, we apply various techniques from speech synthesis including PhaseAug and Avocodo. Different from TTS models which generate short pronunciation from phonemes and a speaker identity, the category-to-sound problem requires to generate diverse sounds just from a category class. To compensate this difference between TTS and category-to- sound while maintaining consistency within each inference, we heavily modified the prior encoder to enhance consistency with posterior latent variables. This introduced additional gaussian on prior encoder which promotes variance within the category. With these modifications, we propose VIFS, variational inference for end-toend Foley sound synthesis, which is able to generate high-quality sounds with diversity.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         Avocodo,GAN,PhaseAug,VAE,VITS,ensemble,flow
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         Gaussian latent variables
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         PhaseAug
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         4
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         92319922,92319922,92319922,369279688,92319922,92319922,92319922,369279688 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Leemaum2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Lee_51_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/junjun3518/vifs" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Leemaum2023label" class="modal fade" id="bibtex-Leemaum2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLeemaum2023label">
        VIFS: An End-To-End Variational Inference For Foley Sound Synthesis
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Leemaum2023,
    Author = "Lee1, Junhyeok and Nam, Hyeonuk and Park, Yong-Hwa",
    title = "VIFS: An End-To-End Variational Inference For Foley Sound Synthesis",
    institution = "maum.ai Inc., Republic of Korea and Korea Advanced Institute of Science and Technology, Republic of Korea",
    year = "2023",
    month = "June",
    abstract = "Foley sound synthesis (FSS) is a task to generate a sound for specific conditions. In this work, FSS is defined as a ”category-to-sound” problem, which is generating various sounds for a given category. To solve this diversity problem, we adopt VITS, a text-to-speech (TTS) model with variational inference. In addition, we apply various techniques from speech synthesis including PhaseAug and Avocodo. Different from TTS models which generate short pronunciation from phonemes and a speaker identity, the category-to-sound problem requires to generate diverse sounds just from a category class. To compensate this difference between TTS and category-to- sound while maintaining consistency within each inference, we heavily modified the prior encoder to enhance consistency with posterior latent variables. This introduced additional gaussian on prior encoder which promotes variance within the category. With these modifications, we propose VIFS, variational inference for end-toend Foley sound synthesis, which is able to generate high-quality sounds with diversity."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="PillayCMU2023" style="box-shadow: none">
<div class="panel-heading" id="heading-PillayCMU2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE Task 7: Foley Sound Synthesis
       </h4>
<p style="text-align:left">
        Ashwin Pillay, Sage Betko, Ari Liloia, Hao Chen, Ankit Shah
       </p>
<p style="text-align:left">
<em>
         Carnegie Mellon University, Pittsburgh, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Pillay_CMU_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-PillayCMU2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-PillayCMU2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-PillayCMU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Pillay_13_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-PillayCMU2023').collapse('show');window.location.hash='#PillayCMU2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-PillayCMU2023" class="panel-collapse collapse" id="collapse-PillayCMU2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE Task 7: Foley Sound Synthesis
      </h4>
<p style="text-align:left">
<small>
        Ashwin Pillay, Sage Betko, Ari Liloia, Hao Chen, Ankit Shah
       </small>
<br/>
<small>
<em>
         Carnegie Mellon University, Pittsburgh, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Foley sound synthesis refers to the creation of realistic, diegetic sound effects for a piece of media, such as film or radio. We propose building a deep learning system for Task 7 of the DCASE 2023 challenge that can generate original mono audio clips belonging to one of seven foley sound categories. Our training dataset consists of 4,850 sound clips from the UrbanSound8K, FSD50K, and BBC Sound Effects datasets. We aim to better the subjective and objective quality of generated sounds by passing as much meaningful information about the input data into latent representations as possible. The primary innovation in our submission is the change from using melspectrograms to using CEmbeddings (combined embeddings), which are input to the VQ-VAE and consist of melspectrograms concatenated with latent representations of audio produced by a pre-trained MERT model. Our submission to track A utilizes a pre-trained MERT model; as such, PixelSNAIL was trained on CEmbeddings. Our submission to track B utilizes PixelSNAIL retrained only on melspectrograms. Our code can be found here: https://github.com/ankitshah009/ foley-sound-synthesis_DCASE_2023.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         PixelSNAIL,VQ-VAE
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time masking, frequency masking
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         3
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         103316216 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-PillayCMU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Pillay_13_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/DCASE2023-Task7-Foley-Sound-Synthesis/dcase2023_task7_baseline" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-PillayCMU2023label" class="modal fade" id="bibtex-PillayCMU2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPillayCMU2023label">
        DCASE Task 7: Foley Sound Synthesis
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{PillayCMU2023,
    Author = "Pillay, Ashwin and Betko, Sage and Liloia, Ari and Chen, Hao and Shah, Ankit",
    title = "DCASE Task 7: Foley Sound Synthesis",
    institution = "Carnegie Mellon University, Pittsburgh, USA",
    year = "2023",
    month = "June",
    abstract = "Foley sound synthesis refers to the creation of realistic, diegetic sound effects for a piece of media, such as film or radio. We propose building a deep learning system for Task 7 of the DCASE 2023 challenge that can generate original mono audio clips belonging to one of seven foley sound categories. Our training dataset consists of 4,850 sound clips from the UrbanSound8K, FSD50K, and BBC Sound Effects datasets. We aim to better the subjective and objective quality of generated sounds by passing as much meaningful information about the input data into latent representations as possible. The primary innovation in our submission is the change from using melspectrograms to using CEmbeddings (combined embeddings), which are input to the VQ-VAE and consist of melspectrograms concatenated with latent representations of audio produced by a pre-trained MERT model. Our submission to track A utilizes a pre-trained MERT model; as such, PixelSNAIL was trained on CEmbeddings. Our submission to track B utilizes PixelSNAIL retrained only on melspectrograms. Our code can be found here: https://github.com/ankitshah009/ foley-sound-synthesis\_DCASE\_2023."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="QianbinBIT2023" style="box-shadow: none">
<div class="panel-heading" id="heading-QianbinBIT2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Auto-Bit for DCASE2023 Task7 Technical Reports: Assemble System of BitDiffusion and PixelSNAIL
       </h4>
<p style="text-align:left">
        Anbin Qi
       </p>
<p style="text-align:left">
<em>
         School Information and Electronics, Beijing Institute of Technology, Beijing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Qianbin_BIT_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-QianbinBIT2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-QianbinBIT2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-QianbinBIT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Qianbin_41_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-QianbinBIT2023" class="panel-collapse collapse" id="collapse-QianbinBIT2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Auto-Bit for DCASE2023 Task7 Technical Reports: Assemble System of BitDiffusion and PixelSNAIL
      </h4>
<p style="text-align:left">
<small>
        Anbin Qi
       </small>
<br/>
<small>
<em>
         School Information and Electronics, Beijing Institute of Technology, Beijing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This paper is a technical report on DCASE TASK7, which proposes using different methods and models for sound synthesis tasks in different scene events. For dogbark and sneeze cough, a non autoregressive model based on conditional generation bit-diffusion was used for sound synthesis. For the other five types of sounds, a autoregressive model based PixelSnail was used.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         VQ-VAE, PixelSNAIL, Bit-diffusion
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         2
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         112857385 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-QianbinBIT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Qianbin_41_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-QianbinBIT2023label" class="modal fade" id="bibtex-QianbinBIT2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexQianbinBIT2023label">
        Auto-Bit for DCASE2023 Task7 Technical Reports: Assemble System of BitDiffusion and PixelSNAIL
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{QianbinBIT2023,
    Author = "Qi, Anbin",
    title = "Auto-Bit for DCASE2023 Task7 Technical Reports: Assemble System of BitDiffusion and PixelSNAIL",
    institution = "School Information and Electronics, Beijing Institute of Technology, Beijing, China",
    year = "2023",
    month = "June",
    abstract = "This paper is a technical report on DCASE TASK7, which proposes using different methods and models for sound synthesis tasks in different scene events. For dogbark and sneeze cough, a non autoregressive model based on conditional generation bit-diffusion was used for sound synthesis. For the other five types of sounds, a autoregressive model based PixelSnail was used."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="QianXuBIT2023" style="box-shadow: none">
<div class="panel-heading" id="heading-QianXuBIT2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        From Noise To Sound: Audio Synthesis Via Diffusion Models
       </h4>
<p style="text-align:left">
        Haojie Zhang, Kun Qian, Lin Shen, Lujundong Li, Kele Xu, Bin Hu
       </p>
<p style="text-align:left">
<em>
         Key Laboratory of Brain Health Intelligent Evaluation and Intervention, Ministry of Education (Beijing Institute of Technology), P. R. China, School of Medical Technology, Beijing Institute of Technology, P. R. China, National University of Defense Technology, P. R. China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">QianXu_BIT_NUDT_task7_trackB_1</span> <span class="label label-primary">QianXu_BIT_NUDT_task7_trackB_2</span> <span class="label label-primary">QianXu_BIT_NUDT_task7_trackB_3</span> <span class="label label-primary">QianXu_BIT_NUDT_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-QianXuBIT2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-QianXuBIT2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-QianXuBIT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_QianXu_86_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-QianXuBIT2023" class="panel-collapse collapse" id="collapse-QianXuBIT2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       From Noise To Sound: Audio Synthesis Via Diffusion Models
      </h4>
<p style="text-align:left">
<small>
        Haojie Zhang, Kun Qian, Lin Shen, Lujundong Li, Kele Xu, Bin Hu
       </small>
<br/>
<small>
<em>
         Key Laboratory of Brain Health Intelligent Evaluation and Intervention, Ministry of Education (Beijing Institute of Technology), P. R. China, School of Medical Technology, Beijing Institute of Technology, P. R. China, National University of Defense Technology, P. R. China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our submission system for DCASE2023 Task 7: Foley Sound Synthesis (Track B). A Sound Pixelate Diffuse model is proposed to realize foley sound synthesis. The model includes data format conversion and synthesising audio through the diffusion model. The Synthesised audio are evaluated on DCASE2023 Task 7 Eval FAD evaluation set and the best FAD score of all categories is 8.429.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         wavelet domain denoise
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         113668609,113668609,113668609,113668609 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-QianXuBIT2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_QianXu_86_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-QianXuBIT2023label" class="modal fade" id="bibtex-QianXuBIT2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexQianXuBIT2023label">
        From Noise To Sound: Audio Synthesis Via Diffusion Models
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{QianXuBIT2023,
    Author = "Zhang, Haojie and Qian, Kun and Shen, Lin and Li, Lujundong and Xu, Kele and Hu, Bin",
    title = "From Noise To Sound: Audio Synthesis Via Diffusion Models",
    institution = "Key Laboratory of Brain Health Intelligent Evaluation and Intervention, Ministry of Education (Beijing Institute of Technology), P. R. China, School of Medical Technology, Beijing Institute of Technology, P. R. China, National University of Defense Technology, P. R. China",
    year = "2023",
    month = "June",
    abstract = "In this technical report, we describe our submission system for DCASE2023 Task 7: Foley Sound Synthesis (Track B). A Sound Pixelate Diffuse model is proposed to realize foley sound synthesis. The model includes data format conversion and synthesising audio through the diffusion model. The Synthesised audio are evaluated on DCASE2023 Task 7 Eval FAD evaluation set and the best FAD score of all categories is 8.429."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="ScheiblerLINE2023" style="box-shadow: none">
<div class="panel-heading" id="heading-ScheiblerLINE2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Class-Conditioned Latent Diffusion Model For DCASE 2023 Foley Sound Synthesis Challenge
       </h4>
<p style="text-align:left">
        Robin Scheibler, Takuya Hasumi, Yusuke Fujita, Tatsuya Komatsu, Ryuichi Yamamoto, Kentaro Tachibana
       </p>
<p style="text-align:left">
<em>
         LINE Corporation, Tokyo, Japan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Scheibler_LINE_task7_trackA_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-ScheiblerLINE2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-ScheiblerLINE2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-ScheiblerLINE2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Scheibler_96_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-ScheiblerLINE2023" class="panel-collapse collapse" id="collapse-ScheiblerLINE2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Class-Conditioned Latent Diffusion Model For DCASE 2023 Foley Sound Synthesis Challenge
      </h4>
<p style="text-align:left">
<small>
        Robin Scheibler, Takuya Hasumi, Yusuke Fujita, Tatsuya Komatsu, Ryuichi Yamamoto, Kentaro Tachibana
       </small>
<br/>
<small>
<em>
         LINE Corporation, Tokyo, Japan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our submission to DCASE 2023 Task7: Foley sound synthesis challenge. We use a latent diffusion model (LDM) that generates a latent representation of audio conditioned on a specified audio class, a variational autoencoder that converts the latent representation to a mel-spectrogram, and a universal neural vocoder based on HIFI-GAN that reconstructs a natural waveform from the mel-spectrogram. We trained the LDM using development set with its audio class indices as conditioners for generating class-specific latent representations.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         VQ-VAE,diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         log-mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         977116210 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-ScheiblerLINE2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Scheibler_96_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-ScheiblerLINE2023label" class="modal fade" id="bibtex-ScheiblerLINE2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexScheiblerLINE2023label">
        Class-Conditioned Latent Diffusion Model For DCASE 2023 Foley Sound Synthesis Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{ScheiblerLINE2023,
    Author = "Scheibler, Robin and Hasumi, Takuya and Fujita, Yusuke and Komatsu, Tatsuya and Yamamoto, Ryuichi and Tachibana, Kentaro",
    title = "Class-Conditioned Latent Diffusion Model For DCASE 2023 Foley Sound Synthesis Challenge",
    institution = "LINE Corporation, Tokyo, Japan",
    year = "2023",
    month = "June",
    abstract = "This report describes our submission to DCASE 2023 Task7: Foley sound synthesis challenge. We use a latent diffusion model (LDM) that generates a latent representation of audio conditioned on a specified audio class, a variational autoencoder that converts the latent representation to a mel-spectrogram, and a universal neural vocoder based on HIFI-GAN that reconstructs a natural waveform from the mel-spectrogram. We trained the LDM using development set with its audio class indices as conditioners for generating class-specific latent representations."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="WendnerJKU2023" style="box-shadow: none">
<div class="panel-heading" id="heading-WendnerJKU2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Audio Diffusion For Foley Sound Synthesis
       </h4>
<p style="text-align:left">
        Timo Wendner, Patricia Hu, Tara Jadidi, Alexander Neuhauser
       </p>
<p style="text-align:left">
<em>
         Johannes Kepler University, Linz, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Wendner_JKU_task7_trackB_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-WendnerJKU2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-WendnerJKU2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-WendnerJKU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Wendner_111_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-WendnerJKU2023').collapse('show');window.location.hash='#WendnerJKU2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-WendnerJKU2023" class="panel-collapse collapse" id="collapse-WendnerJKU2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Audio Diffusion For Foley Sound Synthesis
      </h4>
<p style="text-align:left">
<small>
        Timo Wendner, Patricia Hu, Tara Jadidi, Alexander Neuhauser
       </small>
<br/>
<small>
<em>
         Johannes Kepler University, Linz, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approach for Task 7 (Foley Sound Synthesis), Track B (using no external resources other than the ones provided) of the DCASE2023 Challenge. This work was carried out as part of an elective course in the Artificial Intelligence curriculum at Johannes Kepler University Linz by a student group. We use an ensemble of U-Net based diffusion models for waveform generation in seven predefined sound categories. We apply gain reduction to normalize and time shifting to augment the provided training data and test different noise schedulers and U-Net architectures. Applying different training strategies, we achieve competitive results for the majority of the sound classes while being more parameter efficient and allowing end-to-end generation on audio waveforms. Evaluated on the task's evaluation metric, i.e., the mean FAD score over all classes, we achieve a final score of 12.42 as compared to the score of the challenge baseline model of 9.68.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         diffusion model,ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         gain reduction, time shifting
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         7
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         7167405 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-WendnerJKU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Wendner_111_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/timowendner/AudioDiffusion" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-WendnerJKU2023label" class="modal fade" id="bibtex-WendnerJKU2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexWendnerJKU2023label">
        Audio Diffusion For Foley Sound Synthesis
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{WendnerJKU2023,
    Author = "Wendner, Timo and Hu, Patricia and Jadidi, Tara and Neuhauser, Alexander",
    title = "Audio Diffusion For Foley Sound Synthesis",
    institution = "Johannes Kepler University, Linz, Austria",
    year = "2023",
    month = "June",
    abstract = "This technical report describes our approach for Task 7 (Foley Sound Synthesis), Track B (using no external resources other than the ones provided) of the DCASE2023 Challenge. This work was carried out as part of an elective course in the Artificial Intelligence curriculum at Johannes Kepler University Linz by a student group. We use an ensemble of U-Net based diffusion models for waveform generation in seven predefined sound categories. We apply gain reduction to normalize and time shifting to augment the provided training data and test different noise schedulers and U-Net architectures. Applying different training strategies, we achieve competitive results for the majority of the sound classes while being more parameter efficient and allowing end-to-end generation on audio waveforms. Evaluated on the task's evaluation metric, i.e., the mean FAD score over all classes, we achieve a final score of 12.42 as compared to the score of the challenge baseline model of 9.68."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="XieSJTU2023" style="box-shadow: none">
<div class="panel-heading" id="heading-XieSJTU2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        The X-LANCE System For DCASE2023 Challenge Task 7: Foley Sound Synthesis Track B
       </h4>
<p style="text-align:left">
        Zeyu Xie, Xuenan Xu, Baihan Li, Mengyue Wu, Kai Yu
       </p>
<p style="text-align:left">
<em>
         MoE Key Lab of Artificial Intelligence X-LANCE Lab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Xie_SJTU_task7_trackB_1</span> <span class="label label-primary">Xie_SJTU_task7_trackB_2</span> <span class="label label-primary">Xie_SJTU_task7_trackB_3</span> <span class="label label-primary">Xie_SJTU_task7_trackB_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-XieSJTU2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-XieSJTU2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-XieSJTU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Xie_70_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-XieSJTU2023" class="panel-collapse collapse" id="collapse-XieSJTU2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       The X-LANCE System For DCASE2023 Challenge Task 7: Foley Sound Synthesis Track B
      </h4>
<p style="text-align:left">
<small>
        Zeyu Xie, Xuenan Xu, Baihan Li, Mengyue Wu, Kai Yu
       </small>
<br/>
<small>
<em>
         MoE Key Lab of Artificial Intelligence X-LANCE Lab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes the system submitted to the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 challenge Task 7: foley sound synthesis track B. We first train a VQVAE model to learn the discrete representation of the audio spectrogram. Then an auto-regressive model is trained to predict discrete tokens based on input conditions. Finally, a trained vocoder converts the generated spectrogram into a waveform, where the spectrogram is restored from predicted tokens by VQ-VAE decoder. To achieve higher accuracy, fidelity and diversity, we introduce some training schemes, including (1) a discriminator model to filter audio; (2) mixup method for data augmentation; (3) clustering methods for better training. Our best system achieved a FAD score of 6.99 averaging on all categories.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         Transformer,TransformerDecoder,TrnsformerEncder Discriminator,VQ-VAE
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         3
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         28224194,40843458,44037827,44037827 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-XieSJTU2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Xie_70_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-XieSJTU2023label" class="modal fade" id="bibtex-XieSJTU2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexXieSJTU2023label">
        The X-LANCE System For DCASE2023 Challenge Task 7: Foley Sound Synthesis Track B
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{XieSJTU2023,
    Author = "Xie, Zeyu and Xu, Xuenan and Li, Baihan and Wu, Mengyue and Yu, Kai",
    title = "The X-LANCE System For DCASE2023 Challenge Task 7: Foley Sound Synthesis Track B",
    institution = "MoE Key Lab of Artificial Intelligence X-LANCE Lab, Department of Computer Science and Engineering AI Institute, Shanghai Jiao Tong University, Shanghai, China",
    year = "2023",
    month = "June",
    abstract = "This report describes the system submitted to the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 challenge Task 7: foley sound synthesis track B. We first train a VQVAE model to learn the discrete representation of the audio spectrogram. Then an auto-regressive model is trained to predict discrete tokens based on input conditions. Finally, a trained vocoder converts the generated spectrogram into a waveform, where the spectrogram is restored from predicted tokens by VQ-VAE decoder. To achieve higher accuracy, fidelity and diversity, we introduce some training schemes, including (1) a discriminator model to filter audio; (2) mixup method for data augmentation; (3) clustering methods for better training. Our best system achieved a FAD score of 6.99 averaging on all categories."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="YiSURREY2023" style="box-shadow: none">
<div class="panel-heading" id="heading-YiSURREY2023" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Latent Diffusion Model Based Foley Sound Generation System For DCASE Challenge 2023 Task 7
       </h4>
<p style="text-align:left">
        Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Mark D. Plumbley, Wenwu Wang
       </p>
<p style="text-align:left">
<em>
         University of Surrey, Guildford, United Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Yi_SURREY_task7_trackA_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-YiSURREY2023" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-YiSURREY2023" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-YiSURREY2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Yi_67_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-YiSURREY2023').collapse('show');window.location.hash='#YiSURREY2023';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-YiSURREY2023" class="panel-collapse collapse" id="collapse-YiSURREY2023" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Latent Diffusion Model Based Foley Sound Generation System For DCASE Challenge 2023 Task 7
      </h4>
<p style="text-align:left">
<small>
        Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Mark D. Plumbley, Wenwu Wang
       </small>
<br/>
<small>
<em>
         University of Surrey, Guildford, United Kingdom
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Foley sound generation aims to synthesise the background sound for multimedia content, which involves computationally modelling sound effects with specialized techniques. In this work, we proposed a diffusion-based generative model for DCASE 2023 challenge task 7: Foley Sound Synthesis. The proposed system is based on AudioLDM, which is a diffusion-based text-to-audio generation model. To alleviate the data scarcity of task 7 training set, our model is initially trained with large-scale datasets and downstream into this DCASE task via transfer learning. We have observed that the feature extracted by the encoder can significantly affect the performance of the generation model. Hence, we improve the results by leveraging the input label with related text embedding features obtained by a large language model, i.e.,contrastive language-audio pretraining (CLAP). In addition, we utilize a filtering strategy to further refine the output, i.e. by selecting the best results from the candidate clips generated in terms of the similarity score between the sound and target labels. The overall system achieves a Fr\'{e}chet audio distance (FAD) score of 4.765 on average among all seven different classes, outperforming the baseline system which achieves a FAD score of 9.7.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         System input
        </td>
<td>
         sound event label
        </td>
</tr>
<tr>
<td class="col-md-3">
         Machine learning method
        </td>
<td>
         VQ-VAE,diffusion model
        </td>
</tr>
<tr>
<td class="col-md-3">
         Phase reconstruction method
        </td>
<td>
         HiFi-GAN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Acoustic features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Subsystem count
        </td>
<td>
         2
        </td>
</tr>
<tr>
<td class="col-md-3">
         System comprexity
        </td>
<td>
         1173847474 parameters
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-YiSURREY2023" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2023/technical_reports/DCASE2023_Yi_67_t7.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/yyua8222/Dcase2023_task7" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-YiSURREY2023label" class="modal fade" id="bibtex-YiSURREY2023" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexYiSURREY2023label">
        Latent Diffusion Model Based Foley Sound Generation System For DCASE Challenge 2023 Task 7
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{YiSURREY2023,
    Author = "Yuan, Yi and Liu, Haohe and Liu, Xubo and Kang, Xiyuan and Plumbley, Mark D. and Wang, Wenwu",
    title = "Latent Diffusion Model Based Foley Sound Generation System For DCASE Challenge 2023 Task 7",
    institution = "University of Surrey, Guildford, United Kingdom",
    year = "2023",
    month = "June",
    abstract = "Foley sound generation aims to synthesise the background sound for multimedia content, which involves computationally modelling sound effects with specialized techniques. In this work, we proposed a diffusion-based generative model for DCASE 2023 challenge task 7: Foley Sound Synthesis. The proposed system is based on AudioLDM, which is a diffusion-based text-to-audio generation model. To alleviate the data scarcity of task 7 training set, our model is initially trained with large-scale datasets and downstream into this DCASE task via transfer learning. We have observed that the feature extracted by the encoder can significantly affect the performance of the generation model. Hence, we improve the results by leveraging the input label with related text embedding features obtained by a large language model, i.e.,contrastive language-audio pretraining (CLAP). In addition, we utilize a filtering strategy to further refine the output, i.e. by selecting the best results from the candidate clips generated in terms of the similarity score between the sound and target labels. The overall system achieves a Fr\'{e}chet audio distance (FAD) score of 4.765 on average among all seven different classes, outperforming the baseline system which achieves a FAD score of 9.7."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>