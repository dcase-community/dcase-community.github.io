<!DOCTYPE html><html lang="en">
<head>
    <title>Sound event detection in synthetic audio - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2016/task-sound-event-detection-in-synthetic-audio">
        <meta name="author" content="Toni Heittola" />
        <meta name="description" content="Challenge has ended. Full results for this task can be found here Description This task will focus on event detection of office sounds in synthetic mixtures. This task will focus on event detection of overlapping office sounds in synthetic mixtures. By using synthetic mixtures in testing, this task will study …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2016</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2016/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-events text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-audio-tagging" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-tags text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-audio-tagging"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-audio-tagging-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2016/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2016/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2016/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2016/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/tiles-01.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-synthetic fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Events</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 2</span></span><img src="../images/logos/dcase/dcase2016_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Sound event detection <br>in synthetic audio</h1><hr class="small right bold"><span class="subheading">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Emmanouil Benetos" class="img img-circle" src="/images/person/emmanouil_benetos.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Emmanouil Benetos</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://c4dm.eecs.qmul.ac.uk/">
                                Queen Mary University of London
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Mathieu Lagrange" class="img img-circle" src="/images/person/mathieu_lagrange_.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Mathieu Lagrange</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.irccyn.ec-nantes.fr/en/research-teams/adtsi">
                                IRCCYN
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Grégoire Lafay" class="img img-circle" src="/images/person/default.png" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Grégoire Lafay</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="http://www.irccyn.ec-nantes.fr/en/research-teams/adtsi">
                                IRCCYN
                                </a>
</p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a></li>
<li><a href="#audio-dataset">Audio dataset</a>
<ul>
<li><a href="#recording-and-annotation-procedure">Recording and annotation procedure</a></li>
<li><a href="#challenge-setup">Challenge setup</a></li>
<li><a href="#download">Download</a></li>
</ul>
</li>
<li><a href="#submission">Submission</a></li>
<li><a href="#task-rules">Task rules</a></li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#baseline-system">Baseline system</a>
<ul>
<li><a href="#matlab-implementation">Matlab implementation</a></li>
<li><a href="#baseline-results-for-development-set">Baseline results for development set</a></li>
</ul>
</li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="alert alert-info">
<strong>Challenge has ended.</strong> Full results for this task can be found <a class="btn btn-default btn-xs" href="/challenge2016/task-sound-event-detection-in-synthetic-audio-results">here <i class="fa fa-caret-right"></i></a>
</p>
<h1 id="description">Description</h1>
<p>This task will focus on event detection of office sounds in synthetic mixtures. This task will focus on event detection of overlapping office sounds in synthetic mixtures. By using synthetic mixtures in testing, this task will study the behaviour of tested algorithms when facing different levels of complexity (noise, polyphony), with the added benefit of a very accurate ground truth.</p>
<figure>
<div class="row-fluid row-centered">
<div class="col-xs-10 col-md-5 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2016/task3_overview.png"/>
<figcaption>Figure 1: Overview of sound event detection system.</figcaption>
</div>
</div>
</figure>
<h1 id="audio-dataset">Audio dataset</h1>
<p>Training material for this task consists of isolated sound events for each class and synthetic mixtures of the same examples in multiple SNR and event density conditions. The participants are allowed to use any combination of them for training their system. The test data will consist of synthetic mixtures of (source-independent) sound examples at various SNR levels, event density conditions and polyphony.</p>
<p>The provided sound event categories are: (11)</p>
<ul>
<li>Clearing throat</li>
<li>Coughing</li>
<li>Door knock</li>
<li>Door slam</li>
<li>Drawer</li>
<li>Human laughter</li>
<li>Keyboard</li>
<li>Keys (put on table)</li>
<li>Page turning</li>
<li>Phone ringing</li>
<li>Speech</li>
</ul>
<p>There will be 20 samples provided for each sound event class in the training set, plus a development set consisting of 18 minutes of synthetic mixture material in 2 minute length audio files. The test set will be provided close to the challenge deadline.</p>
<h2 id="recording-and-annotation-procedure">Recording and annotation procedure</h2>
<p>Audio is provided by IRCCYN, École Centrale de Nantes. The material was recorded in a calm environment, using the shotgun microphone <a href="http://www.audio-technica.com/cms/wired_mics/0576da91f00c03db/">AT8035</a> connected to a <a href="https://www.zoom-na.com/products/field-video-recording/field-recording/zoom-h4n-handy-recorder">ZOOM H4n</a> recorder. Audio files are sampled at 44.1kHz and are monophonic. Parameters controlling the synthesized material include the event-to-background ratio (EBR) with values -6, 0, 6 dB, the presence/absence of overlapping events (monophonic/polyphonic scene), as well as the number of events per class. Isolated examples in the training set will be annotated with start time, end time and event label for all sound events, while for the synthetic mixtures annotations are provided automatically by the event sequence synthesizer.</p>
<h2 id="challenge-setup">Challenge setup</h2>
<p>Task 2 consists of two public subsets: a <strong>training dataset</strong> and a <strong>development dataset</strong>. The training dataset consists of 20 isolated sound segments per event class. The development dataset consists of 18 2min recordings, in various noise and event density conditions (see the README.txt file in the dataset folder for more details).</p>
<p>Participants are <strong>not allowed</strong> to use external data for system development. Manipulation of provided data <strong>is allowed</strong>. Participants are allowed to use any combination of the training and development datasets for training their systems.</p>
<h2 id="download">Download</h2>
<p>** Development dataset **</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2016_task2_train_dev" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2016_task2_train_dev" target="_blank">
<span style="font-size:20px;">Task 2, <strong>train and development datasets</strong> <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(120 MB)</span>
<br/>
</div>
</div>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://archive.org/details/dcase2016_task2_test_public" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://archive.org/details/dcase2016_task2_test_public" target="_blank">
<span style="font-size:20px;">Task 2, <strong>evaluation dataset</strong> <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(314 MB)</span>
<br/>
</div>
</div>
<p><br/></p>
<h1 id="submission">Submission</h1>
<p>Detailed information for the challenge submission can found from <a href="/challenge2016/submission">submission page</a>. One should submit single .txt file per evaluated audio recording. The output file should contain a list of detected events, specified by the onset, offset and the event ID separated by a tab. Format:</p>
<div class="highlight"><pre><span></span><code><span class="o">[</span><span class="n">event onset in seconds (float)</span><span class="o">][</span><span class="n">tab</span><span class="o">][</span><span class="n">event offset in seconds (float)</span><span class="o">][</span><span class="n">tab</span><span class="o">][</span><span class="n">event ID (string)</span><span class="o">]</span>
</code></pre></div>
<p>Example file</p>
<div class="highlight"><pre><span></span><code><span class="mf">1.387392290</span><span class="w">    </span><span class="mf">3.262403627</span><span class="w">    </span><span class="n">pageturn</span>
<span class="mf">5.073560090</span><span class="w">    </span><span class="mf">5.793378684</span><span class="w">    </span><span class="n">knock</span>
<span class="mf">...</span>
</code></pre></div>
<p>There should be no additional tab characters anywhere, and there should be no whitespace added after the label, just the newline.
The 11 event IDs to be used for the .txt output are: <code>clearthroat</code>, <code>cough</code>, <code>doorslam</code>, <code>drawer</code>, <code>keyboard</code>, <code>keys</code>, <code>knock</code>, <code>laughter</code>, <code>pageturn</code>, <code>phone</code>, <code>speech</code>.</p>
<h1 id="task-rules">Task rules</h1>
<ul>
<li>Only the provided development dataset can be used to train the submitted system.</li>
<li>The development dataset can be augmented only by mixing data sampled from a pdf; use of real recordings is forbidden.</li>
<li>The evaluation dataset cannot be used to train the submitted system; the use of statistics about the evaluation dataset in the decision making is also forbidden.</li>
<li>Technical report with sufficient description of the system has to be submitted along with the system outputs.</li>
</ul>
<p>More information on <a href="/challenge2016/submission">submission process</a>.</p>
<h1 id="evaluation">Evaluation</h1>
<p>Tasks 2 and 3 will use the same metrics. The main metric for the challenge will be <em>Total error rate ER</em>. Error rate will be evaluated in one-second segments over the entire test set. Ranking of submitted systems will be done using this metric. We will also use the onset-only event-based F-measure (with 200ms tolerance) as an additional metric.</p>
<p>Detailed description of metrics used can be found <a href="/challenge2016/metrics">here</a>.</p>
<p>Code for evaluation is available with the baseline system. Use classes:</p>
<ul>
<li><code>metrics/DCASE2016_EventDetection_SegmentBasedMetrics.m</code></li>
<li><code>metrics/DCASE2016_EventDetection_EventBasedMetrics.m</code></li>
</ul>
<h1 id="results">Results</h1>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="segment_based_F1_overall_eval" data-scatter-y="segment_based_ER_overall_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="segment_based_ER_overall_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true" rowspan="2">Rank</th>
<th class="sep-left-cell" colspan="4">Submission Information</th>
<th class="sep-left-cell" colspan="2">Segment-based (overall)</th>
</tr>
<tr>
<th class="sm-cell" data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell" data-field="corresponding_author" data-sortable="false">
                Author
            </th>
<th class="sm-cell" data-field="corresponding_affiliation" data-sortable="false">
                Affiliation
            </th>
<th class="sep-left-cell text-center" data-field="external_anchor" data-sortable="false" data-value-type="url">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_ER_overall_eval" data-reversed="true" data-sortable="true" data-value-type="float4">
                ER
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="segment_based_F1_overall_eval" data-sortable="true" data-value-type="float1-percentage">
                F1
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Choi_task2_1</td>
<td>Inkyu Choi</td>
<td>Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, South Korea</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Choi2016</td>
<td>0.3660</td>
<td>78.7</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2016 baseline</td>
<td>Emmanouil Benetos</td>
<td>Queen Mary University of London, London, United Kingdom</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Benetos2016</td>
<td>0.8933</td>
<td>37.0</td>
</tr>
<tr>
<td></td>
<td>Giannoulis_task2_1</td>
<td>Panagiotis Giannoulis</td>
<td>School of ECE, National Technical University of Athens, Athens, Greece; Athena Research and Innovation Center, Maroussi, Greece</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Giannoulis2016</td>
<td>0.6774</td>
<td>55.8</td>
</tr>
<tr>
<td></td>
<td>Gutierrez_task2_1</td>
<td>J.M. Gutiérrez-Arriola</td>
<td>Escuela Técnica Superior de Ingeniería y Sistemas de Telecomunicacíon, Universidad Politécnica de Madrid, Madrid, Spain</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Gutirrez-Arriola2016</td>
<td>2.0870</td>
<td>25.0</td>
</tr>
<tr>
<td></td>
<td>Hayashi_task2_1</td>
<td>Tomoki Hayashi</td>
<td>Nagoya University, Nagoya, Japan</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Hayashi2016</td>
<td>0.4082</td>
<td>78.1</td>
</tr>
<tr>
<td></td>
<td>Hayashi_task2_2</td>
<td>Tomoki Hayashi</td>
<td>Nagoya University, Nagoya, Japan</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Hayashi2016</td>
<td>0.4958</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Komatsu_task2_1</td>
<td>Tatsuya Komatsu</td>
<td>Data Science Research Laboratories, NEC Corporation, Kawasaki, Japan</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Komatsu2016</td>
<td>0.3307</td>
<td>80.2</td>
</tr>
<tr>
<td></td>
<td>Kong_task2_1</td>
<td>Qiuqiang Kong</td>
<td>Centre for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Kong2016</td>
<td>3.5464</td>
<td>12.6</td>
</tr>
<tr>
<td></td>
<td>Phan_task2_1</td>
<td>Huy Phan</td>
<td>Institute for Signal Processing, University of Luebeck, Luebeck, Germany; Graduate School for Computing in Medicine and Life Sciences, University of Luebeck, Luebeck, Germany</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Phan2016</td>
<td>0.5901</td>
<td>64.8</td>
</tr>
<tr>
<td></td>
<td>Pikrakis_task2_1</td>
<td>Aggelos Pikrakis</td>
<td>Department of Informatics, University of Piraeus, Piraeus, Greece</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Pikrakis2016</td>
<td>0.7499</td>
<td>37.4</td>
</tr>
<tr>
<td></td>
<td>Vu_task2_1</td>
<td>Toan H. Vu</td>
<td>Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan</td>
<td>task-sound-event-detection-in-synthetic-audio-results#Vu2016</td>
<td>0.8979</td>
<td>52.8</td>
</tr>
</tbody>
</table>
<p><br/></p>
<p>Complete results and technical reports can be found at <a class="btn btn-primary" href="/challenge2016/task-sound-event-detection-in-synthetic-audio-results">Task 2 result page</a></p>
<h1 id="baseline-system">Baseline system</h1>
<p>A baseline system for the task is provided. The system is meant to implement a basic approach for detecting overlapping acoustic events, and provide some comparison point for the participants while developing their systems.</p>
<p>The baseline system is based on supervised <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">non-negative matrix factorization (NMF)</a>, and uses a dictionary of spectral templates for performing detection, which is extracted during the training phase. The output of the NMF system is a non-binary matrix denoting event activation, which is post-processed into a list of detected events.</p>
<p>The baseline system provides also reference implementation of the evaluation metrics (provided by Toni Heittola). The baseline system is provided for Matlab.</p>
<h2 id="matlab-implementation">Matlab implementation</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://code.soundsoftware.ac.uk/projects/dcase-2016-challenge-task-2-baseline-system" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-info"></i>
<i class="fa fa-gears fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://code.soundsoftware.ac.uk/projects/dcase-2016-challenge-task-2-baseline-system" target="_blank">
<span style="font-size:20px;">DCASE2016 Task 2 Matlab baseline, repository <i class="fa fa-download"></i></span>
</a>
<br/>
<span class="text-muted">
                
                version 1.0.2
                
                
                (.zip)
                
                </span>
</div>
</div>
<p><br/></p>
<h2 id="baseline-results-for-development-set">Baseline results for development set</h2>
<p><em>System parameters</em></p>
<ul>
<li>Input: variable-Q transform spectrogram (60 bins/octave, 10ms step)</li>
<li>NMF with beta-divergence (30 iterations, beta=0.6, activation threshold=1.0)</li>
<li>Postprocessing: 90ms median filter span, up to 5 concurrent events, 60ms minimum event duration</li>
</ul>
<div class="table-responsive col-md-8">
<table class="table table-striped">
<caption>Sound event detection results.</caption>
<thead>
<tr>
<th colspan="2">Segment-based overall metrics</th>
<th colspan="1" style="border-left:2px solid #DDD">Event-based overall metrics</th>
</tr>
<tr>
<th class="col-md-2">ER</th>
<th class="col-md-2">F-score</th>
<th class="col-md-2" style="border-left:2px solid #DDD">F-score (onset-only)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.7859</td>
<td>41.6 %</td>
<td style="border-left:2px solid #DDD">30.3 %</td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h1 id="citation">Citation</h1>
<p>When citing <strong>challenge task</strong> and <strong>results</strong> please cite the following papers:</p>
<div class="btex-item" data-item="Mesaros2018_TASLP" data-source="content/data/challenge2016/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Mesaros2018_TASLP"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            A. Mesaros, T. Heittola, E. Benetos, P. Foster, M. Lagrange, T. Virtanen, and M. D. Plumbley.
<em>Detection and classification of acoustic scenes and events: outcome of the DCASE 2016 challenge.</em>
<em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 26(2):379–393, Feb 2018.
<a href="https://doi.org/10.1109/TASLP.2017.2778423">doi:10.1109/TASLP.2017.2778423</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://trepo.tuni.fi//bitstream/handle/10024/126402/dcase2016_taslp.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" class="panel-collapse collapse" id="collapseMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" role="tabpanel">
<h4>Detection and Classification of Acoustic Scenes and Events: Outcome of the DCASE 2016 Challenge</h4>
<h5>Abstract</h5>
<p class="text-justify">Public evaluation campaigns and datasets promote active development in target research areas, allowing direct comparison of algorithms. The second edition of the challenge on detection and classification of acoustic scenes and events (DCASE 2016) has offered such an opportunity for development of the state-of-the-art methods, and succeeded in drawing together a large number of participants from academic and industrial backgrounds. In this paper, we report on the tasks and outcomes of the DCASE 2016 challenge. The challenge comprised four tasks: acoustic scene classification, sound event detection in synthetic audio, sound event detection in real-life audio, and domestic audio tagging. We present each task in detail and analyze the submitted systems in terms of design and performance. We observe the emergence of deep learning as the most popular classification method, replacing the traditional approaches based on Gaussian mixture models and support vector machines. By contrast, feature representations have not changed substantially throughout the years, as mel frequency-based representations predominate in all tasks. The datasets created for and used in DCASE 2016 are publicly available and are a valuable resource for further research.</p>
<h5>Keywords</h5>
<p class="text-justify">Acoustics;Event detection;Hidden Markov models;Speech;Speech processing;Tagging;Acoustic scene classification;audio datasets;pattern recognition;sound event detection</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://trepo.tuni.fi//bitstream/handle/10024/126402/dcase2016_taslp.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71label" class="modal fade" id="bibtexMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexMesaros2018_TASLP56c46ce96c7c4f77bd945011f6884a71label">Detection and Classification of Acoustic Scenes and Events: Outcome of the DCASE 2016 Challenge</h4>
</div>
<div class="modal-body">
<pre>@article{Mesaros2018_TASLP,
    author = "Mesaros, A. and Heittola, T. and Benetos, E. and Foster, P. and Lagrange, M. and Virtanen, T. and Plumbley, M. D.",
    journal = "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    title = "Detection and Classification of Acoustic Scenes and Events: Outcome of the {DCASE} 2016 Challenge",
    year = "2018",
    volume = "26",
    number = "2",
    pages = "379--393",
    abstract = "Public evaluation campaigns and datasets promote active development in target research areas, allowing direct comparison of algorithms. The second edition of the challenge on detection and classification of acoustic scenes and events (DCASE 2016) has offered such an opportunity for development of the state-of-the-art methods, and succeeded in drawing together a large number of participants from academic and industrial backgrounds. In this paper, we report on the tasks and outcomes of the DCASE 2016 challenge. The challenge comprised four tasks: acoustic scene classification, sound event detection in synthetic audio, sound event detection in real-life audio, and domestic audio tagging. We present each task in detail and analyze the submitted systems in terms of design and performance. We observe the emergence of deep learning as the most popular classification method, replacing the traditional approaches based on Gaussian mixture models and support vector machines. By contrast, feature representations have not changed substantially throughout the years, as mel frequency-based representations predominate in all tasks. The datasets created for and used in DCASE 2016 are publicly available and are a valuable resource for further research.",
    keywords = "Acoustics;Event detection;Hidden Markov models;Speech;Speech processing;Tagging;Acoustic scene classification;audio datasets;pattern recognition;sound event detection",
    doi = "10.1109/TASLP.2017.2778423",
    issn = "2329-9290",
    month = "Feb"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Lafay2017" data-source="content/data/challenge2016/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Lafay2017"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            G. <span class="bibtex-protected">Lafay</span>, E. <span class="bibtex-protected">Benetos</span>, and M. <span class="bibtex-protected">Lagrange</span>.
<em>Sound event detection in synthetic audio: analysis of the DCASE 2016 task results.</em>
In 2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), volume, 11–15. Oct 2017.
<a href="https://doi.org/10.1109/WASPAA.2017.8169985">doi:10.1109/WASPAA.2017.8169985</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexLafay2017fc85e03502014bdc917a1d01205c81f3" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/25293/Benetos%20Sound%20Event%20Detection%202017%20Accepted.pdf?sequence=1&amp;isAllowed=y" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseLafay2017fc85e03502014bdc917a1d01205c81f3" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseLafay2017fc85e03502014bdc917a1d01205c81f3" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingLafay2017fc85e03502014bdc917a1d01205c81f3" class="panel-collapse collapse" id="collapseLafay2017fc85e03502014bdc917a1d01205c81f3" role="tabpanel">
<h4>Sound event detection in synthetic audio: Analysis of the DCASE 2016 task results</h4>
<h5>Abstract</h5>
<p class="text-justify">As part of the 2016 public evaluation challenge on Detection and Classification of Acoustic Scenes and Events (DCASE 2016), the second task focused on evaluating sound event detection systems using synthetic mixtures of office sounds. This task, which follows the `Event Detection-Office Synthetic' task of DCASE 2013, studies the behaviour of tested algorithms when facing controlled levels of audio complexity with respect to background noise and polyphony/density, with the added benefit of a very accurate ground truth. This paper presents the task formulation, evaluation metrics, submitted systems, and provides a statistical analysis of the results achieved, with respect to various aspects of the evaluation dataset.</p>
<h5>Keywords</h5>
<p class="text-justify">acoustic signal detection;acoustic signal processing;audio signal processing;signal classification;statistical analysis;synthetic audio;dcase 2016 task results;2016 public evaluation challenge;Acoustic Scenes;sound event detection systems;synthetic mixtures;office sounds;Event Detection-Office Synthetic task;DCASE 2013;audio complexity;background noise;polyphony/density;task formulation;evaluation metrics;evaluation dataset;submitted systems;statistical analysis;Acoustics;Analysis of variance;Event detection;Image analysis;Measurement;Training;Sound event detection;experimental validation;DCASE;acoustic scene analysis;sound scene analysis</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexLafay2017fc85e03502014bdc917a1d01205c81f3" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/25293/Benetos%20Sound%20Event%20Detection%202017%20Accepted.pdf?sequence=1&amp;isAllowed=y" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexLafay2017fc85e03502014bdc917a1d01205c81f3label" class="modal fade" id="bibtexLafay2017fc85e03502014bdc917a1d01205c81f3" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexLafay2017fc85e03502014bdc917a1d01205c81f3label">Sound event detection in synthetic audio: Analysis of the DCASE 2016 task results</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Lafay2017,
    author = "{Lafay}, G. and {Benetos}, E. and {Lagrange}, M.",
    booktitle = "2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
    title = "Sound event detection in synthetic audio: Analysis of the {DCASE} 2016 task results",
    year = "2017",
    volume = "",
    number = "",
    pages = "11-15",
    abstract = "As part of the 2016 public evaluation challenge on Detection and Classification of Acoustic Scenes and Events (DCASE 2016), the second task focused on evaluating sound event detection systems using synthetic mixtures of office sounds. This task, which follows the `Event Detection-Office Synthetic' task of DCASE 2013, studies the behaviour of tested algorithms when facing controlled levels of audio complexity with respect to background noise and polyphony/density, with the added benefit of a very accurate ground truth. This paper presents the task formulation, evaluation metrics, submitted systems, and provides a statistical analysis of the results achieved, with respect to various aspects of the evaluation dataset.",
    keywords = "acoustic signal detection;acoustic signal processing;audio signal processing;signal classification;statistical analysis;synthetic audio;dcase 2016 task results;2016 public evaluation challenge;Acoustic Scenes;sound event detection systems;synthetic mixtures;office sounds;Event Detection-Office Synthetic task;DCASE 2013;audio complexity;background noise;polyphony/density;task formulation;evaluation metrics;evaluation dataset;submitted systems;statistical analysis;Acoustics;Analysis of variance;Event detection;Image analysis;Measurement;Training;Sound event detection;experimental validation;DCASE;acoustic scene analysis;sound scene analysis",
    doi = "10.1109/WASPAA.2017.8169985",
    issn = "1947-1629",
    month = "Oct"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>