<!DOCTYPE html><html lang="en">
<head>
    <title>Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Challenge has ended. Full results for this task can be found in the Results page. If you are interested in the task, you can join us on the dedicated slack channel Description Anomalous sound detection (ASD) is the task of identifying whether the sound emitted from a machine is normal …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2021</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2021/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class="">
        <a href="/challenge2021/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class=" active">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2021/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2021/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/cogs-01.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-large-scale fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Monitoring</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 2</span></span><img src="../images/logos/dcase/dcase2021_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Task description</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left ">
 <div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Coordinators</h3>
</div>
<table class="table bpersonnel-container">
<tr>
<td class="" style="width: 65px;">
<img alt="Yohei Kawaguchi" class="img img-circle" src="/images/person/yohei_kawaguchi.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yohei Kawaguchi</strong>
<a class="icon" href="mailto:yohei.kawaguchi.xk@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Keisuke Imoto" class="img img-circle" src="/images/person/keisuke_imoto.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Keisuke Imoto</strong>
<a class="icon" href="mailto:keisuke.imoto@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Doshisha University
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Yuma Koizumi" class="img img-circle" src="/images/person/yuma_koizumi.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Yuma Koizumi</strong>
<a class="icon" href="mailto:koizumi.yuma@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Google, Inc.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Noboru Harada" class="img img-circle" src="/images/person/noboru_harada.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Noboru Harada</strong>
<a class="icon" href="mailto:noboru@ieee.org"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.ntt.co.jp/md/e/">
                                NTT Corporation
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Daisuke Niizumi" class="img img-circle" src="/images/person/daisuke_niizumi.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Daisuke Niizumi</strong>
</div>
<div class="col-md-12">
<p class="small text-muted">
<a class="text" href="https://www.ntt.co.jp/md/e/">
                                NTT Corporation
                                </a>
</p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Kota Dohi" class="img img-circle" src="/images/person/kota_dohi.png" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Kota Dohi</strong>
<a class="icon" href="mailto:kota.dohi.gr@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Ryo Tanabe" class="img img-circle" src="/images/person/ryo_tanabe.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Ryo Tanabe</strong>
<a class="icon" href="mailto:ryo.tanabe.rw@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Harsh Purohit" class="img img-circle" src="/images/person/harsh_purohit.jpeg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Harsh Purohit</strong>
<a class="icon" href="mailto:harsh_pramodbhai.purohit.yf@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
<tr>
<td class="" style="width: 65px;">
<img alt="Takashi Endo" class="img img-circle" src="/images/person/takashi_endo.jpg" width="48px"/>
</td>
<td class="">
<div class="row">
<div class="col-md-12">
<strong>Takashi Endo</strong>
<a class="icon" href="mailto:takashi.endo.qf@hitachi.com"><i class="pull-right fa fa-envelope-o"></i></a>
</div>
<div class="col-md-12">
<p class="small text-muted">       
                                                                
                                            
                                
                                Hitachi, Ltd.
                                
                            
                            </p>
</div>
</div>
</td>
</tr>
</table>
</div>

 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#description">Description</a>
<ul>
<li><a href="#why-focus-on-domain-shift">Why focus on domain shift?</a></li>
<li><a href="#schedule">Schedule</a></li>
</ul>
</li>
<li><a href="#audio-datasets">Audio datasets</a>
<ul>
<li><a href="#dataset-overview">Dataset overview</a></li>
<li><a href="#definition">Definition</a></li>
<li><a href="#development-and-evaluation-datasets">Development and evaluation datasets</a></li>
<li><a href="#recording-procedure">Recording procedure</a></li>
<li><a href="#reference-labels">Reference labels</a></li>
<li><a href="#short-description-of-each-section-in-the-development-dataset">Short description of each section in the development dataset</a></li>
<li><a href="#short-description-of-each-section-in-the-additional-training-dataset">Short description of each section in the additional training dataset</a></li>
<li><a href="#external-data-resources">External data resources</a></li>
<li><a href="#download">Download</a></li>
</ul>
</li>
<li><a href="#task-setup-and-rules">Task setup and rules</a></li>
<li><a href="#submission">Submission</a></li>
<li><a href="#evaluation">Evaluation</a>
<ul>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#ranking">Ranking</a></li>
</ul>
</li>
<li><a href="#results">Results</a></li>
<li><a href="#baseline-system">Baseline system</a>
<ul>
<li><a href="#autoencoder-based-baseline">Autoencoder-based baseline</a></li>
<li><a href="#mobilenetv2-based-baseline">MobileNetV2-based baseline</a></li>
<li><a href="#repository">Repository</a></li>
<li><a href="#results-with-the-development-dataset">Results with the development dataset</a></li>
</ul>
</li>
<li><a href="#citation">Citation</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <p class="lead"></p>
<p class="alert alert-info">
<strong>Challenge has ended.</strong> Full results for this task can be found in the <a class="btn btn-default btn-xs" href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds-results">Results <i class="fa fa-caret-right"></i></a> page.
</p>
<div class="alert alert-info">
    If you are interested in the task, you can join us on the <strong><a href="https://dcase.slack.com/archives/C01PPSMLTSN">dedicated slack channel</a></strong>
</div>
<h1 id="description">Description</h1>
<p><strong>Anomalous sound detection (ASD) is the task of identifying whether the sound emitted from a machine is normal or anomalous.</strong> Automatic detection of mechanical failure is essential technology in the fourth industrial revolution, including artificial intelligence (AI)-based factory automation. Prompt detection of machine anomalies by observing sounds is useful for machine condition monitoring. Figure 1 shows a simplified task description.</p>
<figure>
<div class="row row-centered">
<div class="col-xs-7 col-md-5 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2021/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_01.png"/>
<figcaption>Figure 1: Overview of ASD system.</figcaption>
</div>
</div>
</figure>
<p><br/></p>
<p>This task is the follow-up to DCASE 2020 Task 2. The 2021 version has two main challenges:  </p>
<ol>
<li>
<p><strong>The task is detecting unknown anomalous sounds under the condition that only normal sound clips have been provided as training data, as in 2020 (i.e., unsupervised learning scenario).</strong> In real-world factories, actual anomalous sounds rarely occur and are highly diverse. Therefore, exhaustive patterns of anomalous sounds are impossible to deliberately make and/or collect. This means we have to detect unknown anomalous sounds that were not observed in the given training data.</p>
</li>
<li>
<p><strong>The task is performed under the conditions that the acoustic characteristics of the training data and the test data are different (i.e., domain shift).</strong> The scope includes differences in operating speed, machine load, environmental noise, etc. Compared to 2020, the advancement of this task is that only a few normal clips are provided for the test domain, so this additional setup simulates a more realistic situation.</p>
</li>
</ol>
<p>The first one is the same as the DCASE 2020 task 2, but the second one is newly added for this year.</p>
<h2 id="why-focus-on-domain-shift">Why focus on domain shift?</h2>
<p>The purpose of this task is to solve the problem of normal sounds being incorrectly judged as anomalous due to changes within the normal conditions (i.e., domain shift).
The task setup of the 2020 version was the ASD under ideal conditions. That is, the training- and testing-phase datasets were generated under the same recording conditions, and enough normal training clips recorded under the test domain were made available. In contrast, real-world cases are more complicated and often involve different machine operating conditions between the training and testing phases. A frequent example of this is when the motor speed continuously varies in a conveyor transporting products on a production line based on the production volume in response to product demand. Since there is infinite variation in rotation speed, the sound will also change with infinite variation. Due to the seasonal demand for many products, a limited period of recording training data limits the motor speed during that period (e.g., 200-300 rpm for autumn) and variations in the training data. However, in the test phase, the ASD system must continue to monitor the conveyor through all seasons, so it must be able to monitor all possible motor speed conditions, including those that differ from the training data (such as 100-400 rpm). In addition to the conditions of the machine, environmental noise conditions (SNR, sound characteristics, etc.) also fluctuate uncontrollably depending on the seasonal demand. In such a situation, the normal state's distribution will be changed (i.e., domain shift).</p>
<h2 id="schedule">Schedule</h2>
<p>Based on the DCASE 2021 Challenge schedule, the important task days will be as follows:</p>
<ul>
<li>Task open: <strong>1st of March 2021</strong></li>
<li>Additional training dataset release: <strong>1st of April 2021</strong></li>
<li>Evaluation dataset release: <strong>1st of June 2021</strong></li>
<li>External resource list lock: <strong>1st of June 2021</strong></li>
<li>Challenge deadline: <strong>15th of June 2021</strong></li>
<li>Challenge results: <strong>1st of July 2021</strong></li>
</ul>
<p>External resources on the "List of external datasets and models allowed" can be used (cf. external data resource section).
The list of external datasets and models allowed will be updated upon request.
Any external resources that are freely accessed before the <strong>1st of April 2021</strong> can be added.
Please send a request email to the task organizers.
The list will be locked after the release date of the evaluation dataset (<strong>1st of June 2021</strong>).
To avoid developing new external resources using machine information in the evaluation dataset, we will release the additional training dataset after the <strong>1st of April 2021</strong>.
Note that the additional training dataset contains the matching training data of machines used in the evaluation dataset (cf. dataset section).</p>
<h1 id="audio-datasets">Audio datasets</h1>
<h2 id="dataset-overview">Dataset overview</h2>
<p>The data used for this task consists of the normal/anomalous operating sounds of seven types of machines. Each recording is single-channel, 10-second audio that includes both the sounds of a machine and its associated equipment as well as environmental sounds. The following seven types of machines are used in this task:</p>
<ul>
<li>Fan</li>
<li>Gearbox</li>
<li>Pump</li>
<li>Slide rail (also called <code>slider</code>)</li>
<li>ToyCar</li>
<li>ToyTrain</li>
<li>Valve</li>
</ul>
<p>Figure 2 shows an overview of the datasets: the development, additional training, and evaluation datasets. Every dataset consists of the seven types of machines, and each type of machine consists of three "sections" (Section 00, 01, and 02 for the development dataset and Section 03, 04, and 05 for the additional training dataset and the evaluation dataset).</p>
<figure>
<div class="row row-centered">
<div class="col-xs-24 col-md-12 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2021/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_02.png"/>
<figcaption>Figure 2: Overview of datasets.</figcaption>
</div>
</div>
</figure>
<p><br/></p>
<h2 id="definition">Definition</h2>
<p>First, we define some important terms in this task: "machine type," "section," "source domain," and "target domain."</p>
<ul>
<li>The machine type means the kind of machine, which can be one of seven in this task: fan, gearbox, pump, slide rail, ToyCar, ToyTrain, and valve.</li>
<li>The section is defined as a subset of the data within one machine type and consists of data from two domains, called the source domain and the target domain, which are described next. The section is a unit for calculating performance metrics and is almost identical to what was called "machine ID" in the 2020 version. In the 2020 version, there was a one-to-one correspondence between machine IDs and products, but in the 2021 version, the same product may appear in different sections, and different products may appear in the same section.</li>
<li>The source domain means the original condition which has enough amount of training clips, and the target domain means the shifted condition where only a few audio clips has been provided as training data. The conditions of source and target domains differ in terms of operating speed, machine load, viscosity, heating temperature, environmental noise, SNR, etc.</li>
</ul>
<h2 id="development-and-evaluation-datasets">Development and evaluation datasets</h2>
<p>Our whole dataset consists of three datasets:  </p>
<p><strong>Development dataset</strong>: This dataset consists of three sections for each machine type (Section 00, 01, and 02), and each section is a complete set of training and test data. For each section, this dataset provides (i) around 1,000 clips of normal sounds in a source domain for training, (ii) only three clips of normal sounds in a target domain for training, (iii) around 100 clips each of normal and anomalous sounds in the source domain for the test, and (iv) around 100 clips each of normal and anomalous sounds in the target domain for the test.<br/>
<strong>Additional training dataset</strong>: This dataset provides the other three sections for each machine type (Section 03, 04, and 05). Each section consists of (i) around 1,000 clips of normal sounds in a source domain for training and (ii) only three clips of normal sounds in a target domain for training. Participants may also use this dataset for training. The additional training dataset will be open on the <strong>1st of April</strong>.<br/>
<strong>Evaluation dataset</strong>: This dataset provides test clips for the three sections identical to the additional training dataset (Section 03, 04, and 05). Each section consists of (i) test clips in the source domain and (ii) test clips in the target domain, none of which have a condition label (i.e., normal or anomaly).
Note that the sections of the evaluation dataset (Section 03, 04, and 05) are the same as the additional training dataset but different from the development dataset (Section 00, 01, and 02).<br/></p>
<p>As described above, the modification from the 2020 version is that the training dataset is extremely unbalanced. Most of the training data (1000 clips for each section) are from the source domain, and only a few normal clips (three clips for each section) are provided for the target domain, even though the number of clips in the test data set is the same in both domains. Thus, the participants have to develop a system adapted to the target domain using a few clips while avoiding performance degradation for the source domain.</p>
<h2 id="recording-procedure">Recording procedure</h2>
<p>Normal/anomalous operating sounds of machines and related equipment were recorded.
Anomalous sounds were collected by deliberately damaging machines.
To simplify the task, we only used the first channel of the multi-channel recordings; all recordings were regarded as single-channel recordings from a fixed microphone.
We mixed a machine sound with environmental noise, and only noisy recordings are provided as training/test data.
The environmental noise clips were recorded in several real factory environments.
We will publish papers on the dataset to explain the details of the recording procedure by the submission deadline.</p>
<h2 id="reference-labels">Reference labels</h2>
<p>The given labels for each training/test clip are machine type, section index, normal/anomaly information, and brief attribute information about conditions other than normal/abnormal. The machine type information is given by the directory name. The section index is given by their respective file names. For the datasets other than the evaluation dataset, the normal/anomaly information is given by their respective file names. For the training data, the attribute information is given by their respective file names.</p>
<h2 id="short-description-of-each-section-in-the-development-dataset">Short description of each section in the development dataset</h2>
<p>Short descriptions of each section in the development dataset and the attribute format in the file names of their training data are as follows:  </p>
<div class="table-responsive col-md-20">
<table class="table table-striped table-condensed">
<tbody>
<tr>
<td><strong>Machine type</strong></td>
<td><strong>Section</strong></td>
<td><strong>Description</strong></td>
<td><strong>Attribute format in file names of training data</strong></td>
</tr>
<tr>
<td>Fan</td>
<td>00</td>
<td>Wind strength variations between domains</td>
<td><span class="label label-primary">strength_&lt;wind_strength_index&gt;_ambient</span></td>
</tr>
<tr>
<td>Fan</td>
<td>01</td>
<td>Two products from the same manufacturer with size variations between domains</td>
<td><span class="label label-primary">strength_1_&lt;product_nickname&gt;_ambient</span> <br/>
<span class="label label-primary">&lt;product_nickname&gt;</span>: <span class="label label-primary">big</span> or <span class="label label-primary">small</span></td>
</tr>
<tr>
<td>Fan</td>
<td>02</td>
<td>Factory noise variations between domains</td>
<td>Source domain: <span class="label label-primary">strength_1_ambient</span> <br/>
                Target domain: <span class="label label-primary">strength_1_Fact_D_ambient</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>00</td>
<td>Voltage variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>01</td>
<td>Arm-length variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>02</td>
<td>Weight variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Pump</td>
<td>00</td>
<td>Submersible pump; viscosity variations between domains</td>
<td><span class="label label-primary">serial_no_&lt;individual_number&gt;_&lt;fluid_type&gt;</span></td>
</tr>
<tr>
<td>Pump</td>
<td>01</td>
<td>SNR variations between domains</td>
<td><span class="label label-primary">serial_no_&lt;individual_number&gt;_&lt;fluid_type&gt;</span></td>
</tr>
<tr>
<td>Pump</td>
<td>02</td>
<td>Multiple pumps running simultaneously in the target domain; anomaly condition indicating an abnormality in one or more of the pumps</td>
<td><span class="label label-primary">serial_no_&lt;individual_numbers&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>00</td>
<td>Ball-screw-type slide rail;<br/>velocity variations between domains</td>
<td><span class="label label-primary">vel&lt;velocity&gt;_dis&lt;distance&gt;_accl&lt;acceleration&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>01</td>
<td>Ball-screw-type slide rail;<br/>operation pattern variations between domains</td>
<td><span class="label label-primary">vel&lt;velocity&gt;_dis&lt;distance&gt;_accl&lt;acceleration&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>02</td>
<td>Belt-type slide rail;<br/>belt material variations between domains</td>
<td><span class="label label-primary">&lt;material&gt;_none</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>00</td>
<td>Car model variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>01</td>
<td>Speed level variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>02</td>
<td>Different microphone types and positions between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>00</td>
<td>Train model variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>01</td>
<td>Speed level variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>02</td>
<td>Different microphone types and positions between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>00</td>
<td>Open/close operation pattern variations between domains</td>
<td><span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>01</td>
<td>No pump running in the source domain</td>
<td><span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>02</td>
<td>Two valves running simultaneously in the target domain; anomaly condition indicates a small piece of metal is caught in one of the valves</td>
<td>Source domain: <span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span> <br/>
                Target domain: <span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;_comb</span></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h2 id="short-description-of-each-section-in-the-additional-training-dataset">Short description of each section in the additional training dataset</h2>
<p>Short descriptions of each section in the additional training dataset (and the evaluation dataset) and the attribute format in the file names of their data are as follows:  </p>
<div class="table-responsive col-md-20">
<table class="table table-striped table-condensed">
<tbody>
<tr>
<td><strong>Machine type</strong></td>
<td><strong>Section</strong></td>
<td><strong>Description</strong></td>
<td><strong>Attribute format in file names of training data</strong></td>
</tr>
<tr>
<td>Fan</td>
<td>03</td>
<td>Wind strength variations between domains</td>
<td><span class="label label-primary">strength_&lt;wind_strength_index&gt;_ambient</span></td>
</tr>
<tr>
<td>Fan</td>
<td>04</td>
<td>Wind strength variations between domains</td>
<td><span class="label label-primary">strength_&lt;wind_strength_index&gt;_ambient</span></td>
</tr>
<tr>
<td>Fan</td>
<td>05</td>
<td>Heating temperature variations between domains</td>
<td>Source domain: <span class="label label-primary">strength_1_temp_min</span> <br/>
                Target domain: <span class="label label-primary">strength_1_temp_max</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>03</td>
<td>Voltage variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>04</td>
<td>Arm-length variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Gearbox</td>
<td>05</td>
<td>Voltage and arm-length variations between domains</td>
<td><span class="label label-primary">&lt;weight&gt;_g_&lt;arm_length&gt;_mm_&lt;voltage&gt;_mV_none</span></td>
</tr>
<tr>
<td>Pump</td>
<td>03</td>
<td>Submersible pump; viscosity variations between domains</td>
<td><span class="label label-primary">serial_no_&lt;individual_number&gt;_&lt;fluid_type&gt;</span></td>
</tr>
<tr>
<td>Pump</td>
<td>04</td>
<td>Factory noise variations between domains</td>
<td><span class="label label-primary">serial_no_&lt;individual_number&gt;</span></td>
</tr>
<tr>
<td>Pump</td>
<td>05</td>
<td>Multiple pumps running simultaneously in the target domain; anomaly condition indicating an abnormality in one or more of the pumps</td>
<td><span class="label label-primary">serial_no_&lt;individual_numbers&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>03</td>
<td>Ball-screw-type slide rail;<br/>velocity variations between domains</td>
<td><span class="label label-primary">vel&lt;velocity&gt;_dis&lt;distance&gt;_accl&lt;acceleration&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>04</td>
<td>Ball-screw-type slide rail;<br/>operation pattern variations between domains</td>
<td><span class="label label-primary">vel&lt;velocity&gt;_dis&lt;distance&gt;_accl&lt;acceleration&gt;</span></td>
</tr>
<tr>
<td>Slide rail</td>
<td>05</td>
<td>Belt-type slide rail;<br/>belt material variations between domains</td>
<td><span class="label label-primary">&lt;material&gt;_none</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>03</td>
<td>Car model variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>04</td>
<td>Speed level variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyCar</td>
<td>05</td>
<td>Different microphone types and positions between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level times 10&gt;VMic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>03</td>
<td>Train model variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>04</td>
<td>Speed level variations between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>ToyTrain</td>
<td>05</td>
<td>Different microphone types and positions between domains</td>
<td><span class="label label-primary">&lt;machine model&gt;Spd&lt;speed level&gt;Mic&lt;microphone number&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>03</td>
<td>Open/close operation pattern variations between domains</td>
<td><span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>04</td>
<td>No pump running in the source domain; water flowing in the target domain</td>
<td><span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span></td>
</tr>
<tr>
<td>Valve</td>
<td>05</td>
<td>Two valves running simultaneously in the target domain; anomaly condition indicates a small piece of metal is caught in one of the valves</td>
<td>Source domain: <span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;</span> <br/>
                Target domain: <span class="label label-primary">pattern_&lt;pattern_index&gt;_&lt;pump_information&gt;_comb</span></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h2 id="external-data-resources">External data resources</h2>
<p>Based on the previous DCASE external data resource policy, we allow the use of external datasets and trained models under the following conditions:</p>
<ol>
<li>Any test data in both development and evaluation datasets shall not be used for training.</li>
<li>Any data in the <a href="https://ieeexplore.ieee.org/document/8937164">ToyADMOS</a> dataset, the <a href="http://dcase.community/documents/workshop2019/proceedings/DCASE2019Workshop_Purohit_21.pdf">MIMII</a> dataset, and the <a href="http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds">datasets of DCASE 2020 Challenge Task 2</a> shall not be used.</li>
<li>Datasets, pre-trained models, and pre-trained parameters on the "List of external data resources allowed" can be used. The list will be updated upon request. Datasets, pre-trained models, and pre-trained parameters, which are freely accessible to any other research group before the <strong>1st of April 2021</strong>, can be added to the list.</li>
<li>If you want us to add the sources of the external datasets, pre-trained models, and pre-trained parameters to the list, send a request to the organizers by the evaluation dataset’s publishing date. We will update the "list of external data resources allowed" on the web page accordingly to give all competitors an equal opportunity to use them.</li>
<li>Once the evaluation set is published, no further external sources will be added. The list will be locked after the <strong>1st of June 2021</strong>.</li>
</ol>
<h3>List of external data resources allowed:</h3>
<table class="datatable table table-hover table-condensed" data-filter-control="false" data-filter-show-clear="false" data-id-field="name" data-pagination="false" data-show-pagination-switch="false" data-sort-name="name" data-sort-order="asc">
<thead>
<tr>
<th data-field="name" data-sortable="true">Dataset name</th>
<th data-field="type" data-filter-control="select" data-sortable="true" data-tag="true">Type</th>
<th data-field="date" data-sortable="true">Added</th>
<th data-field="link" data-value-type="url">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>IDMT-ISA-ELECTRIC-ENGINE</td>
<td>audio</td>
<td>01.03.2021</td>
<td>https://www.idmt.fraunhofer.de/en/publications/isa-electric-engine.html</td>
</tr>
<tr>
<td>AudioSet</td>
<td>audio</td>
<td>01.03.2021</td>
<td>https://research.google.com/audioset/</td>
</tr>
<tr>
<td>VGGish</td>
<td>model</td>
<td>01.03.2021</td>
<td>https://github.com/tensorflow/models/tree/master/research/audioset/vggish</td>
</tr>
<tr>
<td>OpenL3</td>
<td>model</td>
<td>01.03.2021</td>
<td>https://openl3.readthedocs.io/en/latest/</td>
</tr>
<tr>
<td>PANNs</td>
<td>model</td>
<td>01.03.2021</td>
<td>https://zenodo.org/record/3576403/</td>
</tr>
<tr>
<td>PyTorch Image Models (including tens of pre-trained models)</td>
<td>model</td>
<td>13.05.2021</td>
<td>https://github.com/rwightman/pytorch-image-models</td>
</tr>
<tr>
<td>torchvision.models (including tens of pre-trained models)</td>
<td>model</td>
<td>13.05.2021</td>
<td>https://pytorch.org/vision/stable/models.html</td>
</tr>
</tbody>
</table>
<p><br/></p>
<h2 id="download">Download</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/4562016" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/4562016" target="_blank">
<span style="font-size:20px;">Development dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(7.5 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.4562016">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.4562016.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/4660992" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/4660992" target="_blank">
<span style="font-size:20px;">Additional training dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(5.5 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.4660992">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.4660992.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/4884786" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-success"></i>
<i class="fa fa-file-audio-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/4884786" target="_blank">
<span style="font-size:20px;">Evaluation dataset <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(2.2 GB)</span>
<br/>
<a href="https://doi.org/10.5281/zenodo.4884786">
<img src="https://zenodo.org/badge/DOI/10.5281/zenodo.4884786.svg"/>
</a>
<span class="text-muted">
                
                version 1.0
                
                
                </span>
</div>
</div>
<p><br/></p>
<h1 id="task-setup-and-rules">Task setup and rules</h1>
<p>Participants are required to submit both an <strong>anomaly score</strong> and a <strong>normal/anomaly decision result</strong> for each test clip. The anomaly score for each test clip will be used to calculate the area under the receiver operating characteristic (ROC) curve (AUC) and partial-AUC (pAUC) scores, which are used to calculate an official score and a final ranking. The normal/anomaly decision result for each test clip is used to calculate the precision, recall, and F1 scores, which will also be published when the challenge results are open. The method of evaluation is described in the Evaluation section.</p>
<p>The anomaly score takes a large value when the input signal seems to be anomalous, and vice versa. To calculate the anomaly score, participants need to train an anomaly score calculator <span class="math">\(\mathcal{A}\)</span> with parameter <span class="math">\(\theta\)</span>. The input of <span class="math">\(\mathcal{A}\)</span> is a machine's operating sound <span class="math">\(x \in \mathbb{R}^{L}\)</span> and its machine information including machine type, section index, and whether it is in a source or target domain, and <span class="math">\(\mathcal{A}\)</span> outputs one anomaly score for the whole audio clip <span class="math">\(x\)</span> as <span class="math">\(\mathcal{A}_\theta (x) \in \mathbb{R}\)</span>. Then, <span class="math">\(x\)</span> is determined to be anomalous when the anomaly score exceeds a pre-defined threshold value. Thus, <span class="math">\(\mathcal{A}\)</span> needs to be trained so that <span class="math">\(\mathcal{A}_\theta(x)\)</span> will be a large value both when the whole audio clip <span class="math">\(x\)</span> is anomalous and when a part of <span class="math">\(x\)</span> is anomalous, such as with collision anomalous sounds.</p>
<p>Figure 3 shows the overview of this task, where the example is a procedure for calculating the anomaly scores of the test clips of (fan, section 00, target domain). First, the participants train an anomaly score calculator <span class="math">\(\mathcal{A}\)</span> using training data both in the source and target domains and optional external data resources. Then, by using <span class="math">\(\mathcal{A}\)</span>, participants calculate the anomaly scores of all the test clips of (fan, section 00, target domain). By repeating this procedure, participants calculate the anomaly score of all the test clips of all the machine types, sections, and domains.</p>
<p>Arbitral numbers of an anomaly score calculator <span class="math">\(\mathcal{A}\)</span> can be used for to calculate the anomaly scores of test clips. The simplest strategy is to use a single <span class="math">\(\mathcal{A}\)</span> to calculate the anomaly scores for a single section (e.g., section 00) and a single domain (i.e., the source or target domain). In this case, <span class="math">\(\mathcal{A}\)</span> is specialized to a single section and a single domain, so users of such a system are required to train <span class="math">\(\mathcal{A}\)</span> for each machine type, product, and condition. A more challenging strategy is to use a single <span class="math">\(\mathcal{A}\)</span> to calculate the anomaly scores of all the test clips of all the machine types, sections, and both source and target domains. The advantage of this strategy is that participants can use all the training clips provided; however, they need to consider the generalization of the model. Another typical scenario that can be inspired by real-world applications is where you can pre-train a general model with source-domain data but need to adapt the general model to the target domains without the source-domain data. The task organizers do not impose this constraint but would appreciate participants' efforts to impose constraints on themselves based on various real-world applications.</p>
<p>All training data with arbitrary splitting can be used to train an anomaly score calculator. For example, to train <span class="math">\(\mathcal{A}\)</span> to calculate the anomaly score of (valve, section 03, source domain), participants can opt to use training data only in (valve, section 03, source domain), training data in both the source and target domains, training data of all sections of valves, all provided training data, and/or other strategies. Of course, normal/anomalous clips in test data cannot be used for training; however, simulating anomalous samples using the listed external data resources is allowed.</p>
<p>Changing the model (model/architecture/hyperparameters) between machine types within a single submission is allowed. However, we expect participants to develop a simple ASD system (i.e. keep the model and hyperparameters fixed and only change the training data to adapt to each machine type).</p>
<figure>
<div class="row row-centered">
<div class="col-xs-16 col-md-8 col-centered">
<img class="img img-responsive" src="/images/tasks/challenge2021/task2_unsupervised_detection_of_anomalous_sounds_for_machine_condition_monitoring_03.png"/>
<figcaption>Figure 3: Task overview.
            </figcaption>
</div>
</div>
</figure>
<p><br/></p>
<h1 id="submission">Submission</h1>
<p>The official challenge submission consists of:</p>
<ul>
<li>System output for the evaluation data</li>
<li>Meta information files</li>
</ul>
<p>System output should be presented as a text-file that corresponds to each <strong>machine type</strong>, <strong>section index</strong>, and <strong>domain</strong> (source/target). Its file name should be:</p>
<ul>
<li>Anomaly score file: <code>anomaly_score_&lt;machine_type&gt;_section_&lt;section_index&gt;_&lt;domain&gt;.csv</code></li>
<li>Detection result file: <code>decision_result_&lt;machine_type&gt;_section_&lt;section_index&gt;_&lt;domain&gt;.csv</code></li>
</ul>
<p>The anomaly score file (in CSV format, without header row) contains the anomaly score for each audio file in the test data of the evaluation dataset. Result items can be in any order. All rows must be in the following format:</p>
<div class="highlight"><pre><span></span><code>[filename (string)],[anomaly score (real value)]
</code></pre></div>
<p>Anomaly scores in the second column can take a negative value. For example, typical auto-encoder-based anomaly score calculators use the squared reconstruction error, which takes a non-negative value, while statistical model-based methods (such as GMM) use the negative log-likelihood as the anomaly score, which can take both positive and negative values.</p>
<p>The decision result file (in CSV format, without header row) contains the normal/anomaly decision result for each audio file in the test data of the evaluation dataset. Result items can be in any order. All rows must be in the following format:</p>
<div class="highlight"><pre><span></span><code>[filename (string)],[decision result (0: normal, 1: anomaly)]
</code></pre></div>
<p>We allow up to four system output submissions per participant/team.
For each system, meta information should be provided in a separate file that contains the task-specific information.
All files should be packaged into a zip file for submission.
Detailed information on the submission process can be found on the <a href="http://dcase.community/challenge2021/submission">Submission page</a>.</p>
<h1 id="evaluation">Evaluation</h1>
<h2 id="metrics">Metrics</h2>
<p>This task is evaluated with the AUC and the pAUC.
The pAUC is an AUC calculated from a portion of the ROC curve over the pre-specified range of interest.
In our metric, the pAUC is calculated as the AUC over a low false-positive-rate (FPR) range <span class="math">\([0, p]\)</span>.
The AUC and pAUC for each machine type, section, and domain are defined as</p>
<div class="math">$$ {\rm AUC}_{m, m, d} = \frac{1}{N_{-}N_{+}} \sum_{i=1}^{N_{-}} \sum_{j=1}^{N_{+}} \mathcal{H} (\mathcal{A}_{\theta} (x_{j}^{+}) - \mathcal{A}_{\theta} (x_{i}^{-})), $$</div>
<div class="math">$$ {\rm pAUC}_{m, m, d} = \frac{1}{\lfloor p N_{-} \rfloor N_{+}} \sum_{i=1}^{\lfloor p N_{-} \rfloor} \sum_{j=1}^{N_{+}} \mathcal{H} (\mathcal{A}_{\theta} (x_{j}^{+}) - \mathcal{A}_{\theta} (x_{i}^{-})) $$</div>
<p>where <span class="math">\(m\)</span> represents the index of a machine type,
<span class="math">\(n\)</span> represents the index of a section,
<span class="math">\(d = \{ {\rm source}, {\rm target} \}\)</span> represents a domain,
<span class="math">\(\lfloor \cdot \rfloor\)</span> is the flooring function,
and <span class="math">\(\mathcal{H} (x)\)</span> returns 1 when <span class="math">\(x\)</span> &gt; 0 and 0 otherwise.
Here, <span class="math">\(\{x_{i}^{−}\}_{i=1}^{N_{−}}\)</span> and <span class="math">\(\{x_{j}^{+}\}_{j=1}^{N_{+}}\)</span> are normal and anomalous test clips in the domain <span class="math">\(d\)</span> in the section <span class="math">\(n\)</span> in the machine type <span class="math">\(m\)</span>, respectively,
and they have been sorted so that their anomaly scores are in descending order.
Here, <span class="math">\(N_{−}\)</span> and <span class="math">\(N_{+}\)</span> are the number of normal and anomalous test clips in the domain <span class="math">\(d\)</span> in the section <span class="math">\(n\)</span> in the machine type <span class="math">\(m\)</span>, respectively.</p>
<p>The reason for the additional use of the pAUC is based on practical requirements.
If an ASD system frequently gives false alarms frequently, we cannot trust it.
Therefore, it is especially important to increase the true-positive-rate under low FPR conditions. In this task, we will use <span class="math">\(p=0.1\)</span>.</p>
<p>The official score <span class="math">\(\Omega\)</span> for each submitted system is given by the harmonic mean of the AUC and pAUC scores over all the machine types and all the sections as follows:</p>
<div class="math">$$ \Omega = h \left\{
{\rm AUC}_{m, n, d}, \ {\rm pAUC}_{m, n, d}
\quad | \quad m \in \mathcal{M}, \  n \in \mathcal{S}(m), \ d \in \{ {\rm source}, {\rm target} \}
\right\}, $$</div>
<p>where <span class="math">\(h\left\{\cdot\right\}\)</span> represents the harmonic mean (over all machine types, sections, and domains),
<span class="math">\(\mathcal{M}\)</span> represents the set of the machine types,
and <span class="math">\(\mathcal{S}(m)\)</span> represents the set of the sections for the machine type <span class="math">\(m\)</span>.</p>
<p>As the equations above show, a threshold value does not need to be determined to calculate AUC, pAUC, or the official score because the threshold value is the anomaly scores of normal test clips. However, in real applications, the threshold value must be determined, and a decision must be made as to whether it is normal or abnormal. Therefore, participants are also required to submit the normal/anomaly decision results. The organizers will publish the AUC, pAUC, and official scores as well as the precision, recall, and F1-scores calculated for the normal/anomaly decision results.</p>
<p>Note: The submitted normal/anomaly decision results will not be used for the final ranking because the task organizers do not want to encourage participants to use a forbidden approach (i.e., threshold tuning based on the distribution in the evaluation dataset).
Do not use other test clips to determine anomalies for each test clip.</p>
<h2 id="ranking">Ranking</h2>
<p>The final ranking will be decided by sorting based on the official score <span class="math">\(\Omega\)</span>.</p>
<h1 id="results">Results</h1>
<p>Complete results and technical reports can be found in the <a class="btn btn-primary" href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds-results">results page</a></p>
<h1 id="baseline-system">Baseline system</h1>
<p>The task organizers provide two baseline systems.
The baseline systems provide a simple entry-level approach that gives a reasonable performance in the dataset of Task 2.
They are good starting points, especially for entry-level researchers who want to get familiar with the ASD task.</p>
<h2 id="autoencoder-based-baseline">Autoencoder-based baseline</h2>
<p>This is a simple autoencoder (AE)-based anomaly score calculator and the same as the DCASE 2020 task 2.
The anomaly score is calculated as the reconstruction error of the observed sound.
To obtain small anomaly scores for normal sounds, the AE is trained to minimize the reconstruction error of the normal training data.
This method is based on the assumption that the AE cannot reconstruct sounds that are not used in training, that is, unknown anomalous sounds.</p>
<p>In the baseline system, we first calculate the log-mel-spectrogram of the input <span class="math">\(X = \{X_t\}_{t = 1}^T\)</span> where <span class="math">\(X_t \in \mathbb{R}^F\)</span>, and <span class="math">\(F\)</span> and <span class="math">\(T\)</span> are the number of mel-filters and time-frames, respectively.
Then, the acoustic feature at <span class="math">\(t\)</span> is obtained by concatenating consecutive frames of the log-mel-spectrogram as <span class="math">\(\psi_t = (X_t, \cdots, X_{t + P - 1}) \in \mathbb{R}^D\)</span>,
where <span class="math">\(D = P \times F\)</span>, and <span class="math">\(P\)</span> is the number of frames of the context window.
The anomaly score is calculated as:</p>
<div class="math">$$ A_{\theta}(X) = \frac{1}{DT} \sum_{t = 1}^T \| \psi_t - r_{\theta}(\psi_t) \|_{2}^{2}, $$</div>
<p>where <span class="math">\(r_{\theta}\)</span> is the vector reconstructed by the autoencoder, and <span class="math">\(\| \cdot \|_2\)</span> is <span class="math">\(\ell_2\)</span> norm.</p>
<p>To determine the anomaly detection threshold, we assume that <span class="math">\(A_{\theta}\)</span> follows a gamma distribution.
The parameters of the gamma distribution are estimated from the histogram of <span class="math">\(A_{\theta}\)</span>,
and the anomaly detection threshold is determined as the 90th percentile of the gamma distribution.
If <span class="math">\(A_{\theta}\)</span> for each test clip is greater than this threshold, the clip is judged to be abnormal; if it is smaller, it is judged to be normal.</p>
<h3>Parameters</h3>
<h4>Acoustic features</h4>
<ul>
<li>The frame size for STFT is 64 ms (50 % hop size)</li>
<li>Log-mel energies for 128 (<span class="math">\(= F\)</span>) bands</li>
<li>5 (<span class="math">\(= P\)</span>) consecutive frames are concatenated.</li>
<li>640 (<span class="math">\(= D = P \times F\)</span>) dimensions are input to the autoencoder.</li>
</ul>
<h4>Network Architecture</h4>
<ul>
<li>Input shape: 640</li>
<li>Architecture:<ul>
<li>Dense layer #1<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #2<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #3<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #4<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Bottleneck layer<ul>
<li>Dense layer (units: 8)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #5<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #6<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #7<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Dense layer #8<ul>
<li>Dense layer (units: 128)</li>
<li>Batch Normalization</li>
<li>Activation (ReLU)</li>
</ul>
</li>
<li>Output layer<ul>
<li>Dense layer (units: 640)</li>
</ul>
</li>
</ul>
</li>
<li>Learning (epochs: 100, batch size: 512, data shuffling between epochs)<ul>
<li>Optimizer: Adam (learning rate: 0.001)</li>
</ul>
</li>
</ul>
<h2 id="mobilenetv2-based-baseline">MobileNetV2-based baseline</h2>
<p>This is an anomaly score calculator based on machine identification.
In the 2020 version, many teams used something like this approach,
especially, a lot of them used MobileNetV2 combined with metric learning such as ArcFace.
With that in mind, this year the organizers provide a pure MobileNetV2-based baseline.</p>
<p>This baseline identifies from which section the observed signal was generated.
In other words, it outputs the softmax value that is the predicted probability for each section.
The anomaly score is calculated as the averaged negative logit of the predicted probabilities for the correct section.</p>
<p>We first calculate the log-mel-spectrogram of the input <span class="math">\(X = \{X_t\}_{t = 1}^T\)</span> where <span class="math">\(X_t \in \mathbb{R}^F\)</span>, and <span class="math">\(F\)</span> and <span class="math">\(T\)</span> are the number of mel-filters and time-frames, respectively.
Then, the acoustic feature (two-dimensional image) at <span class="math">\(t\)</span> is obtained by concatenating consecutive frames of the log-mel-spectrogram as <span class="math">\(\psi_t = (X_t, \cdots, X_{t + P - 1}) \in \mathbb{R}^{P \times F}\)</span>,
where <span class="math">\(P\)</span> is the number of frames of the context window.
By shifting the context window by <span class="math">\(L\)</span> frames, <span class="math">\(B (= \lfloor \frac{T - P}{L} \rfloor)\)</span> images are extracted.
The anomaly score is calculated as:</p>
<div class="math">$$ A_{\theta}(X) = \frac{1}{B} \sum_{b = 1}^B \log {\LARGE \{} \frac{1 - p_{\theta}(\psi_{t(b)})}{p_{\theta}(\psi_{t(b)})} {\LARGE \}}, $$</div>
<p>where <span class="math">\(t(b)\)</span> is the beginning frame index of the <span class="math">\(b\)</span>-th image, and <span class="math">\(p_{\theta}\)</span> is the softmax output by MobileNetV2 for the correct section.</p>
<p>To determine the anomaly detection threshold, we assume that <span class="math">\(A_{\theta}\)</span> follows a gamma distribution.
The parameters of the gamma distribution are estimated from the histogram of <span class="math">\(A_{\theta}\)</span>,
and the anomaly detection threshold is determined as the 90th percentile of the gamma distribution.
If <span class="math">\(A_{\theta}\)</span> for each test clip is greater than this threshold, the clip is judged to be abnormal; if it is smaller, it is judged to be normal.</p>
<h3>Parameters</h3>
<h4>Acoustic features</h4>
<ul>
<li>The frame size for STFT is 64 ms (50 % hop size)</li>
<li>Log-mel energies for 128 (<span class="math">\(= F\)</span>) bands</li>
<li>64 (<span class="math">\(= P\)</span>) consecutive frames are concatenated.</li>
<li>Images of size <span class="math">\(P \times F\)</span> are input to a network using MobileNetV2.</li>
<li>The context window is shifted by 8 (<span class="math">\(= L\)</span>) frames (called "hop frames" or "stride").</li>
</ul>
<h4>Network Architecture</h4>
<ul>
<li>Input shape: <span class="math">\(64 \times 128\)</span> image</li>
<li>Architecture:<ul>
<li>Triplication layer<ul>
<li>Triplication of the input image to each color channel</li>
</ul>
</li>
<li>MobileNetV2<ul>
<li>Input: <span class="math">\(64 \times 128 \times 3\)</span> image</li>
<li>Output: Softmax for 3 sections (Section 00, 01, and 02)</li>
</ul>
</li>
</ul>
</li>
<li>Learning (epochs: 20, batch size: 32, data shuffling between epochs)<ul>
<li>Optimizer: Adam (learning rate: 0.00001)</li>
</ul>
</li>
</ul>
<h2 id="repository">Repository</h2>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://github.com/y-kawagu/dcase2021_task2_baseline_ae" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x"></i>
<i class="fa fa-github fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://github.com/y-kawagu/dcase2021_task2_baseline_ae" target="_blank">
<span style="font-size:20px;">DCASE2021 Task 2 <strong>baseline (AE)</strong>, repository <i class="fa fa-download"></i></span>
</a>
<br/>
</div>
</div>
<p><br/></p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://github.com/y-kawagu/dcase2021_task2_baseline_mobile_net_v2" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x"></i>
<i class="fa fa-github fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://github.com/y-kawagu/dcase2021_task2_baseline_mobile_net_v2" target="_blank">
<span style="font-size:20px;">DCASE2021 Task 2 <strong>baseline (MobileNetV2)</strong>, repository <i class="fa fa-download"></i></span>
</a>
<br/>
</div>
</div>
<p><br/></p>
<p>Detailed information can be found in the GitHub repository. The directory structure is briefly described here as a reference for label information. When you unzip the files downloaded from the GitHub repository and Zenodo, you can see the following directory structure. As described in the Dataset section, the machine type information is given by directory name, and the section index, domain, and the condition information are given by file name, as:</p>
<ul>
<li>./dcase2021_task2_baseline_ae  <ul>
<li>/00_train.py  </li>
<li>/01_test.py  </li>
<li>/common.py  </li>
<li>/keras_model.py  </li>
<li>/baseline.yaml  </li>
<li>/readme.md  </li>
</ul>
</li>
<li>./dcase2021_task2_baseline_mobile_net_v2  <ul>
<li>/00_train.py  </li>
<li>/01_test.py  </li>
<li>/common.py  </li>
<li>/keras_model.py  </li>
<li>/baseline.yaml  </li>
<li>/readme.md  </li>
</ul>
</li>
<li>/dev_data  <ul>
<li>/fan  <ul>
<li>/train (only normal clips)  <ul>
<li>/section_00_source_train_normal_0000_<attribute>.wav  </attribute></li>
<li>...  </li>
<li>/section_00_source_train_normal_0999_<attribute>.wav  </attribute></li>
<li>/section_00_target_train_normal_0000_<attribute>.wav  </attribute></li>
<li>/section_00_target_train_normal_0001_<attribute>.wav  </attribute></li>
<li>/section_00_target_train_normal_0002_<attribute>.wav  </attribute></li>
<li>/section_01_source_train_normal_0000_<attribute>.wav  </attribute></li>
<li>...  </li>
<li>/section_02_target_train_normal_0999_<attribute>.wav  </attribute></li>
</ul>
</li>
<li>/source_test  <ul>
<li>/section_00_source_test_normal_0000.wav  </li>
<li>...  </li>
<li>/section_00_source_test_normal_0099.wav  </li>
<li>/section_00_source_test_anomaly_0000.wav  </li>
<li>...  </li>
<li>/section_00_source_test_anomaly_0099.wav  </li>
<li>/section_01_source_test_normal_0000.wav  </li>
<li>...  </li>
<li>/section_02_source_test_anomaly_0099.wav  </li>
</ul>
</li>
<li>/target_test  <ul>
<li>/section_00_target_test_normal_0000.wav  </li>
<li>...  </li>
<li>/section_00_target_test_normal_0099.wav  </li>
<li>/section_00_target_test_anomaly_0000.wav  </li>
<li>...  </li>
<li>/section_00_target_test_anomaly_0099.wav  </li>
<li>/section_01_target_test_normal_0000.wav  </li>
<li>...  </li>
<li>/section_02_target_test_anomaly_0099.wav  </li>
</ul>
</li>
</ul>
</li>
<li>/gearbox (The other machine types have the same directory structure as fan.)  </li>
<li>/pump  </li>
<li>/slider (<code>slider</code> means "slide rail")</li>
<li>/ToyCar  </li>
<li>/ToyTrain  </li>
<li>/valve  </li>
</ul>
</li>
<li>/eval_data  <ul>
<li>/fan  <ul>
<li>/train (after launch of the additional training dataset)  <ul>
<li>/section_03_source_train_normal_0000_<attribute>.wav  </attribute></li>
<li>...  </li>
<li>/section_03_source_train_normal_0999_<attribute>.wav  </attribute></li>
<li>/section_03_target_train_normal_0000_<attribute>.wav  </attribute></li>
<li>/section_03_target_train_normal_0001_<attribute>.wav  </attribute></li>
<li>/section_03_target_train_normal_0002_<attribute>.wav  </attribute></li>
<li>/section_04_source_train_normal_0000_<attribute>.wav  </attribute></li>
<li>...  </li>
<li>/section_05_target_train_normal_0999_<attribute>.wav  </attribute></li>
</ul>
</li>
<li>/source_test (after launch of the evaluation dataset)  <ul>
<li>/section_03_source_test_0000.wav  </li>
<li>...  </li>
<li>/section_03_source_test_0199.wav  </li>
<li>/section_04_source_test_0000.wav  </li>
<li>...  </li>
<li>/section_05_source_test_0199.wav  </li>
</ul>
</li>
<li>/target_test (after launch of the evaluation dataset)  <ul>
<li>/section_03_target_test_0000.wav  </li>
<li>...  </li>
<li>/section_03_target_test_0199.wav  </li>
<li>/section_04_target_test_0000.wav  </li>
<li>...  </li>
<li>/section_05_target_test_0199.wav  </li>
</ul>
</li>
</ul>
</li>
<li>/gearbox (The other machine types have the same directory structure as fan.)  </li>
<li>/pump  </li>
<li>/slider (<code>slider</code> means "slide rail")</li>
<li>/ToyCar  </li>
<li>/ToyTrain  </li>
<li>/valve  </li>
</ul>
</li>
</ul>
<p>After you run the training script <code>00_train.py</code> and the test script <code>01_test.py</code>, a csv file for each section index and domain that lists the anomaly scores for each clip will be stored in the directory <code>result/</code>. Also, a csv file for each section index and domain that lists the normal/anomaly decision results for each clip will be stored in the same directory. You can get more detailed information in the GitHub repository.</p>
<h2 id="results-with-the-development-dataset">Results with the development dataset</h2>
<p>We evaluated the AUC and pAUC on the development dataset using several types of GPUs (RTX 2080, etc.). Because the results produced with a GPU are generally non-deterministic, the average and standard deviations from these five independent trials (training and testing) are shown in the following table.</p>
<h3>Detailed results for AE-based baseline</h3>
<div class="table-responsive col-md-10">
<table class="table table-striped table-condensed">
<tbody>
<tr>
<td><span class="label label-success">ToyCar</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>67.63 %<br/>61.97 %<br/>74.36 %<br/>54.50 %<br/>64.12 %<br/>56.57 %<br/>63.19 %<br/>62.49 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>1.21 %<br/>1.50 %<br/>0.82 %<br/>0.89 %<br/>1.07 %<br/>1.53 %<br/>0.80 %<br/>0.81 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>51.87 %<br/>51.82 %<br/>55.56 %<br/>50.52 %<br/>52.14 %<br/>52.61 %<br/>52.42 %<br/>52.36 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.50 %<br/>0.87 %<br/>0.83 %<br/>0.20 %<br/>0.80 %<br/>1.20 %<br/>0.25 %<br/>0.26 %</td>
</tr>
<tr>
<td><span class="label label-success">ToyTrain</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>72.67 %<br/>72.65 %<br/>69.91 %<br/>56.07 %<br/>51.13 %<br/>55.57 %<br/>63.00 %<br/>61.71 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>1.19 %<br/>0.32 %<br/>0.33 %<br/>0.80 %<br/>0.53 %<br/>1.07 %<br/>0.41 %<br/>0.44 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>69.38 %<br/>62.52 %<br/>47.48 %<br/>50.62 %<br/>48.60 %<br/>50.79 %<br/>54.90 %<br/>53.81 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>1.06 %<br/>0.88 %<br/>0.02 %<br/>0.68 %<br/>0.13 %<br/>0.93 %<br/>0.47 %<br/>0.40 %</td>
</tr>
<tr>
<td><span class="label label-success">fan</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>66.69 %<br/>67.43 %<br/>64.21 %<br/>69.70 %<br/>49.99 %<br/>66.19 %<br/>64.03 %<br/>63.24 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.81 %<br/>1.12 %<br/>1.27 %<br/>0.32 %<br/>0.48 %<br/>1.23 %<br/>0.35 %<br/>0.36 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>57.08 %<br/>50.72 %<br/>53.12 %<br/>55.13 %<br/>48.49 %<br/>56.93 %<br/>53.58 %<br/>53.38 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.15 %<br/>0.42 %<br/>0.78 %<br/>0.34 %<br/>0.38 %<br/>1.37 %<br/>0.19 %<br/>0.21 %</td>
</tr>
<tr>
<td><span class="label label-success">gearbox</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>56.03 %<br/>72.77 %<br/>58.96 %<br/>74.29 %<br/>72.12 %<br/>66.41 %<br/>66.76 %<br/>65.97 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.53 %<br/>0.72 %<br/>0.53 %<br/>0.51 %<br/>1.06 %<br/>0.72 %<br/>0.36 %<br/>0.30 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>51.59 %<br/>52.30 %<br/>51.82 %<br/>55.67 %<br/>51.78 %<br/>53.66 %<br/>52.80 %<br/>52.76 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.16 %<br/>0.18 %<br/>0.29 %<br/>0.97 %<br/>0.15 %<br/>0.57 %<br/>0.28 %<br/>0.26 %</td>
</tr>
<tr>
<td><span class="label label-success">pump</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>67.48 %<br/>82.38 %<br/>63.93 %<br/>58.01 %<br/>47.35 %<br/>62.78 %<br/>63.66 %<br/>61.92 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.58 %<br/>0.27 %<br/>0.45 %<br/>0.57 %<br/>0.53 %<br/>0.70 %<br/>0.19 %<br/>0.18 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>61.83 %<br/>58.29 %<br/>55.44 %<br/>51.53 %<br/>49.65 %<br/>51.67 %<br/>54.74 %<br/>54.41 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.41 %<br/>0.77 %<br/>0.52 %<br/>0.27 %<br/>1.46 %<br/>0.35 %<br/>0.43 %<br/>0.46 %</td>
</tr>
<tr>
<td><span class="label label-success">slide rail</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>74.09 %<br/>82.16 %<br/>78.34 %<br/>67.22 %<br/>66.94 %<br/>46.20 %<br/>69.16 %<br/>66.74 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.48 %<br/>0.35 %<br/>0.16 %<br/>0.45 %<br/>0.39 %<br/>0.77 %<br/>0.36 %<br/>0.44 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>52.45 %<br/>60.29 %<br/>65.16 %<br/>57.32 %<br/>53.08 %<br/>50.10 %<br/>56.40 %<br/>55.94 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.63 %<br/>0.30 %<br/>0.55 %<br/>0.52 %<br/>0.39 %<br/>0.31 %<br/>0.16 %<br/>0.17 %</td>
</tr>
<tr>
<td><span class="label label-success">valve</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>50.34 %<br/>53.52 %<br/>59.91 %<br/>47.12 %<br/>56.39 %<br/>55.16 %<br/>53.74 %<br/>53.41 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>0.27 %<br/>0.33 %<br/>0.34 %<br/>0.18 %<br/>1.42 %<br/>0.22 %<br/>0.25 %<br/>0.22 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>50.82 %<br/>49.33 %<br/>51.96 %<br/>48.68 %<br/>53.88 %<br/>48.97 %<br/>50.61 %<br/>50.54 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>0.16 %<br/>0.10 %<br/>0.52 %<br/>0.09 %<br/>0.61 %<br/>0.04 %<br/>0.11 %<br/>0.10 %</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h3>Detailed results for MobileNetV2-based baseline</h3>
<div class="table-responsive col-md-10">
<table class="table table-striped table-condensed">
<tbody>
<tr>
<td><span class="label label-success">ToyCar</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>66.56 %<br/>71.58 %<br/>40.37 %<br/>61.32 %<br/>72.48%<br/>45.17 %<br/>59.58 %<br/>56.04 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>2.68 %<br/>5.54 %<br/>7.19 %<br/>5.94 %<br/>3.68 %<br/>3.36 %<br/>1.49 %<br/>2.25 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>66.47 %<br/>66.44 %<br/>47.48 %<br/>52.61 %<br/>63.99 %<br/>48.85 %<br/>57.64 %<br/>56.37 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>5.67 %<br/>2.84 %<br/>0.23 %<br/>2.41 %<br/>2.60 %<br/>0.94 %<br/>1.13 %<br/>0.87 %</td>
</tr>
<tr>
<td><span class="label label-success">ToyTrain</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>69.84 %<br/>64.79 %<br/>69.28 %<br/>46.28 %<br/>53.38 %<br/>51.42 %<br/>59.16 %<br/>57.46 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>4.39 %<br/>3.65 %<br/>6.73 %<br/>3.85 %<br/>2.47 %<br/>2.64 %<br/>1.02 %<br/>1.27 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>54.43 %<br/>54.09 %<br/>47.66 %<br/>51.27 %<br/>49.60 %<br/>53.40 %<br/>51.74 %<br/>51.61 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>1.65 %<br/>1.15 %<br/>0.40 %<br/>0.73 %<br/>0.88 %<br/>1.12 %<br/>0.53 %<br/>0.51 %</td>
</tr>
<tr>
<td><span class="label label-success">fan</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>43.62 %<br/>78.33 %<br/>74.21 %<br/>53.34 %<br/>78.12 %<br/>60.35 %<br/>64.66 %<br/>61.56 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>2.35 %<br/>1.52 %<br/>3.85 %<br/>2.03 %<br/>4.25 %<br/>3.79 %<br/>1.25 %<br/>1.45 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>50.45 %<br/>78.37 %<br/>76.80 %<br/>56.01 %<br/>66.41 %<br/>60.97 %<br/>64.84 %<br/>63.02 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>1.15 %<br/>2.26 %<br/>0.78 %<br/>1.38 %<br/>7.16 %<br/>6.55 %<br/>2.36 %<br/>2.18 %</td>
</tr>
<tr>
<td><span class="label label-success">gearbox</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>81.35 %<br/>60.74 %<br/>71.58 %<br/>75.02 %<br/>56.27 %<br/>64.45 %<br/>68.24 %<br/>66.70 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>1.59 %<br/>5.11 %<br/>7.16 %<br/>2.92 %<br/>8.27 %<br/>9.67 %<br/>4.25 %<br/>4.97 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>70.46 %<br/>53.88 %<br/>62.23 %<br/>64.77 %<br/>53.30 %<br/>55.58 %<br/>60.03 %<br/>59.16 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>3.67 %<br/>2.82 %<br/>6.67 %<br/>2.52 %<br/>2.97 %<br/>7.90 %<br/>3.18 %<br/>3.10 %</td>
</tr>
<tr>
<td><span class="label label-success">pump</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>64.09 %<br/>86.27 %<br/>53.70 %<br/>59.09 %<br/>71.86 %<br/>50.16 %<br/>64.20 %<br/>61.89 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>4.34 %<br/>3.18 %<br/>4.99 %<br/>3.08 %<br/>5.97 %<br/>3.78 %<br/>2.54 %<br/>2.51 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>62.40 %<br/>66.66 %<br/>50.98 %<br/>53.96 %<br/>62.69 %<br/>51.69 %<br/>58.06 %<br/>57.37 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>1.90 %<br/>5.23 %<br/>1.23 %<br/>0.93 %<br/>2.33 %<br/>1.03 %<br/>1.40 %<br/>1.17 %</td>
</tr>
<tr>
<td><span class="label label-success">slide rail</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>61.51 %<br/>79.97 %<br/>79.86 %<br/>51.96 %<br/>46.83 %<br/>55.61 %<br/>62.62 %<br/>59.26 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>4.92 %<br/>3.70 %<br/>1.41 %<br/>3.17 %<br/>10.65 %<br/>5.48 %<br/>1.39 %<br/>2.04 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>53.97 %<br/>55.62 %<br/>71.88 %<br/>51.96 %<br/>52.02 %<br/>55.71 %<br/>56.86 %<br/>56.00 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>2.03 %<br/>1.57 %<br/>4.64 %<br/>2.96 %<br/>4.17 %<br/>2.84 %<br/>1.10 %<br/>0.86 %</td>
</tr>
<tr>
<td><span class="label label-success">valve</span><br/><strong>Section (Domain)</strong><br/>0 (Source)<br/>1 (Source)<br/>2 (Source)<br/>0 (Target)<br/>1 (Target)<br/>2 (Target)<br/><strong>Arithmetic mean</strong><br/><strong>Harmonic mean</strong></td>
<td><br/><strong>AUC (Ave.)</strong><br/>58.34 %<br/>53.57 %<br/>56.13 %<br/>52.19 %<br/>68.59 %<br/>53.58 %<br/>57.07 %<br/>56.51 %</td>
<td><br/><strong>AUC (Std.)</strong><br/>4.01 %<br/>2.26 %<br/>1.96 %<br/>3.33 %<br/>2.84 %<br/>0.55 %<br/>1.77 %<br/>1.70 %</td>
<td><br/><strong>pAUC (Ave.)</strong><br/>54.97 %<br/>50.09 %<br/>51.69 %<br/>51.54 %<br/>57.83 %<br/>50.86 %<br/>52.83 %<br/>52.64 %</td>
<td><br/><strong>pAUC (Std.)</strong><br/>4.43 %<br/>0.45 %<br/>0.32 %<br/>1.88 %<br/>2.49 %<br/>0.84 %<br/>1.33 %<br/>1.22 %</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="clearfix"></div>
<h1 id="citation">Citation</h1>
<p>If you are participating in this task or using the <strong>MIMII DUE</strong> and <strong>ToyADMOS2</strong>, and <strong>baseline code</strong>, please cite the following papers:</p>
<div class="btex-item" data-item="Tanabe_WASPAA2021_01" data-source="content/data/challenge2021/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Tanabe_WASPAA2021_01"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Ryo Tanabe, Harsh Purohit, Kota Dohi, Takashi Endo, Yuki Nikaido, Toshiki Nakamura, and Yohei Kawaguchi.
<em>MIMII DUE: sound dataset for malfunctioning industrial machine investigation and inspection with domain shifts due to changes in operational and environmental conditions.</em>
<em>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em>, pages 21–25, 2021.
<a href="https://doi.org/10.1109/WASPAA52581.2021.9632802">doi:10.1109/WASPAA52581.2021.9632802</a>.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://arxiv.org/pdf/2105.02702.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" class="panel-collapse collapse" id="collapseTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" role="tabpanel">
<h4>MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection with Domain Shifts due to Changes in Operational and Environmental Conditions</h4>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://arxiv.org/pdf/2105.02702.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2label" class="modal fade" id="bibtexTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexTanabe_WASPAA2021_01336b1853f1594a04999a9e21aa4ac3f2label">MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection with Domain Shifts due to Changes in Operational and Environmental Conditions</h4>
</div>
<div class="modal-body">
<pre>@article{Tanabe_WASPAA2021_01,
    author = "Tanabe, Ryo and Purohit, Harsh and Dohi, Kota and Endo, Takashi and Nikaido, Yuki and Nakamura, Toshiki and Kawaguchi, Yohei",
    title = "{MIMII DUE}: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection with Domain Shifts due to Changes in Operational and Environmental Conditions",
    journal = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
    year = "2021",
    pages = "21-25",
    doi = "10.1109/WASPAA52581.2021.9632802"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Harada2021" data-source="content/data/challenge2021/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Harada2021"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Noboru Harada, Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Masahiro Yasuda, and Shoichiro Saito.
<em>ToyADMOS2: another dataset of miniature-machine operating sounds for anomalous sound detection under domain shift conditions.</em>
In Proceedings of the 6th Detection and Classification of Acoustic Scenes and Events 2021 Workshop (DCASE2021), 1–5. Barcelona, Spain, November 2021.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexHarada20217772811edab840249486531f3ebf98e6" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://dcase.community/documents/workshop2021/proceedings/DCASE2021Workshop_Harada_6.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseHarada20217772811edab840249486531f3ebf98e6" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseHarada20217772811edab840249486531f3ebf98e6" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingHarada20217772811edab840249486531f3ebf98e6" class="panel-collapse collapse" id="collapseHarada20217772811edab840249486531f3ebf98e6" role="tabpanel">
<h4>ToyADMOS2: Another Dataset of Miniature-Machine Operating Sounds for Anomalous Sound Detection under Domain Shift Conditions</h4>
<h5>Abstract</h5>
<p class="text-justify">This paper proposes a new large-scale dataset called “ToyADMOS” for anomaly detection in machine operating sounds (ADMOS). As with our previous ToyADMOS dataset, we collected a large number of operating sounds of miniature machines (toys) under normal and anomaly conditions by deliberately damaging them, but extended them in this case by providing a controlled depth of damages in the anomaly samples. Since typical application scenarios of ADMOS require robust performance under domain-shift conditions, the ToyADMOS2 dataset is designed for evaluating systems under such conditions. The released dataset consists of two sub-datasets for machine-condition inspection: fault diagnosis of machines with geometrically fixed tasks and fault diagnosis of machines with moving tasks. Domain shifts are represented by introducing several differences in operating conditions, such as the use of the same machine type but with different models and parts configurations, operating speeds, microphone arrangements, etc. Each subdataset contains over 27 k samples of normal machine-operating sounds and over 8 k samples of anomalous sounds recorded with five to eight microphones. The dataset is freely available for download at https://github.com/nttcslab/ToyADMOS2-dataset and https://doi.org/10.5281/zenodo.4580270.</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexHarada20217772811edab840249486531f3ebf98e6" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://dcase.community/documents/workshop2021/proceedings/DCASE2021Workshop_Harada_6.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexHarada20217772811edab840249486531f3ebf98e6label" class="modal fade" id="bibtexHarada20217772811edab840249486531f3ebf98e6" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexHarada20217772811edab840249486531f3ebf98e6label">ToyADMOS2: Another Dataset of Miniature-Machine Operating Sounds for Anomalous Sound Detection under Domain Shift Conditions</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Harada2021,
    author = "Harada, Noboru and Niizumi, Daisuke and Takeuchi, Daiki and Ohishi, Yasunori and Yasuda, Masahiro and Saito, Shoichiro",
    title = "{ToyADMOS2}: Another Dataset of Miniature-Machine Operating Sounds for Anomalous Sound Detection under Domain Shift Conditions",
    booktitle = "Proceedings of the 6th Detection and Classification of Acoustic Scenes and Events 2021 Workshop (DCASE2021)",
    address = "Barcelona, Spain",
    month = "November",
    year = "2021",
    pages = "1--5",
    abstract = "This paper proposes a new large-scale dataset called “ToyADMOS” for anomaly detection in machine operating sounds (ADMOS). As with our previous ToyADMOS dataset, we collected a large number of operating sounds of miniature machines (toys) under normal and anomaly conditions by deliberately damaging them, but extended them in this case by providing a controlled depth of damages in the anomaly samples. Since typical application scenarios of ADMOS require robust performance under domain-shift conditions, the ToyADMOS2 dataset is designed for evaluating systems under such conditions. The released dataset consists of two sub-datasets for machine-condition inspection: fault diagnosis of machines with geometrically fixed tasks and fault diagnosis of machines with moving tasks. Domain shifts are represented by introducing several differences in operating conditions, such as the use of the same machine type but with different models and parts configurations, operating speeds, microphone arrangements, etc. Each subdataset contains over 27 k samples of normal machine-operating sounds and over 8 k samples of anomalous sounds recorded with five to eight microphones. The dataset is freely available for download at https://github.com/nttcslab/ToyADMOS2-dataset and https://doi.org/10.5281/zenodo.4580270.",
    isbn = "978-84-09-36072-7",
    doi. = "10.5281/zenodo.5770113"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<div class="btex-item" data-item="Kawaguchi2021" data-source="content/data/challenge2021/publications.bib">
<div class="panel panel-default">
<span class="label label-default" style="padding-top:0.4em;margin-left:0em;margin-top:0em;">Publication<a name="Kawaguchi2021"></a></span>
<div class="panel-body">
<div class="row">
<div class="col-md-9">
<p style="text-align:left">
                            Yohei Kawaguchi, Keisuke Imoto, Yuma Koizumi, Noboru Harada, Daisuke Niizumi, Kota Dohi, Ryo Tanabe, Harsh Purohit, and Takashi Endo.
<em>Description and discussion on dcase 2021 challenge task 2: unsupervised anomalous detection for machine condition monitoring under domain shifted conditions.</em>
In Proceedings of the 6th Detection and Classification of Acoustic Scenes and Events 2021 Workshop (DCASE2021), 186–190. Barcelona, Spain, November 2021.
                            
                            
                            </p>
</div>
<div class="col-md-3">
<div class="btn-group pull-right">
<button class="btn btn-xs btn-danger" data-target="#bibtexKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bib</button>
<a class="btn btn-xs btn-warning btn-btex" data-placement="bottom" href="https://dcase.community/documents/workshop2021/proceedings/DCASE2021Workshop_Kawaguchi_61.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
<button aria-controls="collapseKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#btex-items-accordion" data-toggle="collapse" href="#collapseKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" type="button">
<i class="fa fa-caret-down"></i>
</button>
</div>
</div>
</div>
<div aria-labelledby="headingKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" class="panel-collapse collapse" id="collapseKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" role="tabpanel">
<h4>Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Detection for Machine Condition Monitoring Under Domain Shifted Conditions</h4>
<h5>Abstract</h5>
<p class="text-justify">We present the task description and discussion on the results of the DCASE 2021 Challenge Task 2. In 2020, we organized an unsupervised anomalous sound detection (ASD) task, identifying whether a given sound was normal or anomalous without anomalous training data. In 2021, we organized an advanced unsupervised ASD task under domain-shift conditions, which focuses on the inevitable problem of the practical use of ASD systems. The main challenge of this task is to detect unknown anomalous sounds where the acoustic characteristics of the training and testing samples are different, i.e., domain-shifted. This problem frequently occurs due to changes in seasons, manufactured products, and/or environmental noise. We received 75 submissions from 26 teams, and several novel approaches have been developed in this challenge. On the basis of the analysis of the evaluation results, we found that there are two types of remarkable approaches that TOP-5 winning teams adopted: 1) ensemble approaches of ``outlier exposure'' (OE)-based detectors and ``inlier modeling'' (IM)-based detectors and 2) approaches based on IM-based detection for features learned in a machine-identification task.</p>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtexKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" data-toggle="modal" type="button"><i class="fa fa-file-text-o"></i> Bibtex</button>
<a class="btn btn-sm btn-warning btn-btex2" data-placement="bottom" href="https://dcase.community/documents/workshop2021/proceedings/DCASE2021Workshop_Kawaguchi_61.pdf" rel="tooltip" title="Download pdf"><i class="fa fa-file-pdf-o fa-1x"></i> PDF</a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtexKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4blabel" class="modal fade" id="bibtexKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4b" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true" class="glyphicon glyphicon-remove-sign"></span><span class="sr-only">Close</span></button>
<h4 class="modal-title" id="bibtexKawaguchi2021a7b82fae96074d249e3271b0cfc4ea4blabel">Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Detection for Machine Condition Monitoring Under Domain Shifted Conditions</h4>
</div>
<div class="modal-body">
<pre>@inproceedings{Kawaguchi2021,
    author = "Kawaguchi, Yohei and Imoto, Keisuke and Koizumi, Yuma and Harada, Noboru and Niizumi, Daisuke and Dohi, Kota and Tanabe, Ryo and Purohit, Harsh and Endo, Takashi",
    title = "Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Detection for Machine Condition Monitoring Under Domain Shifted Conditions",
    booktitle = "Proceedings of the 6th Detection and Classification of Acoustic Scenes and Events 2021 Workshop (DCASE2021)",
    address = "Barcelona, Spain",
    month = "November",
    year = "2021",
    pages = "186--190",
    abstract = "We present the task description and discussion on the results of the DCASE 2021 Challenge Task 2. In 2020, we organized an unsupervised anomalous sound detection (ASD) task, identifying whether a given sound was normal or anomalous without anomalous training data. In 2021, we organized an advanced unsupervised ASD task under domain-shift conditions, which focuses on the inevitable problem of the practical use of ASD systems. The main challenge of this task is to detect unknown anomalous sounds where the acoustic characteristics of the training and testing samples are different, i.e., domain-shifted. This problem frequently occurs due to changes in seasons, manufactured products, and/or environmental noise. We received 75 submissions from 26 teams, and several novel approaches have been developed in this challenge. On the basis of the analysis of the evaluation results, we found that there are two types of remarkable approaches that TOP-5 winning teams adopted: 1) ensemble approaches of ``outlier exposure'' (OE)-based detectors and ``inlier modeling'' (IM)-based detectors and 2) approaches based on IM-based detection for features learned in a machine-identification task.",
    isbn = "978-84-09-36072-7",
    doi. = "10.5281/zenodo.5770113"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">Close</button>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>