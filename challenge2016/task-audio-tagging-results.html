<!DOCTYPE html><html lang="en">
<head>
    <title>Domestic audio tagging - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2016/task-audio-tagging-results">
        <meta name="author" content="Toni Heittola" />
        <meta name="description" content="Task description Detailed task description in task description page Challenge results Here you can find complete information on the submissions for Task 4: results on evaluation and development set (when reported by authors), class-wise results, technical reports and bibtex citations. System outputs: DCASE2016 Challenge Submissions Package (28.7 MB) Systems …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/font-mfizz.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2016</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2016/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-acoustic-scene-classification-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-synthetic text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-synthetic-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-events text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2016/task-sound-event-detection-in-real-life-audio-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group  active">
        <a href="/challenge2016/task-audio-tagging" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-tags text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2016/task-audio-tagging"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" active">
        <a href="/challenge2016/task-audio-tagging-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Download data">
        <a href="/challenge2016/download"><i class="fa fa-download"></i>&nbsp;Download</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2016/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2016/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge organizers">
        <a href="/challenge2016/organizers"><i class="fa fa-users"></i>&nbsp;Organizers</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/leafs-01.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-success"></i><i class="fa dc-events fa-stack-1x fa-inverse"></i><strong class="fa-stack-1x dcase-icon-top-text">Events</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 3</span></span><img src="../images/logos/dcase/dcase2016_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Domestic audio tagging</h1><hr class="small right bold"><span class="subheading">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#challenge-results">Challenge results</a>
<ul>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a></li>
</ul>
</li>
<li><a href="#system-characteristics">System characteristics</a></li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h2 id="task-description">Task description</h2>
<p>Detailed task description in <a class="btn btn-primary" href="/challenge2016/task-audio-tagging">task description page</a></p>
<h2 id="challenge-results">Challenge results</h2>
<p>Here you can find complete information on the submissions for Task 4: results on evaluation and development set (when reported by authors), class-wise results, technical reports and bibtex citations.</p>
<p>System outputs:</p>
<div class="row">
<div class="col-md-1">
<a class="icon" href="https://zenodo.org/record/926660" target="_blank">
<span class="fa-stack fa-2x">
<i class="fa fa-square fa-stack-2x text-muted"></i>
<i class="fa fa-file-text-o fa-stack-1x fa-inverse"></i>
</span>
</a>
</div>
<div class="col-md-11">
<a href="https://zenodo.org/record/926660" target="_blank">
<span style="font-size:20px;">DCASE2016 Challenge Submissions Package <i class="fa fa-download"></i></span>
</a>
<span class="text-muted">(28.7 MB)</span>
<br/>
<a href="http://dx.doi.org/10.5281/zenodo.926660">
<img alt="10.5281/zenodo.926660" src="https://zenodo.org/badge/doi/10.5281/zenodo.926660.svg"/>
</a>
</div>
</div>
<p><br/></p>
<h3 id="systems-ranking">Systems ranking</h3>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eer_mean_eval" data-scatter-y="eer_mean_dev" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="eer_mean_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-beginatzero="true" data-chartable="true" data-field="eer_mean_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Equal Error Rate <br/>(evaluation dataset)
            </th>
<th class="sep-left-cell text-center" data-beginatzero="true" data-chartable="true" data-field="eer_mean_dev" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Equal Error Rate <br/>(development dataset)
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Cakir_task4_1</td>
<td>Cakir2016</td>
<td>16.8</td>
<td>17.1</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2016 baseline</td>
<td>Foster2016</td>
<td>20.9</td>
<td>21.3</td>
</tr>
<tr>
<td></td>
<td>Hertel_task4_1</td>
<td>Hertel2016</td>
<td>22.1</td>
<td>17.3</td>
</tr>
<tr>
<td></td>
<td>Kong_task4_1</td>
<td>Kong2016</td>
<td>18.9</td>
<td>20.9</td>
</tr>
<tr>
<td></td>
<td>Lidy_task4_1</td>
<td>Lidy2016</td>
<td>16.6</td>
<td>17.8</td>
</tr>
<tr>
<td></td>
<td>Vu_task4_1</td>
<td>Vu2016</td>
<td>21.1</td>
<td>20.0</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_1</td>
<td>Xu2016</td>
<td>19.5</td>
<td>17.9</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_2</td>
<td>Xu2016</td>
<td>19.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yun_task4_1</td>
<td>Yun2016</td>
<td>17.4</td>
<td>17.6</td>
</tr>
</tbody>
</table>
<h3 id="class-wise-performance">Class-wise performance</h3>
<table class="datatable table" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-comparison-a-row="DCASE2016 baseline" data-comparison-active-set="Class-wise performance" data-comparison-b-row="Lidy_task4_1" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance",
        "data_axis_title": "EER",
        "fields": ["eer_mean_eval","eer_child_speech_eval","eer_adult_male_speech_eval","eer_adult_female_speech_eval","eer_video_game_eval","eer_percussive_eval","eer_broadband_eval","eer_other_eval"]}]' data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="eer_mean_eval" data-scatter-y="eer_mean_eval" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="eer_mean_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th class="sm-cell" data-field="code" data-sortable="true" rowspan="2">
                Submission <br/>code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Tech. <br/>Report
            </th>
<th class="sep-left-cell text-center" colspan="8">
                Equal Error Rate <br/>(evaluation dataset)
            </th>
</tr>
<tr>
<th class="sep-left-cell text-center" data-beginatzero="true" data-chartable="true" data-field="eer_mean_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Average<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_child_speech_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Child <br/>speech<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_adult_male_speech_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Adult <br/>male <br/>speech<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_adult_female_speech_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Adult <br/>female <br/>speech<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_video_game_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Video <br/>game / <br/>TV<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_percussive_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Percussive <br/>sounds<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_broadband_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Broadband <br/>noise<br/>
</th>
<th class="text-center" data-beginatzero="true" data-chartable="true" data-field="eer_other_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage">
                Other <br/>identifiable <br/>sounds<br/>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Cakir_task4_1</td>
<td>Cakir2016</td>
<td>16.8</td>
<td>25.0</td>
<td>15.9</td>
<td>25.0</td>
<td>2.7</td>
<td>20.8</td>
<td>2.2</td>
<td>25.8</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2016 baseline</td>
<td>Foster2016</td>
<td>20.9</td>
<td>19.1</td>
<td>32.6</td>
<td>31.4</td>
<td>5.6</td>
<td>21.2</td>
<td>11.7</td>
<td>24.9</td>
</tr>
<tr>
<td></td>
<td>Hertel_task4_1</td>
<td>Hertel2016</td>
<td>22.1</td>
<td>18.3</td>
<td>27.8</td>
<td>23.4</td>
<td>8.0</td>
<td>20.1</td>
<td>32.3</td>
<td>24.6</td>
</tr>
<tr>
<td></td>
<td>Kong_task4_1</td>
<td>Kong2016</td>
<td>18.9</td>
<td>19.5</td>
<td>28.0</td>
<td>22.9</td>
<td>9.0</td>
<td>22.1</td>
<td>3.9</td>
<td>27.2</td>
</tr>
<tr>
<td></td>
<td>Lidy_task4_1</td>
<td>Lidy2016</td>
<td>16.6</td>
<td>21.0</td>
<td>18.2</td>
<td>21.4</td>
<td>3.5</td>
<td>16.8</td>
<td>3.2</td>
<td>32.0</td>
</tr>
<tr>
<td></td>
<td>Vu_task4_1</td>
<td>Vu2016</td>
<td>21.1</td>
<td>22.6</td>
<td>30.7</td>
<td>29.3</td>
<td>7.8</td>
<td>21.8</td>
<td>7.8</td>
<td>27.9</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_1</td>
<td>Xu2016</td>
<td>19.5</td>
<td>20.9</td>
<td>31.3</td>
<td>21.6</td>
<td>4.0</td>
<td>24.9</td>
<td>6.5</td>
<td>27.2</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_2</td>
<td>Xu2016</td>
<td>19.8</td>
<td>20.3</td>
<td>30.4</td>
<td>23.6</td>
<td>3.7</td>
<td>27.5</td>
<td>4.8</td>
<td>28.0</td>
</tr>
<tr>
<td></td>
<td>Yun_task4_1</td>
<td>Yun2016</td>
<td>17.4</td>
<td>17.7</td>
<td>25.3</td>
<td>17.9</td>
<td>10.2</td>
<td>20.7</td>
<td>3.2</td>
<td>26.6</td>
</tr>
</tbody>
</table>
<h2 id="system-characteristics">System characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="eer_mean_eval" data-sort-order="desc" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true" rowspan="2">Rank</th>
<th data-field="code" data-sortable="true" rowspan="2">
                Submission <br/>code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor" rowspan="2">
                Tech.<br/>Report
            </th>
<th class="sep-left-cell text-center" data-beginatzero="true" data-chartable="true" data-field="eer_mean_eval" data-reversed="true" data-sortable="true" data-value-type="float1-percentage" rowspan="2">
                Equal Error Rate <br/>(evaluation dataset)
            </th>
<th class="sep-left-cell text-center" colspan="2">System characteristics</th>
</tr>
<tr>
<th class="sep-left-cell text-center" data-field="system_features" data-filter-control="select" data-sortable="true" data-tag="true">
                Features
            </th>
<th class="text-center" data-field="system_classifier" data-filter-control="select" data-sortable="true" data-tag="true">
                Classifier
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Cakir_task4_1</td>
<td>Cakir2016</td>
<td>16.8</td>
<td>Mel spectrogram</td>
<td>CNN</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2016 baseline</td>
<td>Foster2016</td>
<td>20.9</td>
<td>MFCCs</td>
<td>GMM</td>
</tr>
<tr>
<td></td>
<td>Hertel_task4_1</td>
<td>Hertel2016</td>
<td>22.1</td>
<td>Magnitude spectrogram</td>
<td>CNN</td>
</tr>
<tr>
<td></td>
<td>Kong_task4_1</td>
<td>Kong2016</td>
<td>18.9</td>
<td>Mel spectrogram</td>
<td>DNN</td>
</tr>
<tr>
<td></td>
<td>Lidy_task4_1</td>
<td>Lidy2016</td>
<td>16.6</td>
<td>CQT features</td>
<td>CNN</td>
</tr>
<tr>
<td></td>
<td>Vu_task4_1</td>
<td>Vu2016</td>
<td>21.1</td>
<td>MFCCs</td>
<td>RNN</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_1</td>
<td>Xu2016</td>
<td>19.5</td>
<td>MFCCs</td>
<td>DNN</td>
</tr>
<tr>
<td></td>
<td>Xu_task4_2</td>
<td>Xu2016</td>
<td>19.8</td>
<td>MFCCs</td>
<td>DNN</td>
</tr>
<tr>
<td></td>
<td>Yun_task4_1</td>
<td>Yun2016</td>
<td>17.4</td>
<td>MFCCs</td>
<td>GMM</td>
</tr>
</tbody>
</table>
<h2 id="technical-reports">Technical reports</h2>
<div class="btex" data-source="content/data/challenge2016/technical_reports_task4.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Cakir2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Cakir2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Domestic Audio Tagging with Convolutional Neural Networks
       </h4>
<p style="text-align:left">
        Emre Cakir, Toni Heittola and Tuomas Virtanen
       </p>
<p style="text-align:left">
<em>
         Tampere University of Technology, Tampere, Finland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Cakir_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Cakir2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Cakir2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Cakir2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Cakir_4003.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Cakir2016" class="panel-collapse collapse" id="collapse-Cakir2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Domestic Audio Tagging with Convolutional Neural Networks
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       In this paper, the method used in our submission for DCASE2016 challenge task 4 (domestic audio tagging) is described. The use of convolutional neural networks (CNN) to label the audio signals recorded in a domestic (home) environment is investigated. A relative 23.8% improvement over the Gaussian mixture model (GMM) baseline method is observed over the development dataset for the challenge.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Cakir2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Cakir_4003.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Cakir2016label" class="modal fade" id="bibtex-Cakir2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexCakir2016label">
        Domestic Audio Tagging with Convolutional Neural Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Cakir2016,
    Author = "Cakir, Emre and Heittola, Toni and Virtanen, Tuomas",
    title = "Domestic Audio Tagging with Convolutional Neural Networks",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "In this paper, the method used in our submission for DCASE2016 challenge task 4 (domestic audio tagging) is described. The use of convolutional neural networks (CNN) to label the audio signals recorded in a domestic (home) environment is investigated. A relative 23.8\% improvement over the Gaussian mixture model (GMM) baseline method is observed over the development dataset for the challenge."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Foster2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Foster2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE2016 Baseline System
       </h4>
<p style="text-align:left">
        Peter Foster<sup>1</sup> and Toni Heittola<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Queen Mary University of London, London, United Kingdom, <sup>2</sup>Tampere University of Technology, Tampere, Finland
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">DCASE2016_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Foster2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Foster2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Foster2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Foster2016').collapse('show');window.location.hash='#Foster2016';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Foster2016" class="panel-collapse collapse" id="collapse-Foster2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE2016 Baseline System
      </h4>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCCs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         GMM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Foster2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/pafoster/dcase2016_task4/tree/master/baseline" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Foster2016label" class="modal fade" id="bibtex-Foster2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexFoster2016label">
        DCASE2016 Baseline System
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Foster2016,
    Author = "Foster, Peter and Heittola, Toni",
    title = "{DCASE}2016 Baseline System",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Hertel2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Hertel2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling
       </h4>
<p style="text-align:left">
        Lars Hertel<sup>1</sup>, Huy Phan<sup>1,2</sup> and Alfred Mertins<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute for Signal Processing, University of Luebeck, Luebeck, Germany, <sup>2</sup>Graduate School for Computing in Medicine and Life Sciences, University of Luebeck, Luebeck, Germany
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Hertel_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Hertel2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Hertel2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Hertel2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Hertel_4004.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Hertel2016" class="panel-collapse collapse" id="collapse-Hertel2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       We trained a deep all-convolutional neural network with masked global pooling to perform single-label classification for acoustic scene classification and multi-label classification for domestic audio tagging in the DCASE-2016 contest. Our network achieved an average accuracy of 84.5 % on the four-fold cross-validation for acoustic scene recognition, compared to the provided baseline of 72.5 %, and an average equal error rate of 0.17 for domestic audio tagging, compared to the baseline of 0.21. The network therefore improves the baselines by a relative amount of 17 % and 19 %, respectively. The network only consists of convolutional layers to extract features from the short-time Fourier transform and one global pooling layer to combine those features. It particularly possesses neither fully-connected layers, besides the fully-connected output layer. nor dropout layers.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Magnitude spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Hertel2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Hertel_4004.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Hertel2016label" class="modal fade" id="bibtex-Hertel2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHertel2016label">
        Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Hertel2016,
    Author = "Hertel, Lars and Phan, Huy and Mertins, Alfred",
    title = "Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "We trained a deep all-convolutional neural network with masked global pooling to perform single-label classification for acoustic scene classification and multi-label classification for domestic audio tagging in the DCASE-2016 contest. Our network achieved an average accuracy of 84.5 \% on the four-fold cross-validation for acoustic scene recognition, compared to the provided baseline of 72.5 \%, and an average equal error rate of 0.17 for domestic audio tagging, compared to the baseline of 0.21. The network therefore improves the baselines by a relative amount of 17 \% and 19 \%, respectively. The network only consists of convolutional layers to extract features from the short-time Fourier transform and one global pooling layer to combine those features. It particularly possesses neither fully-connected layers, besides the fully-connected output layer. nor dropout layers."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kong2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Kong2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Deep Neural Network Baseline for DCASE Challenge 2016
       </h4>
<p style="text-align:left">
        Qiuqiang Kong, Iwona Sobieraj, Wenwu Wang and Mark Plumbley
       </p>
<p style="text-align:left">
<em>
         Centre for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kong_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kong2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kong2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kong2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kong_4002.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Kong2016').collapse('show');window.location.hash='#Kong2016';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kong2016" class="panel-collapse collapse" id="collapse-Kong2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Deep Neural Network Baseline for DCASE Challenge 2016
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       The DCASE Challenge 2016 contains tasks for Acoustic Scene Classification (ASC), Acoustic Event Detection (AED), and audio tagging. Since 2006, Deep Neural Networks (DNNs) have been widely applied to computer visions, speech recognition and natural language processing tasks. In this paper, we provide DNN baselines for the DCASE Challenge 2016. For feature extraction, 40 Mel-filter bank features are used. Two kinds of Mel banks, same area bank and same height bank are discussed. Experimental results show that the same height bank is better than the same area bank. DNNs with the same structure are applied to all four tasks in the DCASE Challenge 2016. In Task 1 we obtained accuracy of 76.4% using Mel + DNN against 72.5% by using Mel Frequency Ceptral Coefficient (MFCC) + Gaussian Mixture Model (GMM). In Task 2 we obtained F value of 17.4% using Mel + DNN against 41.6% by using Constant Q Transform (CQT) + Nonnegative Matrix Factorization (NMF). In Task 3 we obtained F value of 38.1% using Mel + DNN against 26.6% by using MFCC + GMM. In task 4 we obtained Equal Error Rate (ERR) of 20.9% using Mel + DNN against 21.0% by using MFCC + GMM. Therefore the DNN improves the baseline in Task 1 and Task 3, and is similar to the baseline in Task 4, although is worse than the baseline in Task 2. This indicates that DNNs can be successful in many of these tasks, but may not always work.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Mel spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         DNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kong2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Kong_4002.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/qiuqiangkong/DCASE2016_Task4" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kong2016label" class="modal fade" id="bibtex-Kong2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKong2016label">
        Deep Neural Network Baseline for DCASE Challenge 2016
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kong2016,
    Author = "Kong, Qiuqiang and Sobieraj, Iwona and Wang, Wenwu and Plumbley, Mark",
    title = "Deep Neural Network Baseline for {DCASE} Challenge 2016",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "The DCASE Challenge 2016 contains tasks for Acoustic Scene Classification (ASC), Acoustic Event Detection (AED), and audio tagging. Since 2006, Deep Neural Networks (DNNs) have been widely applied to computer visions, speech recognition and natural language processing tasks. In this paper, we provide DNN baselines for the DCASE Challenge 2016. For feature extraction, 40 Mel-filter bank features are used. Two kinds of Mel banks, same area bank and same height bank are discussed. Experimental results show that the same height bank is better than the same area bank. DNNs with the same structure are applied to all four tasks in the DCASE Challenge 2016. In Task 1 we obtained accuracy of 76.4\% using Mel + DNN against 72.5\% by using Mel Frequency Ceptral Coefficient (MFCC) + Gaussian Mixture Model (GMM). In Task 2 we obtained F value of 17.4\% using Mel + DNN against 41.6\% by using Constant Q Transform (CQT) + Nonnegative Matrix Factorization (NMF). In Task 3 we obtained F value of 38.1\% using Mel + DNN against 26.6\% by using MFCC + GMM. In task 4 we obtained Equal Error Rate (ERR) of 20.9\% using Mel + DNN against 21.0\% by using MFCC + GMM. Therefore the DNN improves the baseline in Task 1 and Task 3, and is similar to the baseline in Task 4, although is worse than the baseline in Task 2. This indicates that DNNs can be successful in many of these tasks, but may not always work."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lidy2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Lidy2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CQT-Based Convolutional Neural Networks for Audio Scene Classification and Domestic Audio Tagging
       </h4>
<p style="text-align:left">
        Thomas Lidy<sup>1</sup> and Alexander Schindler<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Institute of Software Technology, Vienna University of Technology, Vienna, Austria, <sup>2</sup>Digital Safety and Security, Austrian Institute of Technolog, Vienna, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lidy_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lidy2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lidy2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lidy2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Lidy_4007.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lidy2016" class="panel-collapse collapse" id="collapse-Lidy2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CQT-Based Convolutional Neural Networks for Audio Scene Classification and Domestic Audio Tagging
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       For the DCASE 2016 audio benchmarking contest, we submitted a parallel Convolutional Neural Network architecture for the tasks of 1) classifying acoustic scenes (task 1) and urban soundscapes and 2) domestic audio tagging (task 4). A popular choice for input to a Convolutional Neural Network in audio classification problems are Mel-transformed spectrograms. We, however, found that a Constant-Q-transformed input improves results. Furthermore, we evaluated critical parameters such as the number of necessary bands and filter sizes in a Convolutional Neural Network. Finally, we propose a parallel (graph-based) neural network architecture which captures relevant audio characteristics both in time and in frequency, and submitted it to the DCASE 2016 tasks 1 and 4, with some slight alterations described in this paper. Our approach shows a 10.7 % relative improvement of the baseline system of the Acoustic Scenes Classification task on the development set of task 1[1].
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         CQT features
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lidy2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Lidy_4007.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lidy2016label" class="modal fade" id="bibtex-Lidy2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLidy2016label">
        CQT-Based Convolutional Neural Networks for Audio Scene Classification and Domestic Audio Tagging
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lidy2016,
    Author = "Lidy, Thomas and Schindler, Alexander",
    title = "{CQT}-Based Convolutional Neural Networks for Audio Scene Classification and Domestic Audio Tagging",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "For the DCASE 2016 audio benchmarking contest, we submitted a parallel Convolutional Neural Network architecture for the tasks of 1) classifying acoustic scenes (task 1) and urban soundscapes and 2) domestic audio tagging (task 4). A popular choice for input to a Convolutional Neural Network in audio classification problems are Mel-transformed spectrograms. We, however, found that a Constant-Q-transformed input improves results. Furthermore, we evaluated critical parameters such as the number of necessary bands and filter sizes in a Convolutional Neural Network. Finally, we propose a parallel (graph-based) neural network architecture which captures relevant audio characteristics both in time and in frequency, and submitted it to the DCASE 2016 tasks 1 and 4, with some slight alterations described in this paper. Our approach shows a 10.7 \% relative improvement of the baseline system of the Acoustic Scenes Classification task on the development set of task 1[1]."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Vu2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Vu2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene and Event Recognition Using Recurrent Neural Networks
       </h4>
<p style="text-align:left">
        Toan H. Vu and Jia-Ching Wang
       </p>
<p style="text-align:left">
<em>
         Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Vu_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Vu2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Vu2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Vu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Vu_4000.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Vu2016" class="panel-collapse collapse" id="collapse-Vu2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene and Event Recognition Using Recurrent Neural Networks
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       The DCASE2016 challenge is designed particularly for research in environmental sound analysis. It consists of four tasks that spread on various problems such as acoustic scene classification and sound event detection. This paper reports our results on all the tasks by using Recurrent Neural Networks (RNNs). Experiments show that our models achieved superior performances compared with the baselines.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCCs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Vu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Vu_4000.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Vu2016label" class="modal fade" id="bibtex-Vu2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexVu2016label">
        Acoustic Scene and Event Recognition Using Recurrent Neural Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Vu2016,
    Author = "Vu, Toan H. and Wang, Jia-Ching",
    title = "Acoustic Scene and Event Recognition Using Recurrent Neural Networks",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "The DCASE2016 challenge is designed particularly for research in environmental sound analysis. It consists of four tasks that spread on various problems such as acoustic scene classification and sound event detection. This paper reports our results on all the tasks by using Recurrent Neural Networks (RNNs). Experiments show that our models achieved superior performances compared with the baselines."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Xu2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Xu2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Fully DNN-Based Multi-Label Regression for Audio Tagging
       </h4>
<p style="text-align:left">
        Yong Xu, Qiang Huang, Wenwu Wang and Mark D. Plumbley
       </p>
<p style="text-align:left">
<em>
         Centre for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Xu_task4_1</span> <span class="label label-primary">Xu_task4_2</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Xu2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Xu2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Xu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Xu_4006.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Xu2016" class="panel-collapse collapse" id="collapse-Xu2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Fully DNN-Based Multi-Label Regression for Audio Tagging
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       Acoustic event detection for content analysis in most cases relies on lots of labeled data. However, manually annotating data is a time-consuming task, which thus makes few annotated resources available so far. Unlike audio event detection, automatic audio tagging, a multi-label acoustic event classification task, only relies on weakly labeled data. This is highly desirable to some practical applications using audio analysis. In this paper we propose to use a fully deep neural network (DNN) framework to handle the multilabel classification task in a regression way. Considering that only chunk-level rather than frame-level labels are available, the whole or almost whole frames of the chunk were fed into the DNN to perform a multi-label regression for the expected tags. The fully DNN, which is regarded as an encoding function, can well map the audio features sequence to a multi-tag vector. A deep pyramid structure was also designed to extract more robust high-level features related to the target tags. Further improved methods were adopted, such as the Dropout and background noise aware training, to enhance its generalization capability for new audio recordings in mismatched environments. Compared with the conventional Gaussian Mixture Model (GMM) and support vector machine (SVM) methods, the proposed fully DNN-based method could well utilize the long-term temporal information with the whole chunk as the input. The results show that our approach obtained a 15% relative improvement compared with the official GMM-based method of DCASE 2016 challenge.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCCs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         DNN
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Xu2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Xu_4006.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Xu2016label" class="modal fade" id="bibtex-Xu2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexXu2016label">
        Fully DNN-Based Multi-Label Regression for Audio Tagging
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Xu2016,
    Author = "Xu, Yong and Huang, Qiang and Wang, Wenwu and Plumbley, Mark D.",
    title = "Fully {DNN}-Based Multi-Label Regression for Audio Tagging",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "Acoustic event detection for content analysis in most cases relies on lots of labeled data. However, manually annotating data is a time-consuming task, which thus makes few annotated resources available so far. Unlike audio event detection, automatic audio tagging, a multi-label acoustic event classification task, only relies on weakly labeled data. This is highly desirable to some practical applications using audio analysis. In this paper we propose to use a fully deep neural network (DNN) framework to handle the multilabel classification task in a regression way. Considering that only chunk-level rather than frame-level labels are available, the whole or almost whole frames of the chunk were fed into the DNN to perform a multi-label regression for the expected tags. The fully DNN, which is regarded as an encoding function, can well map the audio features sequence to a multi-tag vector. A deep pyramid structure was also designed to extract more robust high-level features related to the target tags. Further improved methods were adopted, such as the Dropout and background noise aware training, to enhance its generalization capability for new audio recordings in mismatched environments. Compared with the conventional Gaussian Mixture Model (GMM) and support vector machine (SVM) methods, the proposed fully DNN-based method could well utilize the long-term temporal information with the whole chunk as the input. The results show that our approach obtained a 15\% relative improvement compared with the official GMM-based method of DCASE 2016 challenge."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Yun2016" style="box-shadow: none">
<div class="panel-heading" id="heading-Yun2016" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Discriminative Training of GMM Parameters for Audio Scene Classification
       </h4>
<p style="text-align:left">
        Sungrack Yun, Sungwoong Kim, Sunkuck Moon, Juncheol Cho and Taesu Kim
       </p>
<p style="text-align:left">
<em>
         Qualcomm Research, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Yun_task4_1</span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Yun2016" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Yun2016" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Yun2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Yun_4001.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Yun2016" class="panel-collapse collapse" id="collapse-Yun2016" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Discriminative Training of GMM Parameters for Audio Scene Classification
      </h4>
<h5>
       Abstract
      </h5>
<p class="text-justify">
       This report describes the algorithm for audio scene classification and audio tagging and the result for DCASE 2016 challenge data. We propose a discriminative training algorithm to improve the baseline GMM performance. The algorithm updates the baseline GMM parameters by maximizing the margin between classes to improve discriminative performance. For Task1, we use a hierarchical classifier to maximize discriminative performance, and achieve 84% accuracy for given cross validation data. For Task4, we apply binary classifier for each label, and achieve 16.71% EER for given cross validation data.
      </p>
<h5>
       System characteristics
      </h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         MFCCs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         GMM
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Yun2016" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2016/technical_reports/DCASE2016_Yun_4001.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Yun2016label" class="modal fade" id="bibtex-Yun2016" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexYun2016label">
        Discriminative Training of GMM Parameters for Audio Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Yun2016,
    Author = "Yun, Sungrack and Kim, Sungwoong and Moon, Sunkuck and Cho, Juncheol and Kim, Taesu",
    title = "Discriminative Training of {GMM} Parameters for Audio Scene Classification",
    institution = "DCASE2016 Challenge",
    year = "2016",
    month = "September",
    abstract = "This report describes the algorithm for audio scene classification and audio tagging and the result for DCASE 2016 challenge data. We propose a discriminative training algorithm to improve the baseline GMM performance. The algorithm updates the baseline GMM parameters by maximizing the margin between classes to improve discriminative performance. For Task1, we use a hierarchical classifier to maximize discriminative performance, and achieve 84\% accuracy for given cross validation data. For Task4, we apply binary classifier for each label, and achieve 16.71\% EER for given cross validation data."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>