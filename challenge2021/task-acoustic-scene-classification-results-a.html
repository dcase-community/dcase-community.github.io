<!DOCTYPE html><html lang="en">
<head>
    <title>Low-Complexity Acoustic Scene Classification with Multiple Devices - DCASE</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/favicon.ico" rel="icon">
<link rel="canonical" href="/challenge2021/task-acoustic-scene-classification-results-a">
        <meta name="author" content="DCASE" />
        <meta name="description" content="Task description This subtask is concerned with the basic problem of acoustic scene classification, in which it is required to classify a test audio recording into one of ten known acoustic scene classes. This task targets generalization across a number of different devices, and will use audio data recorded and …" />
    <link href="https://fonts.googleapis.com/css?family=Heebo:900" rel="stylesheet">
    <link rel="stylesheet" href="/theme/assets/bootstrap/css/bootstrap.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/font-awesome/css/font-awesome.min.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/assets/dcaseicons/css/dcaseicons.css?v=1.1" type="text/css"/>
        <link rel="stylesheet" href="/theme/assets/highlight/styles/monokai-sublime.css" type="text/css"/>
    <link rel="stylesheet" href="/theme/css/btex.min.css">
    <link rel="stylesheet" href="/theme/css/datatable.bundle.min.css">
    <link rel="stylesheet" href="/theme/css/btoc.min.css">
    <link rel="stylesheet" href="/theme/css/theme.css?v=1.1" type="text/css"/>
    <link rel="stylesheet" href="/custom.css" type="text/css"/>
    <script type="text/javascript" src="/theme/assets/jquery/jquery.min.js"></script>
</head>
<body>
<nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="195">
    <div class="container">
        <div class="row">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a href="/" class="navbar-brand hidden-lg hidden-md hidden-sm" ><img src="/images/logos/dcase/dcase2024_logo.png"/></a>
            </div>
            <div id="navbar-main" class="navbar-collapse collapse"><ul class="nav navbar-nav" id="menuitem-list-main"><li class="" data-toggle="tooltip" data-placement="bottom" title="Frontpage">
        <a href="/"><img class="img img-responsive" src="/images/logos/dcase/dcase2024_logo.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Workshop">
        <a href="/workshop2024/"><img class="img img-responsive" src="/images/logos/dcase/workshop.png"/></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="DCASE2024 Challenge">
        <a href="/challenge2024/"><img class="img img-responsive" src="/images/logos/dcase/challenge.png"/></a>
    </li></ul><ul class="nav navbar-nav navbar-right" id="menuitem-list"><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-calendar fa-1x fa-fw"></i>&nbsp;Editions&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/events"><i class="fa fa-list fa-fw"></i>&nbsp;Overview</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2023/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2023 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2023/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2023 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2022/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2022 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2022/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2022 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2021/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2021 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2021/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2021 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2020/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2020 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2020/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2020 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2019/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2019 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2019/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2019 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2018/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2018 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2018/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2018 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2017/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2017 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2017/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2017 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/workshop2016/"><i class="fa fa-file-text fa-fw text-warning"></i>&nbsp;2016 Workshop</a>
    </li>
            <li class="">
        <a href="/challenge2016/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2016 Challenge</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="">
        <a href="/challenge2013/"><i class="fa fa-bar-chart fa-fw text-success"></i>&nbsp;2013 Challenge</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown"><i class="fa fa-users fa-1x fa-fw"></i>&nbsp;Community&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Information about the community">
        <a href="/community_info"><i class="fa fa-info-circle fa-fw"></i>&nbsp;DCASE Community</a>
    </li>
            <li class="divider" role="presentation"></li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Venues to publish DCASE related work">
        <a href="/publishing"><i class="fa fa-file fa-fw"></i>&nbsp;Publishing</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="Curated List of Open Datasets for DCASE Related Research">
        <a href="https://dcase-repo.github.io/dcase_datalist/" target="_blank" ><i class="fa fa-database fa-fw"></i>&nbsp;Datasets</a>
    </li>
            <li class="" data-toggle="tooltip" data-placement="bottom" title="A collection of tools">
        <a href="/tools"><i class="fa fa-gears fa-fw"></i>&nbsp;Tools</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="News">
        <a href="/news"><i class="fa fa-newspaper-o fa-1x fa-fw"></i>&nbsp;News</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Google discussions for DCASE Community">
        <a href="https://groups.google.com/forum/#!forum/dcase-discussions" target="_blank" ><i class="fa fa-comments fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Invitation link to Slack workspace for DCASE Community">
        <a href="https://join.slack.com/t/dcase/shared_invite/zt-12zfa5kw0-dD41gVaPU3EZTCAw1mHTCA" target="_blank" ><i class="fa fa-slack fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Twitter for DCASE Challenges">
        <a href="https://twitter.com/DCASE_Challenge" target="_blank" ><i class="fa fa-twitter fa-1x fa-fw"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Github repository">
        <a href="https://github.com/DCASE-REPO" target="_blank" ><i class="fa fa-github fa-1x"></i>&nbsp;</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Contact us">
        <a href="/contact-us"><i class="fa fa-envelope fa-1x"></i>&nbsp;</a>
    </li>                </ul>            </div>
        </div><div class="row">
             <div id="navbar-sub" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right " id="menuitem-list-sub"><li class="disabled subheader" >
        <a><strong>Challenge2021</strong></a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge introduction">
        <a href="/challenge2021/"><i class="fa fa-home"></i>&nbsp;Introduction</a>
    </li><li class="btn-group  active">
        <a href="/challenge2021/task-acoustic-scene-classification" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-scene text-primary"></i>&nbsp;Task1&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-acoustic-scene-classification"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class=" dropdown-header ">
        <strong>Results</strong>
    </li>
            <li class=" active">
        <a href="/challenge2021/task-acoustic-scene-classification-results-a"><i class="fa fa-bar-chart"></i>&nbsp;Subtask A</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-acoustic-scene-classification-results-b"><i class="fa fa-bar-chart"></i>&nbsp;Subtask B</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-large-scale text-success"></i>&nbsp;Task2&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-unsupervised-detection-of-anomalous-sounds-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-sound-event-localization-and-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-localization text-warning"></i>&nbsp;Task3&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-sound-event-localization-and-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-sound-event-localization-and-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-domestic text-info"></i>&nbsp;Task4&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-sound-event-detection-and-separation-in-domestic-environments-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-bird text-danger"></i>&nbsp;Task5&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-few-shot-bioacoustic-event-detection-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="btn-group ">
        <a href="/challenge2021/task-automatic-audio-captioning" class="dropdown-toggle" data-toggle="dropdown"><i class="fa dc-captioning text-task1"></i>&nbsp;Task6&nbsp;<b class="caret"></b></a>
        <ul class="dropdown-menu" role="menu">
            <li class="">
        <a href="/challenge2021/task-automatic-audio-captioning"><i class="fa fa-info-circle"></i>&nbsp;Description</a>
    </li>
            <li class="">
        <a href="/challenge2021/task-automatic-audio-captioning-results"><i class="fa fa-bar-chart"></i>&nbsp;Results</a>
    </li>
        </ul>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Challenge rules">
        <a href="/challenge2021/rules"><i class="fa fa-list-alt"></i>&nbsp;Rules</a>
    </li><li class="" data-toggle="tooltip" data-placement="bottom" title="Submission instructions">
        <a href="/challenge2021/submission"><i class="fa fa-upload"></i>&nbsp;Submission</a>
    </li></ul>
             </div>
        </div></div>
</nav>
<header class="page-top" style="background-image: url(../theme/images/everyday-patterns/grid-05.jpg);box-shadow: 0px 1000px rgba(18, 52, 18, 0.65) inset;overflow:hidden;position:relative">
    <div class="container" style="box-shadow: 0px 1000px rgba(255, 255, 255, 0.1) inset;;height:100%;padding-bottom:20px;">
        <div class="row">
            <div class="col-lg-12 col-md-12">
                <div class="page-heading text-right"><div class="pull-left">
                    <span class="fa-stack fa-5x sr-fade-logo"><i class="fa fa-square fa-stack-2x text-primary"></i><strong class="fa-stack-1x icon-text">A</strong><strong class="fa-stack-1x dcase-icon-top-text">Devices</strong><span class="fa-stack-1x dcase-icon-bottom-text">Task 1</span></span><img src="../images/logos/dcase/dcase2021_logo.png" class="sr-fade-logo" style="display:block;margin:0 auto;padding-top:15px;"></img>
                    </div><h1 class="bold">Low-Complexity Acoustic Scene Classification with Multiple Devices</h1><hr class="small right bold">
                        <span class="subheading subheading-secondary">Challenge results</span></div>
            </div>
        </div>
    </div>
<span class="header-cc-logo" data-toggle="tooltip" data-placement="top" title="Background photo by Toni Heittola / CC BY-NC 4.0"><i class="fa fa-creative-commons" aria-hidden="true"></i></span></header><div class="container-fluid">
    <div class="row">
        <div class="col-sm-3 sidecolumn-left">
 <div class="btoc-container hidden-print" role="complementary">
<div class="panel panel-default">
<div class="panel-heading">
<h3 class="panel-title">Content</h3>
</div>
<ul class="nav btoc-nav">
<li><a href="#task-description">Task description</a></li>
<li><a href="#systems-ranking">Systems ranking</a></li>
<li><a href="#teams-ranking">Teams ranking</a></li>
<li><a href="#system-complexity">System complexity</a></li>
<li><a href="#generalization-performance">Generalization performance</a></li>
<li><a href="#class-wise-performance">Class-wise performance</a>
<ul>
<li><a href="#log-loss">Log loss</a></li>
<li><a href="#accuracy">Accuracy</a></li>
</ul>
</li>
<li><a href="#device-wise-performance">Device-wise performance</a>
<ul>
<li><a href="#log-loss-1">Log loss</a></li>
<li><a href="#accuracy-1">Accuracy</a></li>
</ul>
</li>
<li><a href="#system-characteristics">System characteristics</a>
<ul>
<li><a href="#general-characteristics">General characteristics</a></li>
<li><a href="#machine-learning-characteristics">Machine learning characteristics</a></li>
</ul>
</li>
<li><a href="#technical-reports">Technical reports</a></li>
</ul>
</div>
</div>

        </div>
        <div class="col-sm-9 content">
            <section id="content" class="body">
                <div class="entry-content">
                    <h1 id="task-description">Task description</h1>
<p>This subtask is concerned with the basic problem of acoustic scene classification, in which it is required to classify a test audio recording into one of ten known acoustic scene classes. This task targets <strong>generalization across a number of different devices</strong>, and will use audio data recorded and simulated with a variety of devices. The task also targets <strong>low complexity</strong> solutions for the classification problem in terms of model size.</p>
<p>The development dataset consists of recordings from 10 European cities using 9 different devices: 3 real devices (A, B, C) and 6 simulated devices (S1-S6). Data from devices B, C, and S1-S6 consists of randomly selected segments from the simultaneous recordings, therefore all overlap with the data from device A, but not necessarily with each other. The total amount of audio in the development set is 64 hours. </p>
<p>The evaluation dataset contains data from 12 cities, 10 acoustic scenes, 11 devices. There are five new devices (not available in the development set): real device D and simulated devices S7-S11. Evaluation data contains 22 hours of audio. </p>
<p>The device A consists in a Soundman OKM II Klassik/studio A3, electret binaural microphone and a Zoom F8 audio recorder using 48kHz sampling rate and 24-bit resolution. The other devices are commonly available customer devices: device B is a Samsung Galaxy S7, device C is iPhone SE, and device D is a GoPro Hero5 Session. </p>
<p>More detailed task description can be found in the <a class="btn btn-primary" href="/challenge2021/task-acoustic-scene-classification#subtask-a" style="">task description page</a></p>
<h1 id="systems-ranking">Systems ranking</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval" data-scatter-y="logloss_dev" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>qat_8b</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>68.6 (67.6 - 69.6)</td>
<td>0.820</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>8b_calibm</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>67.5 (66.5 - 68.6)</td>
<td>0.820</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>8b_calibo</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>68.5 (67.5 - 69.6)</td>
<td>0.820</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>16b_prune</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>68.8 (67.8 - 69.8)</td>
<td>0.840</td>
<td>70.2</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>sys_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>66.7 (65.7 - 67.7)</td>
<td>1.038</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>sys_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>64.6 (63.5 - 65.6)</td>
<td>1.108</td>
<td>69.6</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>sys_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>67.2 (66.1 - 68.2)</td>
<td>1.058</td>
<td>71.7</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>sys_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>66.1 (65.1 - 67.1)</td>
<td>1.047</td>
<td>72.4</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding_TJU</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>53.0 (51.9 - 54.1)</td>
<td>1.360</td>
<td>55.5</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding_TJU</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>51.1 (50.0 - 52.2)</td>
<td>1.263</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding_TJU</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>49.1 (48.0 - 50.2)</td>
<td>1.193</td>
<td>55.0</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding_TJU</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>51.4 (50.3 - 52.5)</td>
<td>1.268</td>
<td>50.0</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>res-att</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>68.3 (67.3 - 69.3)</td>
<td>0.870</td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>e2e_CNN_INT8</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>53.9 (52.8 - 55.0)</td>
<td>1.904</td>
<td>56.5</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Clova_AMFM</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>67.0 (66.0 - 68.0)</td>
<td></td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Clova_Res</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>66.9 (65.9 - 67.9)</td>
<td></td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Clova_AMFM_W</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>70.0 (69.0 - 71.0)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Clova_Res_W</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>70.1 (69.1 - 71.1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>R_MNv2_fl</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>51.4 (50.3 - 52.5)</td>
<td>1.258</td>
<td>55.3</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>R_MNv2_af</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>53.3 (52.2 - 54.4)</td>
<td>2.021</td>
<td>54.3</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>CPRes_fl</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>51.6 (50.5 - 52.7)</td>
<td>1.248</td>
<td>54.5</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>CPRes_af</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>49.2 (48.1 - 50.3)</td>
<td>2.030</td>
<td>54.7</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>SparseFCNN</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>55.0 (53.9 - 56.1)</td>
<td>1.464</td>
<td>54.6</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>DiverseSpa</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>51.3 (50.2 - 52.4)</td>
<td>1.593</td>
<td>51.2</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>SparseMNet</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>56.3 (55.2 - 57.4)</td>
<td>1.428</td>
<td>58.2</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>JYH_ETRI_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>66.0 (64.9 - 67.0)</td>
<td>1.006</td>
<td>65.9</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>JYH_ETRI_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>67.0 (65.9 - 68.0)</td>
<td>1.015</td>
<td>64.9</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>JYH_ETRI_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>66.7 (65.7 - 67.7)</td>
<td>1.014</td>
<td>64.6</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>JYH_ETRI_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>66.1 (65.1 - 67.2)</td>
<td>0.968</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>DSSMNet1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>66.8 (65.7 - 67.8)</td>
<td>1.410</td>
<td>63.0</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>DSSMNet2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>63.5 (62.4 - 64.6)</td>
<td>1.242</td>
<td>62.3</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>CNN_pr1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>61.5 (60.4 - 62.6)</td>
<td>1.010</td>
<td>63.4</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>CNN_pr2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>61.6 (60.5 - 62.6)</td>
<td>1.008</td>
<td>63.5</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>CNN_pr3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>62.0 (61.0 - 63.1)</td>
<td>1.009</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>CNN_pr4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>61.3 (60.2 - 62.3)</td>
<td>1.009</td>
<td>63.5</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>KNU-CP1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>64.7 (63.6 - 65.7)</td>
<td>1.068</td>
<td>65.0</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>KNU-CP2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>63.8 (62.8 - 64.9)</td>
<td>1.040</td>
<td>62.0</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>KNU-CP3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>61.3 (60.3 - 62.4)</td>
<td>1.043</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>KNU-CP4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>62.9 (61.8 - 64.0)</td>
<td>1.035</td>
<td>65.3</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>ResNorm_QTI1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>75.0 (74.0 - 76.0)</td>
<td>0.722</td>
<td>77.0</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>ResNorm_QTI2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>76.1 (75.1 - 77.0)</td>
<td>0.716</td>
<td>75.9</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>ResNorm_QTI3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>76.1 (75.2 - 77.1)</td>
<td>0.723</td>
<td>77.5</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>ResNorm_QTI4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>75.2 (74.3 - 76.2)</td>
<td>0.776</td>
<td>75.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>DampedR7NB</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>70.9 (69.9 - 71.9)</td>
<td>0.916</td>
<td>68.6</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>DampedR8</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>71.8 (70.8 - 72.8)</td>
<td>0.944</td>
<td>66.9</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>DampedR8NB</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>72.1 (71.1 - 73.1)</td>
<td>0.890</td>
<td>69.5</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>DampedR8DA</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>71.8 (70.9 - 72.8)</td>
<td>0.880</td>
<td>69.5</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>CAUET-TEFF1-C45-Q</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>67.5 (66.5 - 68.5)</td>
<td>1.673</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>CAUET-TEFF1-P45-Q</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>67.9 (66.9 - 69.0)</td>
<td>1.801</td>
<td>65.7</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>CAUET-TEFF2-C70-Q</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>68.5 (67.5 - 69.5)</td>
<td>1.625</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>CAUET-TEFF3-Q</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>65.8 (64.7 - 66.8)</td>
<td>1.906</td>
<td>63.1</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>FR_agm</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>68.8 (67.8 - 69.8)</td>
<td>0.909</td>
<td>68.2</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>onebit_agm</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>68.2 (67.2 - 69.2)</td>
<td>0.923</td>
<td>68.0</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>onebit_noagm</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>69.6 (68.6 - 70.6)</td>
<td>0.990</td>
<td>65.0</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>weight_qz</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>42.0 (40.9 - 43.1)</td>
<td>1.434</td>
<td>45.4</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>DWTMSCNN</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>9.7 (9.0 - 10.3)</td>
<td>0.628</td>
<td>85.1</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6 (44.5 - 46.7)</td>
<td>1.461</td>
<td>46.9</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>ASC_ResSE</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>60.2 (59.2 - 61.3)</td>
<td></td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham_AIT</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>67.5 (66.4 - 68.5)</td>
<td></td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham_AIT</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>68.4 (67.4 - 69.4)</td>
<td></td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham_AIT</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>69.6 (68.6 - 70.6)</td>
<td></td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>ResNet</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>63.3 (62.3 - 64.4)</td>
<td>1.259</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>ResNet_t3</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>63.3 (62.3 - 64.4)</td>
<td>1.313</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>ResNet_t2</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>65.3 (64.3 - 66.4)</td>
<td>1.259</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>ResNet_t3</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>65.3 (64.3 - 66.4)</td>
<td>1.313</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>ce_tta</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>66.6 (65.6 - 67.6)</td>
<td>0.898</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>ce_mu_tta</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>65.4 (64.4 - 66.5)</td>
<td>0.927</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>fl_tta</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>66.2 (65.1 - 67.2)</td>
<td>0.877</td>
<td>68.7</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao_NCUT</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>52.2 (51.1 - 53.3)</td>
<td>1.001</td>
<td>51.7</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Penult</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>70.3 (69.3 - 71.3)</td>
<td>1.040</td>
<td>69.0</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Stride21</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>71.4 (70.4 - 72.4)</td>
<td>1.089</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Stride22</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>71.3 (70.3 - 72.3)</td>
<td>1.092</td>
<td>72.1</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Stride12</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>71.8 (70.8 - 72.8)</td>
<td>1.106</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh_29KB</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>47.2 (46.1 - 48.3)</td>
<td>1.383</td>
<td>47.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh_53KB</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>44.7 (43.6 - 45.8)</td>
<td>1.394</td>
<td>48.5</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh_74KB</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>46.1 (45.0 - 47.2)</td>
<td>1.395</td>
<td>49.0</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh_71KB</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>46.8 (45.7 - 47.9)</td>
<td>1.413</td>
<td>48.6</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>RION1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>63.8 (62.8 - 64.9)</td>
<td>0.958</td>
<td>70.1</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>RION2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>65.2 (64.2 - 66.3)</td>
<td>0.975</td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>RION3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>65.3 (64.3 - 66.4)</td>
<td>0.937</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>RION4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>64.7 (63.7 - 65.8)</td>
<td>1.062</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>ASC_MB32</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>61.4 (60.3 - 62.4)</td>
<td>1.042</td>
<td>64.4</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>ASC_MB64</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>64.5 (63.4 - 65.5)</td>
<td>0.932</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>ASC_MB128</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>67.3 (66.3 - 68.4)</td>
<td>0.859</td>
<td>70.9</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>ASC_MB160</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>68.1 (67.1 - 69.1)</td>
<td>0.848</td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang_GT_lth_a</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>73.1 (72.1 - 74.0)</td>
<td>0.640</td>
<td>79.4</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang_GT_lth_b</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>72.9 (71.9 - 73.9)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang_GT_lth_c</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>72.9 (71.9 - 73.8)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang_GT_lth_d</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>72.8 (71.8 - 73.8)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao_ratio07</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>51.9 (50.8 - 53.0)</td>
<td>0.893</td>
<td>69.4</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao_ratio065</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>55.2 (54.1 - 56.3)</td>
<td>0.727</td>
<td>76.1</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao_seresnet</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>53.5 (52.4 - 54.6)</td>
<td>1.990</td>
<td>82.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang_resnet_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>63.0 (62.0 - 64.1)</td>
<td></td>
<td>78.2</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang_resnet_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>63.2 (62.2 - 64.3)</td>
<td></td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang_resnet_cbam</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>52.2 (51.1 - 53.3)</td>
<td></td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang_resnet_senet</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>59.0 (57.9 - 60.1)</td>
<td></td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>maxvision1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>61.2 (60.2 - 62.3)</td>
<td>1.494</td>
<td>57.6</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>maxvision2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>63.5 (62.4 - 64.6)</td>
<td>1.482</td>
<td>59.6</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>maxvision3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>63.5 (62.5 - 64.6)</td>
<td>1.258</td>
<td>59.9</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>maxvision4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>62.8 (61.8 - 63.9)</td>
<td>1.485</td>
<td>57.8</td>
</tr>
</tbody>
</table>
<h1 id="teams-ranking">Teams ranking</h1>
<p>Table including only the best performing system per submitting team.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="bar" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="false" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval" data-scatter-y="logloss_dev" data-show-chart="true" data-show-pagination-switch="false" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="3">Submission information</th>
<th class="sep-left-cell text-center" colspan="4">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Development dataset</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sm-cell" data-field="name" data-sortable="true">
                Name
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system rank
            </th>
<th class="text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_team" data-sortable="true" data-value-type="int">
                Team rank
            </th>
<th class="sep-left-cell text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval_confidence" data-sortable="true" data-value-type="float1-percentage-interval-muted">
                Accuracy <br/><small class="text-muted">with 95% confidence interval</small><small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss (Development dataset)" data-chartable="true" data-field="logloss_dev" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Development dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Development dataset)" data-chartable="true" data-field="accuracy_dev" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Development dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>16b_prune</td>
<td>Byttebier2021</td>
<td>17</td>
<td>6</td>
<td>0.905</td>
<td>68.8 (67.8 - 69.8)</td>
<td>0.840</td>
<td>70.2</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>sys_1</td>
<td>Cao2021</td>
<td>49</td>
<td>15</td>
<td>1.136</td>
<td>66.7 (65.7 - 67.7)</td>
<td>1.038</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding_TJU</td>
<td>Ding2021</td>
<td>61</td>
<td>22</td>
<td>1.226</td>
<td>49.1 (48.0 - 50.2)</td>
<td>1.193</td>
<td>55.0</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>res-att</td>
<td>Cui2021</td>
<td>64</td>
<td>23</td>
<td>1.261</td>
<td>68.3 (67.3 - 69.3)</td>
<td>0.870</td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>e2e_CNN_INT8</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>29</td>
<td>2.221</td>
<td>53.9 (52.8 - 55.0)</td>
<td>1.904</td>
<td>56.5</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Clova_Res_W</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>4</td>
<td>0.871</td>
<td>70.1 (69.1 - 71.1)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>CPRes_fl</td>
<td>Horvth2021</td>
<td>76</td>
<td>24</td>
<td>1.460</td>
<td>51.6 (50.5 - 52.7)</td>
<td>1.248</td>
<td>54.5</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>SparseFCNN</td>
<td>Jeng2021</td>
<td>78</td>
<td>26</td>
<td>1.469</td>
<td>55.0 (53.9 - 56.1)</td>
<td>1.464</td>
<td>54.6</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>JYH_ETRI_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>9</td>
<td>0.952</td>
<td>67.0 (65.9 - 68.0)</td>
<td>1.015</td>
<td>64.9</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>DSSMNet2</td>
<td>Kek2021</td>
<td>57</td>
<td>18</td>
<td>1.207</td>
<td>63.5 (62.4 - 64.6)</td>
<td>1.242</td>
<td>62.3</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>CNN_pr3</td>
<td>Kim2021</td>
<td>37</td>
<td>13</td>
<td>1.076</td>
<td>62.0 (61.0 - 63.1)</td>
<td>1.009</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>KNU-CP2</td>
<td>Kim2021a</td>
<td>28</td>
<td>10</td>
<td>1.010</td>
<td>63.8 (62.8 - 64.9)</td>
<td>1.040</td>
<td>62.0</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>ResNorm_QTI2</td>
<td>Kim2021b</td>
<td>1</td>
<td>1</td>
<td>0.724</td>
<td>76.1 (75.1 - 77.0)</td>
<td>0.716</td>
<td>75.9</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>DampedR8NB</td>
<td>Koutini2021</td>
<td>9</td>
<td>3</td>
<td>0.834</td>
<td>72.1 (71.1 - 73.1)</td>
<td>0.890</td>
<td>69.5</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>CAUET-TEFF2-C70-Q</td>
<td>Lim2021</td>
<td>80</td>
<td>27</td>
<td>1.479</td>
<td>68.5 (67.5 - 69.5)</td>
<td>1.625</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>onebit_noagm</td>
<td>Liu2021</td>
<td>13</td>
<td>5</td>
<td>0.878</td>
<td>69.6 (68.6 - 70.6)</td>
<td>0.990</td>
<td>65.0</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>DWTMSCNN</td>
<td>Madhu2021</td>
<td>99</td>
<td>30</td>
<td>3.950</td>
<td>9.7 (9.0 - 10.3)</td>
<td>0.628</td>
<td>85.1</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td>Baseline</td>
<td></td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6 (44.5 - 46.7)</td>
<td>1.461</td>
<td>46.9</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>ASC_ResSE</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>16</td>
<td>1.140</td>
<td>60.2 (59.2 - 61.3)</td>
<td></td>
<td>64.2</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham_AIT</td>
<td>Pham2021</td>
<td>54</td>
<td>17</td>
<td>1.187</td>
<td>68.4 (67.4 - 69.4)</td>
<td></td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>ResNet_t2</td>
<td>Phan2021</td>
<td>60</td>
<td>21</td>
<td>1.223</td>
<td>65.3 (64.3 - 66.4)</td>
<td>1.259</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>fl_tta</td>
<td>Puy2021</td>
<td>22</td>
<td>8</td>
<td>0.939</td>
<td>66.2 (65.1 - 67.2)</td>
<td>0.877</td>
<td>68.7</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao_NCUT</td>
<td>Qiao2021</td>
<td>88</td>
<td>28</td>
<td>1.630</td>
<td>52.2 (51.1 - 53.3)</td>
<td>1.001</td>
<td>51.7</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Penult</td>
<td>Seo2021</td>
<td>32</td>
<td>12</td>
<td>1.030</td>
<td>70.3 (69.3 - 71.3)</td>
<td>1.040</td>
<td>69.0</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh_29KB</td>
<td>Singh2021</td>
<td>77</td>
<td>25</td>
<td>1.464</td>
<td>47.2 (46.1 - 48.3)</td>
<td>1.383</td>
<td>47.7</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>RION3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>11</td>
<td>1.024</td>
<td>65.3 (64.3 - 66.4)</td>
<td>0.937</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>ASC_MB160</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>7</td>
<td>0.924</td>
<td>68.1 (67.1 - 69.1)</td>
<td>0.848</td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang_GT_lth_c</td>
<td>Yang2021</td>
<td>3</td>
<td>2</td>
<td>0.758</td>
<td>72.9 (71.9 - 73.8)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao_ratio065</td>
<td>Yihao2021</td>
<td>59</td>
<td>20</td>
<td>1.222</td>
<td>55.2 (54.1 - 56.3)</td>
<td>0.727</td>
<td>76.1</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang_resnet_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>14</td>
<td>1.113</td>
<td>63.2 (62.2 - 64.3)</td>
<td></td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>maxvision4</td>
<td>Zhao2021</td>
<td>58</td>
<td>19</td>
<td>1.215</td>
<td>62.8 (61.8 - 63.9)</td>
<td>1.485</td>
<td>57.8</td>
</tr>
</tbody>
</table>
<h1 id="system-complexity">System complexity</h1>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval" data-scatter-y="system_complexity_total" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="4">Acoustic model</th>
<th class="sep-left-cell text-center">System</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Eval)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Eval)" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Eval)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Parameters" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Parameters
            </th>
<th class="text-center" data-axis-label="Non-zero parameters" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total_non_zero" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Non-zero <br/>parameters  
            </th>
<th class="text-center" data-axis-label="Sparsity" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_sparsity" data-reversed="true" data-sortable="true" data-value-type="numeric-unit">
                Sparsity
            </th>
<th class="text-center" data-axis-label="Model size" data-chartable="true" data-field="system_complexity_model_size" data-reversed="true" data-sortable="true">
                Size <br/>(KB) *
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_complexity_management" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Complexity <br/>management
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>68.6</td>
<td>114634</td>
<td>113976</td>
<td>0.0057400073276688834</td>
<td>127.6</td>
<td>weight quantization, grouped convolutions, Conv+BN fusion</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>67.5</td>
<td>114634</td>
<td>113976</td>
<td>0.0057400073276688834</td>
<td>127.6</td>
<td>weight quantization, grouped convolutions, Conv+BN fusion</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>68.5</td>
<td>114634</td>
<td>113976</td>
<td>0.0057400073276688834</td>
<td>127.6</td>
<td>weight quantization, grouped convolutions, Conv+BN fusion</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>68.8</td>
<td>82910</td>
<td>62390</td>
<td>0.24749728621396694</td>
<td>121.9</td>
<td>weight quantization, grouped convolutions, pruning</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>66.7</td>
<td>36658</td>
<td>34970</td>
<td>0.04604724753123468</td>
<td>71.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>64.6</td>
<td>36658</td>
<td>34970</td>
<td>0.04604724753123468</td>
<td>71.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>67.2</td>
<td>36658</td>
<td>34970</td>
<td>0.04604724753123468</td>
<td>71.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>66.1</td>
<td>51926</td>
<td>50238</td>
<td>0.03250779956091365</td>
<td>102.9</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>53.0</td>
<td>40230</td>
<td>40230</td>
<td>0.0</td>
<td>78.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>51.1</td>
<td>20250</td>
<td>20250</td>
<td>0.0</td>
<td>39.5</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>49.1</td>
<td>63816</td>
<td>63816</td>
<td>0.0</td>
<td>124.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>51.4</td>
<td>20250</td>
<td>20250</td>
<td>0.0</td>
<td>39.5</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>68.3</td>
<td>93323</td>
<td>93323</td>
<td>0.0</td>
<td>93.3</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>53.9</td>
<td>127637</td>
<td>127637</td>
<td>0.0</td>
<td>124.6</td>
<td>pruning, int8 weight quantization</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>67.0</td>
<td>65424</td>
<td>65424</td>
<td>0.0</td>
<td>127.7</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>66.9</td>
<td>63547</td>
<td>63547</td>
<td>0.0</td>
<td>124.1</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>70.0</td>
<td>65424</td>
<td>65424</td>
<td>0.0</td>
<td>127.7</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>70.1</td>
<td>63547</td>
<td>63547</td>
<td>0.0</td>
<td>124.1</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>51.4</td>
<td>47939</td>
<td>47939</td>
<td>0.0</td>
<td>93.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>53.3</td>
<td>47939</td>
<td>47939</td>
<td>0.0</td>
<td>93.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>51.6</td>
<td>58266</td>
<td>58266</td>
<td>0.0</td>
<td>113.8</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>49.2</td>
<td>58266</td>
<td>58266</td>
<td>0.0</td>
<td>113.8</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>55.0</td>
<td>130457242</td>
<td>129320</td>
<td>0.9990087173543037</td>
<td>126.3</td>
<td>sparsity, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>51.3</td>
<td>130457242</td>
<td>127906</td>
<td>0.9990195561546518</td>
<td>124.9</td>
<td>sparsity, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>56.3</td>
<td>17186944</td>
<td>130999</td>
<td>0.9923779934350168</td>
<td>127.9</td>
<td>sparsity, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>66.0</td>
<td>54845</td>
<td>54845</td>
<td>0.0</td>
<td>113.9</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>67.0</td>
<td>54845</td>
<td>54845</td>
<td>0.0</td>
<td>113.9</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>66.7</td>
<td>60236</td>
<td>60236</td>
<td>0.0</td>
<td>124.4</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>66.1</td>
<td>60236</td>
<td>60236</td>
<td>0.0</td>
<td>124.4</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>66.8</td>
<td>63448</td>
<td>59472</td>
<td>0.0626654898499559</td>
<td>123.9</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>63.5</td>
<td>64850</td>
<td>60842</td>
<td>0.06180416345412487</td>
<td>126.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>61.5</td>
<td>168778</td>
<td>116398</td>
<td>0.31034850513692547</td>
<td>113.7</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>61.6</td>
<td>168778</td>
<td>113428</td>
<td>0.32794558532510165</td>
<td>110.8</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>62.0</td>
<td>168778</td>
<td>120841</td>
<td>0.2840239841685528</td>
<td>118.0</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>61.3</td>
<td>168778</td>
<td>116439</td>
<td>0.31010558248112907</td>
<td>113.7</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>64.7</td>
<td>58472</td>
<td>58374</td>
<td>0.0016760158708442052</td>
<td>125.6</td>
<td>CP-decomposition, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>63.8</td>
<td>64064</td>
<td>64064</td>
<td>0.0</td>
<td>125.1</td>
<td>parameter sharing, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>61.3</td>
<td>58472</td>
<td>58411</td>
<td>0.0010432343685866652</td>
<td>125.7</td>
<td>CP-decomposition, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>62.9</td>
<td>58472</td>
<td>58411</td>
<td>0.0010432343685866652</td>
<td>125.7</td>
<td>CP-decomposition, weight quantization</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>75.0</td>
<td>630042</td>
<td>95472</td>
<td>0.8484672450408068</td>
<td>121.9</td>
<td>weight quantization, pruning, knowledge distillation</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>76.1</td>
<td>630042</td>
<td>95472</td>
<td>0.8484672450408068</td>
<td>121.9</td>
<td>weight quantization, pruning, knowledge distillation</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>76.1</td>
<td>630042</td>
<td>95472</td>
<td>0.8484672450408068</td>
<td>121.9</td>
<td>weight quantization, pruning, knowledge distillation</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>75.2</td>
<td>314990</td>
<td>62721</td>
<td>0.800879392996603</td>
<td>122.5</td>
<td>weight quantization, pruning, knowledge distillation</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>70.9</td>
<td>504104</td>
<td>64690</td>
<td>0.8716733055083872</td>
<td>126.3</td>
<td>float16, sparsity</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>71.8</td>
<td>678184</td>
<td>64928</td>
<td>0.9042619702027768</td>
<td>126.8</td>
<td>float16, sparsity</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>72.1</td>
<td>635176</td>
<td>64625</td>
<td>0.8982565462171115</td>
<td>126.2</td>
<td>float16, sparsity</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>71.8</td>
<td>641320</td>
<td>63529</td>
<td>0.9009402482380091</td>
<td>124.1</td>
<td>float16, sparsity</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>67.5</td>
<td>89910</td>
<td>56499</td>
<td>0.3716049382716049</td>
<td>125.2</td>
<td>weight quantization, sparsity</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>67.9</td>
<td>89910</td>
<td>56499</td>
<td>0.3716049382716049</td>
<td>125.2</td>
<td>weight quantization, sparsity</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>68.5</td>
<td>134748</td>
<td>54504</td>
<td>0.5955116216938285</td>
<td>125.4</td>
<td>weight quantization, sparsity</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>65.8</td>
<td>56046</td>
<td>56046</td>
<td>0.0</td>
<td>118.8</td>
<td>weight quantization, sparsity</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>68.8</td>
<td>643194</td>
<td>643194</td>
<td>0.0</td>
<td>106.7</td>
<td>1-bit quantization,FR_unit</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>68.2</td>
<td>268362</td>
<td>268368</td>
<td>2.235785990567507e-05</td>
<td>42.5</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>69.6</td>
<td>268362</td>
<td>268368</td>
<td>2.235785990567507e-05</td>
<td>42.5</td>
<td>1-bit quantization</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>42.0</td>
<td>60928</td>
<td>60928</td>
<td>0.0</td>
<td>119.0</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>9.7</td>
<td>42774</td>
<td>42774</td>
<td>0.0</td>
<td>89.5</td>
<td>weight quantization</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6</td>
<td>46246</td>
<td>46246</td>
<td>0.0</td>
<td>90.3</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>60.2</td>
<td>50130</td>
<td>50130</td>
<td>0.0</td>
<td>96.0</td>
<td>weight quantization, tflite, float16</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>67.5</td>
<td>10909</td>
<td>10909</td>
<td>0.0</td>
<td>128.0</td>
<td>channel restriction and decomposed convolution</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>68.4</td>
<td>10909</td>
<td>10909</td>
<td>0.0</td>
<td>128.0</td>
<td>channel restriction and decomposed convolution</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>69.6</td>
<td>10909</td>
<td>10909</td>
<td>0.0</td>
<td>128.0</td>
<td>channel restriction and decomposed convolution</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>63.3</td>
<td>41356</td>
<td>36364</td>
<td>0.12070799883934613</td>
<td>75.2</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>63.3</td>
<td>41356</td>
<td>36364</td>
<td>0.12070799883934613</td>
<td>75.2</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>65.3</td>
<td>41356</td>
<td>36364</td>
<td>0.12070799883934613</td>
<td>75.2</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>65.3</td>
<td>41356</td>
<td>36364</td>
<td>0.12070799883934613</td>
<td>75.2</td>
<td>weight quantization, depthwise separable convolutions</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>66.6</td>
<td>62474</td>
<td>62474</td>
<td>0.0</td>
<td>122.0</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>65.4</td>
<td>62474</td>
<td>62474</td>
<td>0.0</td>
<td>122.0</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>66.2</td>
<td>62474</td>
<td>62474</td>
<td>0.0</td>
<td>122.0</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>52.2</td>
<td>31852</td>
<td>31852</td>
<td>0.0</td>
<td>124.4</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>70.3</td>
<td>101173</td>
<td>101173</td>
<td>0.0</td>
<td>125.0</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>71.4</td>
<td>99557</td>
<td>99557</td>
<td>0.0</td>
<td>126.5</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>71.3</td>
<td>99614</td>
<td>99614</td>
<td>0.0</td>
<td>126.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>71.8</td>
<td>99603</td>
<td>99603</td>
<td>0.0</td>
<td>126.5</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>47.2</td>
<td>14754</td>
<td>14754</td>
<td>0.0</td>
<td>28.8</td>
<td>Filter pruning and quantization</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>44.7</td>
<td>27166</td>
<td>27166</td>
<td>0.0</td>
<td>53.1</td>
<td>Filter pruning and quantization</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>46.1</td>
<td>38110</td>
<td>38110</td>
<td>0.0</td>
<td>74.4</td>
<td>Filter pruning and quantization</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>46.8</td>
<td>36578</td>
<td>36578</td>
<td>0.0</td>
<td>71.4</td>
<td>Filter pruning and quantization</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>63.8</td>
<td>339730</td>
<td>86577</td>
<td>0.7451593912813117</td>
<td>94.7</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>65.2</td>
<td>339730</td>
<td>86577</td>
<td>0.7451593912813117</td>
<td>94.7</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>65.3</td>
<td>203838</td>
<td>102606</td>
<td>0.496629676507815</td>
<td>108.3</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>64.7</td>
<td>255940</td>
<td>109804</td>
<td>0.570977572868641</td>
<td>114.6</td>
<td>weight quantization, pruning</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>61.4</td>
<td>62090</td>
<td>62090</td>
<td>0.0</td>
<td>121.3</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>64.5</td>
<td>62154</td>
<td>62154</td>
<td>0.0</td>
<td>121.4</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>67.3</td>
<td>62282</td>
<td>62282</td>
<td>0.0</td>
<td>121.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>68.1</td>
<td>62346</td>
<td>62346</td>
<td>0.0</td>
<td>121.8</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>73.1</td>
<td>4410180</td>
<td>30500</td>
<td>0.9930841825050225</td>
<td>122.0</td>
<td>weight quantization, LTH pruning, teacher-student learning</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>72.9</td>
<td>14640720</td>
<td>111000</td>
<td>0.9924184056521811</td>
<td>111.0</td>
<td>weight quantization, LTH pruning, teacher-student learning</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>72.9</td>
<td>7056288</td>
<td>45750</td>
<td>0.9935164210984586</td>
<td>125.0</td>
<td>weight quantization, LTH pruning, teacher-student learning</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>72.8</td>
<td>7056288</td>
<td>45750</td>
<td>0.9935164210984586</td>
<td>125.0</td>
<td>weight quantization, LTH pruning, teacher-student learning</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>51.9</td>
<td>48075</td>
<td>48075</td>
<td>0.0</td>
<td>93.8</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>55.2</td>
<td>63244</td>
<td>63244</td>
<td>0.0</td>
<td>123.5</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>53.5</td>
<td>50952</td>
<td>50952</td>
<td>0.0</td>
<td>99.5</td>
<td>sparsity</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>63.0</td>
<td>83572</td>
<td>49738</td>
<td>0.4048485138563155</td>
<td>48.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>63.2</td>
<td>83572</td>
<td>49738</td>
<td>0.4048485138563155</td>
<td>48.6</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>52.2</td>
<td>87011</td>
<td>53177</td>
<td>0.3888473871119743</td>
<td>51.9</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>59.0</td>
<td>86516</td>
<td>85706</td>
<td>0.009362430070738337</td>
<td>83.7</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>61.2</td>
<td>59421</td>
<td>59376</td>
<td>0.0007573080224163586</td>
<td>116.1</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>63.5</td>
<td>59421</td>
<td>59376</td>
<td>0.0007573080224163586</td>
<td>116.1</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>63.5</td>
<td>59421</td>
<td>59376</td>
<td>0.0007573080224163586</td>
<td>116.1</td>
<td>weight quantization</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>62.8</td>
<td>59421</td>
<td>59376</td>
<td>0.0007573080224163586</td>
<td>116.1</td>
<td>weight quantization</td>
</tr>
</tbody>
</table>
<p><br/>
*) Model size is calculated accordingly to the task specific rules, and will differ from a real model storage size. See model size calculation examples <a href="/challenge2021/task-acoustic-scene-classification#task-setup-1">here</a>. </p>
<h1 id="generalization-performance">Generalization performance</h1>
<p>All results with evaluation dataset.</p>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_source_seen" data-scatter-y="accuracy_eval_source_unseen" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2">Submission information</th>
<th class="sep-left-cell text-center" colspan="3">Overall</th>
<th class="sep-left-cell text-center" colspan="4">Devices</th>
<th class="sep-left-cell text-center" colspan="4">Cities</th>
</tr>
<tr>
<th></th>
<th class="sep-left-cell text-center" colspan="2"></th>
<th class="sep-left-cell text-center" colspan="3">Evaluation dataset</th>
<th class="sep-left-cell text-center" colspan="2">Unseen</th>
<th class="sep-left-cell text-center" colspan="2">Seen</th>
<th class="sep-left-cell text-center" colspan="2">Unseen</th>
<th class="sep-left-cell text-center" colspan="2">Seen</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy (Evaluation dataset)" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss / unseen devices" data-chartable="true" data-field="logloss_eval_source_unseen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> / <br/>unseen devices (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / unseen devices" data-chartable="true" data-field="accuracy_eval_source_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> / <br/>unseen devices (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss / seen devices" data-chartable="true" data-field="logloss_eval_source_seen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> / <br/>seen devices (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / seen devices" data-chartable="true" data-field="accuracy_eval_source_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> / <br/>seen devices (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss / unseen cities" data-chartable="true" data-field="logloss_eval_city_unseen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> / <br/>unseen cities (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / unseen cities" data-chartable="true" data-field="accuracy_eval_city_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> / <br/>unseen cities (Evaluation dataset)</small>
</th>
<th class="sep-left-cell text-center" data-axis-label="Logloss / seen cities" data-chartable="true" data-field="logloss_eval_city_seen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss<small class="hidden"> / <br/>seen cities (Evaluation dataset)</small>
</th>
<th class="text-center" data-axis-label="Accuracy / seen cities" data-chartable="true" data-field="accuracy_eval_city_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy<small class="hidden"> / <br/>seen cities (Evaluation dataset)</small>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>68.6</td>
<td>1.065</td>
<td>64.5</td>
<td>0.829</td>
<td>72.0</td>
<td>0.972</td>
<td>67.5</td>
<td>0.926</td>
<td>68.6</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>67.5</td>
<td>1.048</td>
<td>63.6</td>
<td>0.801</td>
<td>70.8</td>
<td>1.012</td>
<td>65.4</td>
<td>0.892</td>
<td>68.0</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>68.5</td>
<td>1.094</td>
<td>64.7</td>
<td>0.820</td>
<td>71.7</td>
<td>1.007</td>
<td>67.3</td>
<td>0.931</td>
<td>68.7</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>68.8</td>
<td>1.002</td>
<td>65.5</td>
<td>0.824</td>
<td>71.5</td>
<td>0.914</td>
<td>69.2</td>
<td>0.903</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>66.7</td>
<td>1.214</td>
<td>62.5</td>
<td>1.071</td>
<td>70.2</td>
<td>1.190</td>
<td>63.2</td>
<td>1.126</td>
<td>67.3</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>64.6</td>
<td>1.318</td>
<td>59.0</td>
<td>1.102</td>
<td>69.2</td>
<td>1.249</td>
<td>60.6</td>
<td>1.188</td>
<td>65.4</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>67.2</td>
<td>1.223</td>
<td>63.3</td>
<td>1.066</td>
<td>70.4</td>
<td>1.196</td>
<td>63.4</td>
<td>1.123</td>
<td>68.1</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>66.1</td>
<td>1.250</td>
<td>60.8</td>
<td>1.061</td>
<td>70.5</td>
<td>1.206</td>
<td>61.3</td>
<td>1.135</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>53.0</td>
<td>1.878</td>
<td>46.8</td>
<td>1.265</td>
<td>58.2</td>
<td>1.547</td>
<td>49.0</td>
<td>1.530</td>
<td>54.1</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>51.1</td>
<td>1.488</td>
<td>45.9</td>
<td>1.191</td>
<td>55.4</td>
<td>1.362</td>
<td>48.7</td>
<td>1.310</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>49.1</td>
<td>1.356</td>
<td>43.9</td>
<td>1.118</td>
<td>53.4</td>
<td>1.274</td>
<td>48.9</td>
<td>1.209</td>
<td>49.2</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>51.4</td>
<td>1.426</td>
<td>46.6</td>
<td>1.188</td>
<td>55.4</td>
<td>1.305</td>
<td>50.7</td>
<td>1.293</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>68.3</td>
<td>1.458</td>
<td>65.6</td>
<td>1.098</td>
<td>70.6</td>
<td>1.628</td>
<td>65.6</td>
<td>1.187</td>
<td>69.0</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>53.9</td>
<td>2.488</td>
<td>50.8</td>
<td>1.999</td>
<td>56.5</td>
<td>2.165</td>
<td>54.3</td>
<td>2.191</td>
<td>54.6</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>67.0</td>
<td>1.180</td>
<td>62.6</td>
<td>1.009</td>
<td>70.7</td>
<td>1.099</td>
<td>67.2</td>
<td>1.082</td>
<td>67.1</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>66.9</td>
<td>0.993</td>
<td>64.1</td>
<td>0.878</td>
<td>69.2</td>
<td>0.982</td>
<td>66.1</td>
<td>0.911</td>
<td>67.4</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>70.0</td>
<td>1.110</td>
<td>67.1</td>
<td>0.991</td>
<td>72.5</td>
<td>1.059</td>
<td>68.3</td>
<td>1.039</td>
<td>71.1</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>70.1</td>
<td>0.929</td>
<td>68.1</td>
<td>0.823</td>
<td>71.8</td>
<td>0.864</td>
<td>71.8</td>
<td>0.868</td>
<td>70.3</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>51.4</td>
<td>2.039</td>
<td>44.1</td>
<td>1.228</td>
<td>57.5</td>
<td>1.561</td>
<td>50.3</td>
<td>1.570</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>53.3</td>
<td>2.072</td>
<td>47.1</td>
<td>1.997</td>
<td>58.6</td>
<td>2.040</td>
<td>51.9</td>
<td>2.030</td>
<td>53.8</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>51.6</td>
<td>1.780</td>
<td>44.6</td>
<td>1.193</td>
<td>57.5</td>
<td>1.463</td>
<td>49.7</td>
<td>1.461</td>
<td>51.8</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>49.2</td>
<td>2.111</td>
<td>40.4</td>
<td>2.027</td>
<td>56.5</td>
<td>2.063</td>
<td>49.3</td>
<td>2.065</td>
<td>49.9</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>55.0</td>
<td>1.557</td>
<td>50.9</td>
<td>1.396</td>
<td>58.4</td>
<td>1.479</td>
<td>52.2</td>
<td>1.473</td>
<td>55.1</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>51.3</td>
<td>1.619</td>
<td>47.3</td>
<td>1.480</td>
<td>54.6</td>
<td>1.562</td>
<td>47.5</td>
<td>1.542</td>
<td>51.9</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>56.3</td>
<td>1.613</td>
<td>50.9</td>
<td>1.351</td>
<td>60.8</td>
<td>1.516</td>
<td>53.9</td>
<td>1.464</td>
<td>56.8</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>66.0</td>
<td>1.219</td>
<td>60.6</td>
<td>0.893</td>
<td>70.5</td>
<td>1.045</td>
<td>64.6</td>
<td>1.045</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>67.0</td>
<td>1.094</td>
<td>62.6</td>
<td>0.834</td>
<td>70.6</td>
<td>0.986</td>
<td>64.2</td>
<td>0.940</td>
<td>67.3</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>66.7</td>
<td>1.187</td>
<td>61.4</td>
<td>0.886</td>
<td>71.1</td>
<td>0.971</td>
<td>66.9</td>
<td>1.056</td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>66.1</td>
<td>1.724</td>
<td>59.6</td>
<td>0.816</td>
<td>71.6</td>
<td>1.131</td>
<td>65.8</td>
<td>1.254</td>
<td>66.7</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>66.8</td>
<td>1.461</td>
<td>61.3</td>
<td>1.266</td>
<td>71.3</td>
<td>1.358</td>
<td>66.3</td>
<td>1.354</td>
<td>66.6</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>63.5</td>
<td>1.416</td>
<td>56.6</td>
<td>1.034</td>
<td>69.3</td>
<td>1.230</td>
<td>62.4</td>
<td>1.201</td>
<td>63.6</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>61.5</td>
<td>1.185</td>
<td>57.7</td>
<td>0.986</td>
<td>64.6</td>
<td>1.062</td>
<td>60.7</td>
<td>1.079</td>
<td>62.1</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>61.6</td>
<td>1.185</td>
<td>58.1</td>
<td>0.987</td>
<td>64.5</td>
<td>1.067</td>
<td>61.3</td>
<td>1.080</td>
<td>61.9</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>62.0</td>
<td>1.183</td>
<td>58.6</td>
<td>0.986</td>
<td>64.9</td>
<td>1.060</td>
<td>60.7</td>
<td>1.079</td>
<td>62.3</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>61.3</td>
<td>1.190</td>
<td>57.6</td>
<td>0.986</td>
<td>64.3</td>
<td>1.068</td>
<td>60.4</td>
<td>1.081</td>
<td>61.6</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>64.7</td>
<td>1.317</td>
<td>59.4</td>
<td>0.946</td>
<td>69.1</td>
<td>1.074</td>
<td>67.4</td>
<td>1.125</td>
<td>64.3</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>63.8</td>
<td>1.215</td>
<td>57.2</td>
<td>0.839</td>
<td>69.4</td>
<td>0.991</td>
<td>62.6</td>
<td>1.003</td>
<td>64.1</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>61.3</td>
<td>1.371</td>
<td>56.2</td>
<td>1.036</td>
<td>65.6</td>
<td>1.188</td>
<td>59.9</td>
<td>1.187</td>
<td>61.6</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>62.9</td>
<td>1.315</td>
<td>57.7</td>
<td>1.000</td>
<td>67.3</td>
<td>1.141</td>
<td>63.2</td>
<td>1.143</td>
<td>62.7</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>75.0</td>
<td>0.851</td>
<td>73.6</td>
<td>0.744</td>
<td>76.2</td>
<td>0.745</td>
<td>74.7</td>
<td>0.791</td>
<td>75.3</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>76.1</td>
<td>0.766</td>
<td>74.5</td>
<td>0.689</td>
<td>77.4</td>
<td>0.657</td>
<td>76.2</td>
<td>0.727</td>
<td>76.2</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>76.1</td>
<td>0.792</td>
<td>75.2</td>
<td>0.687</td>
<td>76.9</td>
<td>0.647</td>
<td>78.0</td>
<td>0.746</td>
<td>75.9</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>75.2</td>
<td>0.832</td>
<td>73.3</td>
<td>0.708</td>
<td>76.8</td>
<td>0.713</td>
<td>74.6</td>
<td>0.771</td>
<td>75.3</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>70.9</td>
<td>1.051</td>
<td>66.4</td>
<td>0.743</td>
<td>74.6</td>
<td>0.776</td>
<td>74.1</td>
<td>0.898</td>
<td>70.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>71.8</td>
<td>0.976</td>
<td>68.2</td>
<td>0.730</td>
<td>74.8</td>
<td>0.805</td>
<td>71.3</td>
<td>0.848</td>
<td>71.8</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>72.1</td>
<td>0.947</td>
<td>69.6</td>
<td>0.740</td>
<td>74.2</td>
<td>0.742</td>
<td>73.6</td>
<td>0.844</td>
<td>72.0</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>71.8</td>
<td>0.970</td>
<td>69.3</td>
<td>0.744</td>
<td>74.0</td>
<td>0.737</td>
<td>74.2</td>
<td>0.864</td>
<td>71.5</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>67.5</td>
<td>2.767</td>
<td>62.2</td>
<td>1.280</td>
<td>71.9</td>
<td>1.910</td>
<td>65.0</td>
<td>1.913</td>
<td>68.2</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>67.9</td>
<td>2.892</td>
<td>62.3</td>
<td>1.275</td>
<td>72.6</td>
<td>1.945</td>
<td>65.5</td>
<td>1.996</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>68.5</td>
<td>1.892</td>
<td>64.1</td>
<td>1.134</td>
<td>72.2</td>
<td>1.374</td>
<td>66.5</td>
<td>1.500</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>65.8</td>
<td>2.998</td>
<td>60.1</td>
<td>1.240</td>
<td>70.5</td>
<td>1.996</td>
<td>64.3</td>
<td>2.025</td>
<td>65.7</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>68.8</td>
<td>0.974</td>
<td>66.1</td>
<td>0.838</td>
<td>71.1</td>
<td>0.884</td>
<td>70.9</td>
<td>0.904</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>68.2</td>
<td>0.955</td>
<td>66.4</td>
<td>0.844</td>
<td>69.7</td>
<td>0.859</td>
<td>69.8</td>
<td>0.902</td>
<td>67.8</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>69.6</td>
<td>0.966</td>
<td>66.8</td>
<td>0.804</td>
<td>71.9</td>
<td>0.866</td>
<td>70.8</td>
<td>0.880</td>
<td>69.5</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>42.0</td>
<td>1.756</td>
<td>38.3</td>
<td>1.519</td>
<td>45.0</td>
<td>1.622</td>
<td>42.0</td>
<td>1.632</td>
<td>41.9</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>9.7</td>
<td>3.952</td>
<td>9.2</td>
<td>3.948</td>
<td>10.1</td>
<td>4.011</td>
<td>10.1</td>
<td>3.924</td>
<td>10.0</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6</td>
<td>2.222</td>
<td>38.0</td>
<td>1.320</td>
<td>51.9</td>
<td>1.802</td>
<td>43.6</td>
<td>1.702</td>
<td>45.5</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>60.2</td>
<td>1.348</td>
<td>53.4</td>
<td>0.967</td>
<td>65.9</td>
<td>1.091</td>
<td>61.0</td>
<td>1.139</td>
<td>60.6</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>67.5</td>
<td>1.653</td>
<td>64.3</td>
<td>1.130</td>
<td>70.1</td>
<td>1.302</td>
<td>67.1</td>
<td>1.341</td>
<td>67.9</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>68.4</td>
<td>1.398</td>
<td>64.8</td>
<td>1.011</td>
<td>71.3</td>
<td>1.069</td>
<td>71.5</td>
<td>1.180</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>69.6</td>
<td>2.497</td>
<td>66.1</td>
<td>1.693</td>
<td>72.6</td>
<td>1.843</td>
<td>71.7</td>
<td>2.034</td>
<td>69.8</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>63.3</td>
<td>1.369</td>
<td>59.2</td>
<td>1.191</td>
<td>66.7</td>
<td>1.250</td>
<td>62.8</td>
<td>1.271</td>
<td>63.6</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>63.3</td>
<td>1.419</td>
<td>59.2</td>
<td>1.265</td>
<td>66.7</td>
<td>1.316</td>
<td>62.8</td>
<td>1.334</td>
<td>63.6</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>65.3</td>
<td>1.294</td>
<td>62.8</td>
<td>1.164</td>
<td>67.5</td>
<td>1.190</td>
<td>65.0</td>
<td>1.220</td>
<td>65.7</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>65.3</td>
<td>1.351</td>
<td>62.8</td>
<td>1.242</td>
<td>67.5</td>
<td>1.265</td>
<td>65.0</td>
<td>1.289</td>
<td>65.7</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>66.6</td>
<td>1.159</td>
<td>59.7</td>
<td>0.779</td>
<td>72.4</td>
<td>0.948</td>
<td>66.1</td>
<td>0.947</td>
<td>66.8</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>65.4</td>
<td>1.152</td>
<td>59.4</td>
<td>0.825</td>
<td>70.5</td>
<td>0.999</td>
<td>64.0</td>
<td>0.971</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>66.2</td>
<td>1.116</td>
<td>60.1</td>
<td>0.791</td>
<td>71.2</td>
<td>0.932</td>
<td>65.2</td>
<td>0.934</td>
<td>66.1</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>52.2</td>
<td>1.651</td>
<td>50.7</td>
<td>1.612</td>
<td>53.5</td>
<td>1.598</td>
<td>53.9</td>
<td>1.636</td>
<td>52.1</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>70.3</td>
<td>1.107</td>
<td>67.4</td>
<td>0.965</td>
<td>72.8</td>
<td>1.087</td>
<td>67.9</td>
<td>1.018</td>
<td>70.7</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>71.4</td>
<td>1.164</td>
<td>67.7</td>
<td>1.010</td>
<td>74.4</td>
<td>1.108</td>
<td>71.6</td>
<td>1.073</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>71.3</td>
<td>1.149</td>
<td>67.6</td>
<td>0.995</td>
<td>74.4</td>
<td>1.086</td>
<td>72.1</td>
<td>1.057</td>
<td>71.5</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>71.8</td>
<td>1.175</td>
<td>67.6</td>
<td>1.014</td>
<td>75.3</td>
<td>1.094</td>
<td>71.8</td>
<td>1.083</td>
<td>71.9</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>47.2</td>
<td>1.687</td>
<td>41.5</td>
<td>1.277</td>
<td>51.9</td>
<td>1.444</td>
<td>45.8</td>
<td>1.470</td>
<td>47.1</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>44.7</td>
<td>1.730</td>
<td>40.0</td>
<td>1.337</td>
<td>48.5</td>
<td>1.531</td>
<td>41.9</td>
<td>1.506</td>
<td>44.5</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>46.1</td>
<td>1.761</td>
<td>40.9</td>
<td>1.299</td>
<td>50.4</td>
<td>1.490</td>
<td>45.4</td>
<td>1.517</td>
<td>46.1</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>46.8</td>
<td>1.738</td>
<td>41.3</td>
<td>1.279</td>
<td>51.5</td>
<td>1.485</td>
<td>45.0</td>
<td>1.501</td>
<td>46.7</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>63.8</td>
<td>1.247</td>
<td>57.8</td>
<td>0.953</td>
<td>68.8</td>
<td>1.110</td>
<td>65.4</td>
<td>1.078</td>
<td>63.9</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>65.2</td>
<td>1.231</td>
<td>58.2</td>
<td>0.936</td>
<td>71.0</td>
<td>1.091</td>
<td>66.7</td>
<td>1.061</td>
<td>65.3</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>65.3</td>
<td>1.159</td>
<td>60.8</td>
<td>0.912</td>
<td>69.1</td>
<td>1.022</td>
<td>66.2</td>
<td>1.021</td>
<td>65.5</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>64.7</td>
<td>1.610</td>
<td>57.9</td>
<td>1.036</td>
<td>70.4</td>
<td>1.228</td>
<td>65.5</td>
<td>1.294</td>
<td>64.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>61.4</td>
<td>1.305</td>
<td>55.5</td>
<td>0.978</td>
<td>66.2</td>
<td>1.204</td>
<td>57.9</td>
<td>1.107</td>
<td>62.2</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>64.5</td>
<td>1.144</td>
<td>60.4</td>
<td>0.915</td>
<td>67.8</td>
<td>1.112</td>
<td>60.6</td>
<td>0.998</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>67.3</td>
<td>1.102</td>
<td>63.1</td>
<td>0.852</td>
<td>70.8</td>
<td>1.059</td>
<td>64.6</td>
<td>0.946</td>
<td>67.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>68.1</td>
<td>1.040</td>
<td>64.2</td>
<td>0.827</td>
<td>71.4</td>
<td>1.009</td>
<td>63.5</td>
<td>0.905</td>
<td>69.2</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>73.1</td>
<td>0.846</td>
<td>70.8</td>
<td>0.703</td>
<td>74.9</td>
<td>0.825</td>
<td>73.5</td>
<td>0.753</td>
<td>72.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>72.9</td>
<td>0.840</td>
<td>70.0</td>
<td>0.700</td>
<td>75.4</td>
<td>0.806</td>
<td>73.3</td>
<td>0.754</td>
<td>72.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>72.9</td>
<td>0.832</td>
<td>70.1</td>
<td>0.696</td>
<td>75.1</td>
<td>0.805</td>
<td>73.2</td>
<td>0.748</td>
<td>72.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>72.8</td>
<td>0.850</td>
<td>70.2</td>
<td>0.710</td>
<td>74.9</td>
<td>0.819</td>
<td>73.3</td>
<td>0.762</td>
<td>72.3</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>51.9</td>
<td>1.376</td>
<td>49.7</td>
<td>1.257</td>
<td>53.6</td>
<td>1.293</td>
<td>49.9</td>
<td>1.305</td>
<td>52.4</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>55.2</td>
<td>1.284</td>
<td>53.5</td>
<td>1.171</td>
<td>56.6</td>
<td>1.233</td>
<td>54.3</td>
<td>1.214</td>
<td>55.7</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>53.5</td>
<td>2.114</td>
<td>50.7</td>
<td>2.097</td>
<td>55.8</td>
<td>2.100</td>
<td>52.5</td>
<td>2.106</td>
<td>53.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>63.0</td>
<td>1.243</td>
<td>58.9</td>
<td>1.024</td>
<td>66.4</td>
<td>1.161</td>
<td>59.5</td>
<td>1.112</td>
<td>63.3</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>63.2</td>
<td>1.242</td>
<td>57.4</td>
<td>1.006</td>
<td>68.1</td>
<td>1.102</td>
<td>60.4</td>
<td>1.100</td>
<td>64.0</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>52.2</td>
<td>3.840</td>
<td>47.3</td>
<td>2.958</td>
<td>56.3</td>
<td>3.654</td>
<td>51.2</td>
<td>3.265</td>
<td>52.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>59.0</td>
<td>2.451</td>
<td>53.2</td>
<td>1.525</td>
<td>63.8</td>
<td>1.963</td>
<td>57.0</td>
<td>1.971</td>
<td>59.9</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>61.2</td>
<td>1.598</td>
<td>54.2</td>
<td>1.308</td>
<td>67.1</td>
<td>1.475</td>
<td>58.0</td>
<td>1.429</td>
<td>62.4</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>63.5</td>
<td>1.551</td>
<td>55.6</td>
<td>1.297</td>
<td>70.0</td>
<td>1.436</td>
<td>62.3</td>
<td>1.408</td>
<td>63.5</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>63.5</td>
<td>1.430</td>
<td>55.9</td>
<td>1.057</td>
<td>70.0</td>
<td>1.339</td>
<td>62.4</td>
<td>1.196</td>
<td>63.7</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>62.8</td>
<td>1.406</td>
<td>56.2</td>
<td>1.056</td>
<td>68.3</td>
<td>1.253</td>
<td>61.0</td>
<td>1.213</td>
<td>63.5</td>
</tr>
</tbody>
</table>
<h1 id="class-wise-performance">Class-wise performance</h1>
<h2 id="log-loss">Log loss</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2021 baseline" data-comparison-active-set="Class-wise performance (all)" data-comparison-b-row="Kim_QTI_task1a_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (all)",
        "data_axis_title": "Log loss",
        "fields": ["class_logloss_eval_airport", "class_logloss_eval_bus", "class_logloss_eval_metro", "class_logloss_eval_metro_station", "class_logloss_eval_park", "class_logloss_eval_public_square", "class_logloss_eval_shopping_mall", "class_logloss_eval_street_pedestrian", "class_logloss_eval_street_traffic", "class_logloss_eval_tram"]
        },
        {"title": "Class-wise performance (indoor)","data_axis_title": "Log loss", "fields": ["class_logloss_eval_airport", "class_logloss_eval_metro_station", "class_logloss_eval_shopping_mall"]
        },
        {"title": "Class-wise performance (outdoor)", "data_axis_title": "Log loss", "fields": ["class_logloss_eval_park", "class_logloss_eval_public_square", "class_logloss_eval_street_pedestrian", "class_logloss_eval_street_traffic"]
        },
        {"title": "Class-wise performance (transport)", "data_axis_title": "Log loss", "fields": ["class_logloss_eval_bus","class_logloss_eval_metro","class_logloss_eval_tram"]
        }]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval" data-scatter-y="accuracy_eval" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="class_logloss_eval_airport" data-reversed="true" data-sortable="true" data-value-type="float3">
                Airport
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_bus" data-reversed="true" data-sortable="true" data-value-type="float3">
                Bus
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_metro" data-reversed="true" data-sortable="true" data-value-type="float3">
                Metro
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_metro_station" data-reversed="true" data-sortable="true" data-value-type="float3">
                Metro <br/>station
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_park" data-reversed="true" data-sortable="true" data-value-type="float3">
                Park
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_public_square" data-reversed="true" data-sortable="true" data-value-type="float3">
                Public <br/>square
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_shopping_mall" data-reversed="true" data-sortable="true" data-value-type="float3">
                Shopping <br/>mall
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_street_pedestrian" data-reversed="true" data-sortable="true" data-value-type="float3">
                Street <br/>pedestrian
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_street_traffic" data-reversed="true" data-sortable="true" data-value-type="float3">
                Street <br/>traffic
            </th>
<th class="text-center" data-chartable="true" data-field="class_logloss_eval_tram" data-reversed="true" data-sortable="true" data-value-type="float3">
                Tram
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>1.393</td>
<td>0.431</td>
<td>0.937</td>
<td>0.977</td>
<td>0.355</td>
<td>1.681</td>
<td>0.840</td>
<td>1.695</td>
<td>0.312</td>
<td>0.740</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>1.224</td>
<td>0.526</td>
<td>0.790</td>
<td>1.201</td>
<td>0.434</td>
<td>1.256</td>
<td>0.949</td>
<td>1.586</td>
<td>0.426</td>
<td>0.743</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>1.287</td>
<td>0.473</td>
<td>0.850</td>
<td>1.191</td>
<td>0.348</td>
<td>1.480</td>
<td>0.891</td>
<td>1.687</td>
<td>0.393</td>
<td>0.844</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>1.245</td>
<td>0.540</td>
<td>0.840</td>
<td>0.985</td>
<td>0.392</td>
<td>1.682</td>
<td>0.852</td>
<td>1.581</td>
<td>0.259</td>
<td>0.673</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>1.461</td>
<td>1.007</td>
<td>1.169</td>
<td>1.343</td>
<td>0.753</td>
<td>1.485</td>
<td>1.006</td>
<td>1.576</td>
<td>0.618</td>
<td>0.937</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>1.430</td>
<td>0.808</td>
<td>1.228</td>
<td>1.294</td>
<td>0.812</td>
<td>1.702</td>
<td>1.272</td>
<td>1.863</td>
<td>0.670</td>
<td>0.924</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>1.456</td>
<td>0.919</td>
<td>1.180</td>
<td>1.191</td>
<td>0.829</td>
<td>1.583</td>
<td>1.041</td>
<td>1.603</td>
<td>0.735</td>
<td>0.839</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>1.519</td>
<td>0.997</td>
<td>1.150</td>
<td>1.195</td>
<td>0.713</td>
<td>1.545</td>
<td>1.100</td>
<td>1.610</td>
<td>0.775</td>
<td>0.867</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>1.955</td>
<td>1.598</td>
<td>1.454</td>
<td>1.693</td>
<td>1.021</td>
<td>2.443</td>
<td>1.179</td>
<td>1.872</td>
<td>1.335</td>
<td>0.886</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>1.503</td>
<td>1.280</td>
<td>1.362</td>
<td>1.761</td>
<td>0.947</td>
<td>1.563</td>
<td>1.171</td>
<td>1.778</td>
<td>1.142</td>
<td>0.753</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>1.763</td>
<td>1.135</td>
<td>1.285</td>
<td>1.329</td>
<td>0.827</td>
<td>1.591</td>
<td>0.802</td>
<td>1.749</td>
<td>1.041</td>
<td>0.741</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>1.806</td>
<td>1.231</td>
<td>1.184</td>
<td>1.479</td>
<td>0.809</td>
<td>1.753</td>
<td>0.943</td>
<td>1.764</td>
<td>1.167</td>
<td>0.828</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>1.754</td>
<td>0.695</td>
<td>1.316</td>
<td>1.439</td>
<td>0.936</td>
<td>1.926</td>
<td>1.254</td>
<td>2.392</td>
<td>0.478</td>
<td>0.423</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>2.875</td>
<td>1.782</td>
<td>1.970</td>
<td>3.164</td>
<td>1.838</td>
<td>3.269</td>
<td>1.712</td>
<td>3.128</td>
<td>1.088</td>
<td>1.388</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>1.372</td>
<td>0.949</td>
<td>1.127</td>
<td>1.202</td>
<td>0.829</td>
<td>1.288</td>
<td>1.065</td>
<td>1.463</td>
<td>0.615</td>
<td>0.956</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>1.270</td>
<td>0.616</td>
<td>0.929</td>
<td>1.105</td>
<td>0.720</td>
<td>1.322</td>
<td>0.712</td>
<td>1.487</td>
<td>0.468</td>
<td>0.670</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>1.309</td>
<td>0.913</td>
<td>1.003</td>
<td>1.240</td>
<td>0.806</td>
<td>1.220</td>
<td>1.124</td>
<td>1.390</td>
<td>0.634</td>
<td>0.812</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>1.205</td>
<td>0.583</td>
<td>0.868</td>
<td>1.003</td>
<td>0.492</td>
<td>1.284</td>
<td>0.862</td>
<td>1.342</td>
<td>0.452</td>
<td>0.622</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>1.615</td>
<td>0.865</td>
<td>1.424</td>
<td>1.637</td>
<td>1.438</td>
<td>2.358</td>
<td>1.861</td>
<td>2.608</td>
<td>1.062</td>
<td>1.102</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>2.103</td>
<td>1.884</td>
<td>2.065</td>
<td>2.072</td>
<td>1.991</td>
<td>2.205</td>
<td>2.039</td>
<td>2.172</td>
<td>1.866</td>
<td>1.913</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>1.589</td>
<td>0.764</td>
<td>1.800</td>
<td>1.833</td>
<td>1.101</td>
<td>1.651</td>
<td>1.907</td>
<td>1.910</td>
<td>0.892</td>
<td>1.148</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>2.131</td>
<td>1.857</td>
<td>2.106</td>
<td>2.135</td>
<td>2.041</td>
<td>2.191</td>
<td>2.069</td>
<td>2.192</td>
<td>1.945</td>
<td>1.988</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>1.695</td>
<td>1.508</td>
<td>1.709</td>
<td>1.454</td>
<td>0.849</td>
<td>1.839</td>
<td>1.540</td>
<td>1.746</td>
<td>1.061</td>
<td>1.289</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>1.382</td>
<td>1.506</td>
<td>1.907</td>
<td>1.536</td>
<td>0.887</td>
<td>2.451</td>
<td>1.403</td>
<td>1.991</td>
<td>1.016</td>
<td>1.348</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>1.645</td>
<td>1.297</td>
<td>1.599</td>
<td>1.426</td>
<td>0.996</td>
<td>2.077</td>
<td>1.567</td>
<td>1.724</td>
<td>0.996</td>
<td>1.370</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>1.574</td>
<td>0.455</td>
<td>1.086</td>
<td>1.276</td>
<td>0.487</td>
<td>1.666</td>
<td>1.139</td>
<td>1.473</td>
<td>0.666</td>
<td>0.590</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>1.390</td>
<td>0.455</td>
<td>1.047</td>
<td>1.272</td>
<td>0.451</td>
<td>1.379</td>
<td>1.111</td>
<td>1.287</td>
<td>0.566</td>
<td>0.561</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>1.457</td>
<td>0.548</td>
<td>1.132</td>
<td>1.344</td>
<td>0.359</td>
<td>1.095</td>
<td>1.357</td>
<td>1.581</td>
<td>0.622</td>
<td>0.733</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>1.116</td>
<td>0.528</td>
<td>1.008</td>
<td>1.301</td>
<td>0.746</td>
<td>1.164</td>
<td>1.407</td>
<td>3.708</td>
<td>0.467</td>
<td>0.840</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>1.619</td>
<td>1.049</td>
<td>1.385</td>
<td>1.587</td>
<td>0.948</td>
<td>1.775</td>
<td>1.364</td>
<td>1.740</td>
<td>0.916</td>
<td>1.164</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>1.683</td>
<td>0.572</td>
<td>1.162</td>
<td>1.303</td>
<td>0.808</td>
<td>1.749</td>
<td>1.429</td>
<td>1.694</td>
<td>0.809</td>
<td>0.864</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>1.241</td>
<td>0.851</td>
<td>0.958</td>
<td>1.540</td>
<td>0.705</td>
<td>1.488</td>
<td>1.000</td>
<td>1.385</td>
<td>0.800</td>
<td>0.796</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>1.274</td>
<td>0.848</td>
<td>0.954</td>
<td>1.438</td>
<td>0.715</td>
<td>1.536</td>
<td>1.002</td>
<td>1.398</td>
<td>0.787</td>
<td>0.819</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>1.243</td>
<td>0.848</td>
<td>0.942</td>
<td>1.514</td>
<td>0.744</td>
<td>1.473</td>
<td>1.028</td>
<td>1.391</td>
<td>0.797</td>
<td>0.777</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>1.273</td>
<td>0.921</td>
<td>0.923</td>
<td>1.506</td>
<td>0.678</td>
<td>1.380</td>
<td>1.040</td>
<td>1.577</td>
<td>0.805</td>
<td>0.679</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>1.511</td>
<td>0.694</td>
<td>1.220</td>
<td>1.114</td>
<td>0.773</td>
<td>1.322</td>
<td>1.491</td>
<td>1.662</td>
<td>0.566</td>
<td>0.791</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>1.228</td>
<td>0.547</td>
<td>0.962</td>
<td>1.003</td>
<td>0.564</td>
<td>1.259</td>
<td>1.327</td>
<td>1.564</td>
<td>1.011</td>
<td>0.636</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>1.537</td>
<td>0.924</td>
<td>1.486</td>
<td>1.311</td>
<td>0.914</td>
<td>1.483</td>
<td>1.097</td>
<td>1.844</td>
<td>0.600</td>
<td>0.685</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>1.456</td>
<td>0.856</td>
<td>1.302</td>
<td>1.332</td>
<td>0.786</td>
<td>1.348</td>
<td>1.183</td>
<td>1.700</td>
<td>0.571</td>
<td>0.898</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>1.242</td>
<td>0.397</td>
<td>0.723</td>
<td>0.890</td>
<td>0.363</td>
<td>1.419</td>
<td>0.721</td>
<td>1.397</td>
<td>0.426</td>
<td>0.351</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>1.050</td>
<td>0.351</td>
<td>0.550</td>
<td>0.810</td>
<td>0.400</td>
<td>1.261</td>
<td>0.671</td>
<td>1.298</td>
<td>0.436</td>
<td>0.411</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>0.976</td>
<td>0.398</td>
<td>0.557</td>
<td>0.876</td>
<td>0.378</td>
<td>1.356</td>
<td>0.722</td>
<td>1.310</td>
<td>0.381</td>
<td>0.393</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>1.232</td>
<td>0.332</td>
<td>0.542</td>
<td>0.744</td>
<td>0.273</td>
<td>1.468</td>
<td>0.826</td>
<td>1.350</td>
<td>0.417</td>
<td>0.460</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>1.097</td>
<td>0.369</td>
<td>0.742</td>
<td>0.853</td>
<td>0.309</td>
<td>1.419</td>
<td>1.151</td>
<td>1.905</td>
<td>0.499</td>
<td>0.489</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>1.036</td>
<td>0.378</td>
<td>0.696</td>
<td>0.858</td>
<td>0.334</td>
<td>1.386</td>
<td>1.059</td>
<td>1.628</td>
<td>0.483</td>
<td>0.562</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>0.989</td>
<td>0.364</td>
<td>0.738</td>
<td>0.939</td>
<td>0.322</td>
<td>1.418</td>
<td>0.974</td>
<td>1.682</td>
<td>0.439</td>
<td>0.477</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>1.070</td>
<td>0.374</td>
<td>0.722</td>
<td>0.824</td>
<td>0.307</td>
<td>1.462</td>
<td>1.038</td>
<td>1.685</td>
<td>0.466</td>
<td>0.520</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>2.394</td>
<td>0.393</td>
<td>1.310</td>
<td>2.305</td>
<td>0.596</td>
<td>4.185</td>
<td>2.131</td>
<td>4.457</td>
<td>0.666</td>
<td>1.123</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>2.454</td>
<td>0.364</td>
<td>2.061</td>
<td>2.557</td>
<td>0.805</td>
<td>3.464</td>
<td>2.529</td>
<td>4.386</td>
<td>0.520</td>
<td>0.956</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>1.898</td>
<td>0.509</td>
<td>1.270</td>
<td>2.146</td>
<td>0.472</td>
<td>2.372</td>
<td>2.108</td>
<td>2.408</td>
<td>0.789</td>
<td>0.815</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>1.350</td>
<td>0.411</td>
<td>1.910</td>
<td>3.807</td>
<td>0.749</td>
<td>2.299</td>
<td>3.124</td>
<td>4.841</td>
<td>0.828</td>
<td>1.073</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>1.209</td>
<td>0.543</td>
<td>0.708</td>
<td>1.073</td>
<td>0.597</td>
<td>1.192</td>
<td>1.101</td>
<td>1.438</td>
<td>0.363</td>
<td>0.775</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>1.024</td>
<td>0.522</td>
<td>0.987</td>
<td>0.901</td>
<td>0.463</td>
<td>1.299</td>
<td>0.992</td>
<td>1.524</td>
<td>0.465</td>
<td>0.768</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>1.498</td>
<td>0.600</td>
<td>0.867</td>
<td>0.918</td>
<td>0.468</td>
<td>1.138</td>
<td>0.907</td>
<td>1.496</td>
<td>0.409</td>
<td>0.475</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>1.626</td>
<td>2.583</td>
<td>1.539</td>
<td>1.375</td>
<td>1.413</td>
<td>2.058</td>
<td>1.112</td>
<td>1.931</td>
<td>1.040</td>
<td>1.587</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>4.120</td>
<td>3.971</td>
<td>4.412</td>
<td>3.673</td>
<td>4.147</td>
<td>3.229</td>
<td>4.169</td>
<td>3.351</td>
<td>4.580</td>
<td>3.845</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>2.077</td>
<td>1.615</td>
<td>1.159</td>
<td>1.955</td>
<td>2.173</td>
<td>2.455</td>
<td>1.227</td>
<td>1.744</td>
<td>1.825</td>
<td>1.073</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>1.346</td>
<td>1.046</td>
<td>1.057</td>
<td>0.809</td>
<td>0.875</td>
<td>1.569</td>
<td>1.491</td>
<td>1.352</td>
<td>1.040</td>
<td>0.817</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>1.380</td>
<td>0.624</td>
<td>1.154</td>
<td>1.791</td>
<td>0.608</td>
<td>2.558</td>
<td>1.565</td>
<td>2.133</td>
<td>0.921</td>
<td>0.942</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>1.403</td>
<td>1.045</td>
<td>1.093</td>
<td>1.035</td>
<td>0.510</td>
<td>1.658</td>
<td>1.212</td>
<td>2.524</td>
<td>1.001</td>
<td>0.385</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>2.187</td>
<td>1.302</td>
<td>1.749</td>
<td>2.298</td>
<td>0.853</td>
<td>3.526</td>
<td>2.204</td>
<td>3.980</td>
<td>1.616</td>
<td>0.870</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>1.429</td>
<td>1.095</td>
<td>1.198</td>
<td>1.457</td>
<td>0.902</td>
<td>1.693</td>
<td>1.201</td>
<td>1.756</td>
<td>0.853</td>
<td>1.136</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>1.499</td>
<td>1.195</td>
<td>1.301</td>
<td>1.496</td>
<td>0.991</td>
<td>1.707</td>
<td>1.278</td>
<td>1.764</td>
<td>0.907</td>
<td>1.211</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>1.325</td>
<td>0.947</td>
<td>1.358</td>
<td>1.518</td>
<td>0.933</td>
<td>1.475</td>
<td>1.199</td>
<td>1.607</td>
<td>0.812</td>
<td>1.052</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>1.423</td>
<td>1.061</td>
<td>1.414</td>
<td>1.560</td>
<td>1.014</td>
<td>1.515</td>
<td>1.265</td>
<td>1.654</td>
<td>0.865</td>
<td>1.147</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>1.536</td>
<td>0.404</td>
<td>1.053</td>
<td>1.072</td>
<td>0.480</td>
<td>1.468</td>
<td>1.038</td>
<td>1.485</td>
<td>0.437</td>
<td>0.546</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>1.353</td>
<td>0.638</td>
<td>1.010</td>
<td>1.175</td>
<td>0.448</td>
<td>1.394</td>
<td>1.232</td>
<td>1.395</td>
<td>0.556</td>
<td>0.536</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>1.499</td>
<td>0.486</td>
<td>0.959</td>
<td>1.049</td>
<td>0.501</td>
<td>1.339</td>
<td>1.045</td>
<td>1.322</td>
<td>0.601</td>
<td>0.588</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>1.665</td>
<td>1.313</td>
<td>2.005</td>
<td>2.381</td>
<td>1.075</td>
<td>1.782</td>
<td>1.616</td>
<td>1.844</td>
<td>1.150</td>
<td>1.468</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>1.502</td>
<td>0.735</td>
<td>1.013</td>
<td>1.042</td>
<td>0.634</td>
<td>1.515</td>
<td>0.965</td>
<td>1.606</td>
<td>0.530</td>
<td>0.755</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>1.478</td>
<td>0.849</td>
<td>1.064</td>
<td>1.143</td>
<td>0.710</td>
<td>1.438</td>
<td>1.096</td>
<td>1.580</td>
<td>0.630</td>
<td>0.814</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>1.312</td>
<td>0.853</td>
<td>1.116</td>
<td>1.139</td>
<td>0.666</td>
<td>1.507</td>
<td>1.104</td>
<td>1.558</td>
<td>0.572</td>
<td>0.821</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>1.530</td>
<td>0.911</td>
<td>1.206</td>
<td>1.070</td>
<td>0.742</td>
<td>1.448</td>
<td>1.025</td>
<td>1.485</td>
<td>0.649</td>
<td>0.807</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>1.564</td>
<td>1.549</td>
<td>1.114</td>
<td>1.661</td>
<td>1.341</td>
<td>2.025</td>
<td>1.363</td>
<td>1.564</td>
<td>1.399</td>
<td>1.056</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>1.647</td>
<td>1.437</td>
<td>1.459</td>
<td>1.598</td>
<td>1.629</td>
<td>1.774</td>
<td>1.206</td>
<td>1.516</td>
<td>1.764</td>
<td>1.122</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>1.612</td>
<td>1.466</td>
<td>1.418</td>
<td>1.606</td>
<td>1.450</td>
<td>2.018</td>
<td>1.300</td>
<td>1.596</td>
<td>1.680</td>
<td>0.945</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>1.811</td>
<td>1.506</td>
<td>1.398</td>
<td>1.489</td>
<td>1.262</td>
<td>2.018</td>
<td>1.254</td>
<td>1.739</td>
<td>1.437</td>
<td>0.963</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>1.687</td>
<td>0.924</td>
<td>0.892</td>
<td>1.182</td>
<td>0.544</td>
<td>1.433</td>
<td>1.316</td>
<td>1.382</td>
<td>0.608</td>
<td>0.902</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>1.636</td>
<td>0.841</td>
<td>0.940</td>
<td>1.166</td>
<td>0.500</td>
<td>1.472</td>
<td>1.287</td>
<td>1.393</td>
<td>0.596</td>
<td>0.873</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>1.318</td>
<td>0.613</td>
<td>1.139</td>
<td>1.103</td>
<td>0.446</td>
<td>1.698</td>
<td>1.124</td>
<td>1.539</td>
<td>0.543</td>
<td>0.720</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>1.969</td>
<td>0.643</td>
<td>1.118</td>
<td>1.681</td>
<td>0.307</td>
<td>2.254</td>
<td>1.677</td>
<td>1.718</td>
<td>0.739</td>
<td>0.862</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>1.466</td>
<td>0.827</td>
<td>0.778</td>
<td>1.045</td>
<td>0.799</td>
<td>1.855</td>
<td>1.136</td>
<td>1.985</td>
<td>0.607</td>
<td>0.771</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>1.255</td>
<td>0.784</td>
<td>0.763</td>
<td>0.886</td>
<td>0.615</td>
<td>1.698</td>
<td>1.038</td>
<td>2.023</td>
<td>0.496</td>
<td>0.635</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>1.148</td>
<td>0.558</td>
<td>0.838</td>
<td>0.985</td>
<td>0.512</td>
<td>1.572</td>
<td>1.005</td>
<td>1.935</td>
<td>0.499</td>
<td>0.603</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>1.037</td>
<td>0.484</td>
<td>0.789</td>
<td>0.984</td>
<td>0.475</td>
<td>1.609</td>
<td>0.844</td>
<td>1.970</td>
<td>0.478</td>
<td>0.568</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>1.092</td>
<td>0.316</td>
<td>0.728</td>
<td>0.885</td>
<td>0.431</td>
<td>1.080</td>
<td>0.722</td>
<td>1.559</td>
<td>0.430</td>
<td>0.438</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>0.935</td>
<td>0.277</td>
<td>0.752</td>
<td>0.907</td>
<td>0.414</td>
<td>1.064</td>
<td>0.780</td>
<td>1.626</td>
<td>0.392</td>
<td>0.491</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>0.975</td>
<td>0.282</td>
<td>0.737</td>
<td>0.907</td>
<td>0.406</td>
<td>1.065</td>
<td>0.762</td>
<td>1.588</td>
<td>0.387</td>
<td>0.473</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>1.001</td>
<td>0.305</td>
<td>0.733</td>
<td>0.896</td>
<td>0.435</td>
<td>1.086</td>
<td>0.752</td>
<td>1.631</td>
<td>0.428</td>
<td>0.469</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>1.460</td>
<td>1.325</td>
<td>1.242</td>
<td>1.215</td>
<td>1.132</td>
<td>2.075</td>
<td>0.976</td>
<td>1.814</td>
<td>0.655</td>
<td>1.218</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>1.282</td>
<td>1.399</td>
<td>1.119</td>
<td>1.422</td>
<td>1.081</td>
<td>1.635</td>
<td>1.074</td>
<td>1.594</td>
<td>0.579</td>
<td>1.040</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>2.106</td>
<td>2.136</td>
<td>2.098</td>
<td>2.111</td>
<td>2.063</td>
<td>2.174</td>
<td>2.104</td>
<td>2.162</td>
<td>2.019</td>
<td>2.074</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>1.296</td>
<td>1.315</td>
<td>0.976</td>
<td>1.177</td>
<td>0.798</td>
<td>1.431</td>
<td>0.998</td>
<td>1.639</td>
<td>0.704</td>
<td>0.902</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>1.210</td>
<td>1.270</td>
<td>0.900</td>
<td>1.182</td>
<td>0.659</td>
<td>1.478</td>
<td>1.197</td>
<td>1.601</td>
<td>0.740</td>
<td>0.893</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>4.982</td>
<td>4.172</td>
<td>3.030</td>
<td>3.876</td>
<td>2.235</td>
<td>3.320</td>
<td>3.571</td>
<td>4.635</td>
<td>1.760</td>
<td>2.007</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>2.475</td>
<td>2.964</td>
<td>1.691</td>
<td>2.480</td>
<td>1.237</td>
<td>1.717</td>
<td>1.816</td>
<td>2.932</td>
<td>1.210</td>
<td>0.938</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>1.560</td>
<td>1.115</td>
<td>1.549</td>
<td>1.602</td>
<td>1.040</td>
<td>1.724</td>
<td>1.513</td>
<td>1.974</td>
<td>1.043</td>
<td>1.281</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>1.598</td>
<td>1.157</td>
<td>1.463</td>
<td>1.682</td>
<td>1.199</td>
<td>1.620</td>
<td>1.360</td>
<td>1.797</td>
<td>1.047</td>
<td>1.199</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>1.443</td>
<td>0.804</td>
<td>1.121</td>
<td>1.520</td>
<td>0.985</td>
<td>1.466</td>
<td>1.196</td>
<td>2.055</td>
<td>0.835</td>
<td>0.840</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>1.337</td>
<td>0.760</td>
<td>1.072</td>
<td>1.399</td>
<td>1.096</td>
<td>1.615</td>
<td>0.989</td>
<td>2.056</td>
<td>0.908</td>
<td>0.919</td>
</tr>
</tbody>
</table>
<h2 id="accuracy">Accuracy</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2021 baseline" data-comparison-active-set="Class-wise performance (all)" data-comparison-b-row="Kim_QTI_task1a_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title": "Class-wise performance (all)",
        "data_axis_title": "Accuracy",
        "fields": ["class_accuracy_eval_airport", "class_accuracy_eval_bus", "class_accuracy_eval_metro", "class_accuracy_eval_metro_station", "class_accuracy_eval_park", "class_accuracy_eval_public_square", "class_accuracy_eval_shopping_mall", "class_accuracy_eval_street_pedestrian", "class_accuracy_eval_street_traffic", "class_accuracy_eval_tram"]
        },
        {"title": "Class-wise performance (indoor)","data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_airport", "class_accuracy_eval_metro_station", "class_accuracy_eval_shopping_mall"]
        },
        {"title": "Class-wise performance (outdoor)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_park", "class_accuracy_eval_public_square", "class_accuracy_eval_street_pedestrian", "class_accuracy_eval_street_traffic"]
        },
        {"title": "Class-wise performance (transport)", "data_axis_title": "Accuracy", "fields": ["class_accuracy_eval_bus","class_accuracy_eval_metro","class_accuracy_eval_tram"]
        }]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval" data-scatter-y="accuracy_eval" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="class_accuracy_eval_airport" data-sortable="true" data-value-type="float1-percentage">
                Airport
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_bus" data-sortable="true" data-value-type="float1-percentage">
                Bus
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_metro" data-sortable="true" data-value-type="float1-percentage">
                Metro
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_metro_station" data-sortable="true" data-value-type="float1-percentage">
                Metro <br/>station
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_park" data-sortable="true" data-value-type="float1-percentage">
                Park
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_public_square" data-sortable="true" data-value-type="float1-percentage">
                Public <br/>square
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_shopping_mall" data-sortable="true" data-value-type="float1-percentage">
                Shopping <br/>mall
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_street_pedestrian" data-sortable="true" data-value-type="float1-percentage">
                Street <br/>pedestrian
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_street_traffic" data-sortable="true" data-value-type="float1-percentage">
                Street <br/>traffic
            </th>
<th class="text-center" data-chartable="true" data-field="class_accuracy_eval_tram" data-sortable="true" data-value-type="float1-percentage">
                Tram
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>68.6</td>
<td>49.0</td>
<td>88.1</td>
<td>66.8</td>
<td>66.8</td>
<td>90.0</td>
<td>40.7</td>
<td>73.7</td>
<td>41.5</td>
<td>93.6</td>
<td>75.9</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>67.5</td>
<td>53.8</td>
<td>81.8</td>
<td>73.2</td>
<td>63.3</td>
<td>83.6</td>
<td>51.8</td>
<td>63.0</td>
<td>42.9</td>
<td>88.5</td>
<td>73.5</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>68.5</td>
<td>57.2</td>
<td>83.7</td>
<td>72.5</td>
<td>63.5</td>
<td>88.4</td>
<td>50.5</td>
<td>67.6</td>
<td>41.7</td>
<td>89.9</td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>68.8</td>
<td>54.2</td>
<td>81.7</td>
<td>69.9</td>
<td>67.3</td>
<td>87.4</td>
<td>38.4</td>
<td>72.6</td>
<td>45.3</td>
<td>93.7</td>
<td>77.4</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>66.7</td>
<td>43.7</td>
<td>77.0</td>
<td>67.2</td>
<td>59.3</td>
<td>84.1</td>
<td>49.9</td>
<td>77.3</td>
<td>41.9</td>
<td>85.0</td>
<td>81.6</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>64.6</td>
<td>53.2</td>
<td>84.7</td>
<td>62.1</td>
<td>64.3</td>
<td>81.9</td>
<td>42.4</td>
<td>63.1</td>
<td>30.2</td>
<td>87.4</td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>67.2</td>
<td>46.0</td>
<td>80.4</td>
<td>67.0</td>
<td>66.0</td>
<td>83.2</td>
<td>44.4</td>
<td>72.7</td>
<td>41.2</td>
<td>84.5</td>
<td>86.1</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>66.1</td>
<td>41.7</td>
<td>75.3</td>
<td>64.5</td>
<td>68.7</td>
<td>86.2</td>
<td>45.1</td>
<td>70.8</td>
<td>42.7</td>
<td>80.1</td>
<td>86.0</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>53.0</td>
<td>32.4</td>
<td>50.5</td>
<td>53.8</td>
<td>47.2</td>
<td>72.5</td>
<td>32.3</td>
<td>66.4</td>
<td>36.2</td>
<td>67.3</td>
<td>71.6</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>51.1</td>
<td>33.7</td>
<td>46.3</td>
<td>39.8</td>
<td>38.5</td>
<td>73.9</td>
<td>42.8</td>
<td>65.2</td>
<td>29.8</td>
<td>65.3</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>49.1</td>
<td>19.8</td>
<td>39.0</td>
<td>28.7</td>
<td>45.1</td>
<td>68.8</td>
<td>37.1</td>
<td>86.7</td>
<td>17.3</td>
<td>68.8</td>
<td>79.3</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>51.4</td>
<td>23.6</td>
<td>47.9</td>
<td>44.2</td>
<td>43.7</td>
<td>76.5</td>
<td>37.1</td>
<td>73.7</td>
<td>28.3</td>
<td>65.8</td>
<td>73.2</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>68.3</td>
<td>53.2</td>
<td>81.9</td>
<td>61.6</td>
<td>63.9</td>
<td>81.3</td>
<td>49.1</td>
<td>64.4</td>
<td>54.5</td>
<td>88.0</td>
<td>84.8</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>53.9</td>
<td>38.1</td>
<td>60.0</td>
<td>51.9</td>
<td>43.1</td>
<td>62.8</td>
<td>38.1</td>
<td>64.5</td>
<td>36.9</td>
<td>78.4</td>
<td>65.2</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>67.0</td>
<td>46.6</td>
<td>74.9</td>
<td>65.4</td>
<td>65.8</td>
<td>76.9</td>
<td>58.1</td>
<td>70.1</td>
<td>49.2</td>
<td>88.1</td>
<td>75.0</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>66.9</td>
<td>50.0</td>
<td>78.5</td>
<td>66.7</td>
<td>60.6</td>
<td>77.3</td>
<td>51.3</td>
<td>77.3</td>
<td>43.8</td>
<td>87.1</td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>70.0</td>
<td>52.9</td>
<td>77.1</td>
<td>72.1</td>
<td>63.3</td>
<td>80.7</td>
<td>61.4</td>
<td>68.8</td>
<td>55.7</td>
<td>88.6</td>
<td>79.8</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>70.1</td>
<td>54.3</td>
<td>82.6</td>
<td>68.3</td>
<td>63.8</td>
<td>86.0</td>
<td>54.7</td>
<td>70.8</td>
<td>51.3</td>
<td>88.6</td>
<td>80.8</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>51.4</td>
<td>38.5</td>
<td>72.1</td>
<td>45.8</td>
<td>46.7</td>
<td>65.7</td>
<td>32.8</td>
<td>53.4</td>
<td>30.2</td>
<td>67.0</td>
<td>61.9</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>53.3</td>
<td>41.8</td>
<td>73.9</td>
<td>48.6</td>
<td>48.9</td>
<td>57.3</td>
<td>28.5</td>
<td>51.9</td>
<td>35.1</td>
<td>77.8</td>
<td>69.7</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>51.6</td>
<td>39.1</td>
<td>79.4</td>
<td>34.3</td>
<td>39.1</td>
<td>63.5</td>
<td>34.2</td>
<td>57.3</td>
<td>39.9</td>
<td>71.8</td>
<td>57.3</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>49.2</td>
<td>37.9</td>
<td>81.1</td>
<td>39.4</td>
<td>37.5</td>
<td>54.7</td>
<td>32.7</td>
<td>52.7</td>
<td>30.4</td>
<td>66.7</td>
<td>58.7</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>55.0</td>
<td>38.4</td>
<td>54.5</td>
<td>40.3</td>
<td>59.5</td>
<td>85.4</td>
<td>33.0</td>
<td>51.4</td>
<td>49.0</td>
<td>74.2</td>
<td>64.0</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>51.3</td>
<td>59.7</td>
<td>57.1</td>
<td>30.4</td>
<td>53.3</td>
<td>84.3</td>
<td>0.0</td>
<td>57.1</td>
<td>29.8</td>
<td>76.4</td>
<td>64.8</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>56.3</td>
<td>43.6</td>
<td>67.8</td>
<td>49.9</td>
<td>60.2</td>
<td>76.4</td>
<td>24.0</td>
<td>51.4</td>
<td>47.5</td>
<td>79.4</td>
<td>62.5</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>66.0</td>
<td>45.6</td>
<td>88.8</td>
<td>57.8</td>
<td>59.7</td>
<td>88.3</td>
<td>43.2</td>
<td>64.0</td>
<td>51.3</td>
<td>81.8</td>
<td>79.3</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>67.0</td>
<td>48.0</td>
<td>86.2</td>
<td>61.4</td>
<td>55.4</td>
<td>88.4</td>
<td>46.3</td>
<td>63.6</td>
<td>54.7</td>
<td>84.8</td>
<td>80.8</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>66.7</td>
<td>47.6</td>
<td>85.0</td>
<td>60.0</td>
<td>59.1</td>
<td>88.6</td>
<td>60.7</td>
<td>61.7</td>
<td>51.8</td>
<td>80.3</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>66.1</td>
<td>56.8</td>
<td>83.8</td>
<td>60.0</td>
<td>60.0</td>
<td>82.8</td>
<td>59.1</td>
<td>55.1</td>
<td>48.0</td>
<td>84.3</td>
<td>71.3</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>66.8</td>
<td>48.1</td>
<td>89.8</td>
<td>62.6</td>
<td>58.1</td>
<td>89.9</td>
<td>43.4</td>
<td>68.2</td>
<td>43.7</td>
<td>85.9</td>
<td>77.9</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>63.5</td>
<td>45.5</td>
<td>88.9</td>
<td>64.3</td>
<td>60.0</td>
<td>78.8</td>
<td>41.2</td>
<td>59.0</td>
<td>44.7</td>
<td>77.0</td>
<td>75.9</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>61.5</td>
<td>53.5</td>
<td>71.0</td>
<td>66.2</td>
<td>48.5</td>
<td>77.9</td>
<td>46.0</td>
<td>61.9</td>
<td>44.9</td>
<td>76.1</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>61.6</td>
<td>52.8</td>
<td>71.0</td>
<td>64.9</td>
<td>51.8</td>
<td>78.2</td>
<td>44.3</td>
<td>63.8</td>
<td>45.2</td>
<td>76.4</td>
<td>67.6</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>62.0</td>
<td>53.8</td>
<td>70.7</td>
<td>66.8</td>
<td>49.9</td>
<td>77.3</td>
<td>46.8</td>
<td>62.6</td>
<td>45.6</td>
<td>76.3</td>
<td>70.7</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>61.3</td>
<td>52.5</td>
<td>68.3</td>
<td>66.5</td>
<td>48.5</td>
<td>77.5</td>
<td>49.2</td>
<td>62.1</td>
<td>39.4</td>
<td>74.9</td>
<td>73.7</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>64.7</td>
<td>52.8</td>
<td>79.2</td>
<td>57.4</td>
<td>63.4</td>
<td>76.8</td>
<td>53.7</td>
<td>53.4</td>
<td>48.5</td>
<td>86.7</td>
<td>75.1</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>63.8</td>
<td>54.5</td>
<td>82.1</td>
<td>62.6</td>
<td>65.5</td>
<td>81.9</td>
<td>53.4</td>
<td>52.1</td>
<td>41.4</td>
<td>68.8</td>
<td>75.6</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>61.3</td>
<td>48.4</td>
<td>68.2</td>
<td>46.6</td>
<td>55.3</td>
<td>75.3</td>
<td>48.6</td>
<td>65.3</td>
<td>38.9</td>
<td>85.5</td>
<td>81.4</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>62.9</td>
<td>46.8</td>
<td>74.0</td>
<td>53.9</td>
<td>56.3</td>
<td>78.4</td>
<td>52.4</td>
<td>64.3</td>
<td>45.2</td>
<td>87.1</td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>75.0</td>
<td>60.0</td>
<td>89.3</td>
<td>75.9</td>
<td>74.4</td>
<td>89.5</td>
<td>53.3</td>
<td>78.3</td>
<td>53.8</td>
<td>87.4</td>
<td>88.3</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>76.1</td>
<td>62.4</td>
<td>90.7</td>
<td>80.7</td>
<td>74.4</td>
<td>87.8</td>
<td>56.2</td>
<td>77.9</td>
<td>57.6</td>
<td>86.7</td>
<td>86.6</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>76.1</td>
<td>67.4</td>
<td>89.1</td>
<td>80.2</td>
<td>74.2</td>
<td>88.9</td>
<td>53.5</td>
<td>74.7</td>
<td>57.7</td>
<td>88.6</td>
<td>86.7</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>75.2</td>
<td>59.7</td>
<td>91.4</td>
<td>80.2</td>
<td>76.4</td>
<td>92.7</td>
<td>50.3</td>
<td>73.4</td>
<td>55.9</td>
<td>86.9</td>
<td>85.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>70.9</td>
<td>61.4</td>
<td>87.2</td>
<td>72.7</td>
<td>73.1</td>
<td>90.3</td>
<td>53.0</td>
<td>59.8</td>
<td>43.1</td>
<td>84.8</td>
<td>83.1</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>71.8</td>
<td>61.6</td>
<td>87.8</td>
<td>74.2</td>
<td>72.0</td>
<td>90.5</td>
<td>53.5</td>
<td>66.2</td>
<td>46.8</td>
<td>85.7</td>
<td>79.7</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>72.1</td>
<td>63.3</td>
<td>89.1</td>
<td>72.7</td>
<td>69.4</td>
<td>90.0</td>
<td>53.0</td>
<td>66.5</td>
<td>46.7</td>
<td>87.0</td>
<td>83.2</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>71.8</td>
<td>62.4</td>
<td>88.3</td>
<td>74.6</td>
<td>71.8</td>
<td>90.8</td>
<td>52.4</td>
<td>65.0</td>
<td>44.1</td>
<td>87.2</td>
<td>81.8</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>67.5</td>
<td>54.7</td>
<td>88.3</td>
<td>68.3</td>
<td>63.5</td>
<td>85.1</td>
<td>42.4</td>
<td>63.8</td>
<td>52.9</td>
<td>84.8</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>67.9</td>
<td>55.7</td>
<td>91.0</td>
<td>61.7</td>
<td>62.8</td>
<td>81.3</td>
<td>44.7</td>
<td>63.8</td>
<td>54.2</td>
<td>86.0</td>
<td>78.2</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>68.5</td>
<td>53.4</td>
<td>88.0</td>
<td>66.9</td>
<td>64.1</td>
<td>85.6</td>
<td>47.6</td>
<td>64.8</td>
<td>54.7</td>
<td>84.7</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>65.8</td>
<td>60.5</td>
<td>89.4</td>
<td>57.6</td>
<td>56.3</td>
<td>83.3</td>
<td>49.5</td>
<td>58.2</td>
<td>52.0</td>
<td>79.5</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>68.8</td>
<td>54.2</td>
<td>83.7</td>
<td>78.3</td>
<td>61.2</td>
<td>79.5</td>
<td>57.7</td>
<td>63.1</td>
<td>49.0</td>
<td>90.3</td>
<td>71.2</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>68.2</td>
<td>64.8</td>
<td>84.2</td>
<td>61.1</td>
<td>68.3</td>
<td>84.7</td>
<td>51.4</td>
<td>64.8</td>
<td>41.7</td>
<td>86.9</td>
<td>74.4</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>69.6</td>
<td>43.2</td>
<td>80.6</td>
<td>65.7</td>
<td>69.6</td>
<td>85.4</td>
<td>59.2</td>
<td>72.9</td>
<td>45.3</td>
<td>89.1</td>
<td>85.1</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>42.0</td>
<td>29.4</td>
<td>11.7</td>
<td>41.8</td>
<td>53.5</td>
<td>54.4</td>
<td>29.7</td>
<td>64.9</td>
<td>24.1</td>
<td>68.6</td>
<td>41.5</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>9.7</td>
<td>5.7</td>
<td>13.8</td>
<td>6.6</td>
<td>9.6</td>
<td>12.4</td>
<td>9.5</td>
<td>10.7</td>
<td>11.5</td>
<td>7.8</td>
<td>9.3</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>45.6</td>
<td>24.0</td>
<td>44.6</td>
<td>54.4</td>
<td>37.8</td>
<td>52.7</td>
<td>24.4</td>
<td>63.8</td>
<td>39.9</td>
<td>56.4</td>
<td>58.1</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>60.2</td>
<td>45.1</td>
<td>64.1</td>
<td>57.6</td>
<td>74.6</td>
<td>77.7</td>
<td>38.0</td>
<td>50.4</td>
<td>53.2</td>
<td>70.5</td>
<td>71.3</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>67.5</td>
<td>59.7</td>
<td>86.2</td>
<td>67.4</td>
<td>60.5</td>
<td>86.2</td>
<td>43.9</td>
<td>69.4</td>
<td>50.0</td>
<td>79.9</td>
<td>71.3</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>68.4</td>
<td>58.8</td>
<td>75.1</td>
<td>63.3</td>
<td>72.7</td>
<td>87.5</td>
<td>57.1</td>
<td>67.4</td>
<td>38.1</td>
<td>77.4</td>
<td>86.4</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>69.6</td>
<td>63.0</td>
<td>82.7</td>
<td>67.7</td>
<td>68.9</td>
<td>88.4</td>
<td>52.0</td>
<td>70.3</td>
<td>44.4</td>
<td>79.3</td>
<td>79.5</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>63.3</td>
<td>48.2</td>
<td>75.9</td>
<td>59.3</td>
<td>57.8</td>
<td>85.0</td>
<td>42.2</td>
<td>70.6</td>
<td>39.6</td>
<td>85.6</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>63.3</td>
<td>48.2</td>
<td>75.9</td>
<td>59.3</td>
<td>57.8</td>
<td>85.0</td>
<td>42.2</td>
<td>70.6</td>
<td>39.6</td>
<td>85.6</td>
<td>69.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>65.3</td>
<td>55.7</td>
<td>83.5</td>
<td>48.5</td>
<td>54.0</td>
<td>83.5</td>
<td>48.6</td>
<td>70.2</td>
<td>45.7</td>
<td>86.6</td>
<td>77.1</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>65.3</td>
<td>55.7</td>
<td>83.5</td>
<td>48.5</td>
<td>54.0</td>
<td>83.5</td>
<td>48.6</td>
<td>70.2</td>
<td>45.7</td>
<td>86.6</td>
<td>77.1</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>66.6</td>
<td>41.5</td>
<td>86.5</td>
<td>59.1</td>
<td>66.3</td>
<td>85.0</td>
<td>48.4</td>
<td>64.3</td>
<td>49.7</td>
<td>86.0</td>
<td>79.3</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>65.4</td>
<td>45.5</td>
<td>76.1</td>
<td>61.9</td>
<td>63.1</td>
<td>87.0</td>
<td>49.9</td>
<td>55.9</td>
<td>49.7</td>
<td>83.3</td>
<td>81.9</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>66.2</td>
<td>40.0</td>
<td>84.8</td>
<td>60.9</td>
<td>65.0</td>
<td>85.9</td>
<td>48.2</td>
<td>66.0</td>
<td>52.1</td>
<td>80.2</td>
<td>78.4</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>52.2</td>
<td>41.5</td>
<td>67.8</td>
<td>37.8</td>
<td>14.9</td>
<td>87.9</td>
<td>40.5</td>
<td>60.2</td>
<td>36.7</td>
<td>81.3</td>
<td>53.5</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>70.3</td>
<td>50.9</td>
<td>83.5</td>
<td>71.7</td>
<td>69.7</td>
<td>86.0</td>
<td>50.5</td>
<td>73.4</td>
<td>48.2</td>
<td>88.4</td>
<td>81.2</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>71.4</td>
<td>52.3</td>
<td>83.5</td>
<td>74.4</td>
<td>71.0</td>
<td>85.7</td>
<td>54.9</td>
<td>71.0</td>
<td>50.3</td>
<td>88.1</td>
<td>82.6</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>71.3</td>
<td>59.8</td>
<td>82.7</td>
<td>71.2</td>
<td>69.9</td>
<td>88.1</td>
<td>50.1</td>
<td>70.2</td>
<td>48.9</td>
<td>88.8</td>
<td>83.5</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>71.8</td>
<td>47.6</td>
<td>83.1</td>
<td>67.7</td>
<td>75.6</td>
<td>86.1</td>
<td>53.0</td>
<td>74.1</td>
<td>55.9</td>
<td>87.8</td>
<td>87.4</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>47.2</td>
<td>25.6</td>
<td>38.5</td>
<td>57.2</td>
<td>43.1</td>
<td>62.9</td>
<td>31.3</td>
<td>62.4</td>
<td>37.8</td>
<td>60.7</td>
<td>52.3</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>44.7</td>
<td>25.5</td>
<td>48.1</td>
<td>40.3</td>
<td>42.6</td>
<td>53.3</td>
<td>30.7</td>
<td>66.8</td>
<td>38.4</td>
<td>49.5</td>
<td>51.5</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>46.1</td>
<td>29.0</td>
<td>44.9</td>
<td>44.4</td>
<td>40.3</td>
<td>61.0</td>
<td>24.4</td>
<td>63.8</td>
<td>38.5</td>
<td>50.5</td>
<td>64.0</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>46.8</td>
<td>21.6</td>
<td>43.3</td>
<td>42.8</td>
<td>45.3</td>
<td>62.9</td>
<td>26.8</td>
<td>68.9</td>
<td>33.3</td>
<td>60.4</td>
<td>63.1</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>63.8</td>
<td>29.3</td>
<td>69.7</td>
<td>75.1</td>
<td>64.3</td>
<td>89.5</td>
<td>44.4</td>
<td>55.9</td>
<td>55.3</td>
<td>85.6</td>
<td>69.2</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>65.2</td>
<td>33.2</td>
<td>76.9</td>
<td>71.2</td>
<td>66.5</td>
<td>91.5</td>
<td>41.8</td>
<td>56.3</td>
<td>56.8</td>
<td>84.8</td>
<td>73.0</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>65.3</td>
<td>51.4</td>
<td>85.7</td>
<td>57.1</td>
<td>66.0</td>
<td>88.1</td>
<td>34.6</td>
<td>63.4</td>
<td>47.5</td>
<td>83.2</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>64.7</td>
<td>39.3</td>
<td>80.9</td>
<td>66.5</td>
<td>52.8</td>
<td>91.8</td>
<td>46.5</td>
<td>54.8</td>
<td>58.5</td>
<td>80.6</td>
<td>75.6</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>61.4</td>
<td>45.3</td>
<td>69.9</td>
<td>71.8</td>
<td>64.4</td>
<td>77.9</td>
<td>38.9</td>
<td>63.1</td>
<td>29.7</td>
<td>82.7</td>
<td>69.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>64.5</td>
<td>50.4</td>
<td>73.9</td>
<td>70.3</td>
<td>68.8</td>
<td>82.7</td>
<td>43.3</td>
<td>65.9</td>
<td>26.8</td>
<td>86.0</td>
<td>76.6</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>67.3</td>
<td>56.6</td>
<td>81.6</td>
<td>68.9</td>
<td>67.9</td>
<td>87.1</td>
<td>46.7</td>
<td>67.2</td>
<td>33.3</td>
<td>86.1</td>
<td>77.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>68.1</td>
<td>61.1</td>
<td>82.8</td>
<td>70.7</td>
<td>67.6</td>
<td>88.6</td>
<td>46.2</td>
<td>72.0</td>
<td>27.0</td>
<td>86.6</td>
<td>78.3</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>73.1</td>
<td>57.7</td>
<td>91.0</td>
<td>71.7</td>
<td>66.9</td>
<td>86.6</td>
<td>56.3</td>
<td>76.0</td>
<td>48.7</td>
<td>89.1</td>
<td>86.4</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>72.9</td>
<td>64.6</td>
<td>91.9</td>
<td>70.8</td>
<td>67.3</td>
<td>87.0</td>
<td>58.2</td>
<td>72.0</td>
<td>44.7</td>
<td>89.9</td>
<td>82.7</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>72.9</td>
<td>62.9</td>
<td>91.4</td>
<td>71.2</td>
<td>66.9</td>
<td>87.0</td>
<td>57.1</td>
<td>72.9</td>
<td>46.2</td>
<td>89.8</td>
<td>83.3</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>72.8</td>
<td>61.7</td>
<td>90.9</td>
<td>71.8</td>
<td>67.0</td>
<td>85.6</td>
<td>56.7</td>
<td>74.1</td>
<td>47.0</td>
<td>89.0</td>
<td>84.1</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>51.9</td>
<td>41.2</td>
<td>54.3</td>
<td>53.4</td>
<td>57.6</td>
<td>63.0</td>
<td>25.0</td>
<td>67.7</td>
<td>28.0</td>
<td>79.8</td>
<td>48.6</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>55.2</td>
<td>49.9</td>
<td>49.0</td>
<td>59.6</td>
<td>51.1</td>
<td>61.9</td>
<td>38.0</td>
<td>64.4</td>
<td>36.4</td>
<td>81.6</td>
<td>60.5</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>53.5</td>
<td>48.6</td>
<td>48.6</td>
<td>56.7</td>
<td>53.4</td>
<td>67.0</td>
<td>36.9</td>
<td>49.6</td>
<td>33.7</td>
<td>77.5</td>
<td>62.9</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>63.0</td>
<td>52.5</td>
<td>63.0</td>
<td>66.2</td>
<td>64.3</td>
<td>78.3</td>
<td>49.1</td>
<td>67.0</td>
<td>39.3</td>
<td>81.1</td>
<td>69.4</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>63.2</td>
<td>55.9</td>
<td>63.9</td>
<td>70.3</td>
<td>60.9</td>
<td>81.3</td>
<td>49.0</td>
<td>59.2</td>
<td>40.4</td>
<td>81.7</td>
<td>69.6</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>52.2</td>
<td>40.7</td>
<td>47.5</td>
<td>53.7</td>
<td>51.9</td>
<td>64.8</td>
<td>44.2</td>
<td>48.6</td>
<td>39.8</td>
<td>68.8</td>
<td>62.5</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>59.0</td>
<td>44.8</td>
<td>56.4</td>
<td>57.1</td>
<td>60.0</td>
<td>68.3</td>
<td>50.8</td>
<td>60.5</td>
<td>46.3</td>
<td>75.6</td>
<td>70.5</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>61.2</td>
<td>51.8</td>
<td>83.0</td>
<td>56.7</td>
<td>54.3</td>
<td>79.3</td>
<td>45.5</td>
<td>58.3</td>
<td>35.4</td>
<td>80.2</td>
<td>68.1</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>63.5</td>
<td>47.9</td>
<td>78.4</td>
<td>63.9</td>
<td>50.0</td>
<td>74.6</td>
<td>52.7</td>
<td>67.7</td>
<td>42.4</td>
<td>81.3</td>
<td>76.1</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>63.5</td>
<td>50.0</td>
<td>79.4</td>
<td>65.4</td>
<td>49.5</td>
<td>73.6</td>
<td>52.3</td>
<td>68.4</td>
<td>38.6</td>
<td>80.4</td>
<td>77.8</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>62.8</td>
<td>48.5</td>
<td>82.8</td>
<td>67.0</td>
<td>60.1</td>
<td>72.1</td>
<td>42.0</td>
<td>68.8</td>
<td>40.5</td>
<td>77.7</td>
<td>68.6</td>
</tr>
</tbody>
</table>
<h1 id="device-wise-performance">Device-wise performance</h1>
<h2 id="log-loss-1">Log loss</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2021 baseline" data-comparison-active-set="Device-wise performance (all)" data-comparison-b-row="Kim_QTI_task1a_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title":"Device-wise performance (all)","data_axis_title":"Log loss","fields":["device_logloss_eval_a","device_logloss_eval_b","device_logloss_eval_c","device_logloss_eval_d","device_logloss_eval_s1","device_logloss_eval_s2","device_logloss_eval_s3","device_logloss_eval_s7","device_logloss_eval_s8","device_logloss_eval_s9","device_logloss_eval_s10"]},
        {"title":"Device-wise performance / Real","data_axis_title":"Log loss","fields":["device_logloss_eval_a","device_logloss_eval_b","device_logloss_eval_c","device_logloss_eval_d"]},
        {"title":"Device-wise performance / Simulated","data_axis_title":"Accuracy","fields":["device_logloss_eval_s1","device_logloss_eval_s2","device_logloss_eval_s3","device_logloss_eval_s7","device_logloss_eval_s8","device_logloss_eval_s9","device_logloss_eval_s10"]},
        {"title":"Device-wise performance / Unseen devices","data_axis_title":"Log loss","fields":["device_logloss_eval_d","device_logloss_eval_s7","device_logloss_eval_s8","device_logloss_eval_s9","device_logloss_eval_s10"]},
        {"title":"Device-wise performance / Seen devices","data_axis_title":"Accuracy","fields":["device_logloss_eval_a","device_logloss_eval_b","device_logloss_eval_c","device_logloss_eval_s1","device_logloss_eval_s2","device_logloss_eval_s3"]}]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="logloss_eval_source_seen" data-scatter-y="logloss_eval_source_unseen" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell"></th>
<th class="sep-right-cell" colspan="2"></th>
<th class="sep-right-cell" colspan="4"></th>
<th class="sep-right-cell text-center" colspan="5">Unseen devices</th>
<th class="sep-right-cell text-center" colspan="6">Seen devices</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Log loss
            </th>
<th class="text-center" data-chartable="true" data-field="logloss_eval_source_unseen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Accuracy / <br/>Unseen
            </th>
<th class="text-center" data-chartable="true" data-field="logloss_eval_source_seen" data-reversed="true" data-sortable="true" data-value-type="float3">
                Accuracy / <br/>Seen
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_logloss_eval_d" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-success">D</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s7" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S7</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s8" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S8</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s9" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S9</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s10" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S10</span>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_logloss_eval_a" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-success">A</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_b" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-success">B</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_c" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-success">C</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s1" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S1</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s2" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S2</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_logloss_eval_s3" data-reversed="true" data-sortable="true" data-value-type="float3">
<span class="label label-warning">S3</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>1.065</td>
<td>0.829</td>
<td>1.762</td>
<td>0.861</td>
<td>0.845</td>
<td>0.870</td>
<td>0.984</td>
<td>0.713</td>
<td>0.949</td>
<td>0.821</td>
<td>0.873</td>
<td>0.789</td>
<td>0.827</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>1.048</td>
<td>0.801</td>
<td>1.777</td>
<td>0.843</td>
<td>0.794</td>
<td>0.875</td>
<td>0.954</td>
<td>0.683</td>
<td>0.923</td>
<td>0.809</td>
<td>0.847</td>
<td>0.766</td>
<td>0.779</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>1.094</td>
<td>0.820</td>
<td>1.931</td>
<td>0.871</td>
<td>0.809</td>
<td>0.874</td>
<td>0.987</td>
<td>0.692</td>
<td>0.943</td>
<td>0.820</td>
<td>0.862</td>
<td>0.801</td>
<td>0.800</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>1.002</td>
<td>0.824</td>
<td>1.570</td>
<td>0.808</td>
<td>0.823</td>
<td>0.857</td>
<td>0.953</td>
<td>0.708</td>
<td>0.957</td>
<td>0.818</td>
<td>0.849</td>
<td>0.790</td>
<td>0.824</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>1.214</td>
<td>1.071</td>
<td>1.318</td>
<td>1.081</td>
<td>1.053</td>
<td>1.290</td>
<td>1.326</td>
<td>0.897</td>
<td>1.084</td>
<td>1.011</td>
<td>1.170</td>
<td>1.187</td>
<td>1.075</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>1.318</td>
<td>1.102</td>
<td>1.507</td>
<td>1.122</td>
<td>1.072</td>
<td>1.405</td>
<td>1.485</td>
<td>0.878</td>
<td>1.141</td>
<td>1.057</td>
<td>1.222</td>
<td>1.230</td>
<td>1.084</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>1.223</td>
<td>1.066</td>
<td>1.327</td>
<td>1.064</td>
<td>1.027</td>
<td>1.331</td>
<td>1.364</td>
<td>0.874</td>
<td>1.087</td>
<td>1.011</td>
<td>1.162</td>
<td>1.194</td>
<td>1.070</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>1.250</td>
<td>1.061</td>
<td>1.403</td>
<td>1.076</td>
<td>1.008</td>
<td>1.315</td>
<td>1.448</td>
<td>0.885</td>
<td>1.060</td>
<td>1.019</td>
<td>1.152</td>
<td>1.185</td>
<td>1.068</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>1.878</td>
<td>1.265</td>
<td>2.188</td>
<td>1.404</td>
<td>1.304</td>
<td>2.228</td>
<td>2.264</td>
<td>1.070</td>
<td>1.293</td>
<td>1.106</td>
<td>1.413</td>
<td>1.374</td>
<td>1.336</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>1.488</td>
<td>1.191</td>
<td>1.879</td>
<td>1.316</td>
<td>1.181</td>
<td>1.593</td>
<td>1.473</td>
<td>0.983</td>
<td>1.187</td>
<td>1.022</td>
<td>1.286</td>
<td>1.374</td>
<td>1.291</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>1.356</td>
<td>1.118</td>
<td>1.388</td>
<td>1.211</td>
<td>1.119</td>
<td>1.447</td>
<td>1.612</td>
<td>0.941</td>
<td>1.099</td>
<td>1.003</td>
<td>1.196</td>
<td>1.285</td>
<td>1.187</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>1.426</td>
<td>1.188</td>
<td>1.566</td>
<td>1.338</td>
<td>1.200</td>
<td>1.366</td>
<td>1.662</td>
<td>0.966</td>
<td>1.203</td>
<td>1.029</td>
<td>1.317</td>
<td>1.360</td>
<td>1.253</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>1.458</td>
<td>1.098</td>
<td>2.084</td>
<td>1.351</td>
<td>1.093</td>
<td>1.409</td>
<td>1.351</td>
<td>0.977</td>
<td>1.185</td>
<td>0.873</td>
<td>1.113</td>
<td>1.412</td>
<td>1.026</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>2.488</td>
<td>1.999</td>
<td>2.869</td>
<td>2.020</td>
<td>1.888</td>
<td>2.683</td>
<td>2.979</td>
<td>1.434</td>
<td>2.178</td>
<td>2.152</td>
<td>2.084</td>
<td>2.420</td>
<td>1.729</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>1.180</td>
<td>1.009</td>
<td>1.627</td>
<td>1.024</td>
<td>1.010</td>
<td>1.058</td>
<td>1.180</td>
<td>0.926</td>
<td>1.048</td>
<td>0.991</td>
<td>1.065</td>
<td>1.001</td>
<td>1.022</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>0.993</td>
<td>0.878</td>
<td>1.278</td>
<td>0.879</td>
<td>0.884</td>
<td>0.955</td>
<td>0.967</td>
<td>0.785</td>
<td>0.902</td>
<td>0.843</td>
<td>0.928</td>
<td>0.911</td>
<td>0.896</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>1.110</td>
<td>0.991</td>
<td>1.390</td>
<td>1.007</td>
<td>0.995</td>
<td>1.049</td>
<td>1.109</td>
<td>0.916</td>
<td>1.040</td>
<td>0.992</td>
<td>1.029</td>
<td>0.998</td>
<td>0.971</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>0.929</td>
<td>0.823</td>
<td>1.205</td>
<td>0.822</td>
<td>0.802</td>
<td>0.905</td>
<td>0.912</td>
<td>0.754</td>
<td>0.838</td>
<td>0.843</td>
<td>0.881</td>
<td>0.821</td>
<td>0.802</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>2.039</td>
<td>1.228</td>
<td>2.242</td>
<td>1.388</td>
<td>1.311</td>
<td>3.143</td>
<td>2.111</td>
<td>1.093</td>
<td>1.133</td>
<td>1.066</td>
<td>1.322</td>
<td>1.491</td>
<td>1.265</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>2.072</td>
<td>1.997</td>
<td>2.149</td>
<td>2.012</td>
<td>2.002</td>
<td>2.099</td>
<td>2.096</td>
<td>1.926</td>
<td>2.027</td>
<td>1.996</td>
<td>2.023</td>
<td>2.032</td>
<td>1.978</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>1.780</td>
<td>1.193</td>
<td>2.223</td>
<td>1.223</td>
<td>1.442</td>
<td>2.377</td>
<td>1.634</td>
<td>1.117</td>
<td>1.215</td>
<td>1.165</td>
<td>1.264</td>
<td>1.289</td>
<td>1.108</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>2.111</td>
<td>2.027</td>
<td>2.215</td>
<td>2.037</td>
<td>2.052</td>
<td>2.127</td>
<td>2.123</td>
<td>1.963</td>
<td>2.037</td>
<td>2.022</td>
<td>2.045</td>
<td>2.071</td>
<td>2.027</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>1.557</td>
<td>1.396</td>
<td>1.640</td>
<td>1.445</td>
<td>1.347</td>
<td>1.638</td>
<td>1.713</td>
<td>1.077</td>
<td>1.404</td>
<td>1.326</td>
<td>1.521</td>
<td>1.612</td>
<td>1.436</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>1.619</td>
<td>1.480</td>
<td>1.703</td>
<td>1.510</td>
<td>1.457</td>
<td>1.671</td>
<td>1.752</td>
<td>1.185</td>
<td>1.496</td>
<td>1.386</td>
<td>1.593</td>
<td>1.676</td>
<td>1.542</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>1.613</td>
<td>1.351</td>
<td>1.855</td>
<td>1.448</td>
<td>1.454</td>
<td>1.613</td>
<td>1.694</td>
<td>1.107</td>
<td>1.410</td>
<td>1.345</td>
<td>1.413</td>
<td>1.477</td>
<td>1.352</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>1.219</td>
<td>0.893</td>
<td>1.502</td>
<td>1.106</td>
<td>0.979</td>
<td>1.386</td>
<td>1.125</td>
<td>0.729</td>
<td>0.854</td>
<td>0.780</td>
<td>0.979</td>
<td>1.061</td>
<td>0.954</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>1.094</td>
<td>0.834</td>
<td>1.241</td>
<td>0.927</td>
<td>0.920</td>
<td>1.309</td>
<td>1.071</td>
<td>0.712</td>
<td>0.823</td>
<td>0.719</td>
<td>0.962</td>
<td>0.952</td>
<td>0.835</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>1.187</td>
<td>0.886</td>
<td>1.491</td>
<td>0.950</td>
<td>0.879</td>
<td>1.474</td>
<td>1.143</td>
<td>0.681</td>
<td>0.845</td>
<td>0.726</td>
<td>1.103</td>
<td>1.054</td>
<td>0.908</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>1.724</td>
<td>0.816</td>
<td>4.295</td>
<td>0.911</td>
<td>0.991</td>
<td>1.279</td>
<td>1.144</td>
<td>0.708</td>
<td>0.831</td>
<td>0.786</td>
<td>0.895</td>
<td>0.915</td>
<td>0.758</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>1.461</td>
<td>1.266</td>
<td>1.685</td>
<td>1.330</td>
<td>1.331</td>
<td>1.482</td>
<td>1.479</td>
<td>1.095</td>
<td>1.340</td>
<td>1.232</td>
<td>1.316</td>
<td>1.344</td>
<td>1.268</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>1.416</td>
<td>1.034</td>
<td>2.204</td>
<td>1.061</td>
<td>1.087</td>
<td>1.419</td>
<td>1.309</td>
<td>0.883</td>
<td>1.076</td>
<td>1.036</td>
<td>1.086</td>
<td>1.116</td>
<td>1.002</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>1.185</td>
<td>0.986</td>
<td>1.420</td>
<td>1.051</td>
<td>1.073</td>
<td>1.169</td>
<td>1.212</td>
<td>0.792</td>
<td>1.090</td>
<td>0.912</td>
<td>0.971</td>
<td>1.191</td>
<td>0.959</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>1.185</td>
<td>0.987</td>
<td>1.430</td>
<td>1.038</td>
<td>1.068</td>
<td>1.168</td>
<td>1.222</td>
<td>0.795</td>
<td>1.093</td>
<td>0.907</td>
<td>0.976</td>
<td>1.190</td>
<td>0.961</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>1.183</td>
<td>0.986</td>
<td>1.419</td>
<td>1.039</td>
<td>1.068</td>
<td>1.168</td>
<td>1.220</td>
<td>0.795</td>
<td>1.085</td>
<td>0.909</td>
<td>0.975</td>
<td>1.192</td>
<td>0.963</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>1.190</td>
<td>0.986</td>
<td>1.430</td>
<td>1.043</td>
<td>1.076</td>
<td>1.151</td>
<td>1.249</td>
<td>0.803</td>
<td>1.097</td>
<td>0.917</td>
<td>0.969</td>
<td>1.164</td>
<td>0.963</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>1.317</td>
<td>0.946</td>
<td>2.529</td>
<td>0.953</td>
<td>1.046</td>
<td>1.003</td>
<td>1.056</td>
<td>0.866</td>
<td>1.030</td>
<td>0.925</td>
<td>0.985</td>
<td>0.936</td>
<td>0.931</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>1.215</td>
<td>0.839</td>
<td>1.412</td>
<td>0.988</td>
<td>0.854</td>
<td>1.612</td>
<td>1.212</td>
<td>0.734</td>
<td>0.842</td>
<td>0.757</td>
<td>0.931</td>
<td>0.930</td>
<td>0.839</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>1.371</td>
<td>1.036</td>
<td>2.379</td>
<td>1.047</td>
<td>1.130</td>
<td>1.102</td>
<td>1.198</td>
<td>0.909</td>
<td>1.150</td>
<td>0.983</td>
<td>1.106</td>
<td>1.050</td>
<td>1.016</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>1.315</td>
<td>1.000</td>
<td>2.113</td>
<td>1.063</td>
<td>1.146</td>
<td>1.073</td>
<td>1.182</td>
<td>0.883</td>
<td>1.081</td>
<td>0.958</td>
<td>1.045</td>
<td>1.034</td>
<td>0.997</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>0.851</td>
<td>0.744</td>
<td>1.162</td>
<td>0.756</td>
<td>0.720</td>
<td>0.784</td>
<td>0.832</td>
<td>0.631</td>
<td>0.780</td>
<td>0.749</td>
<td>0.784</td>
<td>0.773</td>
<td>0.749</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>0.766</td>
<td>0.689</td>
<td>1.059</td>
<td>0.665</td>
<td>0.631</td>
<td>0.720</td>
<td>0.754</td>
<td>0.561</td>
<td>0.754</td>
<td>0.719</td>
<td>0.721</td>
<td>0.704</td>
<td>0.675</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>0.792</td>
<td>0.687</td>
<td>1.195</td>
<td>0.680</td>
<td>0.643</td>
<td>0.719</td>
<td>0.724</td>
<td>0.585</td>
<td>0.730</td>
<td>0.724</td>
<td>0.739</td>
<td>0.685</td>
<td>0.659</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>0.832</td>
<td>0.708</td>
<td>1.169</td>
<td>0.733</td>
<td>0.720</td>
<td>0.768</td>
<td>0.772</td>
<td>0.598</td>
<td>0.751</td>
<td>0.725</td>
<td>0.746</td>
<td>0.747</td>
<td>0.680</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>1.051</td>
<td>0.743</td>
<td>1.704</td>
<td>0.784</td>
<td>0.808</td>
<td>0.990</td>
<td>0.968</td>
<td>0.612</td>
<td>0.746</td>
<td>0.720</td>
<td>0.815</td>
<td>0.841</td>
<td>0.727</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>0.976</td>
<td>0.730</td>
<td>1.592</td>
<td>0.741</td>
<td>0.778</td>
<td>0.868</td>
<td>0.904</td>
<td>0.581</td>
<td>0.783</td>
<td>0.723</td>
<td>0.812</td>
<td>0.795</td>
<td>0.686</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>0.947</td>
<td>0.740</td>
<td>1.477</td>
<td>0.739</td>
<td>0.759</td>
<td>0.865</td>
<td>0.896</td>
<td>0.600</td>
<td>0.783</td>
<td>0.748</td>
<td>0.821</td>
<td>0.791</td>
<td>0.695</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>0.970</td>
<td>0.744</td>
<td>1.624</td>
<td>0.761</td>
<td>0.752</td>
<td>0.856</td>
<td>0.859</td>
<td>0.625</td>
<td>0.807</td>
<td>0.786</td>
<td>0.776</td>
<td>0.755</td>
<td>0.716</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>2.767</td>
<td>1.280</td>
<td>5.170</td>
<td>1.776</td>
<td>1.894</td>
<td>3.051</td>
<td>1.944</td>
<td>1.100</td>
<td>1.152</td>
<td>1.168</td>
<td>1.272</td>
<td>1.546</td>
<td>1.443</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>2.892</td>
<td>1.275</td>
<td>6.246</td>
<td>1.406</td>
<td>1.768</td>
<td>3.284</td>
<td>1.754</td>
<td>1.167</td>
<td>1.131</td>
<td>1.201</td>
<td>1.168</td>
<td>1.576</td>
<td>1.406</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>1.892</td>
<td>1.134</td>
<td>2.711</td>
<td>1.624</td>
<td>1.320</td>
<td>1.849</td>
<td>1.955</td>
<td>0.837</td>
<td>1.282</td>
<td>1.061</td>
<td>1.241</td>
<td>1.280</td>
<td>1.106</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>2.998</td>
<td>1.240</td>
<td>7.522</td>
<td>1.699</td>
<td>1.348</td>
<td>2.471</td>
<td>1.952</td>
<td>1.069</td>
<td>1.334</td>
<td>0.977</td>
<td>1.412</td>
<td>1.229</td>
<td>1.417</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>0.974</td>
<td>0.838</td>
<td>1.367</td>
<td>0.873</td>
<td>0.845</td>
<td>0.866</td>
<td>0.920</td>
<td>0.749</td>
<td>0.879</td>
<td>0.796</td>
<td>0.912</td>
<td>0.880</td>
<td>0.813</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>0.955</td>
<td>0.844</td>
<td>1.334</td>
<td>0.848</td>
<td>0.834</td>
<td>0.851</td>
<td>0.907</td>
<td>0.759</td>
<td>0.902</td>
<td>0.796</td>
<td>0.909</td>
<td>0.890</td>
<td>0.810</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>0.966</td>
<td>0.804</td>
<td>1.398</td>
<td>0.833</td>
<td>0.837</td>
<td>0.853</td>
<td>0.908</td>
<td>0.680</td>
<td>0.871</td>
<td>0.823</td>
<td>0.877</td>
<td>0.810</td>
<td>0.766</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>1.756</td>
<td>1.519</td>
<td>1.893</td>
<td>1.622</td>
<td>1.643</td>
<td>1.826</td>
<td>1.796</td>
<td>1.222</td>
<td>1.539</td>
<td>1.276</td>
<td>1.648</td>
<td>1.848</td>
<td>1.580</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>3.952</td>
<td>3.948</td>
<td>3.813</td>
<td>3.947</td>
<td>4.018</td>
<td>3.974</td>
<td>4.008</td>
<td>3.925</td>
<td>3.999</td>
<td>4.019</td>
<td>3.923</td>
<td>3.962</td>
<td>3.858</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>2.222</td>
<td>1.320</td>
<td>3.255</td>
<td>1.609</td>
<td>1.610</td>
<td>2.142</td>
<td>2.494</td>
<td>1.085</td>
<td>1.361</td>
<td>1.174</td>
<td>1.361</td>
<td>1.468</td>
<td>1.473</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>1.348</td>
<td>0.967</td>
<td>1.821</td>
<td>1.043</td>
<td>1.048</td>
<td>1.543</td>
<td>1.285</td>
<td>0.814</td>
<td>0.999</td>
<td>0.944</td>
<td>1.035</td>
<td>1.061</td>
<td>0.949</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>1.653</td>
<td>1.130</td>
<td>2.525</td>
<td>1.185</td>
<td>1.230</td>
<td>1.882</td>
<td>1.443</td>
<td>0.889</td>
<td>1.399</td>
<td>1.037</td>
<td>1.103</td>
<td>1.355</td>
<td>0.994</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>1.398</td>
<td>1.011</td>
<td>1.877</td>
<td>1.105</td>
<td>1.090</td>
<td>1.438</td>
<td>1.479</td>
<td>0.798</td>
<td>1.200</td>
<td>1.089</td>
<td>1.105</td>
<td>1.042</td>
<td>0.830</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>2.497</td>
<td>1.693</td>
<td>3.776</td>
<td>1.829</td>
<td>1.871</td>
<td>2.705</td>
<td>2.306</td>
<td>1.429</td>
<td>2.085</td>
<td>1.691</td>
<td>1.686</td>
<td>1.852</td>
<td>1.412</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>1.369</td>
<td>1.191</td>
<td>1.748</td>
<td>1.193</td>
<td>1.226</td>
<td>1.290</td>
<td>1.387</td>
<td>1.069</td>
<td>1.256</td>
<td>1.211</td>
<td>1.197</td>
<td>1.261</td>
<td>1.152</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>1.419</td>
<td>1.265</td>
<td>1.766</td>
<td>1.270</td>
<td>1.278</td>
<td>1.350</td>
<td>1.431</td>
<td>1.145</td>
<td>1.318</td>
<td>1.271</td>
<td>1.284</td>
<td>1.330</td>
<td>1.240</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>1.294</td>
<td>1.164</td>
<td>1.618</td>
<td>1.156</td>
<td>1.179</td>
<td>1.249</td>
<td>1.266</td>
<td>1.074</td>
<td>1.224</td>
<td>1.177</td>
<td>1.173</td>
<td>1.214</td>
<td>1.120</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>1.351</td>
<td>1.242</td>
<td>1.643</td>
<td>1.228</td>
<td>1.240</td>
<td>1.303</td>
<td>1.342</td>
<td>1.146</td>
<td>1.304</td>
<td>1.251</td>
<td>1.248</td>
<td>1.301</td>
<td>1.201</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>1.159</td>
<td>0.779</td>
<td>1.621</td>
<td>0.937</td>
<td>0.887</td>
<td>1.286</td>
<td>1.066</td>
<td>0.666</td>
<td>0.823</td>
<td>0.647</td>
<td>0.822</td>
<td>0.911</td>
<td>0.804</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>1.152</td>
<td>0.825</td>
<td>1.404</td>
<td>0.953</td>
<td>0.939</td>
<td>1.265</td>
<td>1.199</td>
<td>0.658</td>
<td>0.880</td>
<td>0.701</td>
<td>0.874</td>
<td>0.990</td>
<td>0.848</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>1.116</td>
<td>0.791</td>
<td>1.331</td>
<td>0.920</td>
<td>0.915</td>
<td>1.310</td>
<td>1.107</td>
<td>0.672</td>
<td>0.806</td>
<td>0.688</td>
<td>0.838</td>
<td>0.912</td>
<td>0.829</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>1.651</td>
<td>1.612</td>
<td>1.768</td>
<td>1.609</td>
<td>1.534</td>
<td>1.622</td>
<td>1.724</td>
<td>1.581</td>
<td>1.631</td>
<td>1.592</td>
<td>1.640</td>
<td>1.625</td>
<td>1.603</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>1.107</td>
<td>0.965</td>
<td>1.502</td>
<td>1.006</td>
<td>0.959</td>
<td>1.002</td>
<td>1.068</td>
<td>0.917</td>
<td>0.988</td>
<td>1.007</td>
<td>1.005</td>
<td>0.957</td>
<td>0.916</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>1.164</td>
<td>1.010</td>
<td>1.592</td>
<td>1.033</td>
<td>1.019</td>
<td>1.056</td>
<td>1.123</td>
<td>0.931</td>
<td>1.080</td>
<td>1.016</td>
<td>1.044</td>
<td>1.009</td>
<td>0.977</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>1.149</td>
<td>0.995</td>
<td>1.592</td>
<td>1.008</td>
<td>1.002</td>
<td>1.035</td>
<td>1.106</td>
<td>0.927</td>
<td>1.066</td>
<td>1.014</td>
<td>1.028</td>
<td>0.981</td>
<td>0.953</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>1.175</td>
<td>1.014</td>
<td>1.572</td>
<td>1.045</td>
<td>1.026</td>
<td>1.078</td>
<td>1.155</td>
<td>0.938</td>
<td>1.092</td>
<td>1.001</td>
<td>1.064</td>
<td>1.002</td>
<td>0.986</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>1.687</td>
<td>1.277</td>
<td>1.984</td>
<td>1.445</td>
<td>1.251</td>
<td>1.873</td>
<td>1.883</td>
<td>1.041</td>
<td>1.245</td>
<td>1.112</td>
<td>1.406</td>
<td>1.512</td>
<td>1.349</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>1.730</td>
<td>1.337</td>
<td>1.873</td>
<td>1.425</td>
<td>1.329</td>
<td>2.012</td>
<td>2.010</td>
<td>1.082</td>
<td>1.319</td>
<td>1.195</td>
<td>1.343</td>
<td>1.598</td>
<td>1.482</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>1.761</td>
<td>1.299</td>
<td>1.878</td>
<td>1.436</td>
<td>1.330</td>
<td>2.107</td>
<td>2.055</td>
<td>1.024</td>
<td>1.315</td>
<td>1.164</td>
<td>1.358</td>
<td>1.504</td>
<td>1.430</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>1.738</td>
<td>1.279</td>
<td>1.736</td>
<td>1.473</td>
<td>1.325</td>
<td>2.078</td>
<td>2.080</td>
<td>1.041</td>
<td>1.291</td>
<td>1.159</td>
<td>1.345</td>
<td>1.451</td>
<td>1.386</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>1.247</td>
<td>0.953</td>
<td>1.601</td>
<td>1.038</td>
<td>1.102</td>
<td>1.336</td>
<td>1.159</td>
<td>0.863</td>
<td>1.010</td>
<td>0.878</td>
<td>1.023</td>
<td>1.007</td>
<td>0.939</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>1.231</td>
<td>0.936</td>
<td>1.614</td>
<td>1.017</td>
<td>1.099</td>
<td>1.307</td>
<td>1.118</td>
<td>0.871</td>
<td>0.995</td>
<td>0.875</td>
<td>0.994</td>
<td>0.970</td>
<td>0.915</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>1.159</td>
<td>0.912</td>
<td>1.608</td>
<td>0.945</td>
<td>1.017</td>
<td>1.185</td>
<td>1.043</td>
<td>0.933</td>
<td>0.947</td>
<td>0.864</td>
<td>0.954</td>
<td>0.898</td>
<td>0.875</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>1.610</td>
<td>1.036</td>
<td>2.081</td>
<td>1.254</td>
<td>1.580</td>
<td>2.014</td>
<td>1.124</td>
<td>1.068</td>
<td>1.194</td>
<td>0.905</td>
<td>1.129</td>
<td>0.976</td>
<td>0.941</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>1.305</td>
<td>0.978</td>
<td>1.410</td>
<td>1.114</td>
<td>1.027</td>
<td>1.532</td>
<td>1.444</td>
<td>0.856</td>
<td>0.935</td>
<td>0.902</td>
<td>1.009</td>
<td>1.163</td>
<td>1.005</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>1.144</td>
<td>0.915</td>
<td>1.243</td>
<td>0.990</td>
<td>0.941</td>
<td>1.257</td>
<td>1.290</td>
<td>0.782</td>
<td>0.867</td>
<td>0.831</td>
<td>0.987</td>
<td>1.072</td>
<td>0.954</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>1.102</td>
<td>0.852</td>
<td>1.304</td>
<td>0.888</td>
<td>0.919</td>
<td>1.198</td>
<td>1.203</td>
<td>0.726</td>
<td>0.805</td>
<td>0.771</td>
<td>0.926</td>
<td>0.996</td>
<td>0.886</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>1.040</td>
<td>0.827</td>
<td>1.197</td>
<td>0.886</td>
<td>0.869</td>
<td>1.050</td>
<td>1.200</td>
<td>0.697</td>
<td>0.831</td>
<td>0.766</td>
<td>0.908</td>
<td>0.930</td>
<td>0.829</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>0.846</td>
<td>0.703</td>
<td>1.075</td>
<td>0.721</td>
<td>0.737</td>
<td>0.902</td>
<td>0.792</td>
<td>0.611</td>
<td>0.738</td>
<td>0.688</td>
<td>0.787</td>
<td>0.724</td>
<td>0.673</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>0.840</td>
<td>0.700</td>
<td>1.091</td>
<td>0.707</td>
<td>0.724</td>
<td>0.882</td>
<td>0.797</td>
<td>0.611</td>
<td>0.741</td>
<td>0.671</td>
<td>0.784</td>
<td>0.722</td>
<td>0.670</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>0.832</td>
<td>0.696</td>
<td>1.058</td>
<td>0.711</td>
<td>0.723</td>
<td>0.875</td>
<td>0.795</td>
<td>0.608</td>
<td>0.738</td>
<td>0.667</td>
<td>0.785</td>
<td>0.711</td>
<td>0.667</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>0.850</td>
<td>0.710</td>
<td>1.087</td>
<td>0.724</td>
<td>0.735</td>
<td>0.898</td>
<td>0.805</td>
<td>0.621</td>
<td>0.737</td>
<td>0.692</td>
<td>0.796</td>
<td>0.737</td>
<td>0.679</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>1.376</td>
<td>1.257</td>
<td>1.374</td>
<td>1.255</td>
<td>1.156</td>
<td>1.516</td>
<td>1.578</td>
<td>1.036</td>
<td>1.260</td>
<td>1.171</td>
<td>1.372</td>
<td>1.408</td>
<td>1.297</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>1.284</td>
<td>1.171</td>
<td>1.295</td>
<td>1.174</td>
<td>1.102</td>
<td>1.361</td>
<td>1.487</td>
<td>0.949</td>
<td>1.177</td>
<td>1.126</td>
<td>1.260</td>
<td>1.307</td>
<td>1.211</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>2.114</td>
<td>2.097</td>
<td>2.109</td>
<td>2.098</td>
<td>2.082</td>
<td>2.136</td>
<td>2.145</td>
<td>2.047</td>
<td>2.099</td>
<td>2.079</td>
<td>2.127</td>
<td>2.118</td>
<td>2.112</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>1.243</td>
<td>1.024</td>
<td>1.448</td>
<td>1.135</td>
<td>0.974</td>
<td>1.301</td>
<td>1.358</td>
<td>0.812</td>
<td>0.988</td>
<td>0.967</td>
<td>1.158</td>
<td>1.172</td>
<td>1.048</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>1.242</td>
<td>1.006</td>
<td>1.460</td>
<td>1.044</td>
<td>0.947</td>
<td>1.381</td>
<td>1.377</td>
<td>0.791</td>
<td>0.999</td>
<td>0.911</td>
<td>1.116</td>
<td>1.161</td>
<td>1.056</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>3.840</td>
<td>2.958</td>
<td>4.402</td>
<td>3.559</td>
<td>3.079</td>
<td>4.339</td>
<td>3.819</td>
<td>2.726</td>
<td>2.674</td>
<td>3.054</td>
<td>2.923</td>
<td>2.935</td>
<td>3.438</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>2.451</td>
<td>1.525</td>
<td>3.028</td>
<td>2.127</td>
<td>1.496</td>
<td>2.811</td>
<td>2.796</td>
<td>1.233</td>
<td>1.093</td>
<td>1.223</td>
<td>1.765</td>
<td>2.384</td>
<td>1.451</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>1.598</td>
<td>1.308</td>
<td>1.810</td>
<td>1.375</td>
<td>1.379</td>
<td>1.705</td>
<td>1.722</td>
<td>1.084</td>
<td>1.342</td>
<td>1.271</td>
<td>1.398</td>
<td>1.450</td>
<td>1.305</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>1.551</td>
<td>1.297</td>
<td>1.782</td>
<td>1.355</td>
<td>1.364</td>
<td>1.656</td>
<td>1.596</td>
<td>1.134</td>
<td>1.328</td>
<td>1.288</td>
<td>1.355</td>
<td>1.396</td>
<td>1.279</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>1.430</td>
<td>1.057</td>
<td>1.570</td>
<td>1.170</td>
<td>1.107</td>
<td>1.685</td>
<td>1.620</td>
<td>0.862</td>
<td>1.104</td>
<td>1.037</td>
<td>1.147</td>
<td>1.166</td>
<td>1.024</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>1.406</td>
<td>1.056</td>
<td>1.605</td>
<td>1.193</td>
<td>1.116</td>
<td>1.548</td>
<td>1.569</td>
<td>0.831</td>
<td>1.070</td>
<td>1.087</td>
<td>1.162</td>
<td>1.163</td>
<td>1.024</td>
</tr>
</tbody>
</table>
<h2 id="accuracy-1">Accuracy</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar,scatter,comparison" data-chart-tooltip-fields="code" data-comparison-a-row="DCASE2021 baseline" data-comparison-active-set="Device-wise performance (all)" data-comparison-b-row="Kim_QTI_task1a_2" data-comparison-row-id-field="code" data-comparison-sets-json='[
        {"title":"Device-wise performance (all)","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_d","device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Real","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_d"]},
        {"title":"Device-wise performance / Simulated","data_axis_title":"Accuracy","fields":["device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Unseen devices","data_axis_title":"Accuracy","fields":["device_accuracy_eval_d","device_accuracy_eval_s7","device_accuracy_eval_s8","device_accuracy_eval_s9","device_accuracy_eval_s10"]},
        {"title":"Device-wise performance / Seen devices","data_axis_title":"Accuracy","fields":["device_accuracy_eval_a","device_accuracy_eval_b","device_accuracy_eval_c","device_accuracy_eval_s1","device_accuracy_eval_s2","device_accuracy_eval_s3"]}]' data-filter-control="false" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval_source_seen" data-scatter-y="accuracy_eval_source_unseen" data-show-chart="true" data-show-pagination-switch="yes" data-show-rank="true" data-sort-name="accuracy_eval" data-sort-order="desc">
<thead>
<tr>
<th class="sep-right-cell"></th>
<th class="sep-right-cell" colspan="2"></th>
<th class="sep-right-cell" colspan="4"></th>
<th class="sep-right-cell text-center" colspan="5">Unseen devices</th>
<th class="sep-right-cell text-center" colspan="6">Seen devices</th>
</tr>
<tr>
<th class="sep-right-cell" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval_source_unseen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>Unseen
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval_source_seen" data-sortable="true" data-value-type="float1-percentage">
                Accuracy / <br/>Seen
            </th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_accuracy_eval_d" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">D</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s7" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S7</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s8" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S8</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s9" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S9</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s10" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S10</span>
</th>
<th class="sep-left-cell text-center" data-chartable="true" data-field="device_accuracy_eval_a" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">A</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_b" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">B</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_c" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-success">C</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s1" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S1</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s2" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S2</span>
</th>
<th class="text-center" data-chartable="true" data-field="device_accuracy_eval_s3" data-sortable="true" data-value-type="float1-percentage">
<span class="label label-warning">S3</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>68.6</td>
<td>64.5</td>
<td>72.0</td>
<td>44.0</td>
<td>69.9</td>
<td>71.1</td>
<td>70.3</td>
<td>67.4</td>
<td>77.4</td>
<td>68.3</td>
<td>71.5</td>
<td>70.0</td>
<td>72.2</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>67.5</td>
<td>63.6</td>
<td>70.8</td>
<td>42.9</td>
<td>68.9</td>
<td>70.7</td>
<td>68.3</td>
<td>67.2</td>
<td>75.4</td>
<td>66.5</td>
<td>71.1</td>
<td>70.1</td>
<td>70.7</td>
<td>71.0</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>68.5</td>
<td>64.7</td>
<td>71.7</td>
<td>44.2</td>
<td>70.6</td>
<td>72.4</td>
<td>68.8</td>
<td>67.8</td>
<td>76.1</td>
<td>68.1</td>
<td>71.5</td>
<td>71.5</td>
<td>70.8</td>
<td>72.2</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>68.8</td>
<td>65.5</td>
<td>71.5</td>
<td>48.3</td>
<td>71.4</td>
<td>70.8</td>
<td>70.6</td>
<td>66.5</td>
<td>76.5</td>
<td>68.2</td>
<td>72.1</td>
<td>71.4</td>
<td>70.3</td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>66.7</td>
<td>62.5</td>
<td>70.2</td>
<td>58.3</td>
<td>68.3</td>
<td>67.9</td>
<td>58.5</td>
<td>59.3</td>
<td>75.4</td>
<td>70.6</td>
<td>72.6</td>
<td>65.8</td>
<td>67.9</td>
<td>68.9</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>64.6</td>
<td>59.0</td>
<td>69.2</td>
<td>53.1</td>
<td>68.9</td>
<td>71.0</td>
<td>53.9</td>
<td>48.2</td>
<td>78.3</td>
<td>68.1</td>
<td>73.1</td>
<td>64.3</td>
<td>62.2</td>
<td>69.3</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>67.2</td>
<td>63.3</td>
<td>70.4</td>
<td>58.8</td>
<td>71.4</td>
<td>70.3</td>
<td>58.6</td>
<td>57.2</td>
<td>76.8</td>
<td>70.1</td>
<td>72.5</td>
<td>66.5</td>
<td>65.7</td>
<td>70.8</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>66.1</td>
<td>60.8</td>
<td>70.5</td>
<td>54.3</td>
<td>70.3</td>
<td>71.7</td>
<td>55.4</td>
<td>52.5</td>
<td>76.5</td>
<td>70.6</td>
<td>71.9</td>
<td>66.9</td>
<td>66.3</td>
<td>70.7</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>53.0</td>
<td>46.8</td>
<td>58.2</td>
<td>46.5</td>
<td>52.8</td>
<td>55.7</td>
<td>39.6</td>
<td>39.3</td>
<td>68.3</td>
<td>59.2</td>
<td>62.6</td>
<td>50.8</td>
<td>54.7</td>
<td>53.8</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>51.1</td>
<td>45.9</td>
<td>55.4</td>
<td>41.4</td>
<td>49.9</td>
<td>55.0</td>
<td>40.8</td>
<td>42.2</td>
<td>64.2</td>
<td>53.3</td>
<td>62.1</td>
<td>52.4</td>
<td>47.5</td>
<td>52.9</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>49.1</td>
<td>43.9</td>
<td>53.4</td>
<td>46.4</td>
<td>47.2</td>
<td>46.4</td>
<td>43.1</td>
<td>36.2</td>
<td>61.1</td>
<td>51.9</td>
<td>58.9</td>
<td>50.3</td>
<td>47.6</td>
<td>50.6</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>51.4</td>
<td>46.6</td>
<td>55.4</td>
<td>45.8</td>
<td>46.9</td>
<td>52.9</td>
<td>48.8</td>
<td>38.8</td>
<td>64.7</td>
<td>55.0</td>
<td>61.4</td>
<td>49.4</td>
<td>48.5</td>
<td>53.2</td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>68.3</td>
<td>65.6</td>
<td>70.6</td>
<td>54.7</td>
<td>71.8</td>
<td>69.4</td>
<td>65.8</td>
<td>66.0</td>
<td>74.7</td>
<td>69.0</td>
<td>74.0</td>
<td>68.6</td>
<td>67.5</td>
<td>69.4</td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>53.9</td>
<td>50.8</td>
<td>56.5</td>
<td>50.3</td>
<td>56.2</td>
<td>57.8</td>
<td>47.1</td>
<td>42.6</td>
<td>70.8</td>
<td>51.8</td>
<td>54.6</td>
<td>53.6</td>
<td>49.4</td>
<td>58.5</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>67.0</td>
<td>62.6</td>
<td>70.7</td>
<td>42.5</td>
<td>69.3</td>
<td>70.7</td>
<td>67.2</td>
<td>63.2</td>
<td>74.7</td>
<td>70.0</td>
<td>72.6</td>
<td>67.6</td>
<td>70.7</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>66.9</td>
<td>64.1</td>
<td>69.2</td>
<td>55.8</td>
<td>69.4</td>
<td>66.2</td>
<td>64.9</td>
<td>64.0</td>
<td>74.6</td>
<td>69.9</td>
<td>69.2</td>
<td>67.5</td>
<td>66.4</td>
<td>67.9</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>70.0</td>
<td>67.1</td>
<td>72.5</td>
<td>56.0</td>
<td>71.4</td>
<td>72.6</td>
<td>69.2</td>
<td>66.4</td>
<td>76.7</td>
<td>69.6</td>
<td>72.1</td>
<td>71.3</td>
<td>72.6</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>70.1</td>
<td>68.1</td>
<td>71.8</td>
<td>57.2</td>
<td>71.2</td>
<td>72.9</td>
<td>69.7</td>
<td>69.3</td>
<td>75.1</td>
<td>72.4</td>
<td>70.0</td>
<td>71.0</td>
<td>70.3</td>
<td>72.1</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>51.4</td>
<td>44.1</td>
<td>57.5</td>
<td>44.4</td>
<td>52.4</td>
<td>51.5</td>
<td>32.6</td>
<td>39.3</td>
<td>65.1</td>
<td>57.6</td>
<td>60.0</td>
<td>53.2</td>
<td>53.3</td>
<td>56.0</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>53.3</td>
<td>47.1</td>
<td>58.6</td>
<td>36.4</td>
<td>56.9</td>
<td>57.9</td>
<td>40.8</td>
<td>43.2</td>
<td>69.0</td>
<td>56.1</td>
<td>58.5</td>
<td>53.5</td>
<td>53.3</td>
<td>61.1</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>51.6</td>
<td>44.6</td>
<td>57.5</td>
<td>34.6</td>
<td>56.1</td>
<td>48.5</td>
<td>41.0</td>
<td>42.8</td>
<td>61.9</td>
<td>54.9</td>
<td>55.3</td>
<td>55.3</td>
<td>56.1</td>
<td>61.4</td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>49.2</td>
<td>40.4</td>
<td>56.5</td>
<td>21.0</td>
<td>53.3</td>
<td>52.4</td>
<td>36.1</td>
<td>39.3</td>
<td>66.4</td>
<td>56.3</td>
<td>58.3</td>
<td>52.2</td>
<td>48.8</td>
<td>56.8</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>55.0</td>
<td>50.9</td>
<td>58.4</td>
<td>47.6</td>
<td>54.0</td>
<td>64.3</td>
<td>47.1</td>
<td>41.4</td>
<td>70.1</td>
<td>57.9</td>
<td>63.5</td>
<td>52.6</td>
<td>49.2</td>
<td>56.8</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>51.3</td>
<td>47.3</td>
<td>54.6</td>
<td>43.1</td>
<td>53.2</td>
<td>56.7</td>
<td>43.3</td>
<td>40.4</td>
<td>65.8</td>
<td>54.4</td>
<td>58.9</td>
<td>49.6</td>
<td>47.5</td>
<td>51.2</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>56.3</td>
<td>50.9</td>
<td>60.8</td>
<td>40.7</td>
<td>59.6</td>
<td>57.6</td>
<td>50.8</td>
<td>45.6</td>
<td>68.8</td>
<td>57.4</td>
<td>60.1</td>
<td>60.8</td>
<td>55.4</td>
<td>62.1</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>66.0</td>
<td>60.6</td>
<td>70.5</td>
<td>51.0</td>
<td>66.0</td>
<td>66.0</td>
<td>56.9</td>
<td>62.9</td>
<td>75.6</td>
<td>69.9</td>
<td>73.8</td>
<td>68.2</td>
<td>65.3</td>
<td>70.3</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>67.0</td>
<td>62.6</td>
<td>70.6</td>
<td>57.4</td>
<td>66.8</td>
<td>66.2</td>
<td>59.2</td>
<td>63.6</td>
<td>75.3</td>
<td>69.4</td>
<td>75.4</td>
<td>65.1</td>
<td>68.6</td>
<td>69.6</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>66.7</td>
<td>61.4</td>
<td>71.1</td>
<td>52.8</td>
<td>67.1</td>
<td>66.2</td>
<td>59.6</td>
<td>61.3</td>
<td>76.7</td>
<td>69.7</td>
<td>75.6</td>
<td>67.5</td>
<td>67.1</td>
<td>70.3</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>66.1</td>
<td>59.6</td>
<td>71.6</td>
<td>43.5</td>
<td>67.8</td>
<td>66.3</td>
<td>59.6</td>
<td>61.0</td>
<td>77.4</td>
<td>70.1</td>
<td>72.8</td>
<td>66.7</td>
<td>68.8</td>
<td>73.6</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>66.8</td>
<td>61.3</td>
<td>71.3</td>
<td>45.0</td>
<td>69.3</td>
<td>68.9</td>
<td>61.9</td>
<td>61.2</td>
<td>78.5</td>
<td>65.4</td>
<td>72.4</td>
<td>71.0</td>
<td>69.2</td>
<td>71.5</td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>63.5</td>
<td>56.6</td>
<td>69.3</td>
<td>35.3</td>
<td>67.2</td>
<td>67.6</td>
<td>52.8</td>
<td>60.0</td>
<td>74.2</td>
<td>67.6</td>
<td>69.2</td>
<td>68.2</td>
<td>65.8</td>
<td>70.7</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>61.5</td>
<td>57.7</td>
<td>64.6</td>
<td>51.0</td>
<td>62.6</td>
<td>60.7</td>
<td>59.6</td>
<td>54.9</td>
<td>70.0</td>
<td>62.9</td>
<td>66.8</td>
<td>63.6</td>
<td>58.6</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>61.6</td>
<td>58.1</td>
<td>64.5</td>
<td>52.1</td>
<td>63.1</td>
<td>60.8</td>
<td>59.9</td>
<td>54.6</td>
<td>69.9</td>
<td>63.5</td>
<td>66.9</td>
<td>63.7</td>
<td>58.1</td>
<td>64.9</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>62.0</td>
<td>58.6</td>
<td>64.9</td>
<td>52.1</td>
<td>63.5</td>
<td>61.4</td>
<td>60.7</td>
<td>55.4</td>
<td>71.1</td>
<td>63.1</td>
<td>66.4</td>
<td>63.5</td>
<td>58.3</td>
<td>67.1</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>61.3</td>
<td>57.6</td>
<td>64.3</td>
<td>51.2</td>
<td>62.2</td>
<td>60.6</td>
<td>59.9</td>
<td>54.2</td>
<td>70.1</td>
<td>62.2</td>
<td>65.8</td>
<td>63.5</td>
<td>58.5</td>
<td>65.8</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>64.7</td>
<td>59.4</td>
<td>69.1</td>
<td>32.8</td>
<td>68.5</td>
<td>63.3</td>
<td>67.1</td>
<td>65.6</td>
<td>72.4</td>
<td>66.0</td>
<td>69.9</td>
<td>68.3</td>
<td>68.3</td>
<td>69.6</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>63.8</td>
<td>57.2</td>
<td>69.4</td>
<td>49.9</td>
<td>63.5</td>
<td>67.8</td>
<td>48.9</td>
<td>55.8</td>
<td>75.1</td>
<td>69.3</td>
<td>71.9</td>
<td>63.3</td>
<td>66.4</td>
<td>70.0</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>61.3</td>
<td>56.2</td>
<td>65.6</td>
<td>31.3</td>
<td>65.1</td>
<td>60.8</td>
<td>64.3</td>
<td>59.6</td>
<td>69.7</td>
<td>60.4</td>
<td>68.1</td>
<td>64.9</td>
<td>64.9</td>
<td>65.7</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>62.9</td>
<td>57.7</td>
<td>67.3</td>
<td>35.3</td>
<td>65.0</td>
<td>59.7</td>
<td>66.7</td>
<td>61.7</td>
<td>70.1</td>
<td>64.2</td>
<td>67.8</td>
<td>66.7</td>
<td>66.9</td>
<td>67.9</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>75.0</td>
<td>73.6</td>
<td>76.2</td>
<td>66.0</td>
<td>76.8</td>
<td>76.8</td>
<td>74.7</td>
<td>73.6</td>
<td>81.1</td>
<td>73.3</td>
<td>77.1</td>
<td>74.3</td>
<td>75.3</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>76.1</td>
<td>74.5</td>
<td>77.4</td>
<td>68.9</td>
<td>76.8</td>
<td>76.7</td>
<td>75.8</td>
<td>74.4</td>
<td>82.6</td>
<td>74.2</td>
<td>76.7</td>
<td>76.0</td>
<td>76.8</td>
<td>78.1</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>76.1</td>
<td>75.2</td>
<td>76.9</td>
<td>66.0</td>
<td>78.2</td>
<td>77.8</td>
<td>77.2</td>
<td>76.8</td>
<td>81.1</td>
<td>74.7</td>
<td>76.5</td>
<td>75.6</td>
<td>77.1</td>
<td>76.4</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>75.2</td>
<td>73.3</td>
<td>76.8</td>
<td>66.1</td>
<td>76.4</td>
<td>75.7</td>
<td>75.0</td>
<td>73.5</td>
<td>81.2</td>
<td>74.4</td>
<td>75.3</td>
<td>77.1</td>
<td>75.0</td>
<td>77.5</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>70.9</td>
<td>66.4</td>
<td>74.6</td>
<td>51.0</td>
<td>75.0</td>
<td>72.1</td>
<td>67.5</td>
<td>66.5</td>
<td>80.1</td>
<td>74.7</td>
<td>74.4</td>
<td>73.1</td>
<td>70.4</td>
<td>74.6</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>71.8</td>
<td>68.2</td>
<td>74.8</td>
<td>52.1</td>
<td>75.6</td>
<td>74.0</td>
<td>71.0</td>
<td>68.3</td>
<td>81.4</td>
<td>72.5</td>
<td>74.3</td>
<td>71.1</td>
<td>71.9</td>
<td>77.6</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>72.1</td>
<td>69.6</td>
<td>74.2</td>
<td>57.6</td>
<td>75.0</td>
<td>73.1</td>
<td>71.7</td>
<td>70.6</td>
<td>80.6</td>
<td>73.8</td>
<td>73.6</td>
<td>69.6</td>
<td>72.4</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>71.8</td>
<td>69.3</td>
<td>74.0</td>
<td>54.7</td>
<td>74.6</td>
<td>74.7</td>
<td>70.7</td>
<td>71.8</td>
<td>79.4</td>
<td>71.8</td>
<td>72.4</td>
<td>73.5</td>
<td>72.8</td>
<td>73.9</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>67.5</td>
<td>62.2</td>
<td>71.9</td>
<td>50.6</td>
<td>70.0</td>
<td>68.3</td>
<td>59.7</td>
<td>62.2</td>
<td>77.5</td>
<td>71.4</td>
<td>72.2</td>
<td>68.1</td>
<td>71.4</td>
<td>71.1</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>67.9</td>
<td>62.3</td>
<td>72.6</td>
<td>49.0</td>
<td>71.2</td>
<td>68.5</td>
<td>58.9</td>
<td>64.0</td>
<td>77.9</td>
<td>71.4</td>
<td>74.6</td>
<td>69.7</td>
<td>71.0</td>
<td>71.0</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>68.5</td>
<td>64.1</td>
<td>72.2</td>
<td>56.2</td>
<td>70.0</td>
<td>68.3</td>
<td>62.5</td>
<td>63.3</td>
<td>78.3</td>
<td>68.7</td>
<td>74.2</td>
<td>69.7</td>
<td>69.7</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>65.8</td>
<td>60.1</td>
<td>70.5</td>
<td>41.4</td>
<td>70.4</td>
<td>68.8</td>
<td>58.6</td>
<td>61.1</td>
<td>74.3</td>
<td>68.1</td>
<td>73.8</td>
<td>66.8</td>
<td>65.4</td>
<td>74.7</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>68.8</td>
<td>66.1</td>
<td>71.1</td>
<td>53.5</td>
<td>68.9</td>
<td>69.6</td>
<td>69.9</td>
<td>68.6</td>
<td>75.0</td>
<td>68.1</td>
<td>72.9</td>
<td>70.8</td>
<td>68.1</td>
<td>71.8</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>68.2</td>
<td>66.4</td>
<td>69.7</td>
<td>50.7</td>
<td>70.6</td>
<td>70.6</td>
<td>70.8</td>
<td>69.3</td>
<td>73.2</td>
<td>66.9</td>
<td>70.6</td>
<td>68.9</td>
<td>66.1</td>
<td>72.8</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>69.6</td>
<td>66.8</td>
<td>71.9</td>
<td>54.4</td>
<td>72.5</td>
<td>69.4</td>
<td>70.4</td>
<td>67.4</td>
<td>78.7</td>
<td>69.4</td>
<td>71.4</td>
<td>67.9</td>
<td>70.4</td>
<td>73.5</td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>42.0</td>
<td>38.3</td>
<td>45.0</td>
<td>39.4</td>
<td>39.9</td>
<td>42.5</td>
<td>35.7</td>
<td>34.0</td>
<td>55.1</td>
<td>42.4</td>
<td>52.8</td>
<td>41.2</td>
<td>37.9</td>
<td>40.7</td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>9.7</td>
<td>9.2</td>
<td>10.1</td>
<td>9.2</td>
<td>9.9</td>
<td>9.4</td>
<td>8.3</td>
<td>9.3</td>
<td>10.4</td>
<td>10.4</td>
<td>7.8</td>
<td>9.6</td>
<td>10.6</td>
<td>11.7</td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>45.6</td>
<td>38.0</td>
<td>51.9</td>
<td>29.2</td>
<td>46.5</td>
<td>49.7</td>
<td>34.0</td>
<td>30.6</td>
<td>62.5</td>
<td>51.7</td>
<td>57.6</td>
<td>49.6</td>
<td>44.3</td>
<td>45.8</td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>60.2</td>
<td>53.4</td>
<td>65.9</td>
<td>45.3</td>
<td>60.1</td>
<td>61.4</td>
<td>47.6</td>
<td>52.8</td>
<td>71.3</td>
<td>66.0</td>
<td>66.0</td>
<td>63.9</td>
<td>62.1</td>
<td>66.2</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>67.5</td>
<td>64.3</td>
<td>70.1</td>
<td>55.4</td>
<td>71.0</td>
<td>69.4</td>
<td>61.0</td>
<td>64.9</td>
<td>77.8</td>
<td>65.3</td>
<td>71.9</td>
<td>71.4</td>
<td>62.8</td>
<td>71.4</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>68.4</td>
<td>64.8</td>
<td>71.3</td>
<td>57.8</td>
<td>70.6</td>
<td>70.3</td>
<td>62.8</td>
<td>62.8</td>
<td>78.6</td>
<td>67.4</td>
<td>68.9</td>
<td>69.3</td>
<td>68.5</td>
<td>75.4</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>69.6</td>
<td>66.1</td>
<td>72.6</td>
<td>57.8</td>
<td>72.9</td>
<td>70.3</td>
<td>63.9</td>
<td>65.4</td>
<td>78.8</td>
<td>68.8</td>
<td>71.0</td>
<td>73.3</td>
<td>67.9</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>63.3</td>
<td>59.2</td>
<td>66.7</td>
<td>43.6</td>
<td>64.4</td>
<td>65.3</td>
<td>63.9</td>
<td>59.0</td>
<td>73.5</td>
<td>61.5</td>
<td>67.4</td>
<td>66.4</td>
<td>63.1</td>
<td>68.6</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>63.3</td>
<td>59.2</td>
<td>66.7</td>
<td>43.6</td>
<td>64.4</td>
<td>65.3</td>
<td>63.9</td>
<td>59.0</td>
<td>73.5</td>
<td>61.5</td>
<td>67.4</td>
<td>66.4</td>
<td>63.1</td>
<td>68.6</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>65.3</td>
<td>62.8</td>
<td>67.5</td>
<td>49.9</td>
<td>66.7</td>
<td>67.2</td>
<td>66.4</td>
<td>63.9</td>
<td>72.8</td>
<td>63.9</td>
<td>69.0</td>
<td>66.5</td>
<td>63.7</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>65.3</td>
<td>62.8</td>
<td>67.5</td>
<td>49.9</td>
<td>66.7</td>
<td>67.2</td>
<td>66.4</td>
<td>63.9</td>
<td>72.8</td>
<td>63.9</td>
<td>69.0</td>
<td>66.5</td>
<td>63.7</td>
<td>68.8</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>66.6</td>
<td>59.7</td>
<td>72.4</td>
<td>46.8</td>
<td>66.0</td>
<td>67.9</td>
<td>57.4</td>
<td>60.3</td>
<td>77.2</td>
<td>72.8</td>
<td>77.5</td>
<td>69.0</td>
<td>67.2</td>
<td>70.6</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>65.4</td>
<td>59.4</td>
<td>70.5</td>
<td>49.0</td>
<td>68.6</td>
<td>69.6</td>
<td>53.9</td>
<td>56.0</td>
<td>76.9</td>
<td>69.7</td>
<td>74.9</td>
<td>67.5</td>
<td>63.1</td>
<td>70.7</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>66.2</td>
<td>60.1</td>
<td>71.2</td>
<td>51.9</td>
<td>67.9</td>
<td>66.9</td>
<td>53.9</td>
<td>59.9</td>
<td>77.1</td>
<td>71.2</td>
<td>74.2</td>
<td>68.9</td>
<td>67.5</td>
<td>68.3</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>52.2</td>
<td>50.7</td>
<td>53.5</td>
<td>42.8</td>
<td>54.4</td>
<td>55.7</td>
<td>53.3</td>
<td>47.1</td>
<td>55.1</td>
<td>49.4</td>
<td>54.2</td>
<td>52.1</td>
<td>54.9</td>
<td>55.4</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>70.3</td>
<td>67.4</td>
<td>72.8</td>
<td>53.2</td>
<td>71.1</td>
<td>73.5</td>
<td>71.0</td>
<td>68.3</td>
<td>75.1</td>
<td>73.3</td>
<td>70.3</td>
<td>71.0</td>
<td>72.6</td>
<td>74.3</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>71.4</td>
<td>67.7</td>
<td>74.4</td>
<td>46.8</td>
<td>73.3</td>
<td>77.2</td>
<td>71.9</td>
<td>69.2</td>
<td>78.5</td>
<td>73.6</td>
<td>74.9</td>
<td>72.2</td>
<td>72.8</td>
<td>74.6</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>71.3</td>
<td>67.6</td>
<td>74.4</td>
<td>49.6</td>
<td>72.5</td>
<td>74.3</td>
<td>72.4</td>
<td>69.2</td>
<td>77.2</td>
<td>73.2</td>
<td>73.8</td>
<td>72.6</td>
<td>74.0</td>
<td>75.8</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>71.8</td>
<td>67.6</td>
<td>75.3</td>
<td>47.4</td>
<td>73.6</td>
<td>75.1</td>
<td>73.5</td>
<td>68.5</td>
<td>79.2</td>
<td>72.4</td>
<td>75.6</td>
<td>73.1</td>
<td>75.3</td>
<td>76.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>47.2</td>
<td>41.5</td>
<td>51.9</td>
<td>40.8</td>
<td>45.0</td>
<td>51.4</td>
<td>34.7</td>
<td>35.7</td>
<td>63.6</td>
<td>50.7</td>
<td>57.9</td>
<td>47.6</td>
<td>42.9</td>
<td>48.5</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>44.7</td>
<td>40.0</td>
<td>48.5</td>
<td>41.0</td>
<td>47.9</td>
<td>49.2</td>
<td>30.1</td>
<td>31.9</td>
<td>60.6</td>
<td>47.6</td>
<td>54.3</td>
<td>46.0</td>
<td>41.0</td>
<td>41.7</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>46.1</td>
<td>40.9</td>
<td>50.4</td>
<td>40.6</td>
<td>47.6</td>
<td>50.8</td>
<td>33.8</td>
<td>31.9</td>
<td>63.7</td>
<td>48.5</td>
<td>55.1</td>
<td>47.1</td>
<td>42.6</td>
<td>45.1</td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>46.8</td>
<td>41.3</td>
<td>51.5</td>
<td>45.1</td>
<td>47.2</td>
<td>50.7</td>
<td>32.5</td>
<td>30.8</td>
<td>61.0</td>
<td>48.6</td>
<td>58.6</td>
<td>48.8</td>
<td>44.7</td>
<td>47.2</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>63.8</td>
<td>57.8</td>
<td>68.8</td>
<td>43.6</td>
<td>66.4</td>
<td>61.5</td>
<td>53.9</td>
<td>63.7</td>
<td>72.6</td>
<td>66.1</td>
<td>71.2</td>
<td>65.1</td>
<td>68.1</td>
<td>69.9</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>65.2</td>
<td>58.2</td>
<td>71.0</td>
<td>42.2</td>
<td>67.2</td>
<td>62.1</td>
<td>55.0</td>
<td>64.7</td>
<td>72.8</td>
<td>69.4</td>
<td>72.4</td>
<td>67.1</td>
<td>71.8</td>
<td>72.6</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>65.3</td>
<td>60.8</td>
<td>69.1</td>
<td>43.2</td>
<td>68.9</td>
<td>65.8</td>
<td>58.5</td>
<td>67.5</td>
<td>63.3</td>
<td>67.1</td>
<td>71.0</td>
<td>68.9</td>
<td>71.4</td>
<td>72.8</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>64.7</td>
<td>57.9</td>
<td>70.4</td>
<td>43.1</td>
<td>65.0</td>
<td>61.8</td>
<td>54.4</td>
<td>65.3</td>
<td>72.4</td>
<td>68.3</td>
<td>71.9</td>
<td>67.2</td>
<td>70.7</td>
<td>71.8</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>61.4</td>
<td>55.5</td>
<td>66.2</td>
<td>50.4</td>
<td>62.1</td>
<td>66.8</td>
<td>46.5</td>
<td>51.7</td>
<td>71.8</td>
<td>66.7</td>
<td>67.8</td>
<td>65.8</td>
<td>58.2</td>
<td>67.2</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>64.5</td>
<td>60.4</td>
<td>67.8</td>
<td>55.6</td>
<td>66.2</td>
<td>68.6</td>
<td>55.6</td>
<td>56.1</td>
<td>73.1</td>
<td>68.8</td>
<td>71.2</td>
<td>65.6</td>
<td>62.1</td>
<td>66.4</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>67.3</td>
<td>63.1</td>
<td>70.8</td>
<td>59.9</td>
<td>69.6</td>
<td>69.2</td>
<td>57.8</td>
<td>59.2</td>
<td>74.7</td>
<td>72.6</td>
<td>73.3</td>
<td>69.9</td>
<td>66.0</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>68.1</td>
<td>64.2</td>
<td>71.4</td>
<td>61.4</td>
<td>69.3</td>
<td>68.5</td>
<td>64.4</td>
<td>57.2</td>
<td>76.4</td>
<td>71.2</td>
<td>74.0</td>
<td>68.5</td>
<td>68.1</td>
<td>70.0</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>73.1</td>
<td>70.8</td>
<td>74.9</td>
<td>63.6</td>
<td>74.7</td>
<td>75.0</td>
<td>67.9</td>
<td>72.8</td>
<td>78.8</td>
<td>74.9</td>
<td>76.1</td>
<td>71.4</td>
<td>72.5</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>72.9</td>
<td>70.0</td>
<td>75.4</td>
<td>61.7</td>
<td>74.6</td>
<td>73.9</td>
<td>67.8</td>
<td>71.9</td>
<td>78.5</td>
<td>74.7</td>
<td>77.8</td>
<td>71.4</td>
<td>73.3</td>
<td>76.5</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>72.9</td>
<td>70.1</td>
<td>75.1</td>
<td>62.1</td>
<td>74.6</td>
<td>74.3</td>
<td>67.8</td>
<td>71.9</td>
<td>78.3</td>
<td>74.0</td>
<td>77.9</td>
<td>71.1</td>
<td>73.3</td>
<td>76.1</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>72.8</td>
<td>70.2</td>
<td>74.9</td>
<td>63.1</td>
<td>75.1</td>
<td>74.3</td>
<td>67.4</td>
<td>71.4</td>
<td>76.7</td>
<td>74.7</td>
<td>76.9</td>
<td>72.4</td>
<td>72.9</td>
<td>76.0</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>51.9</td>
<td>49.7</td>
<td>53.6</td>
<td>49.6</td>
<td>52.6</td>
<td>55.6</td>
<td>48.2</td>
<td>42.8</td>
<td>64.2</td>
<td>53.3</td>
<td>56.2</td>
<td>50.4</td>
<td>45.6</td>
<td>51.9</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>55.2</td>
<td>53.5</td>
<td>56.6</td>
<td>53.3</td>
<td>56.5</td>
<td>59.9</td>
<td>51.0</td>
<td>46.9</td>
<td>66.0</td>
<td>57.6</td>
<td>57.2</td>
<td>54.7</td>
<td>49.4</td>
<td>54.9</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>53.5</td>
<td>50.7</td>
<td>55.8</td>
<td>49.3</td>
<td>55.1</td>
<td>59.4</td>
<td>45.7</td>
<td>44.0</td>
<td>63.1</td>
<td>57.1</td>
<td>58.5</td>
<td>50.0</td>
<td>52.2</td>
<td>54.0</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>63.0</td>
<td>58.9</td>
<td>66.4</td>
<td>53.5</td>
<td>63.1</td>
<td>70.3</td>
<td>54.7</td>
<td>53.1</td>
<td>74.2</td>
<td>67.6</td>
<td>70.7</td>
<td>62.4</td>
<td>59.3</td>
<td>64.4</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>63.2</td>
<td>57.4</td>
<td>68.1</td>
<td>49.9</td>
<td>66.1</td>
<td>68.5</td>
<td>49.9</td>
<td>52.6</td>
<td>75.8</td>
<td>70.3</td>
<td>71.2</td>
<td>62.1</td>
<td>61.1</td>
<td>67.9</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>52.2</td>
<td>47.3</td>
<td>56.3</td>
<td>42.1</td>
<td>52.9</td>
<td>57.1</td>
<td>39.0</td>
<td>45.6</td>
<td>64.3</td>
<td>59.9</td>
<td>60.8</td>
<td>51.4</td>
<td>50.7</td>
<td>50.8</td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>59.0</td>
<td>53.2</td>
<td>63.8</td>
<td>54.4</td>
<td>57.6</td>
<td>60.7</td>
<td>48.1</td>
<td>45.4</td>
<td>70.6</td>
<td>68.8</td>
<td>68.5</td>
<td>58.8</td>
<td>55.8</td>
<td>60.7</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>61.2</td>
<td>54.2</td>
<td>67.1</td>
<td>46.9</td>
<td>64.9</td>
<td>66.1</td>
<td>47.6</td>
<td>45.6</td>
<td>76.4</td>
<td>66.4</td>
<td>70.4</td>
<td>61.9</td>
<td>58.9</td>
<td>68.5</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>63.5</td>
<td>55.6</td>
<td>70.0</td>
<td>45.3</td>
<td>67.5</td>
<td>67.1</td>
<td>48.2</td>
<td>50.1</td>
<td>77.4</td>
<td>67.4</td>
<td>70.4</td>
<td>66.2</td>
<td>65.8</td>
<td>73.1</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>63.5</td>
<td>55.9</td>
<td>70.0</td>
<td>46.2</td>
<td>66.9</td>
<td>67.5</td>
<td>48.3</td>
<td>50.3</td>
<td>76.8</td>
<td>67.9</td>
<td>70.3</td>
<td>66.0</td>
<td>66.0</td>
<td>72.8</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>62.8</td>
<td>56.2</td>
<td>68.3</td>
<td>44.2</td>
<td>68.5</td>
<td>66.2</td>
<td>51.7</td>
<td>50.4</td>
<td>77.4</td>
<td>67.1</td>
<td>70.4</td>
<td>64.6</td>
<td>61.7</td>
<td>68.9</td>
</tr>
</tbody>
</table>
<h1 id="system-characteristics">System characteristics</h1>
<h2 id="general-characteristics">General characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="off" data-chart-modes="bar" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Submission label 
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss <br/>(Eval)
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_sampling_rate" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Sampling <br/>rate
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_data_augmentation" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Data <br/>augmentation
            </th>
<th class="text-center narrow-col" data-field="system_features" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Features
            </th>
<th class="text-center narrow-col" data-field="system_embeddings" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Embeddings
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>68.6</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, speed augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>67.5</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, speed augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>68.5</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, speed augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>68.8</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, speed augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>66.7</td>
<td>44.1kHz</td>
<td>mixup, time stretching,pitch shifting,spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>64.6</td>
<td>44.1kHz</td>
<td>mixup, time stretching,pitch shifting,spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>67.2</td>
<td>44.1kHz</td>
<td>mixup, time stretching,pitch shifting,spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>66.1</td>
<td>44.1kHz</td>
<td>mixup, time stretching,pitch shifting,spectrum correction</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>53.0</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>51.1</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>49.1</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>51.4</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>68.3</td>
<td>44.1kHz</td>
<td>reverb, filtering, random gain adjust, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>53.9</td>
<td>16kHz</td>
<td>random noise, random gain, random cropping, mixup</td>
<td>raw waveform</td>
<td>AemNet</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>67.0</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, device augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>66.9</td>
<td>44.1kHz</td>
<td>mixup, tempo, channel corruption</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>70.0</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, device augmentation</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>70.1</td>
<td>44.1kHz</td>
<td>mixup, tempo, channel corruption</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>51.4</td>
<td>44.1kHz</td>
<td>mixup, time stretching, pitch shifting,  random noise, spectrum augmentation, random temporal shuffle, volume change</td>
<td>log-mel energies, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>53.3</td>
<td>44.1kHz</td>
<td>mixup, time stretching, pitch shifting,  random noise, spectrum augmentation, random temporal shuffle, volume change</td>
<td>log-mel energies, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>51.6</td>
<td>44.1kHz</td>
<td>mixup, time stretching, pitch shifting,  random noise, spectrum augmentation, random temporal shuffle, volume change</td>
<td>log-mel energies, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>49.2</td>
<td>44.1kHz</td>
<td>mixup, time stretching, pitch shifting,  random noise, spectrum augmentation, random temporal shuffle, volume change</td>
<td>log-mel energies, HPSS</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>55.0</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>51.3</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>56.3</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>66.0</td>
<td>44.1kHz</td>
<td>temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>67.0</td>
<td>44.1kHz</td>
<td>temporal cropping, SpecAugment</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>66.7</td>
<td>44.1kHz</td>
<td>temporal cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>66.1</td>
<td>44.1kHz</td>
<td>temporal cropping, SpecAugment</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>66.8</td>
<td>44.1kHz</td>
<td></td>
<td>Wavelet Scattering</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>63.5</td>
<td>44.1kHz</td>
<td></td>
<td>Wavelet Scattering</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>61.5</td>
<td>22.05kHz</td>
<td>mixup, SpecAugment</td>
<td>Perceptually-weighted log-mel energies</td>
<td>VGGish</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>61.6</td>
<td>22.05kHz</td>
<td>mixup, SpecAugment</td>
<td>Perceptually-weighted log-mel energies</td>
<td>VGGish</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>62.0</td>
<td>22.05kHz</td>
<td>mixup, SpecAugment</td>
<td>Perceptually-weighted log-mel energies</td>
<td>VGGish</td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>61.3</td>
<td>22.05kHz</td>
<td>mixup, SpecAugment</td>
<td>Perceptually-weighted log-mel energies</td>
<td>VGGish</td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>64.7</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, delta-log-mel energies, delta-delta-log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>63.8</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, delta-log-mel energies, delta-delta-log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>61.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, delta-log-mel energies, delta-delta-log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>62.9</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, delta-log-mel energies, delta-delta-log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>75.0</td>
<td>16kHz</td>
<td>mixup, specaugment, time rolling</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>76.1</td>
<td>16kHz</td>
<td>mixup, specaugment, time rolling</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>76.1</td>
<td>16kHz</td>
<td>mixup, specaugment, time rolling</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>75.2</td>
<td>16kHz</td>
<td>mixup, specaugment, time rolling</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>70.9</td>
<td>22.05kHz</td>
<td>mixup, pitch shifting</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>71.8</td>
<td>22.05kHz</td>
<td>mixup, pitch shifting</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>72.1</td>
<td>22.05kHz</td>
<td>mixup, pitch shifting</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>71.8</td>
<td>22.05kHz</td>
<td>mixup, pitch shifting</td>
<td>Perceptually-weighted log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>67.5</td>
<td>44.1kHz</td>
<td></td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>67.9</td>
<td>44.1kHz</td>
<td></td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>68.5</td>
<td>44.1kHz</td>
<td></td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>65.8</td>
<td>44.1kHz</td>
<td></td>
<td>spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>68.8</td>
<td>44.1kHz</td>
<td>HRTF,mixup,temporal cropping,spectrum correction</td>
<td>log-mel energies,deltas,delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>68.2</td>
<td>44.1kHz</td>
<td>HRTF,mixup,temporal cropping,spectrum correction</td>
<td>log-mel energies,deltas,delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>69.6</td>
<td>44.1kHz</td>
<td>mixup,temporal cropping</td>
<td>log-mel energies,deltas,delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>42.0</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>9.7</td>
<td>44.1kHz</td>
<td>time stretching, pitch shifting, dynamic range compression, background noise, mixup</td>
<td>wavelet based log-mel energies</td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>60.2</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>gammatone spectrogram</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>67.5</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>CQT, Gammatonegram, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>68.4</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>CQT, Gammatonegram, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>69.6</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>CQT, Gammatonegram, log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>63.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>63.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>65.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>65.3</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>66.6</td>
<td>44.1kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>65.4</td>
<td>44.1kHz</td>
<td>SpecAugment, mixup</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>66.2</td>
<td>44.1kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>52.2</td>
<td>44.1kHz</td>
<td>mixup</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>70.3</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, spectrum correction, pitch shifting, speed change, mix audios</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>71.4</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, spectrum correction, pitch shifting, speed change, mix audios</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>71.3</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, spectrum correction, pitch shifting, speed change, mix audios</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>71.8</td>
<td>44.1kHz</td>
<td>mixup, spectrum augmentation, spectrum correction, pitch shifting, speed change, mix audios</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>47.2</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>44.7</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>46.1</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>46.8</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>63.8</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, time-shifting, spectrum modulation</td>
<td>log-mel powers</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>65.2</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, time-shifting, spectrum modulation</td>
<td>log-mel powers</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>65.3</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, time-shifting, spectrum modulation</td>
<td>log-mel powers</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>64.7</td>
<td>44.1kHz</td>
<td>mixup, SpecAugment, time-shifting, spectrum modulation</td>
<td>log-mel powers</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>61.4</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>64.5</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>67.3</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>68.1</td>
<td>44.1kHz</td>
<td>mixup, temporal cropping, SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>73.1</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shifting, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>72.9</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shifting, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>72.9</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shifting, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>72.8</td>
<td>44.1kHz</td>
<td>mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shifting, speed change, random noise, mix audios</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>51.9</td>
<td>16kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>55.2</td>
<td>16kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>53.5</td>
<td>16kHz</td>
<td>SpecAugment</td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>63.0</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>63.2</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>52.2</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>59.0</td>
<td>44.1kHz</td>
<td></td>
<td>log-mel energies</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>61.2</td>
<td>44.1kHz</td>
<td>mixup, random cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>63.5</td>
<td>44.1kHz</td>
<td>mixup, random cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>63.5</td>
<td>44.1kHz</td>
<td>mixup, random cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>62.8</td>
<td>44.1kHz</td>
<td>mixup, random cropping</td>
<td>log-mel energies, deltas, delta-deltas</td>
<td></td>
</tr>
</tbody>
</table>
<p><br/>
<br/></p>
<h2 id="machine-learning-characteristics">Machine learning characteristics</h2>
<table class="datatable table table-hover table-condensed" data-bar-hline="true" data-bar-horizontal-indicator-linewidth="2" data-bar-show-horizontal-indicator="true" data-bar-show-vertical-indicator="true" data-bar-show-xaxis="false" data-bar-tooltip-position="top" data-bar-vertical-indicator-linewidth="2" data-chart-default-mode="scatter" data-chart-modes="bar,scatter" data-chart-tooltip-fields="code" data-filter-control="true" data-filter-show-clear="true" data-id-field="code" data-pagination="true" data-rank-mode="grouped_muted" data-row-highlighting="true" data-scatter-x="accuracy_eval" data-scatter-y="system_complexity_total" data-show-bar-chart-xaxis="false" data-show-chart="true" data-show-pagination-switch="true" data-show-rank="true" data-sort-name="logloss_eval" data-sort-order="desc" data-striped="true" data-tag-mode="column">
<thead>
<tr>
<th class="sep-right-cell text-center" data-rank="true">Rank</th>
<th data-field="code" data-sortable="true">
                Code
            </th>
<th class="sep-left-cell text-center" data-field="bibtex_key" data-sortable="false" data-value-type="anchor">
                Technical<br/>Report
            </th>
<th class="sep-left-cell text-center" data-axis-label="Official rank" data-chartable="true" data-field="rank_entry" data-sortable="true" data-value-type="int">
                Official <br/>system <br/>rank
            </th>
<th class="text-center" data-axis-label="Logloss (Evaluation dataset)" data-chartable="true" data-field="logloss_eval" data-reversed="true" data-sortable="true" data-value-type="float3">
                Logloss <br/>(Eval)
            </th>
<th class="text-center" data-chartable="true" data-field="accuracy_eval" data-sortable="true" data-value-type="float1-percentage">
                Accuracy <br/>(Eval)
            </th>
<th class="sep-left-cell text-center narrow-col" data-field="system_external_data_usage" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data usage
            </th>
<th class="text-center narrow-col" data-field="external_data_sources" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                External <br/>data sources
            </th>
<th class="sep-left-cell text-center narrow-col" data-axis-scale="log10_unit" data-chartable="true" data-field="system_complexity_total" data-sortable="true" data-value-type="numeric-unit">
                Model <br/>complexity
            </th>
<th class="text-center narrow-col" data-field="system_classifier" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Classifier
            </th>
<th class="text-center narrow-col" data-chartable="true" data-field="system_ensemble_method_subsystem_count" data-sortable="true" data-value-type="int">
                Ensemble <br/>subsystems
            </th>
<th class="text-center narrow-col" data-field="system_decision_making" data-filter-control="select" data-filter-strict-search="true" data-sortable="true" data-tag="true">
                Decision <br/>making
            </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_1</td>
<td>Byttebier2021</td>
<td>21</td>
<td>0.936</td>
<td>68.6</td>
<td></td>
<td></td>
<td>114634</td>
<td>SE-ResNet</td>
<td></td>
<td>maximum logit</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_2</td>
<td>Byttebier2021</td>
<td>18</td>
<td>0.914</td>
<td>67.5</td>
<td></td>
<td></td>
<td>114634</td>
<td>SE-ResNet</td>
<td></td>
<td>multinomial logistic regression</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_3</td>
<td>Byttebier2021</td>
<td>23</td>
<td>0.944</td>
<td>68.5</td>
<td></td>
<td></td>
<td>114634</td>
<td>SE-ResNet</td>
<td></td>
<td>ovr logistic regression</td>
</tr>
<tr>
<td></td>
<td>Byttebier_IDLab_task1a_4</td>
<td>Byttebier2021</td>
<td>17</td>
<td>0.905</td>
<td>68.8</td>
<td></td>
<td></td>
<td>82910</td>
<td>SE-ResNet</td>
<td></td>
<td>maximum logit</td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_1</td>
<td>Cao2021</td>
<td>49</td>
<td>1.136</td>
<td>66.7</td>
<td>embeddings</td>
<td></td>
<td>36658</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_2</td>
<td>Cao2021</td>
<td>56</td>
<td>1.200</td>
<td>64.6</td>
<td>embeddings</td>
<td></td>
<td>36658</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_3</td>
<td>Cao2021</td>
<td>50</td>
<td>1.137</td>
<td>67.2</td>
<td>embeddings</td>
<td></td>
<td>36658</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cao_SCUT_task1a_4</td>
<td>Cao2021</td>
<td>53</td>
<td>1.147</td>
<td>66.1</td>
<td>embeddings</td>
<td></td>
<td>51926</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_1</td>
<td>Ding2021</td>
<td>85</td>
<td>1.544</td>
<td>53.0</td>
<td></td>
<td></td>
<td>40230</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_2</td>
<td>Ding2021</td>
<td>70</td>
<td>1.326</td>
<td>51.1</td>
<td></td>
<td></td>
<td>20250</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_3</td>
<td>Ding2021</td>
<td>61</td>
<td>1.226</td>
<td>49.1</td>
<td></td>
<td></td>
<td>63816</td>
<td>CNN</td>
<td></td>
<td>majority vote</td>
</tr>
<tr>
<td></td>
<td>Ding_TJU_task1a_4</td>
<td>Ding2021</td>
<td>67</td>
<td>1.296</td>
<td>51.4</td>
<td></td>
<td></td>
<td>20250</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Fan_NWPU_task1a_1</td>
<td>Cui2021</td>
<td>64</td>
<td>1.261</td>
<td>68.3</td>
<td>embeddings</td>
<td></td>
<td>93323</td>
<td>ResNet, Attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Galindo-Meza_ITESO_task1a_1</td>
<td>Galindo-Meza2021</td>
<td>97</td>
<td>2.221</td>
<td>53.9</td>
<td>pre-trained model</td>
<td>Audioset</td>
<td>127637</td>
<td>CNN</td>
<td></td>
<td>Maximum softmax</td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_1</td>
<td>Hee-Soo2021</td>
<td>42</td>
<td>1.087</td>
<td>67.0</td>
<td></td>
<td></td>
<td>65424</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_2</td>
<td>Hee-Soo2021</td>
<td>20</td>
<td>0.930</td>
<td>66.9</td>
<td></td>
<td></td>
<td>63547</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_3</td>
<td>Hee-Soo2021</td>
<td>34</td>
<td>1.045</td>
<td>70.0</td>
<td></td>
<td></td>
<td>65424</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Heo_Clova_task1a_4</td>
<td>Hee-Soo2021</td>
<td>12</td>
<td>0.871</td>
<td>70.1</td>
<td></td>
<td></td>
<td>63547</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_1</td>
<td>Horvth2021</td>
<td>86</td>
<td>1.597</td>
<td>51.4</td>
<td></td>
<td></td>
<td>47939</td>
<td>MobileNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_2</td>
<td>Horvth2021</td>
<td>92</td>
<td>2.031</td>
<td>53.3</td>
<td></td>
<td></td>
<td>47939</td>
<td>MobileNetV2, ArcFace</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_3</td>
<td>Horvth2021</td>
<td>76</td>
<td>1.460</td>
<td>51.6</td>
<td></td>
<td></td>
<td>58266</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Horváth_HIT_task1a_4</td>
<td>Horvth2021</td>
<td>95</td>
<td>2.065</td>
<td>49.2</td>
<td></td>
<td></td>
<td>58266</td>
<td>ResNet, ArcFace</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_1</td>
<td>Jeng2021</td>
<td>78</td>
<td>1.469</td>
<td>55.0</td>
<td></td>
<td></td>
<td>130457242</td>
<td>CNN</td>
<td></td>
<td>logistical regression</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_2</td>
<td>Jeng2021</td>
<td>84</td>
<td>1.543</td>
<td>51.3</td>
<td></td>
<td></td>
<td>130457242</td>
<td>CNN</td>
<td></td>
<td>logistical regression</td>
</tr>
<tr>
<td></td>
<td>Jeng_CHT+NSYSU_task1a_3</td>
<td>Jeng2021</td>
<td>79</td>
<td>1.470</td>
<td>56.3</td>
<td></td>
<td></td>
<td>17186944</td>
<td>CNN</td>
<td></td>
<td>logistical regression</td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_1</td>
<td>Jeong2021</td>
<td>33</td>
<td>1.041</td>
<td>66.0</td>
<td></td>
<td></td>
<td>54845</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_2</td>
<td>Jeong2021</td>
<td>25</td>
<td>0.952</td>
<td>67.0</td>
<td></td>
<td></td>
<td>54845</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_3</td>
<td>Jeong2021</td>
<td>30</td>
<td>1.023</td>
<td>66.7</td>
<td></td>
<td></td>
<td>60236</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Jeong_ETRI_task1a_4</td>
<td>Jeong2021</td>
<td>63</td>
<td>1.228</td>
<td>66.1</td>
<td></td>
<td></td>
<td>60236</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_1</td>
<td>Kek2021</td>
<td>72</td>
<td>1.355</td>
<td>66.8</td>
<td></td>
<td></td>
<td>63448</td>
<td>CNN, MobileNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kek_NU_task1a_2</td>
<td>Kek2021</td>
<td>57</td>
<td>1.207</td>
<td>63.5</td>
<td></td>
<td></td>
<td>64850</td>
<td>CNN, MobileNetV2, Group convolution, Channel attention</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_1</td>
<td>Kim2021</td>
<td>38</td>
<td>1.076</td>
<td>61.5</td>
<td>pre-trained weights of Vggish</td>
<td></td>
<td>168778</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_2</td>
<td>Kim2021</td>
<td>39</td>
<td>1.077</td>
<td>61.6</td>
<td>pre-trained weights of Vggish</td>
<td></td>
<td>168778</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_3</td>
<td>Kim2021</td>
<td>37</td>
<td>1.076</td>
<td>62.0</td>
<td>pre-trained weights of Vggish</td>
<td></td>
<td>168778</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_3M_task1a_4</td>
<td>Kim2021</td>
<td>40</td>
<td>1.078</td>
<td>61.3</td>
<td>pre-trained weights of Vggish</td>
<td></td>
<td>168778</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_1</td>
<td>Kim2021a</td>
<td>46</td>
<td>1.115</td>
<td>64.7</td>
<td></td>
<td></td>
<td>58472</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_2</td>
<td>Kim2021a</td>
<td>28</td>
<td>1.010</td>
<td>63.8</td>
<td></td>
<td></td>
<td>64064</td>
<td>CNN (Inception)</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_3</td>
<td>Kim2021a</td>
<td>55</td>
<td>1.188</td>
<td>61.3</td>
<td></td>
<td></td>
<td>58472</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_KNU_task1a_4</td>
<td>Kim2021a</td>
<td>52</td>
<td>1.143</td>
<td>62.9</td>
<td></td>
<td></td>
<td>58472</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_1</td>
<td>Kim2021b</td>
<td>8</td>
<td>0.793</td>
<td>75.0</td>
<td></td>
<td></td>
<td>630042</td>
<td>CNN, BC-ResNet</td>
<td>2</td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_2</td>
<td>Kim2021b</td>
<td>1</td>
<td>0.724</td>
<td>76.1</td>
<td></td>
<td></td>
<td>630042</td>
<td>CNN, BC-ResNet</td>
<td>2</td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_3</td>
<td>Kim2021b</td>
<td>2</td>
<td>0.735</td>
<td>76.1</td>
<td></td>
<td></td>
<td>630042</td>
<td>CNN, BC-ResNet</td>
<td>2</td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Kim_QTI_task1a_4</td>
<td>Kim2021b</td>
<td>5</td>
<td>0.764</td>
<td>75.2</td>
<td></td>
<td></td>
<td>314990</td>
<td>CNN, BC-ResNet</td>
<td></td>
<td>maximum likelihood</td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_1</td>
<td>Koutini2021</td>
<td>14</td>
<td>0.883</td>
<td>70.9</td>
<td></td>
<td></td>
<td>504104</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_2</td>
<td>Koutini2021</td>
<td>10</td>
<td>0.842</td>
<td>71.8</td>
<td></td>
<td></td>
<td>678184</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_3</td>
<td>Koutini2021</td>
<td>9</td>
<td>0.834</td>
<td>72.1</td>
<td></td>
<td></td>
<td>635176</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Koutini_CPJKU_task1a_4</td>
<td>Koutini2021</td>
<td>11</td>
<td>0.847</td>
<td>71.8</td>
<td></td>
<td></td>
<td>641320</td>
<td>RF-regularized CNNs</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_1</td>
<td>Lim2021</td>
<td>90</td>
<td>1.956</td>
<td>67.5</td>
<td></td>
<td></td>
<td>89910</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_2</td>
<td>Lim2021</td>
<td>91</td>
<td>2.010</td>
<td>67.9</td>
<td></td>
<td></td>
<td>89910</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_3</td>
<td>Lim2021</td>
<td>80</td>
<td>1.479</td>
<td>68.5</td>
<td></td>
<td></td>
<td>134748</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Lim_CAU_task1a_4</td>
<td>Lim2021</td>
<td>93</td>
<td>2.039</td>
<td>65.8</td>
<td></td>
<td></td>
<td>56046</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_1</td>
<td>Liu2021</td>
<td>16</td>
<td>0.900</td>
<td>68.8</td>
<td></td>
<td></td>
<td>643194</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_2</td>
<td>Liu2021</td>
<td>15</td>
<td>0.895</td>
<td>68.2</td>
<td></td>
<td></td>
<td>268362</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_3</td>
<td>Liu2021</td>
<td>13</td>
<td>0.878</td>
<td>69.6</td>
<td></td>
<td></td>
<td>268362</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Liu_UESTC_task1a_4</td>
<td>Liu2021</td>
<td>87</td>
<td>1.626</td>
<td>42.0</td>
<td></td>
<td></td>
<td>60928</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Madhu_CET_task1a_1</td>
<td>Madhu2021</td>
<td>99</td>
<td>3.950</td>
<td>9.7</td>
<td></td>
<td></td>
<td>42774</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr class="info" data-hline="true">
<td></td>
<td>DCASE2021 baseline</td>
<td></td>
<td></td>
<td>1.730</td>
<td>45.6</td>
<td>embeddings</td>
<td></td>
<td>46246</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Naranjo-Alcazar_ITI_task1a_1</td>
<td>Naranjo-Alcazar2021_t1a</td>
<td>51</td>
<td>1.140</td>
<td>60.2</td>
<td></td>
<td></td>
<td>50130</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_1</td>
<td>Pham2021</td>
<td>73</td>
<td>1.368</td>
<td>67.5</td>
<td></td>
<td></td>
<td>10909</td>
<td>CNN</td>
<td>3</td>
<td>PROD late fusion</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_2</td>
<td>Pham2021</td>
<td>54</td>
<td>1.187</td>
<td>68.4</td>
<td></td>
<td></td>
<td>10909</td>
<td>CNN</td>
<td>3</td>
<td>PROD late fusion</td>
</tr>
<tr>
<td></td>
<td>Pham_AIT_task1a_3</td>
<td>Pham2021</td>
<td>94</td>
<td>2.058</td>
<td>69.6</td>
<td></td>
<td></td>
<td>10909</td>
<td>CNN</td>
<td>3</td>
<td>PROD late fusion</td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_1</td>
<td>Phan2021</td>
<td>65</td>
<td>1.272</td>
<td>63.3</td>
<td></td>
<td></td>
<td>41356</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_2</td>
<td>Phan2021</td>
<td>71</td>
<td>1.335</td>
<td>63.3</td>
<td></td>
<td></td>
<td>41356</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_3</td>
<td>Phan2021</td>
<td>60</td>
<td>1.223</td>
<td>65.3</td>
<td></td>
<td></td>
<td>41356</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Phan_UIUC_task1a_4</td>
<td>Phan2021</td>
<td>66</td>
<td>1.292</td>
<td>65.3</td>
<td></td>
<td></td>
<td>41356</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_1</td>
<td>Puy2021</td>
<td>24</td>
<td>0.952</td>
<td>66.6</td>
<td></td>
<td></td>
<td>62474</td>
<td>CNN</td>
<td>30</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_2</td>
<td>Puy2021</td>
<td>27</td>
<td>0.974</td>
<td>65.4</td>
<td></td>
<td></td>
<td>62474</td>
<td>CNN</td>
<td>30</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Puy_VAI_task1a_3</td>
<td>Puy2021</td>
<td>22</td>
<td>0.939</td>
<td>66.2</td>
<td></td>
<td></td>
<td>62474</td>
<td>CNN</td>
<td>30</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Qiao_NCUT_task1a_1</td>
<td>Qiao2021</td>
<td>88</td>
<td>1.630</td>
<td>52.2</td>
<td></td>
<td></td>
<td>31852</td>
<td>ResNet ensemble</td>
<td>2</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_1</td>
<td>Seo2021</td>
<td>32</td>
<td>1.030</td>
<td>70.3</td>
<td></td>
<td></td>
<td>101173</td>
<td>MobileNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_2</td>
<td>Seo2021</td>
<td>41</td>
<td>1.080</td>
<td>71.4</td>
<td></td>
<td></td>
<td>99557</td>
<td>MobileNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_3</td>
<td>Seo2021</td>
<td>35</td>
<td>1.065</td>
<td>71.3</td>
<td></td>
<td></td>
<td>99614</td>
<td>MobileNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Seo_SGU_task1a_4</td>
<td>Seo2021</td>
<td>44</td>
<td>1.087</td>
<td>71.8</td>
<td></td>
<td></td>
<td>99603</td>
<td>MobileNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_1</td>
<td>Singh2021</td>
<td>77</td>
<td>1.464</td>
<td>47.2</td>
<td>embeddings</td>
<td></td>
<td>14754</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_2</td>
<td>Singh2021</td>
<td>83</td>
<td>1.515</td>
<td>44.7</td>
<td>embeddings</td>
<td></td>
<td>27166</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_3</td>
<td>Singh2021</td>
<td>82</td>
<td>1.509</td>
<td>46.1</td>
<td>embeddings</td>
<td></td>
<td>38110</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Singh_IITMandi_task1a_4</td>
<td>Singh2021</td>
<td>81</td>
<td>1.488</td>
<td>46.8</td>
<td>embeddings</td>
<td></td>
<td>36578</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_1</td>
<td>Sugahara2021</td>
<td>43</td>
<td>1.087</td>
<td>63.8</td>
<td></td>
<td></td>
<td>339730</td>
<td>ResNet, ensemble</td>
<td>5</td>
<td>weighted score average</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_2</td>
<td>Sugahara2021</td>
<td>36</td>
<td>1.070</td>
<td>65.2</td>
<td></td>
<td></td>
<td>339730</td>
<td>ResNet, ensemble</td>
<td>5</td>
<td>score average</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_3</td>
<td>Sugahara2021</td>
<td>31</td>
<td>1.024</td>
<td>65.3</td>
<td></td>
<td></td>
<td>203838</td>
<td>ResNet, ensemble</td>
<td>3</td>
<td>score average</td>
</tr>
<tr>
<td></td>
<td>Sugahara_RION_task1a_4</td>
<td>Sugahara2021</td>
<td>68</td>
<td>1.297</td>
<td>64.7</td>
<td></td>
<td></td>
<td>255940</td>
<td>ResNet, ensemble</td>
<td>3</td>
<td>weighted score average</td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_1</td>
<td>Verbitskiy2021</td>
<td>48</td>
<td>1.127</td>
<td>61.4</td>
<td></td>
<td></td>
<td>62090</td>
<td>CNN, EfficientNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_2</td>
<td>Verbitskiy2021</td>
<td>29</td>
<td>1.019</td>
<td>64.5</td>
<td></td>
<td></td>
<td>62154</td>
<td>CNN, EfficientNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_3</td>
<td>Verbitskiy2021</td>
<td>26</td>
<td>0.966</td>
<td>67.3</td>
<td></td>
<td></td>
<td>62282</td>
<td>CNN, EfficientNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Verbitskiy_DS_task1a_4</td>
<td>Verbitskiy2021</td>
<td>19</td>
<td>0.924</td>
<td>68.1</td>
<td></td>
<td></td>
<td>62346</td>
<td>CNN, EfficientNetV2</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_1</td>
<td>Yang2021</td>
<td>6</td>
<td>0.768</td>
<td>73.1</td>
<td></td>
<td></td>
<td>4410180</td>
<td>Inception</td>
<td>5</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_2</td>
<td>Yang2021</td>
<td>4</td>
<td>0.764</td>
<td>72.9</td>
<td></td>
<td></td>
<td>14640720</td>
<td>Inception</td>
<td>20</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_3</td>
<td>Yang2021</td>
<td>3</td>
<td>0.758</td>
<td>72.9</td>
<td></td>
<td></td>
<td>7056288</td>
<td>Inception</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Yang_GT_task1a_4</td>
<td>Yang2021</td>
<td>7</td>
<td>0.774</td>
<td>72.8</td>
<td></td>
<td></td>
<td>7056288</td>
<td>Inception</td>
<td>8</td>
<td>average</td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_1</td>
<td>Yihao2021</td>
<td>69</td>
<td>1.311</td>
<td>51.9</td>
<td></td>
<td></td>
<td>48075</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_2</td>
<td>Yihao2021</td>
<td>59</td>
<td>1.222</td>
<td>55.2</td>
<td></td>
<td></td>
<td>63244</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Yihao_speakin_task1a_3</td>
<td>Yihao2021</td>
<td>96</td>
<td>2.105</td>
<td>53.5</td>
<td></td>
<td></td>
<td>50952</td>
<td>CNN</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_1</td>
<td>Zhang2021</td>
<td>47</td>
<td>1.124</td>
<td>63.0</td>
<td></td>
<td></td>
<td>83572</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_2</td>
<td>Zhang2021</td>
<td>45</td>
<td>1.113</td>
<td>63.2</td>
<td></td>
<td></td>
<td>83572</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_3</td>
<td>Zhang2021</td>
<td>98</td>
<td>3.359</td>
<td>52.2</td>
<td></td>
<td></td>
<td>87011</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhang_BUPT&amp;BYTEDANCE_task1a_4</td>
<td>Zhang2021</td>
<td>89</td>
<td>1.946</td>
<td>59.0</td>
<td></td>
<td></td>
<td>86516</td>
<td>ResNet</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_1</td>
<td>Zhao2021</td>
<td>75</td>
<td>1.440</td>
<td>61.2</td>
<td></td>
<td></td>
<td>59421</td>
<td>MobileNet</td>
<td>2</td>
<td>model weights average</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_2</td>
<td>Zhao2021</td>
<td>74</td>
<td>1.412</td>
<td>63.5</td>
<td></td>
<td></td>
<td>59421</td>
<td>MobileNet</td>
<td>2</td>
<td>model weights average</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_3</td>
<td>Zhao2021</td>
<td>62</td>
<td>1.227</td>
<td>63.5</td>
<td></td>
<td></td>
<td>59421</td>
<td>MobileNet</td>
<td>2</td>
<td>model weights average</td>
</tr>
<tr>
<td></td>
<td>Zhao_Maxvision_task1a_4</td>
<td>Zhao2021</td>
<td>58</td>
<td>1.215</td>
<td>62.8</td>
<td></td>
<td></td>
<td>59421</td>
<td>MobileNet</td>
<td>2</td>
<td>model weights average</td>
</tr>
</tbody>
</table>
<h1 id="technical-reports">Technical reports</h1>
<div class="btex" data-source="content/data/challenge2021/technical_reports_task1a.bib" data-stats="true">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div aria-multiselectable="true" class="panel-group" id="accordion" role="tablist">
<div class="panel publication-item" id="Byttebier2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Byttebier2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Small-Footprint Acoustic Scene Classification Through 8-Bit Quantization-Aware Training and Pruning of ResNet Models
       </h4>
<p style="text-align:left">
        Laurens Byttebier, Brecht Desplanques, Jenthe Thienpondt, Siyuan Song, Kris Demuynck and Nilesh Madhu
       </p>
<p style="text-align:left">
<em>
         ELIS, Ghent University - imec, Ghent, Belgium
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Byttebier_IDLab_task1a_1</span> <span class="label label-primary">Byttebier_IDLab_task1a_2</span> <span class="label label-primary">Byttebier_IDLab_task1a_3</span> <span class="label label-primary">Byttebier_IDLab_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Byttebier2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Byttebier2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Byttebier2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Byttebier_85_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Byttebier2021" class="panel-collapse collapse" id="collapse-Byttebier2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Small-Footprint Acoustic Scene Classification Through 8-Bit Quantization-Aware Training and Pruning of ResNet Models
      </h4>
<p style="text-align:left">
<small>
        Laurens Byttebier, Brecht Desplanques, Jenthe Thienpondt, Siyuan Song, Kris Demuynck and Nilesh Madhu
       </small>
<br/>
<small>
<em>
         ELIS, Ghent University - imec, Ghent, Belgium
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes the IDLab submissions for Task 1a of the DCASE Challenge 2021. The challenge consists of constructing an acoustic scene classification model with a size of less than 128 KB. All submitted systems consist of a ResNet based model enhanced with Squeeze-and-Excitation (SE) blocks trained with temporal cropping, time domain mixup and speed-change augmentation strategies. Grouped convolutions are incorporated in all models to reduce the model complexity. Three submissions are based on 8-bit quantization-aware training with a fusion of batch norm and convolutional layers to reduce the parameter count even further. Further, two of these three systems explore multi-class score calibration by means of multinomial or one-vs-rest logistic regression. The calibration is then fused with the final linear output layer of the network to avoid an increase in model size. The fourth submission explores parameter pruning on a model with 16-bit weights as an alternative to the 8-bit weight quantization. The uncalibrated 8-bit model out- performs the pruned 16-bit model slightly and achieves a log loss of 0.82 and an accuracy of 71.2% on the standard test set of the TAU Urban Acoustic Scenes 2020 Mobile development dataset.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping, speed augmentation
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         SE-ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         maximum logit; multinomial logistic regression; ovr logistic regression
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, grouped convolutions, Conv+BN fusion; weight quantization, grouped convolutions, pruning
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Byttebier2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Byttebier_85_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Byttebier2021label" class="modal fade" id="bibtex-Byttebier2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexByttebier2021label">
        Small-Footprint Acoustic Scene Classification Through 8-Bit Quantization-Aware Training and Pruning of ResNet Models
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Byttebier2021,
    Author = "Byttebier, Laurens and Desplanques, Brecht and Thienpondt, Jenthe and Song, Siyuan and Demuynck, Kris and Madhu, Nilesh",
    title = "Small-Footprint Acoustic Scene Classification Through 8-Bit Quantization-Aware Training and Pruning of {ResNet} Models",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This report describes the IDLab submissions for Task 1a of the DCASE Challenge 2021. The challenge consists of constructing an acoustic scene classification model with a size of less than 128 KB. All submitted systems consist of a ResNet based model enhanced with Squeeze-and-Excitation (SE) blocks trained with temporal cropping, time domain mixup and speed-change augmentation strategies. Grouped convolutions are incorporated in all models to reduce the model complexity. Three submissions are based on 8-bit quantization-aware training with a fusion of batch norm and convolutional layers to reduce the parameter count even further. Further, two of these three systems explore multi-class score calibration by means of multinomial or one-vs-rest logistic regression. The calibration is then fused with the final linear output layer of the network to avoid an increase in model size. The fourth submission explores parameter pruning on a model with 16-bit weights as an alternative to the 8-bit weight quantization. The uncalibrated 8-bit model out- performs the pruned 16-bit model slightly and achieves a log loss of 0.82 and an accuracy of 71.2\% on the standard test set of the TAU Urban Acoustic Scenes 2020 Mobile development dataset."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Cao2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Cao2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Using Lightweight ResNet with Attention
       </h4>
<p style="text-align:left">
        Wenchang Cao, Yanxiong Li and Qisheng Huang
       </p>
<p style="text-align:left">
<em>
         School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Cao_SCUT_task1a_1</span> <span class="label label-primary">Cao_SCUT_task1a_2</span> <span class="label label-primary">Cao_SCUT_task1a_3</span> <span class="label label-primary">Cao_SCUT_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Cao2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Cao2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Cao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Cao_11_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Cao2021" class="panel-collapse collapse" id="collapse-Cao2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Using Lightweight ResNet with Attention
      </h4>
<p style="text-align:left">
<small>
        Wenchang Cao, Yanxiong Li and Qisheng Huang
       </small>
<br/>
<small>
<em>
         School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our system for the subtask A (Low-Complexity Acoustic Scene Classification with Multiple Devices) of Task1 (Acoustic Scene Classification) of the DCASE2021 Challenge. Due to the limited space-complexity of the model, we choose ResNet with depthwise separable convolution as our backbone network, and introduce the attention mechanism to the network. In addition, some data augmentation techniques, such as Mixup, Spectrum correction, are adopted for expanding the diversities of dataset. Our system achieves the accuracy rate of 71.6% on the development dataset, and the model size meets the requirement of subtask A.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time stretching,pitch shifting,spectrum correction
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Cao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Cao_11_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Cao2021label" class="modal fade" id="bibtex-Cao2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexCao2021label">
        Acoustic Scene Classification Using Lightweight ResNet with Attention
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Cao2021,
    Author = "Cao, Wenchang and Li, Yanxiong and Huang, Qisheng",
    title = "Acoustic Scene Classification Using Lightweight {ResNet} with Attention",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our system for the subtask A (Low-Complexity Acoustic Scene Classification with Multiple Devices) of Task1 (Acoustic Scene Classification) of the DCASE2021 Challenge. Due to the limited space-complexity of the model, we choose ResNet with depthwise separable convolution as our backbone network, and introduce the attention mechanism to the network. In addition, some data augmentation techniques, such as Mixup, Spectrum correction, are adopted for expanding the diversities of dataset. Our system achieves the accuracy rate of 71.6\% on the development dataset, and the model size meets the requirement of subtask A."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Cui2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Cui2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Consistency Learning Based Acoustic Scene Classification with Res-Attention
       </h4>
<p style="text-align:left">
        MengFan Cui, Fan Kui and Liyong Guo
       </p>
<p style="text-align:left">
<em>
         Northwestern Polytechnic University, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Fan_NWPU_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Cui2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Cui2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Cui2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Fan_63_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Cui2021" class="panel-collapse collapse" id="collapse-Cui2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Consistency Learning Based Acoustic Scene Classification with Res-Attention
      </h4>
<p style="text-align:left">
<small>
        MengFan Cui, Fan Kui and Liyong Guo
       </small>
<br/>
<small>
<em>
         Northwestern Polytechnic University, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we propose a consistency learning based method with different data augmentation methods to tackle Acoustic Scene Classification task1a in the DCASE2021 Challenge. Classification of data from multiple devices (real and simulated) targeting generalization properties of systems across a number of different devices and focusing on low- complexity solutions. Consistency learning is used to reduce the embedding distance of the augmented sample and the original sample. With the consistency learning, the algorithm is robust with device variances. For low-complexity and high-accuracy, a Res-Attention structure which combines residual structure with separable convolution layer and attention layer is proposed. On Task1a development dataset, the presented method gets 69.71% accuracy (0.87 log CrossEntropy loss) with the model size 93.3KB by using int8 quantization.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         reverb, filtering, random gain adjust, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet, Attention
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Cui2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Fan_63_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Cui2021label" class="modal fade" id="bibtex-Cui2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexCui2021label">
        Consistency Learning Based Acoustic Scene Classification with Res-Attention
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Cui2021,
    Author = "Cui, MengFan and Kui, Fan and Guo, Liyong",
    title = "Consistency Learning Based Acoustic Scene Classification with Res-Attention",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "In this report, we propose a consistency learning based method with different data augmentation methods to tackle Acoustic Scene Classification task1a in the DCASE2021 Challenge. Classification of data from multiple devices (real and simulated) targeting generalization properties of systems across a number of different devices and focusing on low- complexity solutions. Consistency learning is used to reduce the embedding distance of the augmented sample and the original sample. With the consistency learning, the algorithm is robust with device variances. For low-complexity and high-accuracy, a Res-Attention structure which combines residual structure with separable convolution layer and attention layer is proposed. On Task1a development dataset, the presented method gets 69.71\% accuracy (0.87 log CrossEntropy loss) with the model size 93.3KB by using int8 quantization."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Ding2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Ding2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification Using Simple CNN
       </h4>
<p style="text-align:left">
        Biyun Ding
       </p>
<p style="text-align:left">
<em>
         School of Electrical and Information Engineering, Tianjin University, Tianjin, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Ding_TJU_task1a_1</span> <span class="label label-primary">Ding_TJU_task1a_2</span> <span class="label label-primary">Ding_TJU_task1a_3</span> <span class="label label-primary">Ding_TJU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Ding2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Ding2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Ding2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Ding_28_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Ding2021" class="panel-collapse collapse" id="collapse-Ding2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification Using Simple CNN
      </h4>
<p style="text-align:left">
<small>
        Biyun Ding
       </small>
<br/>
<small>
<em>
         School of Electrical and Information Engineering, Tianjin University, Tianjin, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our Acoustic Scene Classification systems for DCASE2021 challenge Task1A: Low-Complexity Acoustic Scene Classification with Multiple Devices. In this work, many factors affect the performance. To improve the performance while ensure the model complexity, we attempt different methods in term of features, sampling rate, channel, classifier type, the network architecture of CNN, and the post- processing of predictions. According to the experiments on TAU urban acoustic scenes 2020 mobile development dataset, the best accuracy of single system we implemented is 55.89%, which is an improvement of 7% compared to Baseline CNN. Besides, the accuracy of the late fusion is 59.80%, which is an improvement of 11.35% compared to Baseline CNN.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         majority vote
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Ding2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Ding_28_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Ding2021label" class="modal fade" id="bibtex-Ding2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexDing2021label">
        Low-Complexity Acoustic Scene Classification Using Simple CNN
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Ding2021,
    Author = "Ding, Biyun",
    title = "Low-Complexity Acoustic Scene Classification Using Simple {CNN}",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our Acoustic Scene Classification systems for DCASE2021 challenge Task1A: Low-Complexity Acoustic Scene Classification with Multiple Devices. In this work, many factors affect the performance. To improve the performance while ensure the model complexity, we attempt different methods in term of features, sampling rate, channel, classifier type, the network architecture of CNN, and the post- processing of predictions. According to the experiments on TAU urban acoustic scenes 2020 mobile development dataset, the best accuracy of single system we implemented is 55.89\%, which is an improvement of 7\% compared to Baseline CNN. Besides, the accuracy of the late fusion is 59.80\%, which is an improvement of 11.35\% compared to Baseline CNN."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Galindo-Meza2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Galindo-Meza2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        End-To-End CNN Optimization for Low-Complexity Acoustic Scene Classification in the DCASE 2021 Challenge
       </h4>
<p style="text-align:left">
        Carlos Alberto Galindo-Meza<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>2</sup>, Jose Torres Ortega<sup>3</sup> and Paulo Lopez-Meyer<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Departamento de Electronica, Sistemas e Informatica, Instituto Tecnologico de Estudios Superiores de Occidente, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>3</sup>Intel Labs, Intel Corporation, California, USA
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Galindo-Meza_ITESO_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Galindo-Meza2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Galindo-Meza2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Galindo-Meza2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Galindo-Meza_39_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Galindo-Meza2021" class="panel-collapse collapse" id="collapse-Galindo-Meza2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       End-To-End CNN Optimization for Low-Complexity Acoustic Scene Classification in the DCASE 2021 Challenge
      </h4>
<p style="text-align:left">
<small>
        Carlos Alberto Galindo-Meza<sup>1</sup>, Juan Antonio Del Hoyo Ontiveros<sup>2</sup>, Jose Torres Ortega<sup>3</sup> and Paulo Lopez-Meyer<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Departamento de Electronica, Sistemas e Informatica, Instituto Tecnologico de Estudios Superiores de Occidente, Jalisco, Mexico, <sup>2</sup>Intel Labs, Intel Corporation, Jalisco, Mexico, <sup>3</sup>Intel Labs, Intel Corporation, California, USA
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       For the DCASE 2021 challenge we implemented an optimization pipeline to comply with the low-complexity restrictions specified with the Task 1a constraints. Initially, we trained and validated an end-to-end convolutional neural networks-based audio classification model following a typical deep learning training strategy. We then applied an efficient pruning procedure based on the lottery ticket hypothesis, and finally we executed a training-aware quantization to convert the model’s weights from FP32 to INT8 format. Experimentation proved the feasibility of this approach by obtaining accuracy results above the baseline models reported in the challenge guidelines.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         random noise, random gain, random cropping, mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         raw waveform
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         AemNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         Maximum softmax
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         pruning, int8 weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Galindo-Meza2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Galindo-Meza_39_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Galindo-Meza2021label" class="modal fade" id="bibtex-Galindo-Meza2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexGalindo-Meza2021label">
        End-To-End CNN Optimization for Low-Complexity Acoustic Scene Classification in the DCASE 2021 Challenge
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Galindo-Meza2021,
    Author = "Galindo-Meza, Carlos Alberto and Del Hoyo Ontiveros, Juan Antonio and Torres Ortega, Jose and Lopez-Meyer, Paulo",
    title = "End-To-End {CNN} Optimization for Low-Complexity Acoustic Scene Classification in the {DCASE} 2021 Challenge",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "For the DCASE 2021 challenge we implemented an optimization pipeline to comply with the low-complexity restrictions specified with the Task 1a constraints. Initially, we trained and validated an end-to-end convolutional neural networks-based audio classification model following a typical deep learning training strategy. We then applied an efficient pruning procedure based on the lottery ticket hypothesis, and finally we executed a training-aware quantization to convert the model’s weights from FP32 to INT8 format. Experimentation proved the feasibility of this approach by obtaining accuracy results above the baseline models reported in the challenge guidelines."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Hee-Soo2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Hee-Soo2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Clova Submission for the DCASE 2021 Challenge: Acoustic Scene Classification Using Light Architectures and Device Augmentation
       </h4>
<p style="text-align:left">
        Heo Hee-Soo<sup>1</sup>, Jung Jee-weon<sup>1</sup>, Shim Hye-jin<sup>2</sup> and Lee Bong-Jin<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Naver Corporation, Seongnam, South Korea, <sup>2</sup>Computer Science, University of Seoul, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Heo_Clova_task1a_1</span> <span class="label label-primary">Heo_Clova_task1a_2</span> <span class="label label-primary">Heo_Clova_task1a_3</span> <span class="label label-primary">Heo_Clova_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Hee-Soo2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Hee-Soo2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Hee-Soo2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Heo_30_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Hee-Soo2021" class="panel-collapse collapse" id="collapse-Hee-Soo2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Clova Submission for the DCASE 2021 Challenge: Acoustic Scene Classification Using Light Architectures and Device Augmentation
      </h4>
<p style="text-align:left">
<small>
        Heo Hee-Soo<sup>1</sup>, Jung Jee-weon<sup>1</sup>, Shim Hye-jin<sup>2</sup> and Lee Bong-Jin<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Naver Corporation, Seongnam, South Korea, <sup>2</sup>Computer Science, University of Seoul, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report addresses the submitted system of Naver Clova for the DCASE 2021 challenge task 1-a. The aim is to develop an acoustic scene classification system that can generalize towards unknown devices using a DNN with a limited number of parameters. We propose two lightweight architectures using residual networks, a method referred to as attentive max feature map, and multitask learning. After the initial training, the model is further fine-tuned using knowledge distillation. Two augmentation methods are also explored to simulate various recording devices. The proposed two architectures have 63,547 and 65,424 non-zeros parameters with a 16-bit resolution, both less than 128KB. Following the official protocol of train and test set split from the TAU Urban Acoustic Scenes 2020 Mobile development dataset, each model achieves 70.48% and 69.68% accuracy respectively.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, spectrum augmentation, device augmentation; mixup, tempo, channel corruption
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Hee-Soo2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Heo_30_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Hee-Soo2021label" class="modal fade" id="bibtex-Hee-Soo2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHee-Soo2021label">
        Clova Submission for the DCASE 2021 Challenge: Acoustic Scene Classification Using Light Architectures and Device Augmentation
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Hee-Soo2021,
    Author = "Hee-Soo, Heo and Jee-weon, Jung and Hye-jin, Shim and Bong-Jin, Lee",
    title = "Clova Submission for the {DCASE} 2021 Challenge: Acoustic Scene Classification Using Light Architectures and Device Augmentation",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report addresses the submitted system of Naver Clova for the DCASE 2021 challenge task 1-a. The aim is to develop an acoustic scene classification system that can generalize towards unknown devices using a DNN with a limited number of parameters. We propose two lightweight architectures using residual networks, a method referred to as attentive max feature map, and multitask learning. After the initial training, the model is further fine-tuned using knowledge distillation. Two augmentation methods are also explored to simulate various recording devices. The proposed two architectures have 63,547 and 65,424 non-zeros parameters with a 16-bit resolution, both less than 128KB. Following the official protocol of train and test set split from the TAU Urban Acoustic Scenes 2020 Mobile development dataset, each model achieves 70.48\% and 69.68\% accuracy respectively."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Horvth2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Horvth2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Using Arcface Metric Learning for Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Kristóf Horváth, Harsh Purohit, Yohei Kawaguchi, Ryo Tanabe, Kota Dohi, Takashi Endo, Masaaki Yamamoto and Tomoya Nishida
       </p>
<p style="text-align:left">
<em>
         Hitachi Ltd., Tokyo, Japan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Horváth_HIT_task1a_1</span> <span class="label label-primary">Horváth_HIT_task1a_2</span> <span class="label label-primary">Horváth_HIT_task1a_3</span> <span class="label label-primary">Horváth_HIT_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Horvth2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Horvth2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Horvth2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Horváth_47_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Horvth2021').collapse('show');window.location.hash='#Horvth2021';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Horvth2021" class="panel-collapse collapse" id="collapse-Horvth2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Using Arcface Metric Learning for Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Kristóf Horváth, Harsh Purohit, Yohei Kawaguchi, Ryo Tanabe, Kota Dohi, Takashi Endo, Masaaki Yamamoto and Tomoya Nishida
       </small>
<br/>
<small>
<em>
         Hitachi Ltd., Tokyo, Japan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report we present our submissions for DCASE 2021 Challenge Task 1A. For the low-complexity model, we used both a MobileNetV2-based model and a ResNet-based model with reduced number of layers and trained it using ArcFace metric learning. To increase the accuracy, we used test-time augmentation (TTA) during inference. On the development dataset, our models attain an ASC accuracy of around 54–55%, while having less than 128 kB of total parameters.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, time stretching, pitch shifting, random noise, spectrum augmentation, random temporal shuffle, volume change
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, HPSS
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MobileNetV2; MobileNetV2, ArcFace; ResNet; ResNet, ArcFace
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Horvth2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Horváth_47_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/hekkelek/DCASE2021_task1a" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Horvth2021label" class="modal fade" id="bibtex-Horvth2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexHorvth2021label">
        Using Arcface Metric Learning for Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Horvth2021,
    Author = "Horváth, Kristóf and Purohit, Harsh and Kawaguchi, Yohei and Tanabe, Ryo and Dohi, Kota and Endo, Takashi and Yamamoto, Masaaki and Nishida, Tomoya",
    title = "Using Arcface Metric Learning for Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "In this technical report we present our submissions for DCASE 2021 Challenge Task 1A. For the low-complexity model, we used both a MobileNetV2-based model and a ResNet-based model with reduced number of layers and trained it using ArcFace metric learning. To increase the accuracy, we used test-time augmentation (TTA) during inference. On the development dataset, our models attain an ASC accuracy of around 54–55\%, while having less than 128 kB of total parameters."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Jeng2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Jeng2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Diverse Sparsity System Using Convolution Neural Network
       </h4>
<p style="text-align:left">
        Hui Hsin Jeng<sup>1</sup>, Chia-Ping Chen<sup>1</sup>, Chung Li Lu<sup>2</sup> and Bo-Cheng Chan<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan, <sup>2</sup>Chunghwa Telecom, Taoyuan, Taiwan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Jeng_CHT+NSYSU_task1a_1</span> <span class="label label-primary">Jeng_CHT+NSYSU_task1a_2</span> <span class="label label-primary">Jeng_CHT+NSYSU_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Jeng2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Jeng2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Jeng2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Jeng_50_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Jeng2021" class="panel-collapse collapse" id="collapse-Jeng2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Diverse Sparsity System Using Convolution Neural Network
      </h4>
<p style="text-align:left">
<small>
        Hui Hsin Jeng<sup>1</sup>, Chia-Ping Chen<sup>1</sup>, Chung Li Lu<sup>2</sup> and Bo-Cheng Chan<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan, <sup>2</sup>Chunghwa Telecom, Taoyuan, Taiwan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we present our works on pruning convolution neural networks and using the quantization method to reduce parameters. DCASE2021 subtask 1A limit classifier size smaller than DCASE2020 subtask 1B with only 128 KB. Therefore we propose three pruning and quantization methods on Convolution Neural Networks. To prune the bigger network ( FCNN ) with single sparsity or diverse sparsity and quantization method. Another proposed method is simply pruning a smaller network ( MobNet ) with single sparsity and quantization method. Our best system performs 1.428 on validation log loss.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         logistical regression
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         sparsity, weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Jeng2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Jeng_50_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Jeng2021label" class="modal fade" id="bibtex-Jeng2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJeng2021label">
        Diverse Sparsity System Using Convolution Neural Network
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Jeng2021,
    Author = "Jeng, Hui Hsin and Chen, Chia-Ping and Lu, Chung Li and Chan, Bo-Cheng",
    title = "Diverse Sparsity System Using Convolution Neural Network",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "In this technical report, we present our works on pruning convolution neural networks and using the quantization method to reduce parameters. DCASE2021 subtask 1A limit classifier size smaller than DCASE2020 subtask 1B with only 128 KB. Therefore we propose three pruning and quantization methods on Convolution Neural Networks. To prune the bigger network ( FCNN ) with single sparsity or diverse sparsity and quantization method. Another proposed method is simply pruning a smaller network ( MobNet ) with single sparsity and quantization method. Our best system performs 1.428 on validation log loss."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Jeong2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Jeong2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Trident Resnets with Low Complexity for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Youngho Jeong, Sooyoung Park and Taejin Lee
       </p>
<p style="text-align:left">
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Jeong_ETRI_task1a_1</span> <span class="label label-primary">Jeong_ETRI_task1a_2</span> <span class="label label-primary">Jeong_ETRI_task1a_3</span> <span class="label label-primary">Jeong_ETRI_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Jeong2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Jeong2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Jeong2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Jeong_58_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Jeong2021" class="panel-collapse collapse" id="collapse-Jeong2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Trident Resnets with Low Complexity for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Youngho Jeong, Sooyoung Park and Taejin Lee
       </small>
<br/>
<small>
<em>
         Media Coding Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our Acoustic Scene Classification systems for DCASE2021 challenge Task1 subtask A. We designed two Trident ResNets with three parallel path, which is targeted to low complexity. The trident structure with respect to the frequency domain is beneficial when analyzing samples collected from minority or unseen devices. To satisfy the model size requirement, we replaced a standard convolution with a depthwise separable convolution and applied weight quantization to the trained model. As a result of performance evaluation, Trident ResNet B trained by applying data augmentation showed a log loss of 0.968 and a classification accuracy of 65.8% for the test split.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         temporal cropping; temporal cropping, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, depthwise separable convolutions
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Jeong2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Jeong_58_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Jeong2021label" class="modal fade" id="bibtex-Jeong2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexJeong2021label">
        Trident Resnets with Low Complexity for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Jeong2021,
    Author = "Jeong, Youngho and Park, Sooyoung and Lee, Taejin",
    title = "Trident Resnets with Low Complexity for Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our Acoustic Scene Classification systems for DCASE2021 challenge Task1 subtask A. We designed two Trident ResNets with three parallel path, which is targeted to low complexity. The trident structure with respect to the frequency domain is beneficial when analyzing samples collected from minority or unseen devices. To satisfy the model size requirement, we replaced a standard convolution with a depthwise separable convolution and applied weight quantization to the trained model. As a result of performance evaluation, Trident ResNet B trained by applying data augmentation showed a log loss of 0.968 and a classification accuracy of 65.8\% for the test split."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kek2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Kek2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Technical Paper: Deep Scattering Spectrum with Mobile Network for Low Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Xing Yong Kek<sup>1</sup>, Cheng Siong Chin<sup>1</sup> and Li Ye<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Faculty if Science, Agriculture &amp; Engineering, Newcastle University, Singapore, <sup>2</sup>Xylem Inc, Singapore
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kek_NU_task1a_1</span> <span class="label label-primary">Kek_NU_task1a_2</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kek2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kek2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kek2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kek_73_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kek2021" class="panel-collapse collapse" id="collapse-Kek2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Technical Paper: Deep Scattering Spectrum with Mobile Network for Low Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Xing Yong Kek<sup>1</sup>, Cheng Siong Chin<sup>1</sup> and Li Ye<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Faculty if Science, Agriculture &amp; Engineering, Newcastle University, Singapore, <sup>2</sup>Xylem Inc, Singapore
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We present a technical paper that provide details of our classification model submitted to DCASE 2021 Task1a challenge. In this paper, we proposed the use of DSS with mobile network to tackle low complexity computation.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Wavelet Scattering
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, MobileNetV2; CNN, MobileNetV2, Group convolution, Channel attention
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kek2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kek_73_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kek2021label" class="modal fade" id="bibtex-Kek2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKek2021label">
        Technical Paper: Deep Scattering Spectrum with Mobile Network for Low Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kek2021,
    Author = "Kek, Xing Yong and Chin, Cheng Siong and Ye, Li",
    title = "Technical Paper: Deep Scattering Spectrum with Mobile Network for Low Complexity Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "We present a technical paper that provide details of our classification model submitted to DCASE 2021 Task1a challenge. In this paper, we proposed the use of DSS with mobile network to tackle low complexity computation."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kim2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Kim2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Building Light-Weight Convolutional Neural Networks for Acoustic Scene Classification Using Audio Embeddings
       </h4>
<p style="text-align:left">
        Bongjun Kim
       </p>
<p style="text-align:left">
<em>
         3M, Saint Paul, United States
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kim_3M_task1a_1</span> <span class="label label-primary">Kim_3M_task1a_2</span> <span class="label label-primary">Kim_3M_task1a_3</span> <span class="label label-primary">Kim_3M_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kim2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kim2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kim2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_35_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kim2021" class="panel-collapse collapse" id="collapse-Kim2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Building Light-Weight Convolutional Neural Networks for Acoustic Scene Classification Using Audio Embeddings
      </h4>
<p style="text-align:left">
<small>
        Bongjun Kim
       </small>
<br/>
<small>
<em>
         3M, Saint Paul, United States
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes acoustic scene classification mod- els from our submissions for DCASE challenge 2021-task1A. The task is to build a system to perform classification on acoustic scene data. The dataset has 10 acoustic scene labels. Our submissions are Convolutional Neural Network (CNN)-based models which consist of 3 convolutional layers and 1 fully-connected layer. We utilize a small subset of deep audio embedding that has been pre-trained on a large scale of a dataset. We also perform quantization and pruning to reduce the complexity of models to meet the size limit of 128KB for the challenge. We compare the performance of our models with the baseline approach on the provided test dataset. The results show that our models outperform the baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Perceptually-weighted log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Embeddings
        </td>
<td>
         VGGish
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, pruning
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kim2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_35_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kim2021label" class="modal fade" id="bibtex-Kim2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKim2021label">
        Building Light-Weight Convolutional Neural Networks for Acoustic Scene Classification Using Audio Embeddings
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kim2021,
    Author = "Kim, Bongjun",
    title = "Building Light-Weight Convolutional Neural Networks for Acoustic Scene Classification Using Audio Embeddings",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes acoustic scene classification mod- els from our submissions for DCASE challenge 2021-task1A. The task is to build a system to perform classification on acoustic scene data. The dataset has 10 acoustic scene labels. Our submissions are Convolutional Neural Network (CNN)-based models which consist of 3 convolutional layers and 1 fully-connected layer. We utilize a small subset of deep audio embedding that has been pre-trained on a large scale of a dataset. We also perform quantization and pruning to reduce the complexity of models to meet the size limit of 128KB for the challenge. We compare the performance of our models with the baseline approach on the provided test dataset. The results show that our models outperform the baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kim2021a" style="box-shadow: none">
<div class="panel-heading" id="heading-Kim2021a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification with Decomposed Convolution Neural Networks
       </h4>
<p style="text-align:left">
        Minhan Kim<sup>1</sup>, SeungHyeon Shin<sup>1</sup>, Seungjae Baek<sup>1</sup>, Seokjin Lee<sup>2</sup>, Sooyoung Park<sup>3</sup> and Youngho Jeong<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, Republic of Korea, <sup>2</sup>School of Electronics Engineering, School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, Republic of Korea, <sup>3</sup>Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kim_KNU_task1a_1</span> <span class="label label-primary">Kim_KNU_task1a_2</span> <span class="label label-primary">Kim_KNU_task1a_3</span> <span class="label label-primary">Kim_KNU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kim2021a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kim2021a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kim2021a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_46_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kim2021a" class="panel-collapse collapse" id="collapse-Kim2021a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification with Decomposed Convolution Neural Networks
      </h4>
<p style="text-align:left">
<small>
        Minhan Kim<sup>1</sup>, SeungHyeon Shin<sup>1</sup>, Seungjae Baek<sup>1</sup>, Seokjin Lee<sup>2</sup>, Sooyoung Park<sup>3</sup> and Youngho Jeong<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, Republic of Korea, <sup>2</sup>School of Electronics Engineering, School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, Republic of Korea, <sup>3</sup>Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes a model submitted to DCASE2021 Task 1 sub- task A. Our model is developed by applying canonical polyadic decomposition to the conventional convolutional-neural-network- based models to reduce the model size to achieve the goal of Task 1A. More specifically, we apply the decomposition method to dual ResNet, which divides the features into two parts along the frequency axis and processes them independently, and shallow inception model. In order to evaluate our model, a simulation for acoustic scene classification was performed with the development dataset of DCASE 2021 Task 1A, and our model showed about log loss of 1.03-1.06 and macro accuracy of 62%-66% far better than that of the baseline model. Also, the model size of our system is smaller than 128 kbytes, which is the limit of the DCASE2021 Task 1A.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, delta-log-mel energies, delta-delta-log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; CNN (Inception)
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         CP-decomposition, weight quantization; parameter sharing, weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kim2021a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_46_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kim2021alabel" class="modal fade" id="bibtex-Kim2021a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKim2021alabel">
        Acoustic Scene Classification with Decomposed Convolution Neural Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kim2021a,
    Author = "Kim, Minhan and Shin, SeungHyeon and Baek, Seungjae and Lee, Seokjin and Park, Sooyoung and Jeong, Youngho",
    title = "Acoustic Scene Classification with Decomposed Convolution Neural Networks",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This report describes a model submitted to DCASE2021 Task 1 sub- task A. Our model is developed by applying canonical polyadic decomposition to the conventional convolutional-neural-network- based models to reduce the model size to achieve the goal of Task 1A. More specifically, we apply the decomposition method to dual ResNet, which divides the features into two parts along the frequency axis and processes them independently, and shallow inception model. In order to evaluate our model, a simulation for acoustic scene classification was performed with the development dataset of DCASE 2021 Task 1A, and our model showed about log loss of 1.03-1.06 and macro accuracy of 62\%-66\% far better than that of the baseline model. Also, the model size of our system is smaller than 128 kbytes, which is the limit of the DCASE2021 Task 1A."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Kim2021b" style="box-shadow: none">
<div class="panel-heading" id="heading-Kim2021b" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        QTI Submission to DCASE 2021: Residual Normalization for Device-Imbalanced Acoustic Scene Classification with Efficient Design
       </h4>
<p style="text-align:left">
        Byeonggeun Kim, Seunghan Yang, Jangho Kim and Simyung Chang
       </p>
<p style="text-align:left">
<em>
         Qualcomm AI Research, Qualcomm Korea YH, Seoul, Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Kim_QTI_task1a_1</span> <span class="label label-primary">Kim_QTI_task1a_2</span> <span class="label label-primary">Kim_QTI_task1a_3</span> <span class="label label-primary">Kim_QTI_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Kim2021b" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Kim2021b" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Kim2021b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_36_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Kim2021b" class="panel-collapse collapse" id="collapse-Kim2021b" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       QTI Submission to DCASE 2021: Residual Normalization for Device-Imbalanced Acoustic Scene Classification with Efficient Design
      </h4>
<p style="text-align:left">
<small>
        Byeonggeun Kim, Seunghan Yang, Jangho Kim and Simyung Chang
       </small>
<br/>
<small>
<em>
         Qualcomm AI Research, Qualcomm Korea YH, Seoul, Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the details of our TASK1A submission of the DCASE2021 challenge. The goal of the task is to design an audio scene classification system for device-imbalanced datasets under the constraints of model complexity. This report introduces four methods to achieve the goal. First, we propose Residual Normalization, a novel feature normalization method that uses instance normalization with a shortcut path to discard unnecessary device- specific information without losing useful information for classification. Second, we design an efficient architecture, BC-ResNet- Mod, a modified version of the baseline architecture with a limited receptive field. Third, we exploit spectrogram-to-spectrogram translation from one to multiple devices to augment training data. Finally, we utilize three model compression schemes: pruning, quantization, and knowledge distillation to reduce model complexity. The proposed system achieves an average test accuracy of 76.3% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with 315k parameters, and average test accuracy of 75.3% after compression to 62kB of non-zero parameters.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, specaugment, time rolling
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, BC-ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         maximum likelihood
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, pruning, knowledge distillation
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Kim2021b" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Kim_36_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Kim2021blabel" class="modal fade" id="bibtex-Kim2021b" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKim2021blabel">
        QTI Submission to DCASE 2021: Residual Normalization for Device-Imbalanced Acoustic Scene Classification with Efficient Design
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Kim2021b,
    Author = "Kim, Byeonggeun and Yang, Seunghan and Kim, Jangho and Chang, Simyung",
    title = "{QTI} Submission to {DCASE} 2021: Residual Normalization for Device-Imbalanced Acoustic Scene Classification with Efficient Design",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes the details of our TASK1A submission of the DCASE2021 challenge. The goal of the task is to design an audio scene classification system for device-imbalanced datasets under the constraints of model complexity. This report introduces four methods to achieve the goal. First, we propose Residual Normalization, a novel feature normalization method that uses instance normalization with a shortcut path to discard unnecessary device- specific information without losing useful information for classification. Second, we design an efficient architecture, BC-ResNet- Mod, a modified version of the baseline architecture with a limited receptive field. Third, we exploit spectrogram-to-spectrogram translation from one to multiple devices to augment training data. Finally, we utilize three model compression schemes: pruning, quantization, and knowledge distillation to reduce model complexity. The proposed system achieves an average test accuracy of 76.3\% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with 315k parameters, and average test accuracy of 75.3\% after compression to 62kB of non-zero parameters."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Koutini2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Koutini2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Cpjku Submission to Dcase21: Cross-Device Audio Scene Classification with Wide Sparse Frequency-Damped CNNs
       </h4>
<p style="text-align:left">
        Khaled Koutini<sup>1</sup>, Schlüter Jan<sup>2</sup> and Gerhard Widmer<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Computational Perception (CP), Johannes Kepler University (JKU) Linz, Linz, Austria, <sup>2</sup>Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Koutini_CPJKU_task1a_1</span> <span class="label label-primary">Koutini_CPJKU_task1a_2</span> <span class="label label-primary">Koutini_CPJKU_task1a_3</span> <span class="label label-primary">Koutini_CPJKU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Koutini2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Koutini2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Koutini2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Koutini_112_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Koutini2021').collapse('show');window.location.hash='#Koutini2021';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Koutini2021" class="panel-collapse collapse" id="collapse-Koutini2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Cpjku Submission to Dcase21: Cross-Device Audio Scene Classification with Wide Sparse Frequency-Damped CNNs
      </h4>
<p style="text-align:left">
<small>
        Khaled Koutini<sup>1</sup>, Schlüter Jan<sup>2</sup> and Gerhard Widmer<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Computational Perception (CP), Johannes Kepler University (JKU) Linz, Linz, Austria, <sup>2</sup>Institute of Computational Perception, Johannes Kepler University Linz, Linz, Austria
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We describe the CP-JKU team's submission for Task 1A Low- Complexity Acoustic Scene Classification with Multiple Devices of the DCASE2021 Challenge. We use Receptive Field (RF) regularized Convolutional Neural Network (CNN) with Frequency Damping as a baseline. We investigate widening the convolutional layers without increasing the number of parameters by grouping and pruning. We apply iterative magnitude pruning to sparsify the weights of the models. Additionally, We investigate an adversarial domain adaptation approach.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         22.05kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, pitch shifting
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         Perceptually-weighted log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         RF-regularized CNNs
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         float16, sparsity
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Koutini2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Koutini_112_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/kkoutini/cpjku_dcase21" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Koutini2021label" class="modal fade" id="bibtex-Koutini2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexKoutini2021label">
        Cpjku Submission to Dcase21: Cross-Device Audio Scene Classification with Wide Sparse Frequency-Damped CNNs
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Koutini2021,
    Author = "Koutini, Khaled and Jan, Schlüter and Widmer, Gerhard",
    title = "Cpjku Submission to Dcase21: Cross-Device Audio Scene Classification with Wide Sparse Frequency-Damped {CNNs}",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "We describe the CP-JKU team's submission for Task 1A Low- Complexity Acoustic Scene Classification with Multiple Devices of the DCASE2021 Challenge. We use Receptive Field (RF) regularized Convolutional Neural Network (CNN) with Frequency Damping as a baseline. We investigate widening the convolutional layers without increasing the number of parameters by grouping and pruning. We apply iterative magnitude pruning to sparsify the weights of the models. Additionally, We investigate an adversarial domain adaptation approach."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Lim2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Lim2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        CAU-ET Submission to DCASE 2021: Light-Efficientnet for Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Soyoung Lim<sup>1</sup>, Yerin Lee<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Statistics Dept., Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Lim_CAU_task1a_1</span> <span class="label label-primary">Lim_CAU_task1a_2</span> <span class="label label-primary">Lim_CAU_task1a_3</span> <span class="label label-primary">Lim_CAU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Lim2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Lim2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Lim2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Lim_123_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Lim2021" class="panel-collapse collapse" id="collapse-Lim2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       CAU-ET Submission to DCASE 2021: Light-Efficientnet for Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Soyoung Lim<sup>1</sup>, Yerin Lee<sup>1</sup> and Il-Youp Kwak<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Statistics Dept., Chung-Ang University, Seoul, South Korea, <sup>2</sup>Department of Applied Statistics, Chung-Ang University, Seoul, South Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). We presents the solution to Task 1 A (Low- Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 challenge submitted by the Chung-Ang University team. We proposed light-efficientnet model with 3 scaling factors: width, depth, resolution. Additionally, we used lightweight deep learning techniques such as pruning and quantization.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, sparsity
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Lim2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Lim_123_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Lim2021label" class="modal fade" id="bibtex-Lim2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLim2021label">
        CAU-ET Submission to DCASE 2021: Light-Efficientnet for Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Lim2021,
    Author = "Lim, Soyoung and Lee, Yerin and Kwak, Il-Youp",
    title = "{CAU-ET} Submission to {DCASE} 2021: Light-Efficientnet for Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "Acoustic scene classification (ASC) categorizes an audio file based on the environment in which it has been recorded. This has long been studied in the detection and classification of acoustic scenes and events (DCASE). We presents the solution to Task 1 A (Low- Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 challenge submitted by the Chung-Ang University team. We proposed light-efficientnet model with 3 scaling factors: width, depth, resolution. Additionally, we used lightweight deep learning techniques such as pruning and quantization."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Liu2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Liu2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Yingzi Liu<sup>1</sup>, Jiangnan Liang<sup>1</sup>, Luojun Zhao<sup>2</sup>, Jia Liu<sup>2</sup>, Kexin Zhao<sup>2</sup>, Weiyu Liu<sup>2</sup>, Long Zhang<sup>2</sup>, Tanyue Xu<sup>2</sup> and Chuang Shi<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of imformation and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>2</sup>University of Electronic Science and Technology of China, Chengdu,China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Liu_UESTC_task1a_1</span> <span class="label label-primary">Liu_UESTC_task1a_2</span> <span class="label label-primary">Liu_UESTC_task1a_3</span> <span class="label label-primary">Liu_UESTC_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Liu2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Liu2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Liu2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Liu_62_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Liu2021" class="panel-collapse collapse" id="collapse-Liu2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Yingzi Liu<sup>1</sup>, Jiangnan Liang<sup>1</sup>, Luojun Zhao<sup>2</sup>, Jia Liu<sup>2</sup>, Kexin Zhao<sup>2</sup>, Weiyu Liu<sup>2</sup>, Long Zhang<sup>2</sup>, Tanyue Xu<sup>2</sup> and Chuang Shi<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of imformation and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China, <sup>2</sup>University of Electronic Science and Technology of China, Chengdu,China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the systems for the task 1/subtask A of the DCASE 2021 challenge. In order to reduce the number of model parameters, we add the feature reuse units to the deep residual network. Also the one-bit-per-weight convolution layer are used in this paper. The log-mel spectrograms, delta features and delta-delta features are extracted to train the acoustic scene classification model. The HRTF and spectrum correction are used to augment the acoustic features. Our system achieves higher classification accuracies and lower log loss in the development dataset than baseline system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         HRTF,mixup,temporal cropping,spectrum correction; mixup,temporal cropping; mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies,deltas,delta-deltas; log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet; CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         1-bit quantization,FR_unit; 1-bit quantization; weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Liu2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Liu_62_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Liu2021label" class="modal fade" id="bibtex-Liu2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexLiu2021label">
        DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Liu2021,
    Author = "Liu, Yingzi and Liang, Jiangnan and Zhao, Luojun and Liu, Jia and Zhao, Kexin and Liu, Weiyu and Zhang, Long and Xu, Tanyue and Shi, Chuang",
    title = "{DCASE} 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes the systems for the task 1/subtask A of the DCASE 2021 challenge. In order to reduce the number of model parameters, we add the feature reuse units to the deep residual network. Also the one-bit-per-weight convolution layer are used in this paper. The log-mel spectrograms, delta features and delta-delta features are extracted to train the acoustic scene classification model. The HRTF and spectrum correction are used to augment the acoustic features. Our system achieves higher classification accuracies and lower log loss in the development dataset than baseline system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Madhu2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Madhu2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Wavelet Based Mel Scaled Representation for Low Complexity ASC with Multiple Devices
       </h4>
<p style="text-align:left">
        Aswathy Madhu<sup>1</sup> and Suresh K<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Electronics &amp; Communication, College of Engineering Trivandrum, Thiruvananthapuram, Kerala, India, <sup>2</sup>Electronics &amp; Communication, Govt. Engineering College, Barton Hill, Thiruvananthapuram, Kerala, India
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Madhu_CET_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Madhu2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Madhu2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Madhu2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Madhu_4_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Madhu2021" class="panel-collapse collapse" id="collapse-Madhu2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Wavelet Based Mel Scaled Representation for Low Complexity ASC with Multiple Devices
      </h4>
<p style="text-align:left">
<small>
        Aswathy Madhu<sup>1</sup> and Suresh K<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Electronics &amp; Communication, College of Engineering Trivandrum, Thiruvananthapuram, Kerala, India, <sup>2</sup>Electronics &amp; Communication, Govt. Engineering College, Barton Hill, Thiruvananthapuram, Kerala, India
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report presents our submission to the IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2021 for Task1 (Acoustic Scene Classification), subtask A (Low-Complexity Acoustic Scene Classification with Multiple Devices). The proposed system is a simple state-of-the- art approach employing wavelet based mel scaled representation for acoustic signals and a CNN classifier. We use data augmentation to handle device mismatch and post training quantization of network weights to enforce low complexity in terms of model size. The submitted system surpasses the baseline system utilizing CNN developed for this subtask.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         time stretching, pitch shifting, dynamic range compression, background noise, mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         wavelet based log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Madhu2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Madhu_4_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Madhu2021label" class="modal fade" id="bibtex-Madhu2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexMadhu2021label">
        Wavelet Based Mel Scaled Representation for Low Complexity ASC with Multiple Devices
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Madhu2021,
    Author = "Madhu, Aswathy and K, Suresh",
    title = "Wavelet Based Mel Scaled Representation for Low Complexity {ASC} with Multiple Devices",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report presents our submission to the IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2021 for Task1 (Acoustic Scene Classification), subtask A (Low-Complexity Acoustic Scene Classification with Multiple Devices). The proposed system is a simple state-of-the- art approach employing wavelet based mel scaled representation for acoustic signals and a CNN classifier. We use data augmentation to handle device mismatch and post training quantization of network weights to enforce low complexity in terms of model size. The submitted system surpasses the baseline system utilizing CNN developed for this subtask."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Naranjo-Alcazar2021_t1a" style="box-shadow: none">
<div class="panel-heading" id="heading-Naranjo-Alcazar2021_t1a" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Task 1A DCASE 2021: Acoustic Scene Classification with Mismatch-Devices Using Squeeze-Excitation Technique and Low-Complexity Constraint
       </h4>
<p style="text-align:left">
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>1</sup>, Maximo Cobos<sup>1</sup>, Francesc J. Ferri<sup>1</sup> and Pedro Zuccarello<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Computer Science, Universitat de Valencia, Burjassot, Spain, <sup>2</sup>Intituto Tecnológico de Informática, Valencia, Spain
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Naranjo-Alcazar_ITI_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Naranjo-Alcazar2021_t1a" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Naranjo-Alcazar2021_t1a" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Naranjo-Alcazar2021_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Naranjo-Alcazar_33_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Naranjo-Alcazar2021_t1a').collapse('show');window.location.hash='#Naranjo-Alcazar2021_t1a';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Naranjo-Alcazar2021_t1a" class="panel-collapse collapse" id="collapse-Naranjo-Alcazar2021_t1a" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Task 1A DCASE 2021: Acoustic Scene Classification with Mismatch-Devices Using Squeeze-Excitation Technique and Low-Complexity Constraint
      </h4>
<p style="text-align:left">
<small>
        Javier Naranjo-Alcazar<sup>1,2</sup>, Sergi Perez-Castanos<sup>1</sup>, Maximo Cobos<sup>1</sup>, Francesc J. Ferri<sup>1</sup> and Pedro Zuccarello<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Computer Science, Universitat de Valencia, Burjassot, Spain, <sup>2</sup>Intituto Tecnológico de Informática, Valencia, Spain
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Acoustic scene classification (ASC) is one of the most popular problems in the field of machine listening. The objective of this problem is to classify an audio clip into one of the predefined scenes using only the audio data. This problem has considerably progressed over the years in the different editions of DCASE. It usually has several subtasks that allow to tackle this problem with different approaches. The subtask presented in this report corresponds to a ASC problem that is constrained by the complexity of the model as well as having audio recorded from different devices, known as mismatch devices (real and simulated). The work presented in this report follows the research line carried out by the team in previous years. Specifically, a system based on two steps is proposed: a two-dimensional representation of the audio using the Gamamtone filter bank and a convolutional neural network using squeeze-excitation techniques. The presented system outperforms the baseline by about 17 percentage points.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         gammatone spectrogram
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, tflite, float16
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Naranjo-Alcazar2021_t1a" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Naranjo-Alcazar_33_t1a.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/Machine-Listeners-Valencia/DCASE2021-Task1" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Naranjo-Alcazar2021_t1alabel" class="modal fade" id="bibtex-Naranjo-Alcazar2021_t1a" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexNaranjo-Alcazar2021_t1alabel">
        Task 1A DCASE 2021: Acoustic Scene Classification with Mismatch-Devices Using Squeeze-Excitation Technique and Low-Complexity Constraint
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Naranjo-Alcazar2021_t1a,
    Author = "Naranjo-Alcazar, Javier and Perez-Castanos, Sergi and Cobos, Maximo and Ferri, Francesc J. and Zuccarello, Pedro",
    title = "Task {1A} {DCASE} 2021: Acoustic Scene Classification with Mismatch-Devices Using Squeeze-Excitation Technique and Low-Complexity Constraint",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "Acoustic scene classification (ASC) is one of the most popular problems in the field of machine listening. The objective of this problem is to classify an audio clip into one of the predefined scenes using only the audio data. This problem has considerably progressed over the years in the different editions of DCASE. It usually has several subtasks that allow to tackle this problem with different approaches. The subtask presented in this report corresponds to a ASC problem that is constrained by the complexity of the model as well as having audio recorded from different devices, known as mismatch devices (real and simulated). The work presented in this report follows the research line carried out by the team in previous years. Specifically, a system based on two steps is proposed: a two-dimensional representation of the audio using the Gamamtone filter bank and a convolutional neural network using squeeze-excitation techniques. The presented system outperforms the baseline by about 17 percentage points."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Pham2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Pham2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2021 Task 1A: Technique Report
       </h4>
<p style="text-align:left">
        Lam Pham<sup>1</sup>, Alexander Schindler<sup>1</sup>, Hieu Tang<sup>2</sup> and Truong Hoang<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>Center for Digital Safety &amp; Security, Austrian Institute of Technology, Vienna, Austria, <sup>2</sup>Department of Electronic and Electrical Engineering, Hongik University, Korea, <sup>3</sup>FPT company, Ho Chi Minh, Vietnam
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Pham_AIT_task1a_1</span> <span class="label label-primary">Pham_AIT_task1a_2</span> <span class="label label-primary">Pham_AIT_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Pham2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Pham2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Pham2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Pham_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Pham2021" class="panel-collapse collapse" id="collapse-Pham2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2021 Task 1A: Technique Report
      </h4>
<p style="text-align:left">
<small>
        Lam Pham<sup>1</sup>, Alexander Schindler<sup>1</sup>, Hieu Tang<sup>2</sup> and Truong Hoang<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>Center for Digital Safety &amp; Security, Austrian Institute of Technology, Vienna, Austria, <sup>2</sup>Department of Electronic and Electrical Engineering, Hongik University, Korea, <sup>3</sup>FPT company, Ho Chi Minh, Vietnam
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this report, we presents a low-complexity deep learning frameworks for acoustic scene classification (ASC). The proposed framework can be separated into three main steps: Front-end spectrogram extraction, back-end classification, and late fusion of predicted probabilities. In the first step, we use Mel filter, Gammatone filter and Constant Q Transform (CQT) to transform draw audio signal into spectrograms. Three spectrograms are then feed into three individual back- end convolutional neural networks (CNNs) for classification. Finally, a late fusion of three predicted probabilities obtained from three CNNs is conducted to achieve the final classification result. To reduce the complexity of CNN network architecture proposed, we apply two model compression techniques: model restriction and decomposed convolution. Our experiments, which are conducted on DCASE 2021 Task 1A development dataset, achieve a low-complexity CNN based framework with 128 KB trainable parameters and the best classification accuracy of 66.7%, improving DCASE baseline by 19.0%.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         CQT, Gammatonegram, log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         PROD late fusion
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         channel restriction and decomposed convolution
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Pham2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Pham_5_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Pham2021label" class="modal fade" id="bibtex-Pham2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPham2021label">
        DCASE 2021 Task 1A: Technique Report
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Pham2021,
    Author = "Pham, Lam and Schindler, Alexander and Tang, Hieu and Hoang, Truong",
    title = "{DCASE} 2021 Task {1A}: Technique Report",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "In this report, we presents a low-complexity deep learning frameworks for acoustic scene classification (ASC). The proposed framework can be separated into three main steps: Front-end spectrogram extraction, back-end classification, and late fusion of predicted probabilities. In the first step, we use Mel filter, Gammatone filter and Constant Q Transform (CQT) to transform draw audio signal into spectrograms. Three spectrograms are then feed into three individual back- end convolutional neural networks (CNNs) for classification. Finally, a late fusion of three predicted probabilities obtained from three CNNs is conducted to achieve the final classification result. To reduce the complexity of CNN network architecture proposed, we apply two model compression techniques: model restriction and decomposed convolution. Our experiments, which are conducted on DCASE 2021 Task 1A development dataset, achieve a low-complexity CNN based framework with 128 KB trainable parameters and the best classification accuracy of 66.7\%, improving DCASE baseline by 19.0\%."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Phan2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Phan2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Duc Phan and Douglas Jones
       </p>
<p style="text-align:left">
<em>
         ECE, University of Illinois, Urban-Champaign, Illinois, US
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Phan_UIUC_task1a_1</span> <span class="label label-primary">Phan_UIUC_task1a_2</span> <span class="label label-primary">Phan_UIUC_task1a_3</span> <span class="label label-primary">Phan_UIUC_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Phan2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Phan2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Phan2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Phan_86_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Phan2021" class="panel-collapse collapse" id="collapse-Phan2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Duc Phan and Douglas Jones
       </small>
<br/>
<small>
<em>
         ECE, University of Illinois, Urban-Champaign, Illinois, US
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       Decomposing 2D convolution into time and frequency separable 1D convolutions produces a low-complexity neural network with good performance for acoustic scene classification. The final proposed network has roughly 41K parameters with a size of 75KB. It significantly outperforms the DCASE 2021 baseline network [1], with an accuracy of 64 percent on the development dataset[2].
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, depthwise separable convolutions
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Phan2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Phan_86_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Phan2021label" class="modal fade" id="bibtex-Phan2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPhan2021label">
        DCASE 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Phan2021,
    Author = "Phan, Duc and Jones, Douglas",
    title = "{DCASE} 2021 Task 1 Subtask A: Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "Decomposing 2D convolution into time and frequency separable 1D convolutions produces a low-complexity neural network with good performance for acoustic scene classification. The final proposed network has roughly 41K parameters with a size of 75KB. It significantly outperforms the DCASE 2021 baseline network [1], with an accuracy of 64 percent on the development dataset[2]."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Puy2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Puy2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Separable Convolutions and Test-Time Augmentations for Low-Complexity and Calibrated Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Gilles Puy, Himalaya Jain and Andrei Bursuc
       </p>
<p style="text-align:left">
<em>
         valeo.ai, Paris, France
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Puy_VAI_task1a_1</span> <span class="label label-primary">Puy_VAI_task1a_2</span> <span class="label label-primary">Puy_VAI_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Puy2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Puy2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Puy2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Puy_90_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Puy2021').collapse('show');window.location.hash='#Puy2021';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Puy2021" class="panel-collapse collapse" id="collapse-Puy2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Separable Convolutions and Test-Time Augmentations for Low-Complexity and Calibrated Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Gilles Puy, Himalaya Jain and Andrei Bursuc
       </small>
<br/>
<small>
<em>
         valeo.ai, Paris, France
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report details the architecture we used to address Task 1a of the of DCASE2021 challenge. Our architecture is based on 4 layer convolutional neural network taking as input a log-mel spectrogram. The complexity of this network is controlled by using separable convolutions in the channel, time and frequency dimensions. We train different models to investigate the benefit of mixup, focal loss and test time augmentations in improving the performance of the system.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment; SpecAugment, mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Puy2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Puy_90_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/valeoai/SP4ASC" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Puy2021label" class="modal fade" id="bibtex-Puy2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexPuy2021label">
        Separable Convolutions and Test-Time Augmentations for Low-Complexity and Calibrated Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Puy2021,
    Author = "Puy, Gilles and Jain, Himalaya and Bursuc, Andrei",
    title = "Separable Convolutions and Test-Time Augmentations for Low-Complexity and Calibrated Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This report details the architecture we used to address Task 1a of the of DCASE2021 challenge. Our architecture is based on 4 layer convolutional neural network taking as input a log-mel spectrogram. The complexity of this network is controlled by using separable convolutions in the channel, time and frequency dimensions. We train different models to investigate the benefit of mixup, focal loss and test time augmentations in improving the performance of the system."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Qiao2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Qiao2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Acoustic Scene Classification Model Based on Two Parallel Residual Networks
       </h4>
<p style="text-align:left">
        Ziling Qiao, Hongxia Dong, Xichang Cai and Menglong Wu
       </p>
<p style="text-align:left">
<em>
         Electronic and Communication Engineering, North China University of Technology, Beijing, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Qiao_NCUT_task1a_1</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Qiao2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Qiao2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Qiao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Qiao_19_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Qiao2021" class="panel-collapse collapse" id="collapse-Qiao2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Acoustic Scene Classification Model Based on Two Parallel Residual Networks
      </h4>
<p style="text-align:left">
<small>
        Ziling Qiao, Hongxia Dong, Xichang Cai and Menglong Wu
       </small>
<br/>
<small>
<em>
         Electronic and Communication Engineering, North China University of Technology, Beijing, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for task1a of dcase2021 challenge. We calculated 128 log-mel energies under the original sampling rate of 44.1KHz for each time slice by taking 2048 FFT points with 50% overlap. Additionally, deltas and delta- deltas were calculated from the log Mel spectrogram and stacked into the channel axis. The resulting spectrograms were of size 128 frequency bins, 423 time samples and 3 channels with each representing log-mel spectrograms, its delta features and its delta-delta features respectively. Then, the three channel feature map is divided into 0-64 and 64-128 Mel bins on the frequency axis, and the high and low frequency features are input into the two parallel residual networks with identical residual blocks and convolutional residual blocks for training, and then the two network models are concatenate on the channel axis. Finally, after 1 ×1 convolution and global average pooling, the classification results are obtained through softmax output.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Qiao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Qiao_19_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Qiao2021label" class="modal fade" id="bibtex-Qiao2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexQiao2021label">
        Acoustic Scene Classification Model Based on Two Parallel Residual Networks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Qiao2021,
    Author = "Qiao, Ziling and Dong, Hongxia and Cai, Xichang and Wu, Menglong",
    title = "Acoustic Scene Classification Model Based on Two Parallel Residual Networks",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our submission for task1a of dcase2021 challenge. We calculated 128 log-mel energies under the original sampling rate of 44.1KHz for each time slice by taking 2048 FFT points with 50\% overlap. Additionally, deltas and delta- deltas were calculated from the log Mel spectrogram and stacked into the channel axis. The resulting spectrograms were of size 128 frequency bins, 423 time samples and 3 channels with each representing log-mel spectrograms, its delta features and its delta-delta features respectively. Then, the three channel feature map is divided into 0-64 and 64-128 Mel bins on the frequency axis, and the high and low frequency features are input into the two parallel residual networks with identical residual blocks and convolutional residual blocks for training, and then the two network models are concatenate on the channel axis. Finally, after 1 ×1 convolution and global average pooling, the classification results are obtained through softmax output."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Seo2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Seo2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Mobilenet Using Coordinate Attention and Fusions for Low-Complexity Acoustic Scene Classification with Multiple Devices
       </h4>
<p style="text-align:left">
        Soonshin Seo and Ji-Hwan Kim
       </p>
<p style="text-align:left">
<em>
         Dept. of Computer Science and Engineering, Sogang University, Seoul, Repulic of Korea
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Seo_SGU_task1a_1</span> <span class="label label-primary">Seo_SGU_task1a_2</span> <span class="label label-primary">Seo_SGU_task1a_3</span> <span class="label label-primary">Seo_SGU_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Seo2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Seo2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Seo2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Seo_52_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Seo2021').collapse('show');window.location.hash='#Seo2021';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Seo2021" class="panel-collapse collapse" id="collapse-Seo2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Mobilenet Using Coordinate Attention and Fusions for Low-Complexity Acoustic Scene Classification with Multiple Devices
      </h4>
<p style="text-align:left">
<small>
        Soonshin Seo and Ji-Hwan Kim
       </small>
<br/>
<small>
<em>
         Dept. of Computer Science and Engineering, Sogang University, Seoul, Repulic of Korea
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       In this technical report, we describe our acoustic scene classification methods submitted to detection and classification of acoustic scenes and events challenge 2021 task 1a. We extracted the log- Mel filter bank features with delta and delta-delta from the acoustic signals and applied normalization. A total of 6 data augmentations were applied as follows: mixup, spectrum augmentation, spectrum correction, pitch shift, speed change, and mix audios. In addition, we designed MobileNet using coordinate attention and fusions. Inspired by MobileNetV2, inverted residuals and linear bottlenecks are adapted for mobile blocks of the proposed MobileNet. We applied coordinate attention and early/late fusion methods after mobile blocks. In addition, we reduced the model size by applying weight quantization to the trained model. Experiments were conducted on the cross-validation setup of the official development set. We confirmed that our model achieved a log- loss of 1.040 and an accuracy of 72.6% within the 128 KB model size.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, spectrum augmentation, spectrum correction, pitch shifting, speed change, mix audios
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MobileNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Seo2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Seo_52_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/sunshines14/DCASE2021" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Seo2021label" class="modal fade" id="bibtex-Seo2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSeo2021label">
        Mobilenet Using Coordinate Attention and Fusions for Low-Complexity Acoustic Scene Classification with Multiple Devices
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Seo2021,
    Author = "Seo, Soonshin and Kim, Ji-Hwan",
    title = "Mobilenet Using Coordinate Attention and Fusions for Low-Complexity Acoustic Scene Classification with Multiple Devices",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "In this technical report, we describe our acoustic scene classification methods submitted to detection and classification of acoustic scenes and events challenge 2021 task 1a. We extracted the log- Mel filter bank features with delta and delta-delta from the acoustic signals and applied normalization. A total of 6 data augmentations were applied as follows: mixup, spectrum augmentation, spectrum correction, pitch shift, speed change, and mix audios. In addition, we designed MobileNet using coordinate attention and fusions. Inspired by MobileNetV2, inverted residuals and linear bottlenecks are adapted for mobile blocks of the proposed MobileNet. We applied coordinate attention and early/late fusion methods after mobile blocks. In addition, we reduced the model size by applying weight quantization to the trained model. Experiments were conducted on the cross-validation setup of the official development set. We confirmed that our model achieved a log- loss of 1.040 and an accuracy of 72.6\% within the 128 KB model size."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Singh2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Singh2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Pruning and Quantization for Low-Complexity Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Arshdeep Singh<sup>1</sup>, Dhanunjaya Varma Devalraju<sup>2</sup> and Padmanabhan Rajan<sup>2</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>SCEE, Indian institute of technology, Mandi, Mandi, India, <sup>2</sup>School of Computing and Electrical engineering, Indian institute of technology, Mandi, Mandi, India
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Singh_IITMandi_task1a_1</span> <span class="label label-primary">Singh_IITMandi_task1a_2</span> <span class="label label-primary">Singh_IITMandi_task1a_3</span> <span class="label label-primary">Singh_IITMandi_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Singh2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Singh2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Singh2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Singh_7_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
<a class="btn btn-xs btn-success" data-placement="bottom" href="" onclick="$('#collapse-Singh2021').collapse('show');window.location.hash='#Singh2021';return false;" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Source code">
<i class="fa fa-file-code-o">
</i>
         Code
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Singh2021" class="panel-collapse collapse" id="collapse-Singh2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Pruning and Quantization for Low-Complexity Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Arshdeep Singh<sup>1</sup>, Dhanunjaya Varma Devalraju<sup>2</sup> and Padmanabhan Rajan<sup>2</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>SCEE, Indian institute of technology, Mandi, Mandi, India, <sup>2</sup>School of Computing and Electrical engineering, Indian institute of technology, Mandi, Mandi, India
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes the IITMandi AudioTeam’s submission for DCASE 2021 ASC Task 1, Subtask Low-Complexity Acoustic Scene Classification with Multiple Devices. This report aims to design low-complexity systems for acoustic scene classification by eliminating filters in a pre-trained convolution neural network. A filter pruning strategy is opted, which consists of three steps. Step 1 aims to identify the redundant filters which have low- norm. Step 2 explicitly removes the redundant filters and their connecting feature maps from the unpruned network to give a pruned network. Step 3 involves fine-tuning of the pruned network to regain performance. Further, the trained parameters are quantized to 16- bit. On DCASE-2021 task 1A development dataset, the proposed framework reduces 68% parameters with competitive performance
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         Filter pruning and quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Singh2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Singh_7_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
<a class="btn btn-sm btn-success" href="https://github.com/Arshdeep-Singh-Boparai/DCASE2021_codes.git" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Source code">
<i class="fa fa-file-code-o">
</i>
        Source code
       </a>
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Singh2021label" class="modal fade" id="bibtex-Singh2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSingh2021label">
        Pruning and Quantization for Low-Complexity Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Singh2021,
    Author = "Singh, Arshdeep and Devalraju, Dhanunjaya Varma and Rajan, Padmanabhan",
    title = "Pruning and Quantization for Low-Complexity Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes the IITMandi AudioTeam’s submission for DCASE 2021 ASC Task 1, Subtask Low-Complexity Acoustic Scene Classification with Multiple Devices. This report aims to design low-complexity systems for acoustic scene classification by eliminating filters in a pre-trained convolution neural network. A filter pruning strategy is opted, which consists of three steps. Step 1 aims to identify the redundant filters which have low- norm. Step 2 explicitly removes the redundant filters and their connecting feature maps from the unpruned network to give a pruned network. Step 3 involves fine-tuning of the pruned network to regain performance. Further, the trained parameters are quantized to 16- bit. On DCASE-2021 task 1A development dataset, the proposed framework reduces 68\% parameters with competitive performance"
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Sugahara2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Sugahara2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Ensemble of Simple Resnets with Various Mel-Spectrum Time-Frequency Resolutions for Acoustic Scene Classifications
       </h4>
<p style="text-align:left">
        Reiko Sugahara, Masatoshi Osawa and Ryo Sato
       </p>
<p style="text-align:left">
<em>
         RION CO., LTD., Tokyo, Japan
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Sugahara_RION_task1a_1</span> <span class="label label-primary">Sugahara_RION_task1a_2</span> <span class="label label-primary">Sugahara_RION_task1a_3</span> <span class="label label-primary">Sugahara_RION_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Sugahara2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Sugahara2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Sugahara2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Sugahara_108_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Sugahara2021" class="panel-collapse collapse" id="collapse-Sugahara2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Ensemble of Simple Resnets with Various Mel-Spectrum Time-Frequency Resolutions for Acoustic Scene Classifications
      </h4>
<p style="text-align:left">
<small>
        Reiko Sugahara, Masatoshi Osawa and Ryo Sato
       </small>
<br/>
<small>
<em>
         RION CO., LTD., Tokyo, Japan
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes procedure for Task 1A in DCASE 2021[1][2]. Our method adopts ResNet-based models with a mel spectrogram as input. The accuracy was improved by the ensemble of ResNet-based simple models with various mel-spectrum time- frequency resolution. Data augmentations such as mixup, SpecAugment, time-shifting, and spectrum modulate were applied to prevent overfitting. The size of the model was reduced by quantization and pruning. Accordingly, the accuracy of our system was achieved 70.1% with 95 KB for the development set.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, SpecAugment, time-shifting, spectrum modulation
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel powers
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet, ensemble
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         weighted score average; score average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, pruning
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Sugahara2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Sugahara_108_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Sugahara2021label" class="modal fade" id="bibtex-Sugahara2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexSugahara2021label">
        Ensemble of Simple Resnets with Various Mel-Spectrum Time-Frequency Resolutions for Acoustic Scene Classifications
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Sugahara2021,
    Author = "Sugahara, Reiko and Osawa, Masatoshi and Sato, Ryo",
    title = "Ensemble of Simple Resnets with Various Mel-Spectrum Time-Frequency Resolutions for Acoustic Scene Classifications",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes procedure for Task 1A in DCASE 2021[1][2]. Our method adopts ResNet-based models with a mel spectrogram as input. The accuracy was improved by the ensemble of ResNet-based simple models with various mel-spectrum time- frequency resolution. Data augmentations such as mixup, SpecAugment, time-shifting, and spectrum modulate were applied to prevent overfitting. The size of the model was reduced by quantization and pruning. Accordingly, the accuracy of our system was achieved 70.1\% with 95 KB for the development set."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Verbitskiy2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Verbitskiy2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification Using Mobile Inverted Bottleneck Blocks
       </h4>
<p style="text-align:left">
        Sergey Verbitskiy and Viacheslav Vyshegorodtsev
       </p>
<p style="text-align:left">
<em>
         Deepsound, Novosibirsk, Russia
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Verbitskiy_DS_task1a_1</span> <span class="label label-primary">Verbitskiy_DS_task1a_2</span> <span class="label label-primary">Verbitskiy_DS_task1a_3</span> <span class="label label-primary">Verbitskiy_DS_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Verbitskiy2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Verbitskiy2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Verbitskiy2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Verbitskiy_20_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Verbitskiy2021" class="panel-collapse collapse" id="collapse-Verbitskiy2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification Using Mobile Inverted Bottleneck Blocks
      </h4>
<p style="text-align:left">
<small>
        Sergey Verbitskiy and Viacheslav Vyshegorodtsev
       </small>
<br/>
<small>
<em>
         Deepsound, Novosibirsk, Russia
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our approaches for Task 1A (Low- Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 Challenge. We propose a new architecture with mobile inverted bottleneck blocks (Fused-MBConv and MBConv) for acoustic scene classification tasks. This architecture is based on EfficientNetV2. Our models have a very small number of parameters. We also use several data augmentation techniques during the training of models. Our best model has 62,346 non-zero parameters and achieves a classification macro-average accuracy of 70.5% and an average multiclass cross-entropy (log loss) of 0.848 on the development dataset. The resulting model size is 121.8 KB (the model parameters are quantized to float16 after the training).
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, temporal cropping, SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN, EfficientNetV2
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Verbitskiy2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Verbitskiy_20_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Verbitskiy2021label" class="modal fade" id="bibtex-Verbitskiy2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexVerbitskiy2021label">
        Low-Complexity Acoustic Scene Classification Using Mobile Inverted Bottleneck Blocks
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Verbitskiy2021,
    Author = "Verbitskiy, Sergey and Vyshegorodtsev, Viacheslav",
    title = "Low-Complexity Acoustic Scene Classification Using Mobile Inverted Bottleneck Blocks",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our approaches for Task 1A (Low- Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 Challenge. We propose a new architecture with mobile inverted bottleneck blocks (Fused-MBConv and MBConv) for acoustic scene classification tasks. This architecture is based on EfficientNetV2. Our models have a very small number of parameters. We also use several data augmentation techniques during the training of models. Our best model has 62,346 non-zero parameters and achieves a classification macro-average accuracy of 70.5\% and an average multiclass cross-entropy (log loss) of 0.848 on the development dataset. The resulting model size is 121.8 KB (the model parameters are quantized to float16 after the training)."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Yang2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Yang2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification
       </h4>
<p style="text-align:left">
        Chao-Han Huck Yang<sup>1</sup>, Hu Hu<sup>1</sup>, Sabato Marco Siniscalchi<sup>2</sup>, Qing Wang<sup>3</sup>, Wang Yuyang<sup>3</sup>, Xianjun Xia<sup>4</sup>, Yuanjun Zhao<sup>4</sup>, Yuzhong Wu<sup>4</sup>, Yannan Wang<sup>4</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA, <sup>2</sup>Kore University of Enna, Italy, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Shenzhen, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Yang_GT_task1a_1</span> <span class="label label-primary">Yang_GT_task1a_2</span> <span class="label label-primary">Yang_GT_task1a_3</span> <span class="label label-primary">Yang_GT_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Yang2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Yang2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Yang2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Yang_124_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Yang2021" class="panel-collapse collapse" id="collapse-Yang2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification
      </h4>
<p style="text-align:left">
<small>
        Chao-Han Huck Yang<sup>1</sup>, Hu Hu<sup>1</sup>, Sabato Marco Siniscalchi<sup>2</sup>, Qing Wang<sup>3</sup>, Wang Yuyang<sup>3</sup>, Xianjun Xia<sup>4</sup>, Yuanjun Zhao<sup>4</sup>, Yuzhong Wu<sup>4</sup>, Yannan Wang<sup>4</sup>, Jun Du<sup>3</sup> and Chin-Hui Lee<sup>1</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA, <sup>2</sup>Kore University of Enna, Italy, <sup>3</sup>University of Science and Technology of China, HeFei, China, <sup>4</sup>Tencent Media Lab, Shenzhen, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       We propose a novel neural model compression strategy combining data augmentation, knowledge transfer, pruning, and quantization for device-robust acoustic scene classification (ASC). Specifically, we tackle the ASC task in a low-resource environment leveraging a recently proposed advanced neural network pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a sub-network neural model associated with a small amount non-zero model parameters. The effectiveness of LTH for low-complexity acoustic modeling is assessed by investigating various data augmentation and compression schemes, and we report an efficient joint framework for low-complexity multi-device ASC, called Acoustic Lottery. Acoustic Lottery could compress an ASC model up to 1/104 and attain a superior performance (validation accuracy of 74.01% and Log loss of 0.76) compared to its not compressed seed model. All results reported in this work are based on a joint effort of four groups, namely GT-USTC-UKE-Tencent, aiming to address the 'Low-Complexity Acoustic Scene Classification (ASC) with Multiple Devices' in the DCASE 2021 Challenge Task 1a.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, random cropping, channel confusion, SpecAugment, spectrum correction, reverberation-drc, pitch shifting, speed change, random noise, mix audios
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         Inception
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization, LTH pruning, teacher-student learning
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Yang2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Yang_124_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Yang2021label" class="modal fade" id="bibtex-Yang2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexYang2021label">
        A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Yang2021,
    Author = "Yang, Chao-Han Huck and Hu, Hu and Siniscalchi, Sabato Marco and Wang, Qing and Yuyang, Wang and Xia, Xianjun and Zhao, Yuanjun and Wu, Yuzhong and Wang, Yannan and Du, Jun and Lee, Chin-Hui",
    title = "A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "We propose a novel neural model compression strategy combining data augmentation, knowledge transfer, pruning, and quantization for device-robust acoustic scene classification (ASC). Specifically, we tackle the ASC task in a low-resource environment leveraging a recently proposed advanced neural network pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a sub-network neural model associated with a small amount non-zero model parameters. The effectiveness of LTH for low-complexity acoustic modeling is assessed by investigating various data augmentation and compression schemes, and we report an efficient joint framework for low-complexity multi-device ASC, called Acoustic Lottery. Acoustic Lottery could compress an ASC model up to 1/104 and attain a superior performance (validation accuracy of 74.01\% and Log loss of 0.76) compared to its not compressed seed model. All results reported in this work are based on a joint effort of four groups, namely GT-USTC-UKE-Tencent, aiming to address the 'Low-Complexity Acoustic Scene Classification (ASC) with Multiple Devices' in the DCASE 2021 Challenge Task 1a."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Yihao2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Yihao2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification with Multiple Devices
       </h4>
<p style="text-align:left">
        Chen Yihao, Liu Min and Xu Minqiang
       </p>
<p style="text-align:left">
<em>
         SpeakIn Technology, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Yihao_speakin_task1a_1</span> <span class="label label-primary">Yihao_speakin_task1a_2</span> <span class="label label-primary">Yihao_speakin_task1a_3</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Yihao2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Yihao2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Yihao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Yihao_71_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Yihao2021" class="panel-collapse collapse" id="collapse-Yihao2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification with Multiple Devices
      </h4>
<p style="text-align:left">
<small>
        Chen Yihao, Liu Min and Xu Minqiang
       </small>
<br/>
<small>
<em>
         SpeakIn Technology, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our submission to the Task1 Acoustic Scene Classification in the Dcase 2021 challenge. Final submission includes 4 results based on ResNet and SEResNet architectures. We perform several analysis of different backbones and also do experiments to confirm whether the pooling layer is needed. Due to the lack of training data, we try a variety of data enhancement methods including specaugment[1], cutout[2], audio acceleration and deceleration. To meet the requirement of model size, we also do pruning to the models.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         16kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         SpecAugment
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         CNN
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         sparsity
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Yihao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Yihao_71_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Yihao2021label" class="modal fade" id="bibtex-Yihao2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexYihao2021label">
        Low-Complexity Acoustic Scene Classification with Multiple Devices
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Yihao2021,
    Author = "Yihao, Chen and Min, Liu and Minqiang, Xu",
    title = "Low-Complexity Acoustic Scene Classification with Multiple Devices",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This report describes our submission to the Task1 Acoustic Scene Classification in the Dcase 2021 challenge. Final submission includes 4 results based on ResNet and SEResNet architectures. We perform several analysis of different backbones and also do experiments to confirm whether the pooling layer is needed. Due to the lack of training data, we try a variety of data enhancement methods including specaugment[1], cutout[2], audio acceleration and deceleration. To meet the requirement of model size, we also do pruning to the models."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zhang2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Zhang2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        DCASE 2021 Challenge Task1a Technical Report
       </h4>
<p style="text-align:left">
        Jiawang Zhang<sup>1</sup>, Shengchen Li<sup>2</sup> and Bilei Zhu<sup>3</sup>
</p>
<p style="text-align:left">
<em>
<sup>1</sup>AI-Lab Speech &amp; Audio Team, Beijing University of Posts and Telecommunications &amp; ByteDance, Shanghai, China, <sup>2</sup>Xi’an Jiaotong-liverpool University, Suzhou, China, <sup>3</sup>AI-Lab Speech &amp; Audio Team, ByteDance, Shanghai, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Zhang_BUPT&amp;BYTEDANCE_task1a_1</span> <span class="label label-primary">Zhang_BUPT&amp;BYTEDANCE_task1a_2</span> <span class="label label-primary">Zhang_BUPT&amp;BYTEDANCE_task1a_3</span> <span class="label label-primary">Zhang_BUPT&amp;BYTEDANCE_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zhang2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zhang2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zhang2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Zhang_99_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zhang2021" class="panel-collapse collapse" id="collapse-Zhang2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       DCASE 2021 Challenge Task1a Technical Report
      </h4>
<p style="text-align:left">
<small>
        Jiawang Zhang<sup>1</sup>, Shengchen Li<sup>2</sup> and Bilei Zhu<sup>3</sup>
</small>
<br/>
<small>
<em>
<sup>1</sup>AI-Lab Speech &amp; Audio Team, Beijing University of Posts and Telecommunications &amp; ByteDance, Shanghai, China, <sup>2</sup>Xi’an Jiaotong-liverpool University, Suzhou, China, <sup>3</sup>AI-Lab Speech &amp; Audio Team, ByteDance, Shanghai, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This report describes our method for Task 1a (Low-Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 challenge. The task targets low complexity solutions for the classification problem. This report uses Residual Network (ResNet) model and uses Log Mel Spectrogram to process features. To compress system complexity, this report uses Post Training Static Quantization. Post Training Static Quantization are used to do the 8-bits quantization, this method can reduce the model size by four times. The accuracy of the method proposed in this report on the development data set is 73%, which is 25% higher than the baseline.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         ResNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zhang2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Zhang_99_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zhang2021label" class="modal fade" id="bibtex-Zhang2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZhang2021label">
        DCASE 2021 Challenge Task1a Technical Report
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zhang2021,
    Author = "Zhang, Jiawang and Li, Shengchen and Zhu, Bilei",
    title = "{DCASE} 2021 Challenge Task1a Technical Report",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This report describes our method for Task 1a (Low-Complexity Acoustic Scene Classification with Multiple Devices) of the DCASE 2021 challenge. The task targets low complexity solutions for the classification problem. This report uses Residual Network (ResNet) model and uses Log Mel Spectrogram to process features. To compress system complexity, this report uses Post Training Static Quantization. Post Training Static Quantization are used to do the 8-bits quantization, this method can reduce the model size by four times. The accuracy of the method proposed in this report on the development data set is 73\%, which is 25\% higher than the baseline."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
<div class="panel publication-item" id="Zhao2021" style="box-shadow: none">
<div class="panel-heading" id="heading-Zhao2021" role="tab">
<div class="row">
<div class="col-xs-9">
<h4>
        Low-Complexity Acoustic Scene Classification Using Knowledge Distillation and Multiple Classifiers
       </h4>
<p style="text-align:left">
        Na Zhao
       </p>
<p style="text-align:left">
<em>
         Algorithm, Maxvision, Wuhan, China
        </em>
</p>
<p style="text-align:left">
<span class="label label-primary">Zhao_Maxvision_task1a_1</span> <span class="label label-primary">Zhao_Maxvision_task1a_2</span> <span class="label label-primary">Zhao_Maxvision_task1a_3</span> <span class="label label-primary">Zhao_Maxvision_task1a_4</span> <span class="clearfix"></span>
</p>
<p style="text-align:left">
</p>
<button aria-controls="collapse-Zhao2021" aria-expanded="true" class="btn btn-default btn-xs" data-parent="#accordion" data-toggle="collapse" href="#collapse-Zhao2021" type="button">
<i class="fa fa-caret-down">
</i>
        Details...
       </button>
</div>
<div class="col-xs-3">
<div class="btn-group">
<button class="btn btn-xs btn-danger" data-target="#bibtex-Zhao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
         Bibtex
        </button>
<a class="btn btn-xs btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Zhao_55_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:2px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
         PDF
        </a>
</div>
</div>
</div>
</div>
<div aria-labelledby="heading-Zhao2021" class="panel-collapse collapse" id="collapse-Zhao2021" role="tabpanel">
<div class="panel-body well well-sm">
<h4>
       Low-Complexity Acoustic Scene Classification Using Knowledge Distillation and Multiple Classifiers
      </h4>
<p style="text-align:left">
<small>
        Na Zhao
       </small>
<br/>
<small>
<em>
         Algorithm, Maxvision, Wuhan, China
        </em>
</small>
</p>
<h5>
<strong>
        Abstract
       </strong>
</h5>
<p class="text-justify">
       This technical report describes our submission for Task1a of DCASE2021 challenge. Based on the small-size Mobnet[1] of Tencent team in Dcase2020 task1b, we build our baseline model with only one frequency branch and two classifiers. The two classifiers are ten-class classifier and three-class classifier respectively, and they jointly optimize the baseline model. Due to the limitation of model size, we first train a high-accuracy large- size model, and then use distillation method to transfer the knowledge from the large-size model to our baseline model. The final system is quantified from 32-bit float-point to 16-bit float- point.We achieved an accuracy of 59.9% with a model size smaller than 128KB.
      </p>
<h5>
<strong>
        System characteristics
       </strong>
</h5>
<table class="table table-condensed">
<tr>
<td class="col-md-3">
         Sampling rate
        </td>
<td>
         44.1kHz
        </td>
</tr>
<tr>
<td class="col-md-3">
         Data augmentation
        </td>
<td>
         mixup, random cropping
        </td>
</tr>
<tr>
<td class="col-md-3">
         Features
        </td>
<td>
         log-mel energies, deltas, delta-deltas
        </td>
</tr>
<tr>
<td class="col-md-3">
         Classifier
        </td>
<td>
         MobileNet
        </td>
</tr>
<tr>
<td class="col-md-3">
         Decision making
        </td>
<td>
         model weights average
        </td>
</tr>
<tr>
<td class="col-md-3">
         Complexity management
        </td>
<td>
         weight quantization
        </td>
</tr>
</table>
<div class="btn-group">
<button class="btn btn-sm btn-danger" data-target="#bibtex-Zhao2021" data-toggle="modal" type="button">
<i class="fa fa-file-text-o">
</i>
        Bibtex
       </button>
<a class="btn btn-sm btn-warning" data-placement="bottom" href="../documents/challenge2021/technical_reports/DCASE2021_Zhao_55_t1.pdf" rel="tooltip" style="text-decoration:none;border-bottom:0;padding-bottom:6px" title="Download pdf">
<i class="fa fa-file-pdf-o fa-1x">
</i>
        PDF
       </a>
</div>
<div class="btn-group">
</div>
</div>
</div>
</div>
<!-- Modal -->
<div aria-hidden="true" aria-labelledby="bibtex-Zhao2021label" class="modal fade" id="bibtex-Zhao2021" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">
         ×
        </span>
<span class="sr-only">
         Close
        </span>
</button>
<h4 class="modal-title" id="bibtexZhao2021label">
        Low-Complexity Acoustic Scene Classification Using Knowledge Distillation and Multiple Classifiers
       </h4>
</div>
<div class="modal-body">
<pre>@techreport{Zhao2021,
    Author = "Zhao, Na",
    title = "Low-Complexity Acoustic Scene Classification Using Knowledge Distillation and Multiple Classifiers",
    institution = "DCASE2021 Challenge",
    year = "2021",
    month = "June",
    abstract = "This technical report describes our submission for Task1a of DCASE2021 challenge. Based on the small-size Mobnet[1] of Tencent team in Dcase2020 task1b, we build our baseline model with only one frequency branch and two classifiers. The two classifiers are ten-class classifier and three-class classifier respectively, and they jointly optimize the baseline model. Due to the limitation of model size, we first train a high-accuracy large- size model, and then use distillation method to transfer the knowledge from the large-size model to our baseline model. The final system is quantified from 32-bit float-point to 16-bit float- point.We achieved an accuracy of 59.9\% with a model size smaller than 128KB."
}
</pre>
</div>
<div class="modal-footer">
<button class="btn btn-default" data-dismiss="modal" type="button">
        Close
       </button>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p><br/></p>
<script>
(function($) {
    $(document).ready(function() {
        var hash = window.location.hash.substr(1);
        var anchor = window.location.hash;

        var shiftWindow = function() {
            var hash = window.location.hash.substr(1);
            if($('#collapse-'+hash).length){
                scrollBy(0, -100);
            }
        };
        window.addEventListener("hashchange", shiftWindow);

        if (window.location.hash){
            window.scrollTo(0, 0);
            history.replaceState(null, document.title, "#");
            $('#collapse-'+hash).collapse('show');
            setTimeout(function(){
                window.location.hash = anchor;
                shiftWindow();
            }, 2000);
        }
    });
})(jQuery);
</script>
                </div>
            </section>
        </div>
    </div>
</div>    
<br><br>
<ul class="nav pull-right scroll-top">
  <li>
    <a title="Scroll to top" href="#" class="page-scroll-top">
      <i class="glyphicon glyphicon-chevron-up"></i>
    </a>
  </li>
</ul><script type="text/javascript" src="/theme/assets/jquery/jquery.easing.min.js"></script>
<script type="text/javascript" src="/theme/assets/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/theme/assets/scrollreveal/scrollreveal.min.js"></script>
<script type="text/javascript" src="/theme/js/setup.scrollreveal.js"></script>
<script type="text/javascript" src="/theme/assets/highlight/highlight.pack.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre code:not([class])').forEach(function($) {$.className = 'no-highlight';});
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" src="/theme/js/respond.min.js"></script>
<script type="text/javascript" src="/theme/js/btex.min.js"></script>
<script type="text/javascript" src="/theme/js/datatable.bundle.min.js"></script>
<script type="text/javascript" src="/theme/js/btoc.min.js"></script>
<script type="text/javascript" src="/theme/js/theme.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114253890-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-114253890-1');
</script>
</body>
</html>